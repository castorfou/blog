[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "blog",
    "section": "",
    "text": "Update jupyter lab to v4\n\n\n\n\n\n\n\njupyter\n\n\nplotly\n\n\n\n\nand perform all unit tests with tqdm, ipywidget, plotly and everything\n\n\n\n\n\n\nOct 5, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for October 23\n\n\n\n\n\n\n\nlogbook\n\n\nwsl\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nOpen Interpreter\n\n\n\n\n\n\n\nllm\n\n\nubuntu\n\n\n\n\nan open-source Code Interpreter that runs locally. Summarize PDFs, visualize datasets, and control your browser — all from a ChatGPT-like interface in your terminal.\n\n\n\n\n\n\nSep 13, 2023\n\n\n\n\n\n\n  \n\n\n\n\nWSL no space left\n\n\n\n\n\n\n\nwsl\n\n\nubuntu\n\n\n\n\nwhat to do with baobab, pip clean, conda clean\n\n\n\n\n\n\nSep 4, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for September 23\n\n\n\n\n\n\n\nlogbook\n\n\nwsl\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nUpdate jupyter lab to v4\n\n\n\n\n\n\n\njupyter\n\n\nplotly\n\n\n\n\nand perform all unit tests with tqdm, ipywidget, plotly and everything\n\n\n\n\n\n\nAug 24, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for August 23\n\n\n\n\n\n\n\nlogbook\n\n\ngit\n\n\nholoviz\n\n\nnbdev\n\n\nwsl\n\n\n\n\n\n\n\n\n\n\n\nAug 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for July 23\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for May 23\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nTo Do\n\n\n\n\n\n\n\ntodo\n\n\n\n\nan attempt to gather things to learn/test in datascience\n\n\n\n\n\n\nApr 28, 2023\n\n\n\n\n\n\n  \n\n\n\n\nPython scripts from notebooks\n\n\n\n\n\n\n\nfastai\n\n\nnbdev\n\n\njupyter\n\n\n\n\nExtract Python scripts from notebooks with nbdev\n\n\n\n\n\n\nApr 25, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for April 23\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nIcon support in WSL / WSLg with native linux applications [fixed with WSL v1.1.7, broken again with WSL v1.2.x]\n\n\n\n\n\n\n\nwsl\n\n\n\n\nsome icons in taskbar for linux applications are defaulting to Tux\n\n\n\n\n\n\nMar 3, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for March 23\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for February 23\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLive coding sessions from fastai\n\n\n\n\n\n\n\nfastai\n\n\njupyter\n\n\npython\n\n\nwsl\n\n\n\n\nby Jeremy Howard\n\n\n\n\n\n\nJan 25, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLatex in markdown reference\n\n\n\n\n\n\n\njupyter\n\n\nlatex\n\n\n\n\nto be used in jupyter to blog\n\n\n\n\n\n\nJan 23, 2023\n\n\n\n\n\n\n  \n\n\n\n\nChord diagrams\n\n\n\n\n\n\n\nvisualization\n\n\n\n\nusing bokeh\n\n\n\n\n\n\nJan 17, 2023\n\n\n\n\n\n\n  \n\n\n\n\nDeep Learning Foundations to Stable Diffusion\n\n\n\n\n\n\n\nfastai\n\n\n\n\nfastai courses 2022\n\n\n\n\n\n\nJan 12, 2023\n\n\n\n\n\n\n  \n\n\n\n\nZotero\n\n\n\n\n\n\n\ndatascience\n\n\n\n\nManage datascience paper\n\n\n\n\n\n\nJan 11, 2023\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for January 23\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2023\n\n\n\n\n\n\n  \n\n\n\n\nWSL2 from Windows Store\n\n\n\n\n\n\n\nwsl\n\n\n\n\nOut of preview, this is stable and it has tons of new features: systemd, snap, integrated display, etc\n\n\n\n\n\n\nDec 19, 2022\n\n\n\n\n\n\n  \n\n\n\n\nWSL2 on a fresh new PC\n\n\n\n\n\n\n\nwsl\n\n\nwsl_latest\n\n\n\n\nWalkthrough this installation\n\n\n\n\n\n\nDec 14, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for December 22\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for November 22\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nNov 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nPractical Deep Learning for Coders\n\n\n\n\n\n\n\nfastai\n\n\n\n\nfastai courses 2022\n\n\n\n\n\n\nOct 17, 2022\n\n\n\n\n\n\n  \n\n\n\n\nRun dataiku with docker\n\n\n\n\n\n\n\ndocker\n\n\ndataiku\n\n\nwsl\n\n\nlinux\n\n\n\n\nand it is a good time to document some stuff about docker\n\n\n\n\n\n\nOct 13, 2022\n\n\n\n\n\n\n  \n\n\n\n\ngradio and huggingface - handson\n\n\n\n\n\n\n\ngradio\n\n\nhuggingface\n\n\nnbdev\n\n\n\n\nhow to build an app with gradio (and nbdev) and host it with huggingface\n\n\n\n\n\n\nOct 12, 2022\n\n\n\n\n\n\n  \n\n\n\n\npip cheatsheet\n\n\n\n\n\n\n\npip\n\n\n\n\nand other things I would have liked to know earlier\n\n\n\n\n\n\nOct 6, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for October 22\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\ninline images from jupyter with quarto\n\n\n\n\n\n\n\nnbdev\n\n\nquarto\n\n\n\n\nwhy it works with jupyter labs but not completely with jupyter notebook\n\n\n\n\n\n\nSep 23, 2022\n\n\n\n\n\n\n  \n\n\n\n\nBlog - migrate to quarto\n\n\n\n\n\n\n\nnbdev\n\n\nquarto\n\n\nfastpages\n\n\nblog\n\n\n\n\nfollowing migration guide from Hamel Hussain\n\n\n\n\n\n\nSep 16, 2022\n\n\n\n\n\n\n  \n\n\n\n\nnbdev2 - first steps\n\n\n\n\n\n\n\nnbdev\n\n\njupyter\n\n\nfastai\n\n\n\n\nby Jeremy Howard and Hamel Hussain\n\n\n\n\n\n\nSep 12, 2022\n\n\n\n\n\n\n  \n\n\n\n\nSSL: CERTIFICATE_VERIFY_FAILED\n\n\n\n\n\n\n\njupyter\n\n\n\n\nhave to rely on corporate certificate server\n\n\n\n\n\n\nSep 6, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for September 22\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nEvalAI and gitlab\n\n\n\n\n\n\n\ndocker\n\n\nevalai\n\n\ngitlab\n\n\nwsl\n\n\n\n\nhost evalai fully internally (UI and code)\n\n\n\n\n\n\nJul 29, 2022\n\n\n\n\n\n\n  \n\n\n\n\ninstall ubuntu 18.04 on WSL and then evalai\n\n\n\n\n\n\n\nwsl\n\n\n\n\ncould be useful to install evalai\n\n\n\n\n\n\nJul 26, 2022\n\n\n\n\n\n\n  \n\n\n\n\ninstall docker within WSL\n\n\n\n\n\n\n\nwsl\n\n\ndocker\n\n\n\n\nbased on my automatic wsl installation\n\n\n\n\n\n\nJul 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\nAuto export python code from jupyter lab\n\n\n\n\n\n\n\njupyter\n\n\n\n\nbecause it is easier to search from .py files in text format. Using nbautoexports in jupyter lab\n\n\n\n\n\n\nJul 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\ninstall docker within linux\n\n\n\n\n\n\n\nlinux\n\n\ndocker\n\n\n\n\nunder ubuntu 20.04\n\n\n\n\n\n\nJul 21, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for July 22\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nDeep RL class - huggingface\n\n\n\n\n\n\n\nreinforcement learning\n\n\nhuggingface\n\n\n\n\npar Thomas Simonini\n\n\n\n\n\n\nJun 15, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for June 22\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nsave git https credentials under wsl\n\n\n\n\n\n\n\ngit\n\n\n\n\ngit-credential-manager\n\n\n\n\n\n\nMay 3, 2022\n\n\n\n\n\n\n  \n\n\n\n\nupgrade to last version of fastpages\n\n\n\n\n\n\n\nfastpages\n\n\n\n\nfollowing bug with pyYaml\n\n\n\n\n\n\nMay 2, 2022\n\n\n\n\n\n\n  \n\n\n\n\ninstall ubuntu 22.04 on WSL\n\n\n\n\n\n\n\nwsl\n\n\n\n\neven if not available in Windows Store\n\n\n\n\n\n\nApr 25, 2022\n\n\n\n\n\n\n  \n\n\n\n\nkeep dotfiles in git\n\n\n\n\n\n\n\ngit\n\n\nbash\n\n\n\n\nas pointed by Jeremy Howard\n\n\n\n\n\n\nApr 7, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for February 22\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nFeb 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nsetup wsl2 conda mamba and cuda\n\n\n\n\n\n\n\nwsl\n\n\ncuda\n\n\nconda\n\n\n\n\nbest of breed windows + linux\n\n\n\n\n\n\nJan 18, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for January 22\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nJan 1, 2022\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for December 21\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nDec 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for November 21\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nNov 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\nJust some usefull keyboard shortcuts\n\n\n\n\n\n\n\nlinux\n\n\n\n\nlaunch Gnome files, firefox\n\n\n\n\n\n\nOct 21, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for October 21\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nOct 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\nGenerate python modules from jupyter notebooks\n\n\n\n\n\n\n\njupyter\n\n\nfastai\n\n\n\n\nusing nbdev/notebook2script from fastai, Jeremy Howard\n\n\n\n\n\n\nSep 29, 2021\n\n\n\n\n\n\n  \n\n\n\n\nFix pythoncom37.dll popup when launching Jupyter Notebook\n\n\n\n\n\n\n\njupyter\n\n\nconda\n\n\n\n\nthe procedure entry point … could not be located in the dynamic library /pythoncom37.dll\n\n\n\n\n\n\nSep 28, 2021\n\n\n\n\n\n\n  \n\n\n\n\nFix non-unique cell issue in Jupyter Notebook\n\n\n\n\n\n\n\njupyter\n\n\n\n\nwhen copy/paste in jupyter is breaking your notebooks\n\n\n\n\n\n\nSep 16, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for September 21\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nSep 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\ngit clean repo with bfg\n\n\n\n\n\n\n\ngit\n\n\n\n\ngitlab doesn’t like &gt;100MB files - removing crazy big files\n\n\n\n\n\n\nJul 29, 2021\n\n\n\n\n\n\n  \n\n\n\n\ngit ignore large files\n\n\n\n\n\n\n\ngit\n\n\n\n\ngitlab doesn’t like &gt;100MB files\n\n\n\n\n\n\nJul 9, 2021\n\n\n\n\n\n\n  \n\n\n\n\nDeep Neural Network with PyTorch - Coursera\n\n\n\n\n\n\n\npytorch\n\n\ncoursera\n\n\n\n\nFrom IBM\n\n\n\n\n\n\nJul 7, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for July 21\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nJul 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\nAutogenerate documentation from custom python classes\n\n\n\n\n\n\n\npython\n\n\n\n\npdoc3 - installation, generation, browse documentation\n\n\n\n\n\n\nJun 30, 2021\n\n\n\n\n\n\n  \n\n\n\n\nSlideshows from Jupyter notebook\n\n\n\n\n\n\n\njupyter\n\n\n\n\ninstallation, run, structure, split cells, hide code, host in github\n\n\n\n\n\n\nJun 25, 2021\n\n\n\n\n\n\n  \n\n\n\n\nReinforcement Learning Specialization - Coursera - course 4 - A Complete Reinforcement Learning System (Capstone)\n\n\n\n\n\n\n\nreinforcement learning\n\n\ndeepmind\n\n\ncoursera\n\n\n\n\nFrom University of Alberta. My notes on course 4.\n\n\n\n\n\n\nJun 14, 2021\n\n\n\n\n\n\n  \n\n\n\n\nReinforcement Learning Specialization - Coursera - course 3 - Prediction and Control with Function Approximation\n\n\n\n\n\n\n\nreinforcement learning\n\n\ndeepmind\n\n\ncoursera\n\n\n\n\nFrom University of Alberta. My notes on course 3.\n\n\n\n\n\n\nJun 7, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for June 21\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\nReinforcement Learning Specialization - Coursera - course 2 - Sample-based Learning Methods\n\n\n\n\n\n\n\nreinforcement learning\n\n\ndeepmind\n\n\ncoursera\n\n\n\n\nFrom University of Alberta. My notes on course 2.\n\n\n\n\n\n\nMay 25, 2021\n\n\n\n\n\n\n  \n\n\n\n\nMachine learning in python with scikit-learn\n\n\n\n\n\n\n\nmachine learning\n\n\nscikit-learn\n\n\n\n\nby Inria team on fun mooc platform\n\n\n\n\n\n\nMay 21, 2021\n\n\n\n\n\n\n  \n\n\n\n\nReinforcement Learning Specialization - Coursera - course 1 - Fundamentals of Reinforcement Learning\n\n\n\n\n\n\n\nreinforcement learning\n\n\ndeepmind\n\n\ncoursera\n\n\n\n\nFrom University of Alberta. My notes on course 1.\n\n\n\n\n\n\nMay 3, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for May 21\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nMay 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\nsetup wsl2 with cuda and conda\n\n\n\n\n\n\n\nwsl\n\n\ncuda\n\n\nconda\n\n\n\n\nbest of breed windows + linux\n\n\n\n\n\n\nApr 9, 2021\n\n\n\n\n\n\n  \n\n\n\n\nusing SOCKS5 proxy - with git, apt, pip, …\n\n\n\n\n\n\n\ngit\n\n\n\n\nto connect to github behind local firewall\n\n\n\n\n\n\nApr 6, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for April 21\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nApr 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\nANITI’s first Reinforcement Learning Virtual School\n\n\n\n\n\n\n\nreinforcement learning\n\n\n\n\nMy notes\n\n\n\n\n\n\nApr 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\nHeadless raspberry pi: create a wifi to ethernet bridge\n\n\n\n\n\n\n\nraspberry pi\n\n\n\n\nsetup headless raspberry pi to bridge wifi (tethering from phone) to ethernet (for my home wifi-router)\n\n\n\n\n\n\nMar 25, 2021\n\n\n\n\n\n\n  \n\n\n\n\nGit - How To Contribute To A Project\n\n\n\n\n\n\n\ngit\n\n\n\n\nsubmit patch, example with clustergit project\n\n\n\n\n\n\nMar 25, 2021\n\n\n\n\n\n\n  \n\n\n\n\nStable baselines 3 - 1st steps\n\n\n\n\n\n\n\nreinforcement learning\n\n\npytorch\n\n\nsb3\n\n\n\n\ninstallation, 1st experimentations\n\n\n\n\n\n\nMar 24, 2021\n\n\n\n\n\n\n  \n\n\n\n\nGit - How to find all unpushed commits for all projects in a directory?\n\n\n\n\n\n\n\ngit\n\n\n\n\nclustergit, RabbitVCS - installation and usage\n\n\n\n\n\n\nMar 9, 2021\n\n\n\n\n\n\n  \n\n\n\n\nIntroduction to Reinforcement Learning with David Silver\n\n\n\n\n\n\n\nreinforcement learning\n\n\ndeepmind\n\n\n\n\nFrom deepmind. My notes\n\n\n\n\n\n\nMar 9, 2021\n\n\n\n\n\n\n  \n\n\n\n\nUse of gpg under linux\n\n\n\n\n\n\n\ngpg\n\n\n\n\nbetween my windows and linx boxes\n\n\n\n\n\n\nMar 3, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for March 21\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nMar 1, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLogbook for February 21\n\n\n\n\n\n\n\nlogbook\n\n\n\n\n\n\n\n\n\n\n\nFeb 26, 2021\n\n\n\n\n\n\n  \n\n\n\n\nPracticing: Deep Reinforcement Learning Course by Thomas Simonini\n\n\n\n\n\n\n\nreinforcement learning\n\n\n\n\nA Free course in Deep Reinforcement Learning from beginner to expert. My notes\n\n\n\n\n\n\nFeb 19, 2021\n\n\n\n\n\n\n  \n\n\n\n\nConda and jupyter tips\n\n\n\n\n\n\n\nconda\n\n\njupyter\n\n\n\n\nsome useful commands I daily use\n\n\n\n\n\n\nFeb 16, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLearning: College de France - Representations parcimonieuses\n\n\n\n\n\n\n\ndeep learning\n\n\nmath\n\n\n\n\nMy notes/thoughts about the lecture in French\n\n\n\n\n\n\nFeb 10, 2021\n\n\n\n\n\n\n  \n\n\n\n\nLearning: MIT 6.S191 Introduction to Deep Learning - 2021\n\n\n\n\n\n\n\ndeep learning\n\n\nmit\n\n\ntensorflow\n\n\n\n\nMy notes/thoughts about the lecture\n\n\n\n\n\n\nFeb 5, 2021\n\n\n\n\n\n\n  \n\n\n\n\nReinforcement learning readings\n\n\n\n\n\n\n\nreinforcement learning\n\n\n\n\nMy notes about some readings\n\n\n\n\n\n\nJan 26, 2021\n\n\n\n\n\n\n  \n\n\n\n\nAristotle and Deep learning\n\n\n\n\n\n\n\n\n\n\nAll men by nature desire to know…\n\n\n\n\n\n\nJan 21, 2021\n\n\n\n\n\n\n  \n\n\n\n\nseaborn cheatsheet\n\n\n\n\n\n\n\nvisualization\n\n\nseaborn\n\n\ncheatsheet\n\n\n\n\npractical examples from datacamp courses\n\n\n\n\n\n\nJan 19, 2021\n\n\n\n\n\n\n  \n\n\n\n\nJava installation on Ubuntu 20.04\n\n\n\n\n\n\n\nubuntu\n\n\njava\n\n\n\n\nOracle JRE under Ubuntu focal using linuxuprising/java\n\n\n\n\n\n\nJan 14, 2021\n\n\n\n\n\n\n  \n\n\n\n\nmatplotlib cheatsheet\n\n\n\n\n\n\n\nvisualization\n\n\nmatplotlib\n\n\ncheatsheet\n\n\n\n\nso much options\n\n\n\n\n\n\nJan 13, 2021\n\n\n\n\n\n\n  \n\n\n\n\npandas cheatsheet\n\n\n\n\n\n\n\npandas\n\n\ncheatsheet\n\n\n\n\nso much different ways to do something with pandas, …\n\n\n\n\n\n\nJan 13, 2021\n\n\n\n\n\n\n  \n\n\n\n\nHow To Install Packages from the Jupyter Notebook\n\n\n\n\n\n\n\njupyter\n\n\nconda\n\n\n\n\nand why this is so messy\n\n\n\n\n\n\nJan 13, 2021\n\n\n\n\n\n\n  \n\n\n\n\nHello nbdev\n\n\n\n\n\n\n\nfastai\n\n\nnbdev\n\n\njupyter\n\n\n\n\nwalkthrough nbdev tutorial (from fastai team)\n\n\n\n\n\n\nJan 12, 2021\n\n\n\n\n\n\n  \n\n\n\n\nAbout my datacamp learning process\n\n\n\n\n\n\n\ndatacamp\n\n\ndata science\n\n\n\n\nkeep lectures, notebooks, progress, … and git structure\n\n\n\n\n\n\nJan 7, 2021\n\n\n\n\n\n\n  \n\n\n\n\nAuto export python code from jupyter notebooks\n\n\n\n\n\n\n\njupyter\n\n\n\n\nbecause it is easier to search from .py files in text format. Using file save hooks from Jupyter, using nbconvert\n\n\n\n\n\n\nJan 5, 2021\n\n\n\n\n\n\n  \n\n\n\n\nFrom cron to anacron\n\n\n\n\n\n\n\nubuntu\n\n\ncron\n\n\n\n\nexecute recurrent scripts with anacron to deal with missed jobs (system off)\n\n\n\n\n\n\nDec 13, 2020\n\n\n\n\n\n\n  \n\n\n\n\nRepo with 2 remote-urls\n\n\n\n\n\n\n\ngit\n\n\n\n\nshare data-scientist-skills repo with gitlab and github\n\n\n\n\n\n\nDec 8, 2020\n\n\n\n\n\n\n  \n\n\n\n\nPush large files to github: git-lfs\n\n\n\n\n\n\n\ngit\n\n\n\n\nto answer to exceeding GitHub’s file size limit of 100.00 MB\n\n\n\n\n\n\nDec 2, 2020\n\n\n\n\n\n\n  \n\n\n\n\nUse git with github (ssh) behind corporate proxy\n\n\n\n\n\n\n\ngit\n\n\nwsl\n\n\n\n\nusing corkscrew to tunnel ssh through http proxy\n\n\n\n\n\n\nOct 21, 2020\n\n\n\n\n\n\n  \n\n\n\n\nOpen Jupyter Notebook with http launch instead of redirect file\n\n\n\n\n\n\n\njupyter\n\n\nwsl\n\n\n\n\nusefull when starting jupyter notebook from WSL\n\n\n\n\n\n\nOct 21, 2020\n\n\n\n\n\n\n  \n\n\n\n\nedX MIT 6.00.2x Introduction to Computational Thinking and Data Science\n\n\n\n\n\n\n\nedx\n\n\nmit\n\n\ndata science\n\n\npython\n\n\n\n\nabout the UNIT 1\n\n\n\n\n\n\nOct 20, 2020\n\n\n\n\n\n\n  \n\n\n\n\nValidation of jupyter inner images with fastpages\n\n\n\n\n\n\n\nblog\n\n\nfastpages\n\n\n\n\n\n\n\n\n\n\n\nOct 19, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGAN Specialization course 2 week 3 - Apply and certificate\n\n\n\n\n\n\n\ngan\n\n\npytorch\n\n\n\n\nfrom Sharon Zhou, deeplearning.ai. What I have learnt from gan specialization course 2 (Build Better GAN) on week 3:\n\n\n\n\n\n\nOct 15, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGAN Specialization course 2 week 1 - evaluations on GANs\n\n\n\n\n\n\n\ngan\n\n\npytorch\n\n\n\n\nfrom Sharon Zhou, deeplearning.ai. What I have learnt from gan specialization course 2 (Build Better GAN) on week 1: features extraction, FID Frechet Inception Distance\n\n\n\n\n\n\nOct 9, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGAN Specialization course 2 week 2 - Disadvantages and Bias\n\n\n\n\n\n\n\ngan\n\n\npytorch\n\n\n\n\nfrom Sharon Zhou, deeplearning.ai. What I have learnt from gan specialization course 2 (Build Better GAN) on week 2:\n\n\n\n\n\n\nOct 9, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGAN Specialization course 1 week 3 - mode collapse, vanishing gradient, wasserstein loss\n\n\n\n\n\n\n\ngan\n\n\npytorch\n\n\n\n\nfrom Sharon Zhou, deeplearning.ai. What I have learnt from gan specialization course 1 (Build Basic GAN) on week 3\n\n\n\n\n\n\nOct 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nConda activate from bash scripts\n\n\n\n\n\n\n\nconda\n\n\nbash\n\n\n\n\nhow to launch bash scripts with an effective conda environment: conda activate, …\n\n\n\n\n\n\nOct 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nVariables traces using show_guts decorator\n\n\n\n\n\n\n\npython\n\n\n\n\nusefull to debug\n\n\n\n\n\n\nOct 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGAN Specialization course 1 week 4 - conditional generation, controllable generation\n\n\n\n\n\n\n\ngan\n\n\npytorch\n\n\n\n\nfrom Sharon Zhou, deeplearning.ai. What I have learnt from gan specialization course 1 (Build Basic GAN) on week 4\n\n\n\n\n\n\nOct 7, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGAN Specialization course 1 week 2 - Deep Convolutional GAN\n\n\n\n\n\n\n\ngan\n\n\npytorch\n\n\n\n\nfrom Sharon Zhou, deeplearning.ai. What I have learnt from gan specialization course 1 (Build Basic GAN) on week 2\n\n\n\n\n\n\nOct 6, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGAN Specialization course 1 week 1 - intro to GAN\n\n\n\n\n\n\n\ngan\n\n\npytorch\n\n\n\n\nfrom Sharon Zhou, deeplearning.ai. What I have learnt from gan specialization course 1 (Build Basic GAN) on week 1\n\n\n\n\n\n\nOct 6, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGenerative Adversarial Networks (GANs) Specialization from Coursera\n\n\n\n\n\n\n\ngan\n\n\npytorch\n\n\n\n\nfrom Sharon Zhou, deeplearning.ai\n\n\n\n\n\n\nOct 1, 2020\n\n\n\n\n\n\n  \n\n\n\n\nUse fingerprint to authenticate on Ubuntu, and passwordless on some apps\n\n\n\n\n\n\n\nubuntu\n\n\n\n\nFingerprints, sudoers\n\n\n\n\n\n\nOct 1, 2020\n\n\n\n\n\n\n  \n\n\n\n\nUpgrade ubuntu LTS 18.04 to 20.04\n\n\n\n\n\n\n\nubuntu\n\n\n\n\nInstructions to upgrade to last LTS version. Not available yet though (09/28)\n\n\n\n\n\n\nSep 28, 2020\n\n\n\n\n\n\n  \n\n\n\n\nMultiple subplots and animations with matplotlib\n\n\n\n\n\n\n\nmatplotlib\n\n\n\n\nPlaying with subplots, //, %, and animation\n\n\n\n\n\n\nSep 26, 2020\n\n\n\n\n\n\n  \n\n\n\n\nFastai book Deep Learning for Coders with fastai and Pytorch\n\n\n\n\n\n\n\nfastai\n\n\njupyter\n\n\nfastbook\n\n\n\n\ndescription of my learning environment, following fastai reco\n\n\n\n\n\n\nSep 24, 2020\n\n\n\n\n\n\n  \n\n\n\n\nSetup ubuntu box with fastai\n\n\n\n\n\n\n\nfastai\n\n\ncuda\n\n\nlinux\n\n\n\n\nlist of actions to get a fastai workstation ready\n\n\n\n\n\n\nSep 23, 2020\n\n\n\n\n\n\n  \n\n\n\n\nFastai on WSL 2 with Cuda\n\n\n\n\n\n\n\nwsl\n\n\nfastai\n\n\nwsl2\n\n\ncuda\n\n\n\n\nhow to NOT get an operational corporate workstation with windows 10, cuda, wsl2, fastai, pytorch…\n\n\n\n\n\n\nSep 21, 2020\n\n\n\n\n\n\n  \n\n\n\n\nAutodetect Home / Office network + Proxy\n\n\n\n\n\n\n\nwsl\n\n\nlinux\n\n\nbash\n\n\n\n\nDepending on my location (home, office, hotspot), I want my network configuration to adapt and set the proper settings: proxy for http, conda, git, etc\n\n\n\n\n\n\nSep 15, 2020\n\n\n\n\n\n\n  \n\n\n\n\nFast read Excel files with pandas\n\n\n\n\n\n\n\npandas\n\n\n\n\nmy way to fast read big Excel files with Pandas using cvs cache\n\n\n\n\n\n\nSep 14, 2020\n\n\n\n\n\n\n  \n\n\n\n\nGit push to github without password\n\n\n\n\n\n\n\ngit\n\n\n\n\nhow to move from https to git to push to github, using ssh keys to authenticate\n\n\n\n\n\n\nSep 11, 2020\n\n\n\n\n\n\n  \n\n\n\n\nBlog from jupyter notebook\n\n\n\n\n\n\n\n\n\n\n\n\nSep 10, 2020\n\n\n\n\n\n\n  \n\n\n\n\nBlog from jupyter notebook\n\n\n\n\n\n\n\nfastpages\n\n\njupyter\n\n\nnotebooks\n\n\n\n\nhow to setup fastpages to blog from jupyter notebook\n\n\n\n\n\n\nSep 10, 2020\n\n\n\n\n\n\n  \n\n\n\n\nBlogging from github\n\n\n\n\n\n\n\nblog\n\n\nfastpages\n\n\ngit\n\n\n\n\nhttps://github.com/features/actions\n\n\n\n\n\n\nSep 9, 2020\n\n\n\n\n\n\n  \n\n\n\n\nBecoming a datascientist\n\n\n\n\n\n\n\nme\n\n\n\n\nOverall resume and why I have turned as a datascientist\n\n\n\n\n\n\nSep 8, 2020\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2020-10-07-gan-specialization-week4-conditional_generation-controllable-generation.html",
    "href": "posts/2020-10-07-gan-specialization-week4-conditional_generation-controllable-generation.html",
    "title": "GAN Specialization course 1 week 4 - conditional generation, controllable generation",
    "section": "",
    "text": "Conditional generation, controllable generation, disentanglement of Z-space\n\n\n\nalt text\n\n\n\n\nEnd of course\nNext one is a 3 week course named: Build Better Generative Adversarial Networks (GANs)\nHere is my certificate\n\n\n\nalt text"
  },
  {
    "objectID": "posts/2023-09-13-open-interpreter.html",
    "href": "posts/2023-09-13-open-interpreter.html",
    "title": "Open Interpreter",
    "section": "",
    "text": "As published by Killian"
  },
  {
    "objectID": "posts/2023-09-13-open-interpreter.html#interpreter-environnement",
    "href": "posts/2023-09-13-open-interpreter.html#interpreter-environnement",
    "title": "Open Interpreter",
    "section": "interpreter environnement",
    "text": "interpreter environnement\nmamba create -n interpreter -y python=3.11\nmamba activate interpreter\npip install open-interpreter\n\nsudo apt install build-essential cmake"
  },
  {
    "objectID": "posts/2023-09-13-open-interpreter.html#configuration-of-interpreter-installation-of-llama_cpp",
    "href": "posts/2023-09-13-open-interpreter.html#configuration-of-interpreter-installation-of-llama_cpp",
    "title": "Open Interpreter",
    "section": "configuration of interpreter, installation of llama_cpp",
    "text": "configuration of interpreter, installation of llama_cpp\n1st thing is a configuration.\nI don’t have GPT-4 API key, which is the preferred option. No other choice than to use Code-Llama (free but less capable).\nAdvantage is that it is a local version, and interpreter asks about its configuration:\n\nparameter count (I choosed 34 B)\nquality (I choosed Large - 33.4 GB)\nGPU (of course yes)\n\n\nerror log\nBut during installation of TheBloke/CodeLlama-34B-Instruct-GGUF, it fails with this message.\nBuilding wheels for collected packages: llama-cpp-python\n  Building wheel for llama-cpp-python (pyproject.toml) ... error\n  error: subprocess-exited-with-error\n\n  × Building wheel for llama-cpp-python (pyproject.toml) did not run successfully.\n  │ exit code: 1\n  ╰─&gt; [26 lines of output]\n      *** scikit-build-core 0.5.0 using CMake 3.27.4 (wheel)\n      *** Configuring CMake...\n      2023-09-13 19:04:10,988 - scikit_build_core - WARNING - libdir/ldlibrary: /home/guillaume/miniconda/envs/interpreter/lib/libpython3.11.a is not a real file!\n      2023-09-13 19:04:10,989 - scikit_build_core - WARNING - Can't find a Python library, got libdir=/home/guillaume/miniconda/envs/interpreter/lib, ldlibrary=libpython3.11.a, multiarch=x86_64-linux-gnu, masd=None\n      loading initial cache file /tmp/tmph_bvsb06/build/CMakeInit.txt\n      -- The C compiler identification is unknown\n      -- The CXX compiler identification is unknown\n      CMake Error at CMakeLists.txt:3 (project):\n        No CMAKE_C_COMPILER could be found.\n\n        Tell CMake where to find the compiler by setting either the environment\n        variable \"CC\" or the CMake cache entry CMAKE_C_COMPILER to the full path to\n        the compiler, or to the compiler name if it is in the PATH.\n\n\n      CMake Error at CMakeLists.txt:3 (project):\n        No CMAKE_CXX_COMPILER could be found.\n\n        Tell CMake where to find the compiler by setting either the environment\n        variable \"CXX\" or the CMake cache entry CMAKE_CXX_COMPILER to the full path\n        to the compiler, or to the compiler name if it is in the PATH.\n\n\n      -- Configuring incomplete, errors occurred!\n\n      *** CMake configuration failed\n      [end of output]\n\n  note: This error originates from a subprocess, and is likely not a problem with pip.\n  ERROR: Failed building wheel for llama-cpp-python\nFailed to build llama-cpp-python\nERROR: Could not build wheels for llama-cpp-python, which is required to install pyproject.toml-based projects\nError during installation with cuBLAS: Command\n'['/home/guillaume/miniconda/envs/interpreter/bin/python', '-m',\n'pip', 'install', 'llama-cpp-python']' returned non-zero exit status1.\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/guillaume/miniconda/envs/interpreter/lib/python3.11/site-packages/interpreter/interpreter.py\", line 203, in chat\n    self.llama_instance = get_hf_llm(self.model, self.debug_mode, self.context_window)\n                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/guillaume/miniconda/envs/interpreter/lib/python3.11/site-packages/interpreter/get_hf_llm.py\", line 200, in get_hf_llm\n    from llama_cpp import Llama\nModuleNotFoundError: No module named 'llama_cpp'\n\nFailed to install TheBloke/CodeLlama-34B-Instruct-GGUF.\n\nCommon Fixes: You can follow our simple setup docs at the link belowto resolve common errors.\n\n\n https://github.com/KillianLucas/open-interpreter/tree/main/docs\n\n\nIf you've tried that and you're still getting an error, we have\nlikely not built the proper TheBloke/CodeLlama-34B-Instruct-GGUF\nsupport for your system.\n\n( Running language models locally is a difficult task! If you have\ninsight into the best way to implement this across\nplatforms/architectures, please join the Open Interpreter community\nDiscord and consider contributing the project's development. )\n\n\ninterpreter help\nThis page explains additionnal stuff\nhttps://github.com/KillianLucas/open-interpreter/blob/main/docs/GPU.md#windows-subsystem-for-linux-2-wsl2\nI tried with\nCUDA_PATH=/usr/local/cuda FORCE_CMAKE=1 CMAKE_ARGS='-DLLAMA_CUBLAS=on' \\\npip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir -vv"
  },
  {
    "objectID": "posts/2023-09-13-open-interpreter.html#with-a-smaller-modele",
    "href": "posts/2023-09-13-open-interpreter.html#with-a-smaller-modele",
    "title": "Open Interpreter",
    "section": "with a smaller modele",
    "text": "with a smaller modele\n\n\n\nimage.png\n\n\nHere this is reasonnably fast but runs in CPU and answers are not what I expect. Is it due to smaller model? Do I have to switch to a bigger one on GPU? Or to GPT-4 ?"
  },
  {
    "objectID": "posts/2023-09-13-open-interpreter.html#option-1---install-nvidia-toolkit-for-wsl2",
    "href": "posts/2023-09-13-open-interpreter.html#option-1---install-nvidia-toolkit-for-wsl2",
    "title": "Open Interpreter",
    "section": "option 1 - install NVIDIA toolkit for WSL2",
    "text": "option 1 - install NVIDIA toolkit for WSL2\nAs explained in https://github.com/KillianLucas/open-interpreter/blob/main/docs/GPU.md#windows-subsystem-for-linux-2-wsl2\nGet the latest NVIDIA CUDA Toolkit for WSL2 and run the provided steps in a WSL terminal.\n\nOperating System: Linux\nArchitecture: x86_64\nDistribution: WSL-Ubuntu\nVersion: 2.0\nInstaller Type: deb (local) (recommended network but it cannot work in my configuration)\n\nInstall it\nwget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\nsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/12.2.2/local_installers/cuda-repo-wsl-ubuntu-12-2-local_12.2.2-1_amd64.deb\nsudo dpkg -i cuda-repo-wsl-ubuntu-12-2-local_12.2.2-1_amd64.deb\nsudo cp /var/cuda-repo-wsl-ubuntu-12-2-local/cuda-*-keyring.gpg /usr/share/keyrings/\nsudo apt-get update\nsudo apt-get -y install cuda\nAnd check if it is installed correctly\n&gt; ls /usr/local/cuda/bin/nvcc\n/usr/local/cuda/bin/nvcc\nLet’s reinstall llama-cpp-python\nCUDA_PATH=/usr/local/cuda FORCE_CMAKE=1 CMAKE_ARGS='-DLLAMA_CUBLAS=on' \\\npip install llama-cpp-python --force-reinstall --upgrade --no-cache-dir -vv\nAnd now it should run on GPU\n❯ python -c \"from llama_cpp import GGML_USE_CUBLAS; print(GGML_USE_CUBLAS)\"\nTrue"
  },
  {
    "objectID": "posts/2023-09-13-open-interpreter.html#option-2---install-nvidia-toolkit-for-wsl2",
    "href": "posts/2023-09-13-open-interpreter.html#option-2---install-nvidia-toolkit-for-wsl2",
    "title": "Open Interpreter",
    "section": "option 2 - install NVIDIA toolkit for WSL2",
    "text": "option 2 - install NVIDIA toolkit for WSL2\nThis PR installs official NVIDIA wheels for CUDA support so the CUDA Toolkit does not need to be installed.\nIt has not yet been integrated but it will with no doubt be the next preferred way to setup interpreter."
  },
  {
    "objectID": "posts/2020-09-24-fastai-book.html",
    "href": "posts/2020-09-24-fastai-book.html",
    "title": "Fastai book Deep Learning for Coders with fastai and Pytorch",
    "section": "",
    "text": "Of course the 1st tep is to purchase this great book:\n\n\n\nalt text\n\n\nI have liked what Jeremy Howard said about why this is important to purchase it (in video 1). Fastai is offering full access to the book as notebooks. So that we can run all codes from them."
  },
  {
    "objectID": "posts/2020-09-24-fastai-book.html#update-jupyter-to-include-extensions-toc",
    "href": "posts/2020-09-24-fastai-book.html#update-jupyter-to-include-extensions-toc",
    "title": "Fastai book Deep Learning for Coders with fastai and Pytorch",
    "section": "update jupyter to include extensions (toc, …)",
    "text": "update jupyter to include extensions (toc, …)\nconda install -c conda-forge jupyter_contrib_nbextensions\n I like table of content, others are quite usefull as well (scratchpad, ExecuteTime…)."
  },
  {
    "objectID": "posts/2020-09-24-fastai-book.html#install-some-libraries-to-run-book-examples",
    "href": "posts/2020-09-24-fastai-book.html#install-some-libraries-to-run-book-examples",
    "title": "Fastai book Deep Learning for Coders with fastai and Pytorch",
    "section": "Install some libraries to run book examples",
    "text": "Install some libraries to run book examples\nconda install -c fastai fastbook\nIt will install graphviz, nbdev, and other libraries.\nAnd most of them can be loaded by calling from utils import *"
  },
  {
    "objectID": "posts/2020-09-24-fastai-book.html#launch-jupyter-notebook-and-start-expermenting",
    "href": "posts/2020-09-24-fastai-book.html#launch-jupyter-notebook-and-start-expermenting",
    "title": "Fastai book Deep Learning for Coders with fastai and Pytorch",
    "section": "Launch jupyter notebook and start expermenting",
    "text": "Launch jupyter notebook and start expermenting\ncd ~/git/guillaume\nconda activate fastai\njupyter notebook\nAnd launch several tabs at: blog entries, fastai experiments, fastai courses and fastai videos.\nAnd I keep track of progress with git."
  },
  {
    "objectID": "posts/2023-08-24-update-jupyterlab-v4.html",
    "href": "posts/2023-08-24-update-jupyterlab-v4.html",
    "title": "Update jupyter lab to v4",
    "section": "",
    "text": "As mentionned in logbook May-23, jupyter lab v4 is now available."
  },
  {
    "objectID": "posts/2023-08-24-update-jupyterlab-v4.html#base_jupyter-jupyter-lab-v3",
    "href": "posts/2023-08-24-update-jupyterlab-v4.html#base_jupyter-jupyter-lab-v3",
    "title": "Update jupyter lab to v4",
    "section": "base_jupyter (jupyter lab v3)",
    "text": "base_jupyter (jupyter lab v3)\nAs I explained in my WSL setup, I run jupyterlab from base_jupyter a specific python environment with this defintion:\n\n!cat ~/_conda_env/base_jupyter.txt\n\nconda remove --name base_jupyter --all\nmamba create -n base_jupyter  -c conda-forge -y python=3.10 \nconda activate base_jupyter\nmamba install -c conda-forge \"jupyterlab&lt;4.0\" \"ipywidgets&gt;=7.6, &lt;8.0\"\n#at that step tqdm should work https://github.com/tqdm/tqdm/issues/1310\nmamba install -c conda-forge -c plotly -y jupyter-dash\nmamba install -c conda-forge -y ipykernel 'jupyterlab_execute_time&lt;3.0'\npython -m ipykernel install --user --name=base_jupyter\n#jupyter labextension install jupyterlab-plotly\n\njupyter-lab --generate-config\n# in .jupyter/jupyter_lab_config.py\n# replace # c.ServerApp.use_redirect_file = True\n# with c.ServerApp.use_redirect_file = False\n# or get it from gitlab/JANUS/dotfiles\n\n#check nodejs installation using nvm\n#e.g. nvm install 18.16.0\n#  nvm alias default 18.16.0\n#  node -v\n# et pour le CA\n# npm config set cafile  /home/guillaume/miniconda/lib/python3.9/site-packages/certifi/cacert.pem\njupyter lab build --minimize=False\n\nmamba install -c pyviz pyviz_comms\n\n\nAnd here are the versions of packages used in this environment\n❯ conda list|grep jupyter\n# packages in environment at /home/guillaume/miniconda/envs/base_jupyter:\njupyter-dash              0.4.2              pyhd8ed1ab_1    conda-forge\njupyter_client            8.2.0              pyhd8ed1ab_0    conda-forge\njupyter_core              5.3.1           py310hff52083_0    conda-forge\njupyter_events            0.6.3              pyhd8ed1ab_0    conda-forge\njupyter_server            2.6.0              pyhd8ed1ab_0    conda-forge\njupyter_server_fileid     0.9.0              pyhd8ed1ab_0    conda-forge\njupyter_server_terminals  0.4.4              pyhd8ed1ab_1    conda-forge\njupyter_server_ydoc       0.8.0              pyhd8ed1ab_0    conda-forge\njupyter_ydoc              0.2.4              pyhd8ed1ab_0    conda-forge\njupyterlab                3.6.4              pyhd8ed1ab_0    conda-forge\njupyterlab_execute_time   2.3.1              pyhd8ed1ab_0    conda-forge\njupyterlab_pygments       0.2.2              pyhd8ed1ab_0    conda-forge\njupyterlab_server         2.23.0             pyhd8ed1ab_0    conda-forge\njupyterlab_widgets        1.1.4              pyhd8ed1ab_0    conda-forge"
  },
  {
    "objectID": "posts/2023-08-24-update-jupyterlab-v4.html#base_jupyter_v4-jupyter-lab-v4",
    "href": "posts/2023-08-24-update-jupyterlab-v4.html#base_jupyter_v4-jupyter-lab-v4",
    "title": "Update jupyter lab to v4",
    "section": "base_jupyter_v4 (jupyter lab v4)",
    "text": "base_jupyter_v4 (jupyter lab v4)\nBecause I don’t want to ruin my config, I will create a new specfic environment base_jupyter_v4\nand keep my jupyter config:\nmv .jupyter .jupyter_backup_20230824\n# stop running jupyter lab instance\nsudo systemctl stop jupyterlab\n\nconda remove --name base_jupyter_v4 --all\nmamba create -y -n base_jupyter_v4 -c conda-forge python=3.10\nconda activate base_jupyter_v4\nmamba install -c conda-forge jupyterlab ipywidgets --yes\nThis setup brings these versions:\n❯ conda list|grep jupyter\n# packages in environment at /home/guillaume/miniconda/envs/base_jupyter_v4:\njupyter-lsp               2.2.0              pyhd8ed1ab_0    conda-forge\njupyter_client            8.3.0              pyhd8ed1ab_0    conda-forge\njupyter_core              5.3.1           py310hff52083_0    conda-forge\njupyter_events            0.7.0              pyhd8ed1ab_2    conda-forge\njupyter_server            2.7.1              pyhd8ed1ab_0    conda-forge\njupyter_server_terminals  0.4.4              pyhd8ed1ab_1    conda-forge\njupyterlab                4.0.5              pyhd8ed1ab_0    conda-forge\njupyterlab_pygments       0.2.2              pyhd8ed1ab_0    conda-forge\njupyterlab_server         2.24.0             pyhd8ed1ab_0    conda-forge\njupyterlab_widgets        3.0.8              pyhd8ed1ab_0    conda-forge\nLet’s see what works or not from this installation.\njupyer lab"
  },
  {
    "objectID": "posts/2023-03-01-logbook-March-23.html",
    "href": "posts/2023-03-01-logbook-March-23.html",
    "title": "Logbook for March 23",
    "section": "",
    "text": "Will use tilix as terminal in WSL\n\n\n\nimage.png\n\n\n\n\n\nbug with version 1.3.242, switched back to stable version\nsee ERROR: File name too longERROR: File name too long\n\n\n\nIt has already hapenned once with bash and agin now that I have switched to zsh.\nI don’t see snap apps from nautilus (for example to edit a text file with sublime-text)\nOption was to ensure to have XDG_DATA_DIRS variable set up. But here it doesn’t help.\nhttps://askubuntu.com/questions/910821/programs-installed-via-snap-not-showing-up-in-launcher"
  },
  {
    "objectID": "posts/2023-03-01-logbook-March-23.html#friday-0303",
    "href": "posts/2023-03-01-logbook-March-23.html#friday-0303",
    "title": "Logbook for March 23",
    "section": "",
    "text": "Will use tilix as terminal in WSL\n\n\n\nimage.png\n\n\n\n\n\nbug with version 1.3.242, switched back to stable version\nsee ERROR: File name too longERROR: File name too long\n\n\n\nIt has already hapenned once with bash and agin now that I have switched to zsh.\nI don’t see snap apps from nautilus (for example to edit a text file with sublime-text)\nOption was to ensure to have XDG_DATA_DIRS variable set up. But here it doesn’t help.\nhttps://askubuntu.com/questions/910821/programs-installed-via-snap-not-showing-up-in-launcher"
  },
  {
    "objectID": "posts/2023-03-01-logbook-March-23.html#wednesday-0308",
    "href": "posts/2023-03-01-logbook-March-23.html#wednesday-0308",
    "title": "Logbook for March 23",
    "section": "Wednesday 03/08",
    "text": "Wednesday 03/08\n\nhomebrew brew\nRunning through gitlab news, I have met glabwhich is a CLI for gitlab\n\nand it installs through brew.\nBrew is a package manager for macos, linux, windows.\nI followed this doc https://www.how2shout.com/linux/install-brew-on-wsl-windows-subsystem-for-linux/ to install it\n/bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\"    \n\n#and add this to .zshrc\neval $(/home/linuxbrew/.linuxbrew/bin/brew shellenv)\n\n#you can then test it\n&gt; brew doctor\nYour system is ready to brew.\n\n\nglab\nbrew install glab\nhttps://ghcr.io/v2/homebrew/core/glab/manifests/1.25.3 unfortunately not accessible from my PC (blocked by company policy)"
  },
  {
    "objectID": "posts/2023-03-01-logbook-March-23.html#friday-0310",
    "href": "posts/2023-03-01-logbook-March-23.html#friday-0310",
    "title": "Logbook for March 23",
    "section": "Friday 03/10",
    "text": "Friday 03/10\n3rd video from S.Mallat: will have to rewatch the last part after Entropie Differentielle. His description is exactly what I try to undertsand in my project."
  },
  {
    "objectID": "posts/2023-04-01-logbook-April-23.html",
    "href": "posts/2023-04-01-logbook-April-23.html",
    "title": "Logbook for April 23",
    "section": "",
    "text": "Display week number in ubuntu calendar widget\ngsettings set org.gnome.desktop.calendar show-weekdate true\n\n\n\nimage.png\n\n\n(before)\n\n\n\nimage.png\n\n\n(after)\n\n\n\nafter March-24 [2023] I have this message when dealing with github.com\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the RSA key sent by the remote host is\nSHA256:uNiVztksCsDhcc0u9e8BujQXVUpKZIDTMczCvj3tD2s.\nPlease contact your system administrator.\nAdd correct host key in /home/explore/.ssh/known_hosts to get rid of this message.\nOffending RSA key in /home/explore/.ssh/known_hosts:1\n  remove with:\n  ssh-keygen -f \"/home/explore/.ssh/known_hosts\" -R \"github.com\"\nHost key for github.com has changed and you have requested strict checking.\nHost key verification failed.\nfatal: Could not read from remote repository.\nThis is explained at\ngit - “Warning: Remote Host Identification Has Changed” — Did GitHub change their RSA key? - Stack Overflow\n\nFrom Github:\n\nAt approximately 05:00 UTC on March 24 [2023], out of an abundance of caution, we replaced our RSA SSH host key used to secure Git operations for GitHub.com. We did this to protect our users from any chance of an adversary impersonating GitHub or eavesdropping on their Git operations over SSH. This key does not grant access to GitHub’s infrastructure or customer data. This change only impacts Git operations over SSH using RSA. Web traffic to GitHub.com and HTTPS Git operations are not affected.\n\nSOLUTION: Remove old RSA SSH key of github from .ssh/ known_hosts and update the new one.\n\nAnd I fixed it y running\nssh-keygen -R github.com\n\n\n\n\n\n\n1.1.7 has been released and it fixes my icons issue.\nUnfortunately a side effect is Starting GUI apps takes longer with new version\n(update April/11) sarim suggests to create these links ln -s /mnt/wslg/runtime-dir/wayland-0* /run/user/1000/. And then I deleted them due to side effects but at the end it fixed it anyway.\n\n\n\n\n\n\n1.2.0 released and installed\nStill this side effect\n\n\n\n\nannouncement on fatsai blog\nPractical Deep Learning for Coders - Part 2 homepage\n\n (tweet from jeremy)\nI know what I will do in the following weeks !"
  },
  {
    "objectID": "posts/2023-04-01-logbook-April-23.html#sunday-0402",
    "href": "posts/2023-04-01-logbook-April-23.html#sunday-0402",
    "title": "Logbook for April 23",
    "section": "",
    "text": "Display week number in ubuntu calendar widget\ngsettings set org.gnome.desktop.calendar show-weekdate true\n\n\n\nimage.png\n\n\n(before)\n\n\n\nimage.png\n\n\n(after)\n\n\n\nafter March-24 [2023] I have this message when dealing with github.com\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\n@    WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED!     @\n@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\nIT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY!\nSomeone could be eavesdropping on you right now (man-in-the-middle attack)!\nIt is also possible that a host key has just been changed.\nThe fingerprint for the RSA key sent by the remote host is\nSHA256:uNiVztksCsDhcc0u9e8BujQXVUpKZIDTMczCvj3tD2s.\nPlease contact your system administrator.\nAdd correct host key in /home/explore/.ssh/known_hosts to get rid of this message.\nOffending RSA key in /home/explore/.ssh/known_hosts:1\n  remove with:\n  ssh-keygen -f \"/home/explore/.ssh/known_hosts\" -R \"github.com\"\nHost key for github.com has changed and you have requested strict checking.\nHost key verification failed.\nfatal: Could not read from remote repository.\nThis is explained at\ngit - “Warning: Remote Host Identification Has Changed” — Did GitHub change their RSA key? - Stack Overflow\n\nFrom Github:\n\nAt approximately 05:00 UTC on March 24 [2023], out of an abundance of caution, we replaced our RSA SSH host key used to secure Git operations for GitHub.com. We did this to protect our users from any chance of an adversary impersonating GitHub or eavesdropping on their Git operations over SSH. This key does not grant access to GitHub’s infrastructure or customer data. This change only impacts Git operations over SSH using RSA. Web traffic to GitHub.com and HTTPS Git operations are not affected.\n\nSOLUTION: Remove old RSA SSH key of github from .ssh/ known_hosts and update the new one.\n\nAnd I fixed it y running\nssh-keygen -R github.com"
  },
  {
    "objectID": "posts/2023-04-01-logbook-April-23.html#tuesday-0404",
    "href": "posts/2023-04-01-logbook-April-23.html#tuesday-0404",
    "title": "Logbook for April 23",
    "section": "",
    "text": "1.1.7 has been released and it fixes my icons issue.\nUnfortunately a side effect is Starting GUI apps takes longer with new version\n(update April/11) sarim suggests to create these links ln -s /mnt/wslg/runtime-dir/wayland-0* /run/user/1000/. And then I deleted them due to side effects but at the end it fixed it anyway."
  },
  {
    "objectID": "posts/2023-04-01-logbook-April-23.html#wednesday-0405",
    "href": "posts/2023-04-01-logbook-April-23.html#wednesday-0405",
    "title": "Logbook for April 23",
    "section": "",
    "text": "1.2.0 released and installed\nStill this side effect\n\n\n\n\nannouncement on fatsai blog\nPractical Deep Learning for Coders - Part 2 homepage\n\n (tweet from jeremy)\nI know what I will do in the following weeks !"
  },
  {
    "objectID": "posts/2023-04-01-logbook-April-23.html#friday-0421",
    "href": "posts/2023-04-01-logbook-April-23.html#friday-0421",
    "title": "Logbook for April 23",
    "section": "Friday 04/21",
    "text": "Friday 04/21\n\nwsl upgrade\n1.2.5 released and installed\nIssue Starting GUI apps takes longer with new version fixed\nIssue WSL some icons in taskbar for linux applications are defaulting to Tux back\nand a new issue when starting sublime-text (kill the session), I should open a ticket\n\n\nsnap\nStrange that we need sudo to install snap apps.\nFound this https://forum.snapcraft.io/t/sudo-snap-install-or-just-snap-install/3909 that explains that sudo snap login is needed then snap can be used without sudo. Should try that but it requires an Ubuntu account."
  },
  {
    "objectID": "posts/2023-04-01-logbook-April-23.html#monday-0424",
    "href": "posts/2023-04-01-logbook-April-23.html#monday-0424",
    "title": "Logbook for April 23",
    "section": "Monday 04/24",
    "text": "Monday 04/24\n\nwsl crash with sublime-text\nIssue opened: https://github.com/microsoft/wslg/issues/1051"
  },
  {
    "objectID": "posts/2023-04-01-logbook-April-23.html#wednesday-426",
    "href": "posts/2023-04-01-logbook-April-23.html#wednesday-426",
    "title": "Logbook for April 23",
    "section": "Wednesday 4/26",
    "text": "Wednesday 4/26\n\nautoencoder day\nI have kept the full day to work on autoencoders and specially conditional VAE.\nI would like to update latent space structure based on a different information, and I have found a nice paper explaining such an approach Variational AutoEncoder For Regression: Application to Brain Aging Analysis. There is a tensorflow-keras implementation located at VAE for Regression\nKL divergence\nTime to get closer look to KL divergence, and this source is a good starting point. As I had understood, there is a direct link with entropy. KL divergence is a way to calculate how much information is lost when we approximate one distribution with another.\nbayesian statistics\nThis site suggests a book to learn about bayesian statistics. May be a good idea to go through it: https://nostarch.com/learnbayes\nVAE And a starting point for VAE from arxiv: Tutorial on Variational Autoencoders\nmonte carlo simulation\nThis points to an introduction to monte carlo simulation using R\nmakov-chain optimization\nAnd even the optimization of markov-chain using linear algebra Understanding Markov Chains with the Black Friday Puzzle\ncountbayesie\nVery complete site to have a global overview of such techniques.\nThere is a blog (and rss feed) at https://www.countbayesie.com/. (added to feedly)\nPyro and probabilistic programming language (PPL)\nBy going through these resources, they mention Edward which is a library to run these experimentations in python using tensorflow/keras. There is a paper around these techniques Deep Probabilistic Programming.\nBy looking for something more modern, using pytorch, I found Pyro.ai which has tons of content: &gt; Pyro is a universal probabilistic programming language (PPL) written in Python and supported by PyTorch on the backend. Pyro enables flexible and expressive deep probabilistic modeling, unifying the best of modern deep learning and Bayesian modeling. It was designed with these key principles:\nI would like later to go through Pyro examples, and apply some of the examples in my data. For example there is something about conditional VAE."
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html",
    "title": "WSL2 on a fresh new PC",
    "section": "",
    "text": "As an example from T15Gen2, corporate mastered.\nThis procedure needs admin rights on 2 steps (install nvidia drivers, activate wsl)\nAnd if based on WSL from Windows store (wsl --version&gt;=1.0), lots of new features such as systemd, snap, integrated display, etc. Detailed in WSL2 from Windows Store"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#install-windows-terminal",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#install-windows-terminal",
    "title": "WSL2 on a fresh new PC",
    "section": "install Windows Terminal",
    "text": "install Windows Terminal\nJust install Windows Terminal from Windows Store at https://aka.ms/terminal\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#download-nvidia-driver",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#download-nvidia-driver",
    "title": "WSL2 on a fresh new PC",
    "section": "download Nvidia driver",
    "text": "download Nvidia driver\nTo get drivers in link to cuda versions:\nhttps://developer.nvidia.com/cuda-toolkit-archive\n\n\n\nimage.png\n\n\n(Jan-18 23: cuda 11.7.1 using cuda_11.7.1_516.94_windows.exe)\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 515.65.01    Driver Version: 516.94       CUDA Version: 11.7     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  On   | 00000000:01:00.0  On |                  N/A |\n| N/A   54C    P8    18W /  N/A |    274MiB / 16384MiB |      1%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#download-ubuntu-lts-image",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#download-ubuntu-lts-image",
    "title": "WSL2 on a fresh new PC",
    "section": "download Ubuntu LTS image",
    "text": "download Ubuntu LTS image\nDownload from https://cloud-images.ubuntu.com/daily/server/wsl/\nThis address may change (search for « cloud wsl ubuntu images »)\n\n\n\nimage.png\n\n\n(Dec-22: this file ubuntu-jammy-wsl-amd64-wsl.rootfs.tar.gz)"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#install-nvidia-driver",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#install-nvidia-driver",
    "title": "WSL2 on a fresh new PC",
    "section": "install Nvidia driver",
    "text": "install Nvidia driver\nas admin, install the driver"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#install-ubuntu-in-wsl",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#install-ubuntu-in-wsl",
    "title": "WSL2 on a fresh new PC",
    "section": "install Ubuntu in WSL",
    "text": "install Ubuntu in WSL\n\nactivate WSL\nas admin, open windows terminal, and run\nwsl --install\nwsl --set-default-version 2\n\n\nupdate WSL, upgrade WSL\nI am closely following new updates from WSL and WSLg at https://github.com/microsoft/WSL/releases\nTo know which version we use, run wsl --version in Powershell.\nAnd to upgrade to the latest version, run wsl --update --pre-release\n\n\ninstall Ubuntu LTS\nfollowing instructions from install ubuntu 22.04 on WSL # Automatic setup.\nAnd here are the steps\nCreate 2 folders: C:\\wsl\\Ubuntu-22.04\\download, C:\\wsl\\Ubuntu-22.04\\instance\nMove ubuntu-jammy-wsl-amd64-wsl.rootfs.tar.gz in C:\\wsl\\Ubuntu-22.04\\download\nCopy scripts setup_wsl_root.sh and setup_wsl_user.sh to C:\\wsl\\Ubuntu-22.04\\download\n\ninstall wsl-vpnkit\nCopy wsl-vpnkit to C:\\wsl\\Ubuntu-22.04\\download (see https://dev.michelin.com/wsl2/fundamentals for more details)\nInstall wsl-vpnkit from Windows Terminal:\nwsl --import wsl-vpnkit $env:USERPROFILE\\wsl-vpnkit C:\\wsl\\ubuntu-22.04\\download\\wsl-vpnkit.tar.gz\nwsl -d wsl-vpnkit\nwsl -d wsl-vpnkit service wsl-vpnkit start\nIf wsl-vpnkit stopped unexpectedly, check logs with wsl.exe -d wsl-vpnkit --cd /app tail -f /var/log/wsl-vpnkit.log. If “cannot connect to host: fork/exec ./wsl-vpnkit/wsl-gvproxy.exe: exec format error” appears, apply this solution:\nsudo sh -c 'echo :WSLInterop:M::MZ::/init:PF &gt; /usr/lib/binfmt.d/WSLInterop.conf'\nsudo systemctl unmask systemd-binfmt.service\nsudo systemctl restart systemd-binfmt\nsudo systemctl mask systemd-binfmt.service\nMore details at logbook Aug 23\n\n\ninstall ubuntu and setup root\nInstall ubuntu-lts from Windows Terminal:\nwsl --import ubuntu-22.04 C:\\wsl\\ubuntu-22.04\\instance C:\\wsl\\ubuntu-22.04\\download\\ubuntu-jammy-wsl-amd64-wsl.rootfs.tar.gz\n# close windows terminal / launch it (ubuntu-22.04 entry should be added within it)\nwsl -d ubuntu-22.04 # or launch from Windows Terminal menu\ncd\ncp /mnt/c/wsl/Ubuntu-22.04/download/setup_wsl_* ~/\nchmod +x setup_wsl_root.sh\n./setup_wsl_root.sh\nProvide username, password and quit session with Ctrl-D\nFrom Windows Terminal, stop wsl with wsl -t ubuntu-22.04, a new profile for ubuntu-22.04 should have been automatically created in Windows Terminal\n\n\n\nimage.png\n\n\n\n\nsetup user\nStart ubuntu-22.04 by clicking the profile in Windows Terminal\nShould start with something like\n\n\n\nimage.png\n\n\nStep 2: accept default entries (type enter). Add the generated key to gitlab &gt; preferences &gt; SSH keys. And then resume.\nAt that stage this is a fully operating image of ubuntu (internet, apt)\n\n\n\nactivate systemd\nIf running wsl version &gt; 1.0, you can activate systemd\nModify /etc/wsl.conf with\n[boot]\nsystemd=true\nAnd restart wsl image (wsl -t ubuntu-22.04)\nTest that it works by running\nsystemctl list-unit-files --type=service\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#keep-config-files-in-git",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#keep-config-files-in-git",
    "title": "WSL2 on a fresh new PC",
    "section": "keep config files in git",
    "text": "keep config files in git\nI have explained how and why to do this step at keep dotfiles in git\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_00_config_files_in_git.sh | bash\nsource ~/.bashrc\nTODO: take branch name as a parameter. Meanwhile download the script and update branch name to something new"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#git-credential-manager-to-push-on-github",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#git-credential-manager-to-push-on-github",
    "title": "WSL2 on a fresh new PC",
    "section": "git credential manager to push on github",
    "text": "git credential manager to push on github\nThis is explained at git-credential-manager repo\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_06_git_credential_manager.sh | bash\nYou need to create a personal access token in github.\nAnd when pushing to a github repo, use this token as the password\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#optional-automount-secured-vbox",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#optional-automount-secured-vbox",
    "title": "WSL2 on a fresh new PC",
    "section": "(optional) automount secured vbox",
    "text": "(optional) automount secured vbox\nBecause I keep secured data within my secured disks mounted in windows (Z:, Y:, …)\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_01_automount_secured_vbox.sh | bash\nModify /etc/vbox.autofs to match your actual mounted disks. sudo service autofs start to start the service.\nif it fails, check that kernel is at least v5. uname -a. If not maybe in WSL 1 insted of WSL 2? (sudo automount -f -v should provide more information)\n\n#my vbox.autofs file\n!cat /etc/vbox.autofs\n\njanus   -fstype=drvfs,uid=1000,gid=1000 :Z:\n\n\nif systemd is activated, we can manage services with journalctl\n#restart autofs\nsudo systemctl restart autofs.service\n\n#read logs for autofs (-r: display last entries first)\n#to use it as user, add your user to adm group\n#sudo usermod -a -G adm &lt;your_username&gt;\njournalctl -r -u autofs\n\n#print warning\njournalctl -r -p warning\nother examples with journalctl:\nhttps://www.geeksforgeeks.org/journalctl-command-in-linux-with-examples/"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#python-with-conda-and-configure-base-environment-jupyterlab-mamba",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#python-with-conda-and-configure-base-environment-jupyterlab-mamba",
    "title": "WSL2 on a fresh new PC",
    "section": "python with conda and configure base environment (jupyterlab, mamba)",
    "text": "python with conda and configure base environment (jupyterlab, mamba)\nGive a look to script sources\n# install miniconda\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_02_install_python_conda_part1.sh | bash\nsource ~/.bashrc\n# install mamba\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_02_install_python_conda_part2.sh | bash\nsource ~/.bashrc\n# install certificates for Python\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_02_install_python_conda_part3.sh | bash\nsource ~/.bashrc\n# create base_jupyter environment\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_02_install_python_conda_part4.sh | bash\nsource ~/.bashrc"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#python-with-pip",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#python-with-pip",
    "title": "WSL2 on a fresh new PC",
    "section": "python with pip",
    "text": "python with pip\nGive a look to script sources\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_08_pip.sh | bash"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#jupyter-lab",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#jupyter-lab",
    "title": "WSL2 on a fresh new PC",
    "section": "jupyter lab",
    "text": "jupyter lab\nIn order to preserve base environment, I won’t install anything in it.\nI will create a base_jupyter env with what is needed for running jupyter lab. And create a jupyterlab service to automatically start jupyter lab with my distro (and stop/restart it)\nbase_jupyter\n\n!cat /home/guillaume/_conda_env/base_jupyter.txt\n\nconda remove --name base_jupyter --all\nmamba create -n base_jupyter python=3.9\nconda activate base_jupyter\nmamba install -c conda-forge jupyterlab\nmamba install -c conda-forge ipywidgets\njupyter labextension install jupyterlab-plotly\n\njupyter-lab --generate-config\n# in .jupyter/jupyter_lab_config.py\n# replace # c.ServerApp.use_redirect_file = True\n# with c.ServerApp.use_redirect_file = False\n# or get it from gitlab/JANUS/dotfiles\n\n\nmamba install -c conda-forge jupyterlab_execute_time\n\npip install azure-cli\n\n\njupyterlab as a service:\nFILE /etc/systemd/system/jupyterlab.service\n[Unit]\nDescription=Jupyter lab boot scriptJupyter lab boot script\nDefaultDependencies=no\nAfter=network.target\n\n[Service]\nType=simple\nUser=guillaume\nGroup=adm\n1Environment=\"LD_LIBRARY_PATH=/usr/lib/wsl/lib\"\nExecStart=/home/guillaume/bin/jupyterlab.sh\nExecStop=screen -X -S jupyter_screen kill\nTimeoutStartSec=0\nRemainAfterExit=yes\n\n[Install]\nWantedBy=default.target\n\n1\n\nThis is to allow execution of GPU instructions within jupyter lab\n\n\n\n!cat /home/guillaume/bin/jupyterlab\n\n#!/bin/bash\ncd ~\nsource ~/miniconda/etc/profile.d/conda.sh\nconda activate base_jupyter\njupyter lab\n\n\n\n!cat /home/guillaume/bin/jupyterlab.sh\n\n#!/bin/bash -x\nscreen -d -S \"jupyter_screen\" -m ~guillaume/bin/jupyterlab\n\n\n\n!cat /home/guillaume/bin/jupyterlab_stop.sh\n\n#!/bin/bash -x\nscreen -X -S jupyter_screen kill\n\n\nThen enable this service\nchmod +x /home/guillaume/bin/jupyterlab.sh\nsudo systemctl daemon-reload\nsudo systemctl enable jupyterlab.service\nsudo systemctl restart jupyterlab.service\nand to monitor logs of this service\njournalctl -xefu jupyterlab\nJust pointing to http://localhost:8888/lab\nand if you want we can add an alias alias jl='/home/guillaume/bin/jupyterlab.sh' in .bash_aliases"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#optional-zsh-oh-my-zsh-powerlevel10k",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#optional-zsh-oh-my-zsh-powerlevel10k",
    "title": "WSL2 on a fresh new PC",
    "section": "(optional) zsh oh-my-zsh powerlevel10k",
    "text": "(optional) zsh oh-my-zsh powerlevel10k\nfollowing https://medium.com/@satriajanaka09/setup-zsh-oh-my-zsh-powerlevel10k-on-ubuntu-20-04-c4a4052508fd\nInstall zsh\nsudo apt install zsh\nzsh --version\n#set as default shell for current user\nchsh -s /usr/bin/zsh\nSome settings to be set to start wsl-vpnkit with my user with zsh.\ntee ~/.zprofile &lt;&lt; EOF\nemulate sh\n. ~/.profile\nemulate zsh\nEOF\nHere I have to restart ubuntu and wsl-vpnkit. (from powershell wsl --shutdown) and check network is fine (e.g. wget https://wwww.google.com)\nInstall oh-my-zsh\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\nSwitch to other theme - agnoster Change ZSH_THEME=“agnoster” And apply change exec zsh\nInstall fonts\nsudo apt-get install fonts-powerline\n\n\n\nimage.png\n\n\nLoad bash aliases\ntee -a ~/.zshrc &lt;&lt; EOF\nsource $HOME/.bash_aliases\nEOF\nUpdate PATH and other variables\ntee -a ~/.zshrc &lt;&lt; EOF\nexport OPENSSL_CONF=/etc/ssl/openssl.cnf\nsudo /usr/sbin/service autofs start\nexport REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\nexport SSL_CERT_FILE=/home/guillaume/miniconda/lib/python3.9/site-packages/certifi/cacert.pem\nexport BROWSER='chrome.exe'\nexport PATH=$PATH:\"/mnt/c/Program Files/Google/Chrome/Application:/home/guillaume/miniconda/condabin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/usr/lib/wsl/lib:/mnt/c/Program Files (x86)/Java/jre8/bin:/mnt/c/ProgramData/Oracle/Java/javapath:/mnt/c/WINDOWS/system32:/mnt/c/WINDOWS:/mnt/c/WINDOWS/System32/Wbem:/mnt/c/WINDOWS/System32/WindowsPowerShell/v1.0:/mnt/c/WINDOWS/System32/OpenSSH:/mnt/c/Program Files/SafeNet/Authentication/SAC/x64:/mnt/c/Program Files/SafeNet/Authentication/SAC/x32:/mnt/c/Program Files (x86)/NVIDIA Corporation/PhysX/Common:/mnt/c/Users/f279814/AppData/Local/Microsoft/WindowsApps:/snap/bin:/home/guillaume/bin\"\nexport PATH=$PATH:\"/mnt/c/Users/f279814/AppData/Local/Programs/Microsoft VS Code/bin\"\n\nexport GPG_TTY=$(tty)\nexport DISPLAY=:0\n\n# Could not load library libcudnn_cnn_infer.so.8. Error: libcuda.so: cannot open shared object file: No such file or directory\nexport LD_LIBRARY_PATH=/usr/lib/wsl/lib\n\nEOF\nDouble check PATH env\nInstall power10klevel\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k\nand update in .zshrc ZSH_THEME=\"powerlevel10k/powerlevel10k\"\nInstall fonts for power10klevel https://github.com/romkatv/powerlevel10k#manual-font-installation\nCould need installation of font-manager sudo apt install font-manager And install them in windows as well to have it properly rendered in Windows Terminal https://sicse.dev/blog/wsl-2-prompt-powerlevel10k-theme\nManually configure or get a version from dotfiles\nInstall plugins\n#zsh autosuggestions\ngit clone https://github.com/zsh-users/zsh-autosuggestions ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-autosuggestions\n\n#zsh syntax highlighting\ngit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ${ZSH_CUSTOM:-~/.oh-my-zsh/custom}/plugins/zsh-syntax-highlighting\n\nand in .zshrc\nplugins=(git zsh-autosuggestions zsh-syntax-highlighting python history)"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#snapd",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#snapd",
    "title": "WSL2 on a fresh new PC",
    "section": "snapd",
    "text": "snapd\nUpgrade snap\nsudo apt-get -y upgrade snapd\nCheck it is running\n$ snap list\nName    Version        Rev    Tracking       Publisher   Notes\ncore20  20220318       1405   latest/stable  canonical✓  base\nlxd     5.0.0-b0287c1  22923  5.0/stable/…   canonical✓  -\nsnapd   2.55.3         15534  latest/stable  canonical✓  snapd"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#firefox",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#firefox",
    "title": "WSL2 on a fresh new PC",
    "section": "firefox",
    "text": "firefox\nAnd install firefox\nsudo snap install firefox\n# due to a bug when opening settings\n# https://answers.launchpad.net/ubuntu/+question/701403https://answers.launchpad.net/ubuntu/+question/701403\nsudo apt install xdg-desktop-portal-gtk\n\n\n\nimage.png\n\n\nTo allow external websites, import this certificate /usr/local/share/ca-certificates/cert_M_X5C_sase-mob-sslfwd-trust-ca.crt in the certificate manager\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#nautilus",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#nautilus",
    "title": "WSL2 on a fresh new PC",
    "section": "nautilus",
    "text": "nautilus\nAnd install nautilus\nsudo apt install nautilus nautilus-extension-gnome-terminal\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#sublime-text",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#sublime-text",
    "title": "WSL2 on a fresh new PC",
    "section": "sublime text",
    "text": "sublime text\nI like this text editor even if it is not exactly opensource.\nI may even buy a license later.\nAnyway I will use the snap version\nsudo snap install sublime-text --classic\nand because of this issue from WSLg WSL some icons in taskbar for linux applications are defaulting to Tux, I add this\ncd /var/lib/snapd/desktop/applications\nsudo ln -s sublime-text_subl.desktop  sublime_text.desktop\ncd ~/bin\ntouch sublime_text\nchmod +x sublime_text\ntee sublime_text &lt;&lt; EOF\n#!/bin/bash\nenv BAMF_DESKTOP_FILE_HINT=/var/lib/snapd/desktop/applications/sublime-text_subl.desktop /snap/bin/sublime-text.subl --launch-or-new-window\nEOF\nLaunching sublime_text in command line should open sublime_text with matching icon in taskbar. The same when right clicking a text file in nautilus and editing with sublime text."
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#gnome-tweaks-and-yaru-theme",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#gnome-tweaks-and-yaru-theme",
    "title": "WSL2 on a fresh new PC",
    "section": "gnome-tweaks and yaru theme",
    "text": "gnome-tweaks and yaru theme\nsudo add-apt-repository univ\nsudo apt-get -y install gnome-tweaks\nsudo apt-get -y install yaru-theme-gtk\nsudo apt-get -y install yaru-theme-icon\n\n\n\nimage.png\n\n\nAnd impact on nautilus is directly visible\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#tilix",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#tilix",
    "title": "WSL2 on a fresh new PC",
    "section": "tilix",
    "text": "tilix\ntilix is a terminal with split windows integrated (as with tmux or screen or vi)\nsudo apt install tilix\nuse zsh / powerlevel10k fonts sandwich &gt; Preferences &gt; Profiles / Default &gt; Text Appearance / Custom Font &gt; MesloLGS NF Regular\nupdate Copy/Paste shortcuts sandwich &gt; Preferences &gt; Shortcuts &gt; Copy (Ctrl-C) and Paste (Ctrl-V) as for other terminals, interrupt is now Shift-Ctrl-C\nvte config as explained in https://gnunn1.github.io/tilix-web/manual/vteconfig/ add this in .zshrc\nif [ $TILIX_ID ] || [ $VTE_VERSION ]; then\n        source /etc/profile.d/vte.sh\nfi\nand create this symlink\nln -s /etc/profile.d/vte-2.91.sh /etc/profile.d/vte.sh"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#gimp",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#gimp",
    "title": "WSL2 on a fresh new PC",
    "section": "gimp",
    "text": "gimp\nAnd install gimp\nsudo apt install gimp"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#zotero",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#zotero",
    "title": "WSL2 on a fresh new PC",
    "section": "zotero",
    "text": "zotero\nsnap find zotero\nName         Version  Publisher   Notes  Summary\nzotero-snap  6.0.18   extraymond  -      Zotero helps you collect, organize, cite, and share research.\nqnotero      2.3.1    ealbiter    -      Standalone sidekick to Zotero reference manager.\nzotviewer    1.5.0    fvalle      -      Zotero Visualizer\n\nsudo snap install zotero-snap\nzotero-snap 6.0.18 from extraymond installed\nand there is something to do to activate sync: https://github.com/extraymond/zotero-snap/issues/29\nFIREFOX_PROFILE=`find ~/snap/firefox/common/.mozilla/ -name *.default`\nZOTERO_PROFILE=`find ~/snap/zotero-snap/common/.zotero/ -name *.default`\ncp $FIREFOX_PROFILE/cert9.db $ZOTERO_PROFILE\ncp $FIREFOX_PROFILE/key4.db $ZOTERO_PROFILE\ncp $FIREFOX_PROFILE/pkcs11.txt $ZOTERO_PROFILE"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#pdf-support",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#pdf-support",
    "title": "WSL2 on a fresh new PC",
    "section": "pdf support",
    "text": "pdf support\n#acrobat reader (which uses wine)\nsudo snap install acrordrdc\n\n#evince universal documen reader for ubuntu\nsudo apt install evince"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#install-test-distro-from-scratch",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#install-test-distro-from-scratch",
    "title": "WSL2 on a fresh new PC",
    "section": "install test distro from scratch",
    "text": "install test distro from scratch\nfrom powershell\nwsl --import ubuntu-x11 C:\\wsl\\Ubuntu-22.04_X11\\instance C:\\wsl\\Ubuntu-22.04_X11\\download\\ubuntu-jammy-wsl-amd64-wsl.rootfs.tar.gz\nwsl -d ubuntu-x11\ncd\ncp /mnt/c/wsl/Ubuntu-22.04_X11/download/setup_wsl_* ~/\nchmod +x setup_wsl_root.sh\n./setup_wsl_root.sh\nfrom powershell\nwsl -t ubuntu-x11\nstart ubuntu-x11 from windows terminal menu\nand enter informations requested (ssh keys (paste to gitlab), update certificates (enter password)). Other steps are automatic.\nOther steps: - activate systemd (by modifying /etc/wsl.conf) - restart"
  },
  {
    "objectID": "posts/2022-12-15-wsl2-fresh-pc.html#activate-gnome-session-and-launch-gnome-shell",
    "href": "posts/2022-12-15-wsl2-fresh-pc.html#activate-gnome-session-and-launch-gnome-shell",
    "title": "WSL2 on a fresh new PC",
    "section": "activate gnome-session and launch gnome-shell",
    "text": "activate gnome-session and launch gnome-shell\nHere we have a fully working distro. And we will test what is suggested at : https://askubuntu.com/a/1445415\n\nCreate the file /etc/pam.d/system/systemd-user\nRestart distro\nsudo apt install ubuntu-desktop acpi-support-\nprevent gdm service to start\n\nsudo systemctl stop gdm.service\nsudo systemctl disable gdm.service\n\nactivate x11 config at boot\n\nsudo systemctl is-enabled rc-local.service\n(if static it means it has be activated)\nsudo systemctl enable rc-local.service\n#create rc.local file\nsudo vi /etc/rc.local\n\n#!/bin/sh -e\nmount -o rw,remount /tmp/.X11-unix/\nchmod +t /tmp/.X11-unix\nchmod o+rw /dev/dri/renderD128\n/usr/libexec/at-spi-bus-launcher --launch-immediately &\nexit 0\n\n#save & exit\nsudo chmod 700 /etc/rc.local\n\nsudo usermod -a -G adm guillaume\nRestart distro\nlaunch XDG_SESSION_TYPE=x11 gnome-session --disable-acceleration-check --session=ubuntu --systemd-service &gt; /dev/null 2&gt;&1 (this can be added to .bashrc or as a service)\n\nand then\n\nMUTTER_DEBUG_DUMMY_MODE_SPECS=1920x1080 gnome-shell --nested --no-x11 2&gt; /dev/null &\n\n\n\n\nimage.png\n\n\nThen we can start it by running gnomeshell.sh\ncat bin/gnomeshell.sh\n#!/bin/bash\nMUTTER_DEBUG_DUMMY_MODE_SPECS=1920x1080 gnome-shell --nested --no-x11 2&gt; /dev/null &"
  },
  {
    "objectID": "posts/2022-10-06-pip_cheatsheet.html",
    "href": "posts/2022-10-06-pip_cheatsheet.html",
    "title": "pip cheatsheet",
    "section": "",
    "text": "I like this version\nhttp://dcjtech.info/wp-content/uploads/2015/10/Pip-Cheatsheet.pdf\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-10-06-pip_cheatsheet.html#install-last-versions",
    "href": "posts/2022-10-06-pip_cheatsheet.html#install-last-versions",
    "title": "pip cheatsheet",
    "section": "install last versions",
    "text": "install last versions\nDidn’t know that to specify to install at least a given version, one need quotes\npip install 'PKG&gt;=1.0'"
  },
  {
    "objectID": "posts/2022-10-06-pip_cheatsheet.html#freeze",
    "href": "posts/2022-10-06-pip_cheatsheet.html#freeze",
    "title": "pip cheatsheet",
    "section": "freeze",
    "text": "freeze\nto generate requirements.txt\n\n!pip freeze &gt; ~/temp/requirements.txt\n\n\n!cat ~/temp/requirements.txt\n\ncertifi @ file:///opt/conda/conda-bld/certifi_1663615672595/work/certifi\nnumpy==1.23.3\npandas==1.4.0\npython-dateutil==2.8.2\npytz==2022.4\nsix==1.16.0"
  },
  {
    "objectID": "posts/2022-10-06-pip_cheatsheet.html#pip-upgrader",
    "href": "posts/2022-10-06-pip_cheatsheet.html#pip-upgrader",
    "title": "pip cheatsheet",
    "section": "pip-upgrader",
    "text": "pip-upgrader\nPlaying with pip-upgrader\n\nimport sys\n!{sys.executable} -m pip install pip-upgrader\n\nLooking in indexes: https://pypi.org/simple/, https://artifactory.michelin.com/api/pypi/pypi/simple\nCollecting pip-upgrader\n  Using cached https://artifactory.michelin.com/api/pypi/pypi/packages/packages/b2/42/36c09ad93ddbf10406e301f3d4d7d063cf27fa5cf7a881ccea78bb22cdc7/pip_upgrader-1.4.15-py2.py3-none-any.whl (16 kB)\nCollecting packaging\n  Using cached https://artifactory.michelin.com/api/pypi/pypi/packages/packages/05/8e/8de486cbd03baba4deef4142bd643a3e7bbe954a784dc1bb17142572d127/packaging-21.3-py3-none-any.whl (40 kB)\nCollecting requests\n  Using cached https://artifactory.michelin.com/api/pypi/pypi/packages/packages/ca/91/6d9b8ccacd0412c08820f72cebaa4f0c0441b5cda699c90f618b6f8a1b42/requests-2.28.1-py3-none-any.whl (62 kB)\nCollecting colorclass\n  Using cached https://artifactory.michelin.com/api/pypi/pypi/packages/packages/30/b6/daf3e2976932da4ed3579cff7a30a53d22ea9323ee4f0d8e43be60454897/colorclass-2.2.2-py2.py3-none-any.whl (18 kB)\nCollecting docopt\n  Using cached docopt-0.6.2-py2.py3-none-any.whl\nCollecting terminaltables\n  Using cached https://artifactory.michelin.com/api/pypi/pypi/packages/packages/c4/fb/ea621e0a19733e01fe4005d46087d383693c0f4a8f824b47d8d4122c87e0/terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\nCollecting pyparsing!=3.0.5,&gt;=2.0.2\n  Using cached https://artifactory.michelin.com/api/pypi/pypi/packages/packages/6c/10/a7d0fa5baea8fe7b50f448ab742f26f52b80bfca85ac2be9d35cdd9a3246/pyparsing-3.0.9-py3-none-any.whl (98 kB)\nCollecting urllib3&lt;1.27,&gt;=1.21.1\n  Using cached https://artifactory.michelin.com/api/pypi/pypi/packages/packages/6f/de/5be2e3eed8426f871b170663333a0f627fc2924cc386cd41be065e7ea870/urllib3-1.26.12-py2.py3-none-any.whl (140 kB)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /home/guillaume/miniconda/envs/poubelle/lib/python3.9/site-packages (from requests-&gt;pip-upgrader) (2022.9.14)\nCollecting charset-normalizer&lt;3,&gt;=2\n  Using cached https://artifactory.michelin.com/api/pypi/pypi/packages/packages/db/51/a507c856293ab05cdc1db77ff4bc1268ddd39f29e7dc4919aa497f0adbec/charset_normalizer-2.1.1-py3-none-any.whl (39 kB)\nCollecting idna&lt;4,&gt;=2.5\n  Using cached https://artifactory.michelin.com/api/pypi/pypi/packages/packages/fc/34/3030de6f1370931b9dbb4dad48f6ab1015ab1d32447850b9fc94e60097be/idna-3.4-py3-none-any.whl (61 kB)\nInstalling collected packages: docopt, urllib3, terminaltables, pyparsing, idna, colorclass, charset-normalizer, requests, packaging, pip-upgrader\nSuccessfully installed charset-normalizer-2.1.1 colorclass-2.2.2 docopt-0.6.2 idna-3.4 packaging-21.3 pip-upgrader-1.4.15 pyparsing-3.0.9 requests-2.28.1 terminaltables-3.1.10 urllib3-1.26.12\n\n\n\n!{sys.prefix}/bin/pip-upgrade --skip-package-installation ~/temp/requirements.txt\n\nFound valid requirements file(s): \n/home/guillaume/temp/requirements.txt\nSetting API url to https://pypi.org/simple/{package}/ as found in /home/guillaume/.config/pip/pip.conf. Use --default-index-url to use pypi default index\n2/6: numpy ... up to date: 1.23.3\n3/6: pandas ... upgrade available: 1.4.0 ==&gt; 1.5.0 (uploaded on -)\n4/6: python-dateutil ... up to date: 2.8.2\n5/6: pytz ... up to date: 2022.4\n6/6: six ... up to date: 1.16.0\n\nAvailable upgrades:\n+-----+----------+-----------------+----------------+--------------+\n| No. | Package  | Current version | Latest version | Release date |\n+-----+----------+-----------------+----------------+--------------+\n|  1  |  pandas  | 1.4.0           | 1.5.0          | -            |\n+-----+----------+-----------------+----------------+--------------+\n\nPlease choose which packages should be upgraded. Choices: \"all\", \"q\" (quit), \"x\" (exit) or \"1 2 3\"\nChoice: ^C\n\nUpgrade interrupted."
  },
  {
    "objectID": "posts/2023-10-01-logbook-October-23.html",
    "href": "posts/2023-10-01-logbook-October-23.html",
    "title": "Logbook for October 23",
    "section": "",
    "text": "wsl cursor theme, fastai delegates getattr (delegated composition, delegated inheritance)"
  },
  {
    "objectID": "posts/2023-10-01-logbook-October-23.html#thursday-1012",
    "href": "posts/2023-10-01-logbook-October-23.html#thursday-1012",
    "title": "Logbook for October 23",
    "section": "Thursday 10/12",
    "text": "Thursday 10/12\nIn WSL, I have often this entry in kern.log\nGdk-Message: 08:21:35.347: Unable to load hand2 from the cursor theme\nIt is due to missing cursor icon hand2 in the default cursor theme. hand2 appears for example when you go other hyperlink (in console in my case).\nEasy way to fix it, open gnome-tweaks and select Yaru as cursor theme (under Appearance)"
  },
  {
    "objectID": "posts/2023-10-01-logbook-October-23.html#thursday-1019",
    "href": "posts/2023-10-01-logbook-October-23.html#thursday-1019",
    "title": "Logbook for October 23",
    "section": "Thursday 10/19",
    "text": "Thursday 10/19\nI have just seen in fastai code a decorator used in many places: delegates.\nWant to know what it does and why Jeremy used it? And luckily he explained that in Make Delegation Work in Python.\nAnd can be used for class\n\nfrom fastcore.meta import *\nimport inspect\n\nclass WebPage:\n    def __init__(self, title, category=\"General\", date=None, author=\"Jeremy\"):\n        self.title,self.category,self.author = title,category,author\n\n@delegates()\nclass ProductPage(WebPage):\n    def __init__(self, title, price, cost, **kwargs):\n        super().__init__(title, **kwargs)\n\nprint(inspect.signature(ProductPage))\n\n(title, price, cost, *, category='General', date=None, author='Jeremy')\n\n\nOr for functions\n\nfrom fastcore.meta import *\nimport inspect\n\ndef create_web_page(title, category=\"General\", date=None, author=\"Jeremy\"):\n    pass\n\n@delegates(create_web_page)\ndef create_product_page(title, cost, price=10, **kwargs):\n    pass\n\nprint(inspect.signature(create_product_page))\n\n(title, cost, price=10, *, category='General', date=None, author='Jeremy')\n\n\nAnd he explains when to use delegated inheritance or delegated composition.\n\nIf you’ll be using the composed object in a few different places, the delegated composition approach will probably be best. If you’re adding some functionality to an existing class, delegated inheritance might result in a cleaner API for your class users.\n\nIn case of delegated composition, Jeremy created GetAttr to allow easily access attributes from your composed class.\n\nfrom fastcore.basics import *\n\nclass ProductPage(GetAttr):\n    def __init__(self, page, price, cost):\n        self.page,self.price,self.cost = page,price,cost\n        self.default = page\npage = WebPage('Soap', category='Bathroom', author=\"Sylvain\")\n\np = ProductPage(page, 15.0, 10.50)\np.author\n\n'Sylvain'"
  },
  {
    "objectID": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html",
    "href": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html",
    "title": "Setup ubuntu box with fastai",
    "section": "",
    "text": "Get miniconda Linux installer.\nCheck sha256sum: sha256sum Miniconda3-latest-Linux-x86_64.sh\nRun install: ./Miniconda3-latest-Linux-x86_64.sh -p $HOME/miniconda3"
  },
  {
    "objectID": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#install-miniconda",
    "href": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#install-miniconda",
    "title": "Setup ubuntu box with fastai",
    "section": "",
    "text": "Get miniconda Linux installer.\nCheck sha256sum: sha256sum Miniconda3-latest-Linux-x86_64.sh\nRun install: ./Miniconda3-latest-Linux-x86_64.sh -p $HOME/miniconda3"
  },
  {
    "objectID": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#install-fastai",
    "href": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#install-fastai",
    "title": "Setup ubuntu box with fastai",
    "section": "Install fastai",
    "text": "Install fastai\nconda create -n fastai python=3.8\nconda activate fastai\nconda install -c fastai -c pytorch fastai"
  },
  {
    "objectID": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#install-jupyter-within-fastai-environment",
    "href": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#install-jupyter-within-fastai-environment",
    "title": "Setup ubuntu box with fastai",
    "section": "Install jupyter within fastai environment",
    "text": "Install jupyter within fastai environment\nconda activate fastai\nconda install jupyter"
  },
  {
    "objectID": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#test-fastai-installation-valid-for-v1",
    "href": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#test-fastai-installation-valid-for-v1",
    "title": "Setup ubuntu box with fastai",
    "section": "Test fastai installation (valid for v1)",
    "text": "Test fastai installation (valid for v1)\nWith fastai v1, there was an easy way to check installation:\nconda activate fastai\npython -m fastai.utils.show_install"
  },
  {
    "objectID": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#get-git-repo-to-learn-from-fastai",
    "href": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#get-git-repo-to-learn-from-fastai",
    "title": "Setup ubuntu box with fastai",
    "section": "get git repo to learn from fastai",
    "text": "get git repo to learn from fastai\nFrom git folder,\ngit clone https://github.com/fastai/fastai"
  },
  {
    "objectID": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#test-fastai-v2-installation",
    "href": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#test-fastai-v2-installation",
    "title": "Setup ubuntu box with fastai",
    "section": "Test fastai v2 installation",
    "text": "Test fastai v2 installation\nFrom python environment:\nfrom fastai.vision.all import *\nFrom jupyter notebook\n\nfrom fastai.vision.all import *"
  },
  {
    "objectID": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#install-nvidia-drivers-for-ubuntu",
    "href": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#install-nvidia-drivers-for-ubuntu",
    "title": "Setup ubuntu box with fastai",
    "section": "Install nvidia drivers for ubuntu",
    "text": "Install nvidia drivers for ubuntu\nI tried by downloading a driver from nvidia website. But I was unable to install it (nvidia-drm-drv.c:662:44: error: 'DRIVER_PRIME' undeclared here (not in a function); did you mean 'DRIVER_PCI_DMA'?)\nsudo ubuntu-drivers autoinstall\nthen rebooting fixed the issue."
  },
  {
    "objectID": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#run-courses-from-fastai-github-repo",
    "href": "posts/2020-09-23-setup-ubuntu-box-with-fastai.html#run-courses-from-fastai-github-repo",
    "title": "Setup ubuntu box with fastai",
    "section": "Run courses from fastai github repo",
    "text": "Run courses from fastai github repo\njust run fastai/dev_nbs/course/lesson1-pets.ipynb\nAnd everything is just fined ;)\n\ninstall nbdev\nThis is for rendering reasons: To get a prettier result with hyperlinks to source code and documentation, install nbdev: pip install nbdev\n\n!pip install nbdev\n\nCollecting nbdev\n  Downloading nbdev-1.0.18-py3-none-any.whl (57 kB)\n     |████████████████████████████████| 57 kB 1.5 MB/s eta 0:00:01\nRequirement already satisfied: fastcore&gt;=1.0.5 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (1.0.13)\nRequirement already satisfied: packaging in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (20.4)\nRequirement already satisfied: jupyter-client in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (6.1.6)\nRequirement already satisfied: nbconvert&lt;6 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.6.1)\nRequirement already satisfied: nbformat&gt;=4.4.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.0.7)\nCollecting fastscript&gt;=1.0.0\n  Downloading fastscript-1.0.0-py3-none-any.whl (11 kB)\nRequirement already satisfied: pyyaml in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.3.1)\nRequirement already satisfied: pip in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (20.2.2)\nRequirement already satisfied: ipykernel in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbdev) (5.3.4)\nRequirement already satisfied: pyparsing&gt;=2.0.2 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from packaging-&gt;nbdev) (2.4.7)\nRequirement already satisfied: six in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from packaging-&gt;nbdev) (1.15.0)\nRequirement already satisfied: pyzmq&gt;=13 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (19.0.2)\nRequirement already satisfied: tornado&gt;=4.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (6.0.4)\nRequirement already satisfied: python-dateutil&gt;=2.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (2.8.1)\nRequirement already satisfied: traitlets in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (4.3.3)\nRequirement already satisfied: jupyter-core&gt;=4.6.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jupyter-client-&gt;nbdev) (4.6.3)\nRequirement already satisfied: pandocfilters&gt;=1.4.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (1.4.2)\nRequirement already satisfied: pygments in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (2.7.1)\nRequirement already satisfied: mistune&lt;2,&gt;=0.8.1 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.8.4)\nRequirement already satisfied: defusedxml in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.6.0)\nRequirement already satisfied: bleach in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (3.2.1)\nRequirement already satisfied: jinja2&gt;=2.4 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (2.11.2)\nRequirement already satisfied: testpath in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.4.4)\nRequirement already satisfied: entrypoints&gt;=0.2.2 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbconvert&lt;6-&gt;nbdev) (0.3)\nRequirement already satisfied: jsonschema!=2.5.0,&gt;=2.4 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbformat&gt;=4.4.0-&gt;nbdev) (3.0.2)\nRequirement already satisfied: ipython-genutils in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from nbformat&gt;=4.4.0-&gt;nbdev) (0.2.0)\nRequirement already satisfied: ipython&gt;=5.0.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipykernel-&gt;nbdev) (7.18.1)\nRequirement already satisfied: decorator in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from traitlets-&gt;jupyter-client-&gt;nbdev) (4.4.2)\nRequirement already satisfied: webencodings in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from bleach-&gt;nbconvert&lt;6-&gt;nbdev) (0.5.1)\nRequirement already satisfied: MarkupSafe&gt;=0.23 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jinja2&gt;=2.4-&gt;nbconvert&lt;6-&gt;nbdev) (1.1.1)\nRequirement already satisfied: pyrsistent&gt;=0.14.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (0.17.3)\nRequirement already satisfied: attrs&gt;=17.4.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (20.2.0)\nRequirement already satisfied: setuptools in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jsonschema!=2.5.0,&gt;=2.4-&gt;nbformat&gt;=4.4.0-&gt;nbdev) (49.6.0.post20200814)\nRequirement already satisfied: backcall in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.2.0)\nRequirement already satisfied: pexpect&gt;4.3; sys_platform != \"win32\" in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (4.8.0)\nRequirement already satisfied: pickleshare in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.7.5)\nRequirement already satisfied: jedi&gt;=0.10 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.17.2)\nRequirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (3.0.7)\nRequirement already satisfied: ptyprocess&gt;=0.5 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from pexpect&gt;4.3; sys_platform != \"win32\"-&gt;ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.6.0)\nRequirement already satisfied: parso&lt;0.8.0,&gt;=0.7.0 in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from jedi&gt;=0.10-&gt;ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.7.0)\nRequirement already satisfied: wcwidth in /home/explore/miniconda3/envs/fastai/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,&lt;3.1.0,&gt;=2.0.0-&gt;ipython&gt;=5.0.0-&gt;ipykernel-&gt;nbdev) (0.2.5)\nInstalling collected packages: fastscript, nbdev\nSuccessfully installed fastscript-1.0.0 nbdev-1.0.18"
  },
  {
    "objectID": "posts/2023-02-01-logbook-February-23.html",
    "href": "posts/2023-02-01-logbook-February-23.html",
    "title": "Logbook for February 23",
    "section": "",
    "text": "Just watched Live coding session #4 from fastai\nJust watched video #2 of Stephane Mallat 2023.\nHere is a link to Elements of information theory by Thomas Cover and Joy Thomas, reading suggested by S. Mallat (~800 pages)\nJust watched Live coding session #5 from fastai\n\n\n\nReading comments in Live coding session #5 - forums, I felt on https://automatetheboringstuff.com/, and it reminds me these days where we try with my kids to learn Python by controling Minecraft.\nAnd there is an update about this which seems to run under PC version of Minecraft.\nhttps://inventwithpython.com/blog/2020/12/24/installing-the-computercraft-mod-for-minecraft-116-and-later/\n\n\n\nimage.png\n\n\nWould be a perfect activity for the next 2 weeks during shool break!\nhttps://www.curseforge.com/minecraft/mc-mods/cc-tweaked\nJust watched Live coding session #6 from fastai\n\n\nwsl --update --pre-release\n\nVersion WSL : 1.1.2.0\nVersion du noyau : 5.15.83.1\nVersion WSLg : 1.0.49\nVersion MSRDC : 1.2.3770\nVersion direct3D : 1.608.2-61064218\nVersion de DXCore : 10.0.25131.1002-220531-1700.rs-onecore-base2-hyp\nversion Windows : 10.0.19044.2486"
  },
  {
    "objectID": "posts/2023-02-01-logbook-February-23.html#wednesday-0201",
    "href": "posts/2023-02-01-logbook-February-23.html#wednesday-0201",
    "title": "Logbook for February 23",
    "section": "",
    "text": "Just watched Live coding session #4 from fastai\nJust watched video #2 of Stephane Mallat 2023.\nHere is a link to Elements of information theory by Thomas Cover and Joy Thomas, reading suggested by S. Mallat (~800 pages)\nJust watched Live coding session #5 from fastai"
  },
  {
    "objectID": "posts/2023-02-01-logbook-February-23.html#thursday-0202",
    "href": "posts/2023-02-01-logbook-February-23.html#thursday-0202",
    "title": "Logbook for February 23",
    "section": "",
    "text": "Reading comments in Live coding session #5 - forums, I felt on https://automatetheboringstuff.com/, and it reminds me these days where we try with my kids to learn Python by controling Minecraft.\nAnd there is an update about this which seems to run under PC version of Minecraft.\nhttps://inventwithpython.com/blog/2020/12/24/installing-the-computercraft-mod-for-minecraft-116-and-later/\n\n\n\nimage.png\n\n\nWould be a perfect activity for the next 2 weeks during shool break!\nhttps://www.curseforge.com/minecraft/mc-mods/cc-tweaked\nJust watched Live coding session #6 from fastai\n\n\nwsl --update --pre-release\n\nVersion WSL : 1.1.2.0\nVersion du noyau : 5.15.83.1\nVersion WSLg : 1.0.49\nVersion MSRDC : 1.2.3770\nVersion direct3D : 1.608.2-61064218\nVersion de DXCore : 10.0.25131.1002-220531-1700.rs-onecore-base2-hyp\nversion Windows : 10.0.19044.2486"
  },
  {
    "objectID": "posts/2023-02-01-logbook-February-23.html#monday-0206",
    "href": "posts/2023-02-01-logbook-February-23.html#monday-0206",
    "title": "Logbook for February 23",
    "section": "Monday 02/06",
    "text": "Monday 02/06\nJust watched Live coding session #7 from fastai\nFixed issue with kernel dying when using GPU in some cases. It was due to an env variable not setup. I need export LD_LIBRARY_PATH=/usr/lib/wsl/lib including in systemd jupyterlab service.\nMoved to quarto pre-release version to get access to code annotation. This is done by updating publish.yml\nindex 503ee47..9cda82b 100644\n--- a/.github/workflows/publish.yml\n+++ b/.github/workflows/publish.yml\n@@ -16,6 +16,8 @@ jobs:\n \n       - name: Set up Quarto\n         uses: quarto-dev/quarto-actions/setup@v2\n+        with:\n+          version: 'pre-release'\n \n       - name: Render and Publish\n         uses: quarto-dev/quarto-actions/publish@v2"
  },
  {
    "objectID": "posts/2023-02-01-logbook-February-23.html#saturday-0225",
    "href": "posts/2023-02-01-logbook-February-23.html#saturday-0225",
    "title": "Logbook for February 23",
    "section": "Saturday 02/25",
    "text": "Saturday 02/25\n\nweek number in ubuntu/calendar widget\nHow to Activate week number in calendar widget within gnome ubuntu:\ngsettings set org.gnome.desktop.calendar show-weekdate true\n\n\nla maison vivante\nI have started to listen to Tristan Nitot’s podcast L'octet vert: le podcast qui parle de climat, numérique, et qui file la pêche\nl’Octet vert\nFor each episode, there is a list of subjects discussed and some recommandations by guest (books, podcasts, blogs, …)\nThis morning I listened to S02E08 Ivan Enderlin et sa maison autonome\nI have to read his blog https://lamaisonvivante.blog/ which explains all steps to go from this crazy idea to a completely clean house.\nAnd he recommends to follow Jean-Marc Jancovici’s lectures at Ecole des Mines: 8 lectures of 2h30 each.\n\n\nzsh ohmyzsh powerlevel10k\nsudo apt install zsh\nsh -c \"$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n\n# https://github.com/romkatv/powerlevel10k\n\n# install fonts\nmkdir ~/.fonts\nwget https://github.com/romkatv/powerlevel10k-media/raw/master/MesloLGS%20NF%20Regular.ttf .fonts/\nfc-cache -fv\n\n#install powerlevel10k\ngit clone --depth=1 https://github.com/romkatv/powerlevel10k.git ~/powerlevel10k\necho 'source ~/powerlevel10k/powerlevel10k.zsh-theme' &gt;&gt;~/.zshrc\nexec zsh\np10k configure\n\n# https://medium.com/@satriajanaka09/setup-zsh-oh-my-zsh-powerlevel10k-on-ubuntu-20-04-c4a4052508fd\nand follow next stepx at https://medium.com/@satriajanaka09/setup-zsh-oh-my-zsh-powerlevel10k-on-ubuntu-20-04-c4a4052508fd\n\n\n\nimage.png\n\n\nWill have to modify jupyterlab.service with\nEnvironment=SHELL=/usr/bin/zsh"
  },
  {
    "objectID": "posts/2023-02-01-logbook-February-23.html#sunday-0226",
    "href": "posts/2023-02-01-logbook-February-23.html#sunday-0226",
    "title": "Logbook for February 23",
    "section": "Sunday 02/26",
    "text": "Sunday 02/26\nTo update snap-store: close it and\nsudo snap refresh snap-store\ncan’t believe we cannot do it from snap-store, and each time I have to search for it."
  },
  {
    "objectID": "posts/2023-02-01-logbook-February-23.html#monday-0227",
    "href": "posts/2023-02-01-logbook-February-23.html#monday-0227",
    "title": "Logbook for February 23",
    "section": "Monday 02/27",
    "text": "Monday 02/27\n\njupyterlab ctrl+v pastes the copied content twice\nas discussed https://github.com/jupyterlab/jupyterlab/issues/11639\nMay be fixed in v3.6.1, I am in v3.5.2. Updating…\nmamba update -c conda-forge jupyterlab\nsudo systemctl restart jupyterlab\nIt needs to rebuild stuff and for that needs node.js v14\ncurl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.1/install.sh | bash\nexec zsh\nnvm install lts/fermium\nnode -v\nand then build\njupyter lab build\nI had to manually uninstall jupyter lab plotly extension"
  },
  {
    "objectID": "posts/2022-09-01-logbook-September-22.html",
    "href": "posts/2022-09-01-logbook-September-22.html",
    "title": "Logbook for September 22",
    "section": "",
    "text": "Monday 9/5\n\nStart with fastai courses version 2022. Video of Lesson 1\n\nTuesday 9/6\nKeep backups on an external drive to upgrade PC. Using freefilesync.\n\nbackup files\nsbox\ngit (check with clustergit)\nwsl\n\n\nfrom WSL2 Backup and Restore Images using Import and Export\n# from PowerShell\nwsl --list\n&gt; Ubuntu (par défaut)\n&gt; ubuntu-docker\n&gt; ubuntu-18.04\n&gt; ubuntu-22.04\n&gt; wsl-vpnkit\n\nwsl --shutdown\n\nwsl --export &lt;Image Name&gt; &lt;Export location file name.tar&gt;\n\n\ninstalled apps\n\nwsl2, prtscr, vscode, jdiskreport (centre logiciel), accessdatabasenginex64, driver nvidia, freefilesync (centre logiciel), notepad++ (centre logiciel), keepass (centre logiciel), zotero (centre logiciel), Windows Terminal, barrier, GWSL, typora,\n\nversion windows - 21H2 19044.1889\ntree structure\n\nD:\\&gt; tree &gt; e:\\tree_structure.txt\nD:\\&gt; xcopy d: e:\\t /t /s\nWednesday 9/7\nFrom time to time when running screen from WSL I have the following error:\n$ screen -dR\nCannot make directory '/run/screen': Permission denied\nthen one can run\nsudo /etc/init.d/screen-cleanup start\nThurdsay 9/8\nRestore backups on this new PC and without administrator rights.\nInstall of wsl2 following corporate instructions"
  },
  {
    "objectID": "posts/2022-09-01-logbook-September-22.html#week-36---september-22",
    "href": "posts/2022-09-01-logbook-September-22.html#week-36---september-22",
    "title": "Logbook for September 22",
    "section": "",
    "text": "Monday 9/5\n\nStart with fastai courses version 2022. Video of Lesson 1\n\nTuesday 9/6\nKeep backups on an external drive to upgrade PC. Using freefilesync.\n\nbackup files\nsbox\ngit (check with clustergit)\nwsl\n\n\nfrom WSL2 Backup and Restore Images using Import and Export\n# from PowerShell\nwsl --list\n&gt; Ubuntu (par défaut)\n&gt; ubuntu-docker\n&gt; ubuntu-18.04\n&gt; ubuntu-22.04\n&gt; wsl-vpnkit\n\nwsl --shutdown\n\nwsl --export &lt;Image Name&gt; &lt;Export location file name.tar&gt;\n\n\ninstalled apps\n\nwsl2, prtscr, vscode, jdiskreport (centre logiciel), accessdatabasenginex64, driver nvidia, freefilesync (centre logiciel), notepad++ (centre logiciel), keepass (centre logiciel), zotero (centre logiciel), Windows Terminal, barrier, GWSL, typora,\n\nversion windows - 21H2 19044.1889\ntree structure\n\nD:\\&gt; tree &gt; e:\\tree_structure.txt\nD:\\&gt; xcopy d: e:\\t /t /s\nWednesday 9/7\nFrom time to time when running screen from WSL I have the following error:\n$ screen -dR\nCannot make directory '/run/screen': Permission denied\nthen one can run\nsudo /etc/init.d/screen-cleanup start\nThurdsay 9/8\nRestore backups on this new PC and without administrator rights.\nInstall of wsl2 following corporate instructions"
  },
  {
    "objectID": "posts/2022-09-01-logbook-September-22.html#week-37---september-22",
    "href": "posts/2022-09-01-logbook-September-22.html#week-37---september-22",
    "title": "Logbook for September 22",
    "section": "Week 37 - September 22",
    "text": "Week 37 - September 22\nThursday 9/15\nPlayed a lot with nbdev2. Most thinks work now with gitlab. That’s great\nFriday 9/16 Hamel just announced that fastpages will be discontinued as nbdev+quarto is now a valid option to provide a blogging platform. He has written a migration guide for that. Will have to follow that."
  },
  {
    "objectID": "posts/2022-09-01-logbook-September-22.html#week-38---september-22",
    "href": "posts/2022-09-01-logbook-September-22.html#week-38---september-22",
    "title": "Logbook for September 22",
    "section": "Week 38 - September 22",
    "text": "Week 38 - September 22\nThursday 9/22 I have completed migration of my blog to quarto as explaine in Blog - migrate to quarto\nFriday 9/23 Activate Auto export python code from jupyter lab Remove previous hack (jupyter_notebook_config.py)"
  },
  {
    "objectID": "posts/2022-09-01-logbook-September-22.html#week-39---september-22",
    "href": "posts/2022-09-01-logbook-September-22.html#week-39---september-22",
    "title": "Logbook for September 22",
    "section": "Week 39 - September 22",
    "text": "Week 39 - September 22\nMonday 9/26 Just tested way to install last (untagged) version of a lib from gitlab with\npip uninstall janus-tools\npip install git+https://gitlab.michelin.com/janus/janus_tools.git"
  },
  {
    "objectID": "posts/2021-10-01-logbook-October.html",
    "href": "posts/2021-10-01-logbook-October.html",
    "title": "Logbook for October 21",
    "section": "",
    "text": "Monday 10/4\nJupyter Lab is now packaged as a desktop app. Gave a try 2 minutes but issue with my running environment\nTo do: read and handson Understanding Variational Autoencoders (VAEs)\nTo do: reand and handson Patsy: Build Powerful Features with Arbitrary Python Code\nThursday 10/7\n\nDeep learning seems unstoppable! I’m particularly impressed by the recent progress of deep learning on tabular data. This new survey paper provides an overview of the SOTA deep learning methods on tabular data. A great read for students and practitioners.\nDeep Neural Networks and Tabular Data: A Survey - arxiv 2110.01889"
  },
  {
    "objectID": "posts/2021-10-01-logbook-October.html#week-40---october-21",
    "href": "posts/2021-10-01-logbook-October.html#week-40---october-21",
    "title": "Logbook for October 21",
    "section": "",
    "text": "Monday 10/4\nJupyter Lab is now packaged as a desktop app. Gave a try 2 minutes but issue with my running environment\nTo do: read and handson Understanding Variational Autoencoders (VAEs)\nTo do: reand and handson Patsy: Build Powerful Features with Arbitrary Python Code\nThursday 10/7\n\nDeep learning seems unstoppable! I’m particularly impressed by the recent progress of deep learning on tabular data. This new survey paper provides an overview of the SOTA deep learning methods on tabular data. A great read for students and practitioners.\nDeep Neural Networks and Tabular Data: A Survey - arxiv 2110.01889"
  },
  {
    "objectID": "posts/2021-10-01-logbook-October.html#week-42---october-21",
    "href": "posts/2021-10-01-logbook-October.html#week-42---october-21",
    "title": "Logbook for October 21",
    "section": "Week 42 - October 21",
    "text": "Week 42 - October 21\nWednesday 10/20\nUsing fastai forums to get inspirational content for VAE with tabular data. This one sounds good: Adversarial Autoencoders (with Pytorch). And this talk demystifying bayesian stuff.\n\n“Most of human and animal learning is unsupervised learning. If intelligence was a cake, unsupervised learning would be the cake [base], supervised learning would be the icing on the cake, and reinforcement learning would be the cherry on the cake. We know how to make the icing and the cherry, but we don’t know how to make the cake.”\nYann LeCunn\n\nAnd Intuitively Understanding Variational Autoencoders mentioned by Jeremy Howard"
  },
  {
    "objectID": "posts/2022-12-01-logbook-December-22.html",
    "href": "posts/2022-12-01-logbook-December-22.html",
    "title": "Logbook for December 22",
    "section": "",
    "text": "Running through lesson 8"
  },
  {
    "objectID": "posts/2022-12-01-logbook-December-22.html#thursday-1201",
    "href": "posts/2022-12-01-logbook-December-22.html#thursday-1201",
    "title": "Logbook for December 22",
    "section": "",
    "text": "Running through lesson 8"
  },
  {
    "objectID": "posts/2022-12-01-logbook-December-22.html#monday-1205",
    "href": "posts/2022-12-01-logbook-December-22.html#monday-1205",
    "title": "Logbook for December 22",
    "section": "Monday 12/05",
    "text": "Monday 12/05\n\nChatGPT\nWaiting for some models to be trained, I have some time to play with ChatGPT from openai.\nSome questions:\n\nwhat are the causes of climate change in France?\nand what are the options to face it?\nhow to train a deep neural network with fastai?\nwhat is the most beautiful Franch word?\n\n\n\n\nimage.png\n\n\nnice and fun!"
  },
  {
    "objectID": "posts/2022-12-01-logbook-December-22.html#friday-1209",
    "href": "posts/2022-12-01-logbook-December-22.html#friday-1209",
    "title": "Logbook for December 22",
    "section": "Friday 12/09",
    "text": "Friday 12/09\nI have just encountered an issue in conda/mamba with error messages libtinfow.so.6: no version information available\n(base) guillaume@L001LPF3RKAR5:~$ conda info\n/home/guillaume/miniconda/bin/python: /home/guillaume/miniconda/bin/../lib/./libtinfow.so.6: no version information available (required by /home/guillaume/miniconda/bin/../lib/libpypy3.9-c.so)\nA solution for me was issued from https://stackoverflow.com/questions/72103046/libtinfo-so-6-no-version-information-available-message-using-conda-environment\nInstall ncurses from conda-forge\nTo call conda install -y -c conda-forge ncurses before installing mamba"
  },
  {
    "objectID": "posts/2022-12-01-logbook-December-22.html#monday-1212",
    "href": "posts/2022-12-01-logbook-December-22.html#monday-1212",
    "title": "Logbook for December 22",
    "section": "Monday 12/12",
    "text": "Monday 12/12\n\nfastai course lesson 8 - Convolutions (CNN)\nContinuing lesson 8"
  },
  {
    "objectID": "posts/2022-12-01-logbook-December-22.html#wednesday-1214",
    "href": "posts/2022-12-01-logbook-December-22.html#wednesday-1214",
    "title": "Logbook for December 22",
    "section": "Wednesday 12/14",
    "text": "Wednesday 12/14\n\nChatGPT and RLHF Reinforcement Learning from Human Feedback\n1 hour live from Nathan Lambert and Thomas Simonini. Video here\n\n\n\nimage.png\n\n\nAnd there is a blog post written by Nathan and all. (on HuggingFace blog) Illustrating Reinforcement Learning from Human Feedback (RLHF)\n\n\n\nimage.png\n\n\nI like the way to ask this question\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-01-logbook-December-22.html#monday-1219",
    "href": "posts/2022-12-01-logbook-December-22.html#monday-1219",
    "title": "Logbook for December 22",
    "section": "Monday 12/19",
    "text": "Monday 12/19\n\nWSL version 1.0\nI have just received windows update KB5020812 and with that it means WSL version 1.0! It is now using the Windows Store version.\n wsl --version\nVersion WSL : 1.0.3.0\nVersion du noyau : 5.15.79.1\nVersion WSLg : 1.0.47\nVersion MSRDC : 1.2.3575\nVersion direct3D : 1.606.4\nVersion de DXCore : 10.0.25131.1002-220531-1700.rs-onecore-base2-hyp\nversion Windows : 10.0.19044.2364\nUsing the Store version of WSL allows you to get updates to WSL much faster compared to when it was a Windows component.\nCreating a blog entry WSL2 from Windows Store for all experiences I will have with this version.\nCanonical has published a whitepaper about how to setup WSL/ubuntu for datascientist: https://ubuntu.com/blog/upgrade-data-science-workflows-ubuntu-wsl\nAnd there is a WSL page on ubuntu wiki with fancy tips such as how to activate sound into WSL: https://wiki.ubuntu.com/WSL"
  },
  {
    "objectID": "posts/2022-12-01-logbook-December-22.html#wednesday-1221",
    "href": "posts/2022-12-01-logbook-December-22.html#wednesday-1221",
    "title": "Logbook for December 22",
    "section": "Wednesday 12/21",
    "text": "Wednesday 12/21\n\ndesktop linux in WSL\nTrying with kali linux - https://www.kali.org/docs/wsl/win-kex/ * download kali from https://learn.microsoft.com/en-us/windows/wsl/install-manual#downloading-distributions * double-click on KaliLinux_1.13.1.0.appx * create kali-linux entry in Windows Terminal * create wsl.conf with systemd: systemd=true in /etc/wsl.conf, restart kali * activate wsl-vpnkit: echo ‘wsl.exe -d wsl-vpnkit service wsl-vpnkit start’ &gt;&gt; ~/.profile, restart kali * I acnnot activate kali repos which are not within artifactory…"
  },
  {
    "objectID": "posts/2021-03-24-stable-baselines-3.html",
    "href": "posts/2021-03-24-stable-baselines-3.html",
    "title": "Stable baselines 3 - 1st steps",
    "section": "",
    "text": "I have just read about this new release. This is a complete rewrite of stable baselines 2, without any reference to tensorflow, and based on pytorch (&gt;1.4+).\nThere is a lot of running implementations of RL algorithms, based on gym. A very good introduction in this blog entry\nStable-Baselines3: Reliable Reinforcement Learning Implementations | Antonin Raffin | Homepage\nLinks\n\nGitHub repository: https://github.com/DLR-RM/stable-baselines3\nDocumentation: https://stable-baselines3.readthedocs.io/\nRL Baselines3 Zoo: https://github.com/DLR-RM/rl-baselines3-zoo\nContrib: https://github.com/Stable-Baselines-Team/stable-baselines3-contrib\nRL Tutorial: https://github.com/araffin/rl-tutorial-jnrr19"
  },
  {
    "objectID": "posts/2021-03-24-stable-baselines-3.html#tips-and-tricks",
    "href": "posts/2021-03-24-stable-baselines-3.html#tips-and-tricks",
    "title": "Stable baselines 3 - 1st steps",
    "section": "Tips and tricks",
    "text": "Tips and tricks\nThis page covers general advice about RL (where to start, which algorithm to choose, how to evaluate an algorithm, …), as well as tips and tricks when using a custom environment or implementing an RL algorithm.\n\nBe familiar with RL, see resource page\nread SB3 documentation\ndo the tutorial\n\nTune hyperparameters RL zoo is introduced. It contains some hyperparameter optimization.\nRL evaluation We suggest you reading Deep Reinforcement Learning that Matters for a good discussion about RL evaluation.\nwhich algorithm to choose 1st criteria is discrete vs continuous actions. And 2nd is capacity to parallelize training.\nDiscrete Actions\n\nDiscrete Actions - Single Process\n\nDQN with extensions (double DQN, prioritized replay, …) are the recommended algorithms. We notably provide QR-DQN in our contrib repo. DQN is usually slower to train (regarding wall clock time) but is the most sample efficient (because of its replay buffer).\n\nDiscrete Actions - Multiprocessed\n\nYou should give a try to PPO or A2C.\nContinuous Actions\n\nContinuous Actions - Single Process\n\nCurrent State Of The Art (SOTA) algorithms are SAC, TD3 and TQC (available in our contrib repo). Please use the hyperparameters in the RL zoo for best results.\n\nContinuous Actions - Multiprocessed\n\nTake a look at PPO or A2C. Again, don’t forget to take the hyperparameters from the RL zoo for continuous actions problems (cf Bullet envs).\nCreating a custom env\nmultiple times there are advices about normalizing: observation and action space. A good practice is to rescale your actions to lie in [-1, 1]. This does not limit you as you can easily rescale the action inside the environment\ntips and tricks to reproduce a RL paper\nReinforcement Learning Tips and Tricks — Stable Baselines3 1.1.0a1 documentation\n\nA personal pick (by @araffin) for environments with gradual difficulty in RL with continuous actions:\n\nPendulum (easy to solve)\nHalfCheetahBullet (medium difficulty with local minima and shaped reward)\nBipedalWalkerHardcore (if it works on that one, then you can have a cookie)\n\nin RL with discrete actions:\n\nCartPole-v1 (easy to be better than random agent, harder to achieve maximal performance)\nLunarLander\nPong (one of the easiest Atari game)\nother Atari games (e.g. Breakout)"
  },
  {
    "objectID": "posts/2021-03-24-stable-baselines-3.html#resource-page",
    "href": "posts/2021-03-24-stable-baselines-3.html#resource-page",
    "title": "Stable baselines 3 - 1st steps",
    "section": "Resource page",
    "text": "Resource page\nReinforcement Learning Resources — Stable Baselines3 1.1.0a1 documentation\nStable-Baselines3 assumes that you already understand the basic concepts of Reinforcement Learning (RL).\nHowever, if you want to learn about RL, there are several good resources to get started:\n\nOpenAI Spinning Up\nDavid Silver’s course\nLilian Weng’s blog\nBerkeley’s Deep RL Bootcamp\nBerkeley’s Deep Reinforcement Learning course\nMore resources"
  },
  {
    "objectID": "posts/2021-03-24-stable-baselines-3.html#examples",
    "href": "posts/2021-03-24-stable-baselines-3.html#examples",
    "title": "Stable baselines 3 - 1st steps",
    "section": "Examples",
    "text": "Examples\nI will run these examples in 01 -hands-on.ipynb from handson_stablebaselines3\nDQN lunarlander \nMy module is never landing :(\nNote: animated gif created with peek.\nPPO with multiprocessing cartpole\n\nMonitor training using callback\nThis could be useful when you want to monitor training, for instance display live learning curves in Tensorboard (or in Visdom) or save the best agent.\n\nAtari game such as pong (A2C with 6 envt) or breakout\n\nHere the list of valid gym atari environments: https://gym.openai.com/envs/#atari\n\n\n\nsb3_breakout.gif\n\n\npybullet\nThis is a SDK to real-time collision detection and multi-physics simulation for VR, games, visual effects, robotics, machine learning etc.\nhttps://github.com/bulletphysics/bullet3/\n\nWe need to install it: pip install pybullet\nI don’t have rendering capacity when playing with it. Because robotic is far from my need, I will skip on this one\nHindsight Experience Replay (HER)\nusing Highway-Env\ninstallation with pip install highway-env\nAfter 1h15m of training, some 1st results:\n\nAnd after that some technical stuff such as: * Learning Rate Schedule: start with high value and reduce it as learning goes * Advanced Saving and Loading: how to easily create a test environment to evaluate an agent periodically, use a policy independently from a model (and how to save it, load it) and save/load a replay buffer. * Accessing and modifying model parameters: These functions are useful when you need to e.g. evaluate large set of models with same network structure, visualize different layers of the network or modify parameters manually. * Record a video or make a gif\nMake a GIF of a Trained Agent\npip install imageio\nand this time the lander is getting closer to moon but not at all between flags."
  },
  {
    "objectID": "posts/2021-05-01-logbook-May.html",
    "href": "posts/2021-05-01-logbook-May.html",
    "title": "Logbook for May 21",
    "section": "",
    "text": "Monday 5/3\nReinforcement Learning Specialization - enrolled - Coursera (University of Alberta) - start of course 1 (Fundamentals of Reinforcement Learning) week 1 (An introduction to Sequential Decision-Making)\nTuesday 5/4\nReinforcement Learning Specialization - end of assignement for C1W1\nRL Course by David Silver Policy Gradient Methods (lecture 7)\nFriday 5/7\nReinforcement Learning Specialization - C1W2 - Markov Decision Process"
  },
  {
    "objectID": "posts/2021-05-01-logbook-May.html#week-18---may-21",
    "href": "posts/2021-05-01-logbook-May.html#week-18---may-21",
    "title": "Logbook for May 21",
    "section": "",
    "text": "Monday 5/3\nReinforcement Learning Specialization - enrolled - Coursera (University of Alberta) - start of course 1 (Fundamentals of Reinforcement Learning) week 1 (An introduction to Sequential Decision-Making)\nTuesday 5/4\nReinforcement Learning Specialization - end of assignement for C1W1\nRL Course by David Silver Policy Gradient Methods (lecture 7)\nFriday 5/7\nReinforcement Learning Specialization - C1W2 - Markov Decision Process"
  },
  {
    "objectID": "posts/2021-05-01-logbook-May.html#week-19---may-21",
    "href": "posts/2021-05-01-logbook-May.html#week-19---may-21",
    "title": "Logbook for May 21",
    "section": "Week 19 - May 21",
    "text": "Week 19 - May 21\nMonday 5/10\nReinforcement Learning Specialization - C1W3 - Value Functions & Bellman Equations"
  },
  {
    "objectID": "posts/2021-05-01-logbook-May.html#week-20---may-21",
    "href": "posts/2021-05-01-logbook-May.html#week-20---may-21",
    "title": "Logbook for May 21",
    "section": "Week 20 - May 21",
    "text": "Week 20 - May 21\nMonday 5/17\nReinforcement Learning Specialization - C1W3 - Value Functions & Bellman Equations\nTuesday 5/18\nReinforcement Learning Specialization - C1W4 - Dynamic Programming\nFriday 5/21\nReinforcement Learning Specialization - C1W4 - Dynamic Programming - assignment completed and end of course 1 ;)\nStart of Machine learning in python with scikit-learn by Inria"
  },
  {
    "objectID": "posts/2021-05-01-logbook-May.html#week-21---may-21",
    "href": "posts/2021-05-01-logbook-May.html#week-21---may-21",
    "title": "Logbook for May 21",
    "section": "Week 21 - May 21",
    "text": "Week 21 - May 21\nTuesday 5/25\nMachine learning in python with scikit-learn end of module 1\nReinforcement Learning Specialization - C2W1 - Monte-Carlo\nWednesday 5/26\nReinforcement Learning Specialization - C2W1 - Monte-Carlo - end of week 1\nThursday 5/27\nMachine learning in python with scikit-learn start of module 2. Selecting the best model\nReinforcement Learning Specialization - C2W2 - Temporal Difference for Prediction - start"
  },
  {
    "objectID": "posts/2021-05-01-logbook-May.html#week-22---may-21",
    "href": "posts/2021-05-01-logbook-May.html#week-22---may-21",
    "title": "Logbook for May 21",
    "section": "Week 22 - May 21",
    "text": "Week 22 - May 21\nMonday 5/31\nMachine learning in python with scikit-learn start of module 3. Hyperparameter tuning"
  },
  {
    "objectID": "posts/2020-09-14-fast-read-excel-pandas.html",
    "href": "posts/2020-09-14-fast-read-excel-pandas.html",
    "title": "Fast read Excel files with pandas",
    "section": "",
    "text": "from functools import wraps\nfrom time import time\ndef measure_time(func):\n    @wraps(func)\n    def _time_it(*args, **kwargs):\n        start = int(round(time() * 1000))\n        try:\n            return func(*args, **kwargs)\n        finally:\n            end_ = int(round(time() * 1000)) - start\n            print(f\"Total execution time: {end_ if end_ &gt; 0 else 0} ms\")\n    return _time_it\n\n\n\n\n\nbig_excel_file = root_data+'/pandas-caching/big_excel_file.xlsx'\n\n\n@measure_time\ndef load_excel(file):\n    dataframe = pd.read_excel(file)\n    return dataframe\n\n\ndataframe = load_excel(big_excel_file)\n\nTotal execution time: 36196 ms\n\n\n{% include alert.html text=“Waouh, 36 sec to read this file!” %}\n\n\n\n\ncsv_file = root_data+'/pandas-caching/big_csv_file_turned_from_excel.csv'\n\n\n@measure_time\ndef load_csv(file):\n    dataframe = pd.read_csv(file, sep=';', decimal=',')\n    return dataframe\n\n\ndf_csv = load_csv(csv_file)\n\nTotal execution time: 836 ms\n\n\n{% include alert.html text=“Much better, 0.8 sec!” %}"
  },
  {
    "objectID": "posts/2020-09-14-fast-read-excel-pandas.html#problem-description",
    "href": "posts/2020-09-14-fast-read-excel-pandas.html#problem-description",
    "title": "Fast read Excel files with pandas",
    "section": "",
    "text": "from functools import wraps\nfrom time import time\ndef measure_time(func):\n    @wraps(func)\n    def _time_it(*args, **kwargs):\n        start = int(round(time() * 1000))\n        try:\n            return func(*args, **kwargs)\n        finally:\n            end_ = int(round(time() * 1000)) - start\n            print(f\"Total execution time: {end_ if end_ &gt; 0 else 0} ms\")\n    return _time_it\n\n\n\n\n\nbig_excel_file = root_data+'/pandas-caching/big_excel_file.xlsx'\n\n\n@measure_time\ndef load_excel(file):\n    dataframe = pd.read_excel(file)\n    return dataframe\n\n\ndataframe = load_excel(big_excel_file)\n\nTotal execution time: 36196 ms\n\n\n{% include alert.html text=“Waouh, 36 sec to read this file!” %}\n\n\n\n\ncsv_file = root_data+'/pandas-caching/big_csv_file_turned_from_excel.csv'\n\n\n@measure_time\ndef load_csv(file):\n    dataframe = pd.read_csv(file, sep=';', decimal=',')\n    return dataframe\n\n\ndf_csv = load_csv(csv_file)\n\nTotal execution time: 836 ms\n\n\n{% include alert.html text=“Much better, 0.8 sec!” %}"
  },
  {
    "objectID": "posts/2020-09-14-fast-read-excel-pandas.html#caching-library",
    "href": "posts/2020-09-14-fast-read-excel-pandas.html#caching-library",
    "title": "Fast read Excel files with pandas",
    "section": "Caching library",
    "text": "Caching library\n\nimport os\n\ndef read_CachedXLS(filename, forceReload = False, **options):\n    \"\"\"\n    Part d'un fichier excel natif (filename).\n    Si le dataframe caché correspondant n'existe pas encore, alors sauve le dataframe caché au format csv dans le rep source.\n    (s'il existe et si forceReload==True, alors écrase le dataframe caché existant par une nouvelle version)\n    Lit le dataframe caché correspondant avec les **options et retourne le dataframe.\n    \n    Examples\n    --------\n    &gt;&gt;&gt; filename = '/mnt/z/data/Stam-CC/ExportData 25625.xlsx'\n        forceReload = False\n        option={'dayfirst':True, 'parse_dates':['Fecha de Medida', 'Fecha de Fabricacion'], 'sheetname':0}\n        getCachedXLSRaw(filename, forceRelead, **option).info()\n\n    Parameters\n    ----------\n    filename : string\n        Emplacement du fichier XLS. Avec l'extension. Format complet\n        Ex: '/mnt/z/data/Stam-CC/ExportData 25625.xlsx'\n    forceReload : boolean, optional, default value = False\n        Si forceReload == True, le fichier sera relu et sauvé même s'il existe déjà en cache\n    options : **keyword args, optional\n        Arguments de lecture du fichier XLS :  https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html\n        Ex: sheetname=1\n\n    Returns\n    -------\n    dataframe\n        Dataframe correspondant \n    \"\"\"\n    \n    #split pour ne garder que le nom sans le chemin de filename : Stam-CC/ExportData 25625 --&gt; ExportData 25625\n    dataframe_filename = os.path.dirname(filename)+'/'+os.path.basename(filename)+'.csv'\n    #bug de pandas.to_csv quand il y a des espaces ?\n    dataframe_filename = dataframe_filename.replace(\" \", \"_\")\n\n    dataframe=[]\n    xls_toget = False\n    \n    #print(dataframe_filename)\n    if (forceReload and os.path.exists(dataframe_filename)):\n        print(\"Cached file \"+dataframe_filename+\" déjà existant mais forceReload=True - FORCE RELOAD\")\n        xls_toget = True\n        \n    if (not os.path.exists(dataframe_filename)):\n        print(\"Cached file  \"+dataframe_filename+\" inexistant - read_CachedXLS\")\n        xls_toget = True\n        \n    if (xls_toget):\n        dataframe = pd.read_excel(filename, **options)\n        dataframe.to_csv(dataframe_filename)\n    else:\n        print(\"Cached file \"+dataframe_filename+\" existe en cache, relecture\")\n    \n    #index_col pour ignorer les n° de lignes excel \n    options['sep']=','\n    options['decimal']='.'\n    options['skiprows']=0\n    options.pop('sheet_name')\n    dataframe = pd.read_csv(dataframe_filename,**options)\n    return dataframe\n\n\noption={'sheet_name':0}\nread_CachedXLS(big_excel_file, **option)\nprint(\"et voila\")\n\nCached file /mnt/z/data//pandas-caching/big_excel_file.xlsx.csv existe en cache, relecture\net voila"
  },
  {
    "objectID": "posts/2022-05-02-upgrade-fastpages.html",
    "href": "posts/2022-05-02-upgrade-fastpages.html",
    "title": "upgrade to last version of fastpages",
    "section": "",
    "text": "as detailed in https://github.com/fastai/fastpages/issues/634\nHamel asks to restart from a new repo. But how to keep the same blog url?\nEasy way is to rename former repo (from guillaume_blog to guillaume_blog_old) and initiate new repo as former one (guillaume_blog).\nHere are the steps."
  },
  {
    "objectID": "posts/2022-05-02-upgrade-fastpages.html#source-of-inspiration",
    "href": "posts/2022-05-02-upgrade-fastpages.html#source-of-inspiration",
    "title": "upgrade to last version of fastpages",
    "section": "",
    "text": "as detailed in https://github.com/fastai/fastpages/issues/634\nHamel asks to restart from a new repo. But how to keep the same blog url?\nEasy way is to rename former repo (from guillaume_blog to guillaume_blog_old) and initiate new repo as former one (guillaume_blog).\nHere are the steps."
  },
  {
    "objectID": "posts/2022-05-02-upgrade-fastpages.html#installation-and-setup",
    "href": "posts/2022-05-02-upgrade-fastpages.html#installation-and-setup",
    "title": "upgrade to last version of fastpages",
    "section": "Installation and setup",
    "text": "Installation and setup\n\nInstallation\n\nGenerate a copy of fastpages repo. Just have to follow instructions by clicking at https://github.com/fastai/fastpages/generate. Name repo as guillaume_blog\nClick on the PR Initial Setup in your new repo. There are instructions to create a SSH_DEPLOY_KEY.\nMerge this PR\nClone this repo locally\nBecause I use https, I have to create a token at Settings &gt; Developer Settings &gt; Personal Access Tokens\nand to keep this token locally, I enter git config --global credential.helper manager before pushing\n\n\n\nCopy content\n\nDirectories: _notebooks, _posts, _files, _images\nClean content from directories (examples) in _notebooks, _posts, _words\nPages: _pages/about.md, index.html, README.md\nand utils: refresh_blog_content.sh, publish.sh"
  },
  {
    "objectID": "posts/2021-02-16-conda-and-jupyter-tips.html",
    "href": "posts/2021-02-16-conda-and-jupyter-tips.html",
    "title": "Conda and jupyter tips",
    "section": "",
    "text": "I manage all my python environments with conda from miniconda.\n\n\nHowever I don’t have a strong process to keep track of my environment specifications. Usually I manually create an env.txt file under my projects. Keeping all commands I have used to create that environment.\n\n!cat /home/explore/git/guillaume/mit_6S191_Intro_to_deep_learning/env\\ \\ mit_6S191.txt\n\nenv_name: mit_6S191\nlibraries: python 3.7, tensorflow 2\n\n\nInstallation commands:\nconda create -n mit_6S191 python=3.7\nconda activate mit_6S191\n\nconda install tensorflow tensorflow-gpu\nconda install -c conda-forge jupyter_contrib_nbextensions\nconda install matplotlib numpy opencv\nconda install -c pytorch torchvision\nconda install nb_conda\n\n\nWhat happens if I add packages in that environment. Or want to use that environment in another project. I have to remember the link between env name and project name.\nThat is not robust.\n\n\n\nKeeping a yml file could be a solution to keep track of environment specifications. It doesn’t answer to my last concern though (linking env name and project name)\nBut there is a limitation linked with channels.\n\n!conda env export --from-history\n\nname: fastai\nchannels:\n  - defaults\ndependencies:\n  - python=3.8\n  - fastai\n  - jupyter\n  - jupyter_contrib_nbextensions\n  - fastbook\nprefix: /home/explore/miniconda3/envs/fastai\n\n\nIn that example, fastai package should come from fastai channel but conda doesn’t keep that information.\nUsing\nconda install -n my_env rdkit::rdkit\ncould be an option.\n\n\n\nSince conda keeps active environment in env variable CONDA_DEFAULT_ENV, we can automatically create up-to-date yml file.\n\n!echo $CONDA_DEFAULT_ENV\n\nfastai\n\n\n\n!conda env export --from-history &gt; ~/temp/env_`echo $CONDA_DEFAULT_ENV`.yml\n!ls ~/temp/env_`echo $CONDA_DEFAULT_ENV`.yml\n\n/home/explore/temp/env_fastai.yml\n\n\nBut for it to be usable, I will have to install package using the &lt;channel&gt;::&lt;package&gt; way.\n\n!cat /home/explore/git/guillaume/mit_6S191_Intro_to_deep_learning/create_yml.sh\n\n#!/bin/bash\nconda env export --from-history &gt; env_`echo $CONDA_DEFAULT_ENV`.yml"
  },
  {
    "objectID": "posts/2021-02-16-conda-and-jupyter-tips.html#manual-way",
    "href": "posts/2021-02-16-conda-and-jupyter-tips.html#manual-way",
    "title": "Conda and jupyter tips",
    "section": "",
    "text": "However I don’t have a strong process to keep track of my environment specifications. Usually I manually create an env.txt file under my projects. Keeping all commands I have used to create that environment.\n\n!cat /home/explore/git/guillaume/mit_6S191_Intro_to_deep_learning/env\\ \\ mit_6S191.txt\n\nenv_name: mit_6S191\nlibraries: python 3.7, tensorflow 2\n\n\nInstallation commands:\nconda create -n mit_6S191 python=3.7\nconda activate mit_6S191\n\nconda install tensorflow tensorflow-gpu\nconda install -c conda-forge jupyter_contrib_nbextensions\nconda install matplotlib numpy opencv\nconda install -c pytorch torchvision\nconda install nb_conda\n\n\nWhat happens if I add packages in that environment. Or want to use that environment in another project. I have to remember the link between env name and project name.\nThat is not robust."
  },
  {
    "objectID": "posts/2021-02-16-conda-and-jupyter-tips.html#yml-way",
    "href": "posts/2021-02-16-conda-and-jupyter-tips.html#yml-way",
    "title": "Conda and jupyter tips",
    "section": "",
    "text": "Keeping a yml file could be a solution to keep track of environment specifications. It doesn’t answer to my last concern though (linking env name and project name)\nBut there is a limitation linked with channels.\n\n!conda env export --from-history\n\nname: fastai\nchannels:\n  - defaults\ndependencies:\n  - python=3.8\n  - fastai\n  - jupyter\n  - jupyter_contrib_nbextensions\n  - fastbook\nprefix: /home/explore/miniconda3/envs/fastai\n\n\nIn that example, fastai package should come from fastai channel but conda doesn’t keep that information.\nUsing\nconda install -n my_env rdkit::rdkit\ncould be an option."
  },
  {
    "objectID": "posts/2021-02-16-conda-and-jupyter-tips.html#automate-yml-way",
    "href": "posts/2021-02-16-conda-and-jupyter-tips.html#automate-yml-way",
    "title": "Conda and jupyter tips",
    "section": "",
    "text": "Since conda keeps active environment in env variable CONDA_DEFAULT_ENV, we can automatically create up-to-date yml file.\n\n!echo $CONDA_DEFAULT_ENV\n\nfastai\n\n\n\n!conda env export --from-history &gt; ~/temp/env_`echo $CONDA_DEFAULT_ENV`.yml\n!ls ~/temp/env_`echo $CONDA_DEFAULT_ENV`.yml\n\n/home/explore/temp/env_fastai.yml\n\n\nBut for it to be usable, I will have to install package using the &lt;channel&gt;::&lt;package&gt; way.\n\n!cat /home/explore/git/guillaume/mit_6S191_Intro_to_deep_learning/create_yml.sh\n\n#!/bin/bash\nconda env export --from-history &gt; env_`echo $CONDA_DEFAULT_ENV`.yml"
  },
  {
    "objectID": "posts/2021-02-16-conda-and-jupyter-tips.html#jupyter-extensions",
    "href": "posts/2021-02-16-conda-and-jupyter-tips.html#jupyter-extensions",
    "title": "Conda and jupyter tips",
    "section": "Jupyter extensions",
    "text": "Jupyter extensions\nI have already explained how to install jupyter extensions and the one I use. update jupyter to include extensions"
  },
  {
    "objectID": "posts/2021-02-16-conda-and-jupyter-tips.html#nb_conda",
    "href": "posts/2021-02-16-conda-and-jupyter-tips.html#nb_conda",
    "title": "Conda and jupyter tips",
    "section": "nb_conda",
    "text": "nb_conda\nThis is usefull to switch from environment to another without having to stop/restart jupyter."
  },
  {
    "objectID": "posts/2022-07-21-install docker on linux.html",
    "href": "posts/2022-07-21-install docker on linux.html",
    "title": "install docker within linux",
    "section": "",
    "text": "Install Docker Engine on Ubuntu"
  },
  {
    "objectID": "posts/2022-07-21-install docker on linux.html#source-of-inspiration",
    "href": "posts/2022-07-21-install docker on linux.html#source-of-inspiration",
    "title": "install docker within linux",
    "section": "",
    "text": "Install Docker Engine on Ubuntu"
  },
  {
    "objectID": "posts/2022-07-21-install docker on linux.html#installation-and-test",
    "href": "posts/2022-07-21-install docker on linux.html#installation-and-test",
    "title": "install docker within linux",
    "section": "Installation and test",
    "text": "Installation and test\n\nSet up the repository\nsudo apt-get update\nsudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n    lsb-release\n\n# Add Docker’s official GPG key\nsudo mkdir -p /etc/apt/keyrings\ncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n\n# set up the Docker repository\necho \\\n  \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n\n\nInstall Docker Engine\n# Install Docker Engine\nsudo apt-get update\nsudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin\n\n\nTest\nsudo docker run hello-world\n&gt; Hello from Docker!\n&gt; [...]"
  },
  {
    "objectID": "posts/2023-04-28-ToDo.html",
    "href": "posts/2023-04-28-ToDo.html",
    "title": "To Do",
    "section": "",
    "text": "list\n\n[] Jun-23 after ChatGPT Prompt Engineering for Developers, DeepLearning.ai proposes 3 new short courses: How Diffusion Models Work, LangChain for LLM Application Development, Building Systems with the ChatGPT API\n[] May-23: adaptive lib for active learning page\n[] SSL cookbook paper: arxiv page pdf\n[] Pyro tutorials (DPP: deep probabilistic programming). Tutorials\n[] Apr-23 ChatGPT Prompt Engineering for Developers Detection\n[0] Apr-23 new fastai courses: Practical Deep Learning for Coders - Part 2. To start Detection Part1 notes Lesson 11\n[0] Jan-23 Mallat 2023. (todo: video 6)\n[0] Jan-23 fastai live coding lessons (todo: lesson 8). On-going notes\n\n\n\nwhy this list\nto keep track of large long term actions. And to go to the end of it.\nNot sure this is the best way to do it. Maybe a trello would be smarter.\nWill see if I can keep it updated.\nWould have been nice to get checklist widget in markdown (as task lists under github). Will ask quarto community.\nLegend:\n\n[] not started\n[0] started\ncompleted"
  },
  {
    "objectID": "posts/2022-04-25-install ubuntu 22.04 on WSL.html",
    "href": "posts/2022-04-25-install ubuntu 22.04 on WSL.html",
    "title": "install ubuntu 22.04 on WSL",
    "section": "",
    "text": "How to install Ubuntu 21.10 on WSL for Windows 10 and 11"
  },
  {
    "objectID": "posts/2022-04-25-install ubuntu 22.04 on WSL.html#source-of-inspiration",
    "href": "posts/2022-04-25-install ubuntu 22.04 on WSL.html#source-of-inspiration",
    "title": "install ubuntu 22.04 on WSL",
    "section": "",
    "text": "How to install Ubuntu 21.10 on WSL for Windows 10 and 11"
  },
  {
    "objectID": "posts/2022-04-25-install ubuntu 22.04 on WSL.html#installation",
    "href": "posts/2022-04-25-install ubuntu 22.04 on WSL.html#installation",
    "title": "install ubuntu 22.04 on WSL",
    "section": "Installation",
    "text": "Installation\n\nuninstall image (if needed)\n# wsl --unregister &lt;distroName&gt;\nwsl --unregister ubuntu-22.04\n\n\ndownload images\nFrom cloud images ubuntu (cloud-images &gt; jammy &gt; current), now there are wsl images:\n\n\n\nubuntu cloud images\n\n\nI just have to download the last jammy (22.04) image jammy-server-cloudimg-amd64-wsl.rootfs.tar.gz\n\n\ninstall and setup from powershell\nI have downloaded this ubuntu image to D:\\wsl\\ubuntu-22.04\\download\n(base) guillaume@LL11LPC0PQARQ:/mnt/d/wsl$ tree\n.\n├── Ubuntu-20.04\n│   └── ext4.vhdx\n├── Ubuntu-22.04\n│   ├── download\n│   │   └── jammy-server-cloudimg-amd64-wsl.rootfs.tar.gz\n│   └── instance\nand my ubuntu-22.04 instance will stand in D:\\wsl\\ubuntu-22.04\\instance\nInstall with this command from powershell\n# wsl --import &lt;distroname&gt; &lt;location of instance&gt; &lt;location of download&gt;\nwsl --import ubuntu-22.04 D:\\wsl\\ubuntu-22.04\\instance D:\\wsl\\ubuntu-22.04\\download\\jammy-server-cloudimg-amd64-wsl.rootfs.tar.gz\nIt takes 3-4 minutes to install. and should be visible in your wsl instances.\n wsl --list --all -v\n  NAME            STATE           VERSION\n  ubuntu-22.04    Stopped         2\nthen to run it\n# wsl -d &lt;distroname&gt;\nwsl -d ubuntu-22.04\nor\n\nuse Windows Terminal as a launcher\nWindows Terminal is a smart way to group all terminals (powershell, and all your wsl instances)\n\n\n\nwindows terminal\n\n\nIt can be installed even with limited windows store access by clicking install in Installer le Terminal Windows et commencer à le configurer\nAutomatically all wsl instances appear in Settings."
  },
  {
    "objectID": "posts/2022-04-25-install ubuntu 22.04 on WSL.html#automatic-setup",
    "href": "posts/2022-04-25-install ubuntu 22.04 on WSL.html#automatic-setup",
    "title": "install ubuntu 22.04 on WSL",
    "section": "Automatic setup",
    "text": "Automatic setup\ncopy these 2 scripts in /root/ (given they are in D:\\wsl\\ubuntu-22.04\\download)\ncp /mnt/d/wsl/Ubuntu-22.04/download/setup_wsl_* .\nsetup_wsl_root.sh download\n#!/bin/bash\n\necho \"0. get username: \"\nread user_name\n\n. /etc/lsb-release\n\necho Configuration for user [$user_name]\necho of distribution $DISTRIB_CODENAME\necho\n\necho \"1. create user and add in sudo\"\n#adduser --disabled-password --gecos \"\" $user_name\nadduser --gecos \"\" $user_name\nusermod -aG sudo $user_name\necho\n\necho \"2. create wsl.conf file\"\nrm -rf /etc/wsl.conf\ntee /etc/wsl.conf &lt;&lt; EOF\n# Set the user when launching a distribution with WSL.\n[user]\ndefault=$user_name\nEOF\necho\n\necho \"3. prepare setup by user\"\ncp setup_wsl_user.sh /home/$user_name\nchown $user_name:users /home/$user_name/setup_wsl_user.sh\nchmod 750  /home/$user_name/setup_wsl_user.sh\ntee -a /home/$user_name/.bashrc &lt;&lt; EOF\nif [ ! -f ~/\".wsl_configured\" ]; then\n        ~/setup_wsl_user.sh\n        touch ~/.wsl_configured\nfi\nEOF\necho\n\necho \"end of configuration for root\"\necho \"stop wsl instance by running 'wsl -t &lt;distro-name&gt;' from powershell\"\necho \"and start from Windows Terminal\"\nsetup_wsl_user.sh download\n#!/bin/bash\n\necho \"1. setup wsl-vpnkit\"\nif grep -Fxq \"wsl-vpnkit\" ~/.profile\nthen\n    # code if found\n    echo \"   wsl-vpnkit already setup\"\nelse\n    # code if not found\n    echo 'wsl.exe -d wsl-vpnkit service wsl-vpnkit start' &gt;&gt; ~/.profile\nfi\nwsl.exe -d wsl-vpnkit service wsl-vpnkit start\nsource ./.bashrc\necho\n\necho \"2. create ssh key to copy to gitlab\"\n. /etc/lsb-release\nif [ ! -e \".ssh/id_rsa.pub\" ]; then\n        ssh-keygen -t rsa -b 4096 -C \"WSL2 ubuntu $DISTRIB_RELEASE\"\n        cat .ssh/id_rsa.pub\n        echo \"copy this content to gitlab &gt; preferences &gt; SSH Keys\"\n        read -p \"Press any key to resume ...\"\nfi\necho\n\necho \"3. update certificates\"\nif [ ! -n \"$(grep \"^gitlab.michelin.com \" ~/.ssh/known_hosts)\" ]; then ssh-keyscan gitlab.michelin.com &gt;&gt; ~/.ssh/known_hosts 2&gt;/dev/null; fi\ngit clone git@gitlab.michelin.com:devops-foundation/devops_environment.git /tmp/devops_environment\nsudo cp /tmp/devops_environment/certs/* /usr/local/share/ca-certificates/\nsudo update-ca-certificates\nrm -rf /tmp/devops_environment\nif [ $DISTRIB_RELEASE == \"22.04\" ]\nthen\necho 'bug SSL with ubuntu 22.04 - https://bugs.launchpad.net/ubuntu/+source/openssl/+bug/1963834/comments/7'\nsudo tee -a /etc/ssl/openssl.cnf &lt;&lt; EOF\n[openssl_init]\nssl_conf = ssl_sect\n\n[ssl_sect]\nsystem_default = system_default_sect\n\n[system_default_sect]\nOptions = UnsafeLegacyRenegotiation\nEOF\nfi\ntee -a ~/.bashrc &lt;&lt; EOF\nexport OPENSSL_CONF=/etc/ssl/openssl.cnf\nEOF\necho\n\necho \"4. update apt sources with artifactory\"\necho 'Acquire { http::User-Agent \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:13.37) Gecko/20100101 Firefox/31.33.7\"; };' | sudo tee /etc/apt/apt.conf.d/90globalprotectconf\nsudo sed -i 's,http://archive.ubuntu.com/ubuntu,https://artifactory.michelin.com/artifactory/ubuntu-archive-remote,g' /etc/apt/sources.list\nsudo sed -i 's,http://security.ubuntu.com/ubuntu,https://artifactory.michelin.com/artifactory/ubuntu-archive-remote,g' /etc/apt/sources.list\nsudo apt update\nsudo apt upgrade -y\necho\nThen\nchmod +x setup_wsl_root.sh\n./setup_wsl_root.sh\nAs explained stop wsl instance by running wsl --shutdown ubuntu-22.04 from powershell and start from Windows Terminal\nIt restarts from your user and it will install:\n\nsetup wsl-vpnkit\ncreate ssh key to copy to gitlab\nupdate certificates\nupdate apt sources with artifactory"
  },
  {
    "objectID": "posts/2022-04-25-install ubuntu 22.04 on WSL.html#and-now-we-can-install-other-parts",
    "href": "posts/2022-04-25-install ubuntu 22.04 on WSL.html#and-now-we-can-install-other-parts",
    "title": "install ubuntu 22.04 on WSL",
    "section": "And now we can install other parts",
    "text": "And now we can install other parts\nall the scripts are in https://github.com/castorfou/blog/tree/master/files\n\n00 - keep config files in git\nview\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_00_config_files_in_git.sh | bash\nsource .bashrc\n\n\n01 - automount secured vbox\nview\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_01_automount_secured_vbox.sh | bash\n\n\n02 - python with conda and configure base environment (jupyterlab, mamba)\nview1 view2 view3 view4\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_02_install_python_conda_part1.sh | bash\ncd \nsource .bashrc\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_02_install_python_conda_part2.sh | bash\nsource .bashrc\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_02_install_python_conda_part3.sh | bash\nsource .bashrc\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_02_install_python_conda_part4.sh | bash\nsource .bashrc\n\n\n03 - bat cat\nview\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_03_install_batcat.sh | bash\nsource .bashrc\nTo use batcat but not display line numbers, just use -p option cat .bashrc -p\n\n\n04 - git access\nln -s /mnt/d/git/ ~/\n\n\n05 - X access with GWSL\nGWSL Homepage\nif you have access to Windows Store, it is available.\nOr alternate download are possible.\n\n\n\n06 - git credential manager\nview\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_06_git_credential_manager.sh | bash\n\n\n07 - install wslu\nview\nwslu\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_07_wslu.sh | bash\nSome examples:\n$ wslfetch\n\n               .-/+oossssoo+/-.               Windows Subsystem for Linux (WSL2)\n           `:+ssssssssssssssssss+:`           guillaume@LL11LPC0PQARQ\n         -+ssssssssssssssssssyyssss+-         Build: 19044\n       .ossssssssssssssssssdMMMNysssso.       Branch: vb_release\n      /ssssssssssshdmmNNmmyNMMMMhssssss/      Release: Ubuntu 22.04 LTS\n     +ssssssssshmydMMMMMMMNddddyssssssss+     Kernel: Linux 5.10.102.1-microsoft-standard-WSL2\n    /sssssssshNMMMyhhyyyyhmNMMMNhssssssss/    Uptime: 0d 3h 44m\n   .ssssssssdMMMNhsssssssssshNMMMdssssssss.\n   +sssshhhyNMMNyssssssssssssyNMMMysssssss+\n   ossyNMMMNyMMhsssssssssssssshmmmhssssssso\n   ossyNMMMNyMMhsssssssssssssshmmmhssssssso\n   +sssshhhyNMMNyssssssssssssyNMMMysssssss+\n   .ssssssssdMMMNhsssssssssshNMMMdssssssss.\n    /sssssssshNMMMyhhyyyyhdNMMMNhssssssss/\n     +sssssssssdmydMMMMMMMMddddyssssssss+\n      /ssssssssssshdmNNNNmyNMMMMhssssss/\n       .ossssssssssssssssssdMMMNysssso.\n         -+sssssssssssssssssyyyssss+-\n           `:+ssssssssssssssssss+:`\n               .-/+oossssoo+/-.\n               \n$ wslpath -u \"C:\\Program Files\\Typora\\Typora.exe\"\n/mnt/c/Program Files/Typora/Typora.exe\n\n\n08 - configure pip\nview\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_08_pip.sh | bash\n\n\n09 - install vscode\ncode .\n(given Visual Studio Code is installed on the Windows side (not in WSL))\n(and if needed install Remote development)\n\n\n10 - docker\nview\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/blog/master/files/setup_wsl_10_docker.sh | bash\nwhen relogging, docker service will be added to test docker\ndocker ps\ndocker run docker.artifactory.michelin.com/hello-world"
  },
  {
    "objectID": "posts/2022-04-25-install ubuntu 22.04 on WSL.html#manual-setup-skip-if-to-follow-automatic-setup",
    "href": "posts/2022-04-25-install ubuntu 22.04 on WSL.html#manual-setup-skip-if-to-follow-automatic-setup",
    "title": "install ubuntu 22.04 on WSL",
    "section": "Manual setup (skip if to follow automatic setup)",
    "text": "Manual setup (skip if to follow automatic setup)\n\nbasic setup\nWith this way to install, you don’t have any user, you don’t have any launcher within Windows.\nCreate a user and add it to sudo:\n# adduser &lt;yourusername&gt;\n# usermod -aG sudo &lt;yourusername&gt;\nadduser guillaume\nusermod -aG sudo guillaume\nand I can switch to this user simply with\n# su &lt;yourusername&gt;\nsu guillaume\n\n\nlaunch distro with yourusername - update wsl.conf\nManually you can now start your distro with your username from powershell\n# wsl -d &lt;distroname&gt; -u &lt;yourusername&gt;\nwsl -d ubuntu-22.04 -u guillaume\nOr from another wsl (huge avantage to run in linux terminal instead of powershell)\nwsl.exe -d ubuntu-22.04 -u guillaume\nbut you can better keep this username setting by updating wsl.conf\n# /etc/wsl.conf\n# Set the user when launching a distribution with WSL.\n[user]\ndefault=YourUserName\nIt is now setup. You can now shutdown this instance from powershell.\n# wsl --shutdown &lt;distroname&gt;\nwsl --shutdown ubuntu-22.04\nand when starting wsl -d ubuntu-22.04, you reach your username.\n\n\nwsl-vpnkit\nAs wsl-vpnkit is already installed, I just have to\necho 'wsl.exe -d wsl-vpnkit service wsl-vpnkit start' &gt;&gt; ~/.profile\nsource .bashrc\n\n\ngitlab\nssh-keygen -t rsa -b 4096 -C \"WSL2 ubuntu 22.04\"\nand copy id_rsa.pub into gitlab &gt; preferences &gt; SSH Keys\n\n\ncorporate CA certificates\ngit clone git@gitlab.michelin.com:devops-foundation/devops_environment.git /tmp/devops_environment\nsudo cp /tmp/devops_environment/certs/* /usr/local/share/ca-certificates/\nsudo update-ca-certificates\nrm -rf /tmp/devops_environment\n\n\napt sources\nhad to replace focal (20.04) to jammy (22.04)\necho 'Acquire { http::User-Agent \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:13.37) Gecko/20100101 Firefox/31.33.7\"; };' | sudo tee /etc/apt/apt.conf.d/90globalprotectconf\nsudo sed -i 's@^\\(deb \\)http://archive.ubuntu.com/ubuntu/\\( jammy\\(-updates\\)\\?.*\\)$@\\1https://artifactory.michelin.com/artifactory/ubuntu-archive-remote\\2\\n# &@' /etc/apt/sources.list\nsudo sed -i 's@^\\(deb \\)http://security.ubuntu.com/ubuntu/\\( jammy\\(-updates\\)\\?.*\\)$@\\1https://artifactory.michelin.com/artifactory/ubuntu-security-remote\\2\\n# &@' /etc/apt/sources.list\n\n\ncheck everything is ok\n\nThis command must return google ip:\n\n  host google.fr\n\nThis command must return artifactory ip:\n\n  host artifactory.michelin.com\n\nYou are able to update your distribution without error:\n\n  sudo apt update\n  sudo apt upgrade -y\n\n\nSetup config dotfiles with whole filesystem (/)\nas detailed in keep dotfiles in git\nbut to manage the whole filesystem.\n\ninit local repo\nsudo mkdir -p /.cfg\nsudo chown $USER:users /.cfg\ngit init --bare /.cfg\nalias config='/usr/bin/git --git-dir=/.cfg/ --work-tree=/'\nconfig config --local status.showUntrackedFiles no\necho \"alias config='/usr/bin/git --git-dir=/.cfg/ --work-tree=/'\" &gt;&gt; $HOME/.bash_aliases\ncd\nsource .bashrc\n\n\ngit default identity (if needed)\nconfig config --global user.email \"guillaume.ramelet@michelin.com\"\nconfig config --global user.name \"guillaume\"\n\n\nsetup branch and push to central repo\nconfig remote add origin git@gitlab.michelin.com:janus/dotfiles.git\nconfig fetch\ncd\nconfig add .bashrc\nconfig commit -m 'init with .bashrc'\n\nconfig branch GR_WSL2_ubuntu22.04\nconfig checkout GR_WSL2_ubuntu22.04\nconfig push --set-upstream origin GR_WSL2_ubuntu22.04"
  },
  {
    "objectID": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html",
    "href": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html",
    "title": "Fastai on WSL 2 with Cuda",
    "section": "",
    "text": "This is based on what is explained in https://forums.fast.ai/t/fastai-on-wsl-2-ubuntu-0-7-0-or-any-version/76651"
  },
  {
    "objectID": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#install-update-of-nvidia-drivers",
    "href": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#install-update-of-nvidia-drivers",
    "title": "Fastai on WSL 2 with Cuda",
    "section": "install update of nvidia drivers",
    "text": "install update of nvidia drivers\nBased on Deep Learning Course Forums Platform: Windows 10 using WSL2 w/GPU fastai users\n\ncreate nvidia account\ndownload quadro driver from https://developer.nvidia.com/cuda/wsl/download (460.15)\ninstall\n\n(xgboost) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog$ nvidia-smi.exe\nMon Sep 21 16:00:46 2020\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 460.15       Driver Version: 460.15       CUDA Version: 11.1     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|===============================+======================+======================|\n|   0  Quadro M1000M      WDDM  | 00000000:01:00.0  On |                  N/A |\n| N/A   59C    P0    N/A /  N/A |    905MiB /  4096MiB |      0%      Default |\n+-------------------------------+----------------------+----------------------+"
  },
  {
    "objectID": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#install-of-wsl2-and-convert-existing-images",
    "href": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#install-of-wsl2-and-convert-existing-images",
    "title": "Fastai on WSL 2 with Cuda",
    "section": "install of WSL2 and convert existing images",
    "text": "install of WSL2 and convert existing images\nOpen a PowerShell window as an Administrator\nRun wsl –set-default-version 2\n\nupdate KB\n{% include alert.html text=“–set-default-version 2 is not a valid option. KB4566116 should be installed” %}\nThis can be downloaded from Catalog Microsoft Update\n\n\nupdate kernel version\nIf you see this message after running the command: WSL 2 requires an update to its kernel component. For information please visit https://aka.ms/wsl2kernel. You still need to install the MSI Linux kernel update package.\nDownload from https://docs.microsoft.com/en-us/windows/wsl/install-win10#step-4---download-the-linux-kernel-update-package\n\n\nset default WSL to be version 2\nPS C:\\WINDOWS\\system32&gt; wsl --set-default-version 2\n\n\nconvert existing images\nPS C:\\WINDOWS\\system32&gt; wsl --list --verbose\n  NAME            STATE           VERSION\n* Ubuntu-18.04    Running         1\nPS C:\\WINDOWS\\system32&gt; wsl --set-version Ubuntu-18.04 2\nLa conversion est en cours. Cette opération peut prendre quelques minutes...\nPour plus d’informations sur les différences de clés avec WSL 2, visitez https://aka.ms/wsl2\nLa conversion est terminée.\nIt took a while (~1 hour) for my unique ubuntu image.\nAnd at the end it has worked.\nPS C:\\WINDOWS\\system32&gt; wsl --list --verbose\n  NAME            STATE           VERSION\n* Ubuntu-18.04    Stopped         2"
  },
  {
    "objectID": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#install-of-nvidia-drivers-under-ubuntu",
    "href": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#install-of-nvidia-drivers-under-ubuntu",
    "title": "Fastai on WSL 2 with Cuda",
    "section": "install of nvidia drivers under ubuntu",
    "text": "install of nvidia drivers under ubuntu\n[Installation instructions)(https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1804&target_type=deblocal)\nwget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64/cuda-ubuntu1804.pin\nsudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/11.0.3/local_installers/cuda-repo-ubuntu1804-11-0-local_11.0.3-450.51.06-1_amd64.deb\nsudo dpkg -i cuda-repo-ubuntu1804-11-0-local_11.0.3-450.51.06-1_amd64.deb\nsudo apt-key add /var/cuda-repo-ubuntu1804-11-0-local/7fa2af80.pub\nsudo apt-get update\nsudo apt-get -y install cuda\n\n!cat /usr/local/cuda/version.txt\n\nCUDA Version 11.0.228\n\n\n\n!/usr/local/cuda/samples/4_Finance/BlackScholes/BlackScholes\n\n[/usr/local/cuda/samples/4_Finance/BlackScholes/BlackScholes] - Starting...\nCUDA error at ../../common/inc/helper_cuda.h:777 code=35(cudaErrorInsufficientDriver) \"cudaGetDeviceCount(&device_count)\" \n\n\nThere is an error when launching CUDA samples. Googling that error maybe my video card is running on low driver version?\nI have posted on nvidia (cuda+wsl) forum: https://forums.developer.nvidia.com/t/cuda-sample-throwing-error/142537/18\n(update 09-22: it is not possible to have cuda on wsl2 if not in Windows Insider build from Dev Channel. (20145 or higher))\n{% include alert.html text=“because I am in version 1909 (18363.1049), it won’t work for me. ;(” %}\n\ncuda for WSL\nHere is a link that could be interesting: https://docs.nvidia.com/cuda/wsl-user-guide/index.html\nAccording to this, I should not have installed cuda but cuda-toolkit. Do not choose the cuda, cuda-11-0, or cuda-drivers meta-packages under WSL 2 since these packages will result in an attempt to install the Linux NVIDIA driver under WSL 2.\nIs it causing my issue?\napt-get install -y cuda-toolkit-11-0\n\n!/usr/local/cuda/bin/nvcc --version\n\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2020 NVIDIA Corporation\nBuilt on Wed_Jul_22_19:09:09_PDT_2020\nCuda compilation tools, release 11.0, V11.0.221\nBuild cuda_11.0_bu.TC445_37.28845127_0"
  },
  {
    "objectID": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#install-a-new-distro-ubuntu-20.04",
    "href": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#install-a-new-distro-ubuntu-20.04",
    "title": "Fastai on WSL 2 with Cuda",
    "section": "install a new distro (ubuntu 20.04)",
    "text": "install a new distro (ubuntu 20.04)\nBecause I cannot use windows store, I have to manually install https://docs.microsoft.com/fr-fr/windows/wsl/install-manual\nInstallation by just launching Ubuntu_2004.2020.424.0_x64.appx.\nI have now 2 distros,\nPS C:\\WINDOWS\\system32&gt; wsl --list -v\n  NAME            STATE           VERSION\n* Ubuntu-18.04    Running         2\n  Ubuntu-20.04    Running         2"
  },
  {
    "objectID": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#wsl2-and-network",
    "href": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#wsl2-and-network",
    "title": "Fastai on WSL 2 with Cuda",
    "section": "WSL2 and network",
    "text": "WSL2 and network\nThere is a change of network architecture between WSL 1 and WSL 2. In WSL 2, a new network interface is available:\nCarte Ethernet vEthernet (WSL) :\n\n   Suffixe DNS propre à la connexion. . . :\n   Adresse IPv6 de liaison locale. . . . .: \n   Adresse IPv4. . . . . . . . . . . . . .: 192.168.81.193\n   Masque de sous-réseau. . . . . . . . . : 255.255.255.240\n   Passerelle par défaut. . . . . . . . . :\n\nRevert image to WSL1 to get back network access\nPS C:\\WINDOWS\\system32&gt; wsl --set-version Ubuntu-18.04 1\nLa conversion est en cours. Cette opération peut prendre quelques minutes...\nLa conversion est terminée.\nPS C:\\WINDOWS\\system32&gt; wsl --list -v\n  NAME            STATE           VERSION\n* Ubuntu-18.04    Stopped         1\n  Ubuntu-20.04    Stopped         2"
  },
  {
    "objectID": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#access-to-linux-files-from-windows",
    "href": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#access-to-linux-files-from-windows",
    "title": "Fastai on WSL 2 with Cuda",
    "section": "access to linux files from windows",
    "text": "access to linux files from windows\nFor running state distros:\nFiles are available at \\\\wsl$\\.\nFor stopped state distros:\nFiles are available at C:\\Users\\&lt;users&gt;\\AppData\\Local\\Packages\\CanonicalGroupLimited.Ubuntu*\\LocalState\\rootfs"
  },
  {
    "objectID": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#some-usefull-wsl-commands",
    "href": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#some-usefull-wsl-commands",
    "title": "Fastai on WSL 2 with Cuda",
    "section": "some usefull wsl commands",
    "text": "some usefull wsl commands\nList distros\n\n!wsl --list --verbose\n\n  NAME            STATE           VERSION\n\n* Ubuntu-18.04    Running         1\n\n  Ubuntu-20.04    Stopped         2\nStop a distro\n\n!wsl --terminate Ubuntu-18.04\n\nUpdate dns settings\nas explained here\njust switch from generateResolvConf = true to generateResolvConf = false in /etc/wsl.conf and edit /etc/resolv.conf\nBut still have issues, mainly I think linked to Symantec Endpoint protection."
  },
  {
    "objectID": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#workaround-network-issue-with-wsl2",
    "href": "posts/2020-09-21-windows10-fastai-wsl2-cuda.html#workaround-network-issue-with-wsl2",
    "title": "Fastai on WSL 2 with Cuda",
    "section": "Workaround network issue with WSL2",
    "text": "Workaround network issue with WSL2\nhttps://github.com/sakai135/wsl-vpnkit\n\ninstallation setup\n\nvpnkit\ninstall docker for windows\ninstall genisoimage in ubuntu (from http://archive.ubuntu.com/ubuntu/pool/main/c/cdrkit/genisoimage_1.1.11-3.1ubuntu1_amd64.deb)\ninstall vpnkit\nisoinfo -i /mnt/c/Program\\ Files/Docker/Docker/resources/wsl/docker-for-wsl.iso -R -x /containers/services/vpnkit-tap-vsockd/lower/sbin/vpnkit-tap-vsockd &gt; ./vpnkit-tap-vsockd\nchmod +x vpnkit-tap-vsockd\nsudo mv vpnkit-tap-vsockd /sbin/vpnkit-tap-vsockd\nsudo chown root:root /sbin/vpnkit-tap-vsockd\n\n\nnpiperelay\ninstall unzip in ubuntu (from http://archive.ubuntu.com/ubuntu/pool/main/u/unzip/unzip_6.0-25ubuntu1_amd64.deb)\ndownload npiprelay (from https://github.com/jstarks/npiperelay/releases/download/v0.1.0/npiperelay_windows_amd64.zip )\ninstall npiprelay\nunzip npiperelay_windows_amd64.zip npiperelay.exe\nrm npiperelay_windows_amd64.zip\nmkdir -p /mnt/c/bin\nmv npiperelay.exe /mnt/c/bin/\nsudo ln -s /mnt/c/bin/npiperelay.exe /usr/local/bin/npiperelay.exe\n\n\nsocat\ninstall socat in ubuntu (from http://archive.ubuntu.com/ubuntu/pool/main/s/socat/socat_1.7.3.3-2_amd64.deb)\n\n\nConfigure DNS for WSL\nDisable WSL from generating and overwriting /etc/resolv.conf.\nsudo tee /etc/wsl.conf &lt;&lt;EOL\n[network]\ngenerateResolvConf = false\nEOL\nManually set DNS servers to use when not running this script. 1.1.1.1 is provided as an example.\nsudo tee /etc/resolv.conf &lt;&lt;EOL\nnameserver 1.1.1.1\nEOL\n\n\nwsl-vpnkit\nfrom https://github.com/sakai135/wsl-vpnkit/archive/refs/heads/main.zip\nunzip ~/git/wsl-vpnkit-main.zip -d ~/Applications/wsl-vpnkit\n\n\n\nexecution\n~/Applications/wsl-vpnkit/wsl-vpnkit-main$ sudo ./wsl-vpnkit\n\n\nproxychains\nI can now use proxychains and everything works beautifully ;)\n\n\nclean from local deb install to ubuntu repo\n~/git$ ls *.deb\ngenisoimage_1.1.11-3.1ubuntu1_amd64.deb                proxychains_3.1-8.1_all.deb\nlibproxychains3_3.1-8.1_amd64.deb                      socat_1.7.3.3-2_amd64.deb\nnet-tools_1.60+git20180626.aebd88e-1ubuntu1_amd64.deb  unzip_6.0-25ubuntu1_amd64.deb\nsudo apt remove genisoimage  net-tools  socat unzip\nsudo proxychains apt install genisoimage libproxychains3 net-tools proxychains socat unzip\nI don’t exactly see how to do it with proxychains."
  },
  {
    "objectID": "posts/2023-07-01-logbook-July-23.html",
    "href": "posts/2023-07-01-logbook-July-23.html",
    "title": "Logbook for July 23",
    "section": "",
    "text": "datashader or how to use plotly/bokeh with millions of points\nI should create a full entry with this experiment.\nWaiting for it, I tried holoviz which is a way to seamlessly integrate various graph libs such as hvplot and datashader.\n\n\n\nimage.png\n\n\nI have started to play with the tutorial, and what I would likely use is this hvplot/datashader combo which allows to quickly display millions of points in a graph without any performance issue. And when zooming in, it gets more details.\nThis works perfectly when executed from the tutorial environment. But I have not succeeded in making it work on my own environments.\nI have posted a in their forum."
  },
  {
    "objectID": "posts/2023-07-01-logbook-July-23.html#friday-0721",
    "href": "posts/2023-07-01-logbook-July-23.html#friday-0721",
    "title": "Logbook for July 23",
    "section": "",
    "text": "datashader or how to use plotly/bokeh with millions of points\nI should create a full entry with this experiment.\nWaiting for it, I tried holoviz which is a way to seamlessly integrate various graph libs such as hvplot and datashader.\n\n\n\nimage.png\n\n\nI have started to play with the tutorial, and what I would likely use is this hvplot/datashader combo which allows to quickly display millions of points in a graph without any performance issue. And when zooming in, it gets more details.\nThis works perfectly when executed from the tutorial environment. But I have not succeeded in making it work on my own environments.\nI have posted a in their forum."
  },
  {
    "objectID": "posts/2021-10-21-Just-some-usefull-keyboard-shortcuts.html",
    "href": "posts/2021-10-21-Just-some-usefull-keyboard-shortcuts.html",
    "title": "Just some usefull keyboard shortcuts",
    "section": "",
    "text": "I cannot believe I have been using linux for more than 20 years as my main system and have never configured keyboard shortcuts to launch explorer files."
  },
  {
    "objectID": "posts/2022-11-01-logbook-November-22.html",
    "href": "posts/2022-11-01-logbook-November-22.html",
    "title": "Logbook for November 22",
    "section": "",
    "text": "freshly back from vacations (2 weeks) without touching anything AI-computer related\n\n\n\n\n\nLast time I had to fix broken links on this blog. For that I have setup google search console.\nBut for the moment I have this report\n\n\n\nimage.png\n\n\nHave to figure out why.\nAnd sitemap as well is not configured. Maybe quarto can help to generate one.\n\n\n\nMamba released v1.0.\nI can now update my environments:\n(base) $ conda update -c conda-forge mamba\n\n\n\n\n\n\nUnfortuantely having updated mamba broke my WSL system. My other environment (with same update) is fine.\nI think this is linked to openssl version (v3 on WSL, v1.1.1 on linux)\nHere are some more information about this problem\n$ conda create -n fastai python=3.9\nLooking for: ['python=3.9']\nDownload error (35) SSL connect error [https://repo.anaconda.com/pkgs/r/noarch/repodata.json]\nerror:0A000152:SSL routines::unsafe legacy renegotiation disabled\nand information about the environment\n# openssl version\n$ openssl version\nOpenSSL 3.0.7 1 Nov 2022 (Library: OpenSSL 3.0.7 1 Nov 2022)\n\n# ubuntu version (using lsb-release)\n$ . /etc/lsb-release && echo $DISTRIB_RELEASE\n22.04\n\n# SSL declarations that could impact this behaviour\n$ declare -p|grep -i ssl\ndeclare -x CURL_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\"\ndeclare -x REQUESTS_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\"\ndeclare -x SSL_CERT_FILE=\"/home/guillaume/miniconda/lib/python3.9/site-packages/certifi/cacert.pem\"\nInitially I thought of this issue as fixed in WSL installation (setup_wsl_user.sh / “3. update certificates”).\nBut the workaround/fix is still active\n$ cat /etc/ssl/openssl.cnf|grep -i unsafe\nOptions = UnsafeLegacyRenegotiation\n[FIX]\nJust had to export OPENSSL_CONF\nexport OPENSSL_CONF=/etc/ssl/openssl.cnf\nModifying .bashrc to integrated thie environment variable.\n\n\n\nStart of lesson 4"
  },
  {
    "objectID": "posts/2022-11-01-logbook-November-22.html#monday-117",
    "href": "posts/2022-11-01-logbook-November-22.html#monday-117",
    "title": "Logbook for November 22",
    "section": "",
    "text": "freshly back from vacations (2 weeks) without touching anything AI-computer related"
  },
  {
    "objectID": "posts/2022-11-01-logbook-November-22.html#wednesday-119",
    "href": "posts/2022-11-01-logbook-November-22.html#wednesday-119",
    "title": "Logbook for November 22",
    "section": "",
    "text": "Last time I had to fix broken links on this blog. For that I have setup google search console.\nBut for the moment I have this report\n\n\n\nimage.png\n\n\nHave to figure out why.\nAnd sitemap as well is not configured. Maybe quarto can help to generate one.\n\n\n\nMamba released v1.0.\nI can now update my environments:\n(base) $ conda update -c conda-forge mamba"
  },
  {
    "objectID": "posts/2022-11-01-logbook-November-22.html#thursday-1110",
    "href": "posts/2022-11-01-logbook-November-22.html#thursday-1110",
    "title": "Logbook for November 22",
    "section": "",
    "text": "Unfortuantely having updated mamba broke my WSL system. My other environment (with same update) is fine.\nI think this is linked to openssl version (v3 on WSL, v1.1.1 on linux)\nHere are some more information about this problem\n$ conda create -n fastai python=3.9\nLooking for: ['python=3.9']\nDownload error (35) SSL connect error [https://repo.anaconda.com/pkgs/r/noarch/repodata.json]\nerror:0A000152:SSL routines::unsafe legacy renegotiation disabled\nand information about the environment\n# openssl version\n$ openssl version\nOpenSSL 3.0.7 1 Nov 2022 (Library: OpenSSL 3.0.7 1 Nov 2022)\n\n# ubuntu version (using lsb-release)\n$ . /etc/lsb-release && echo $DISTRIB_RELEASE\n22.04\n\n# SSL declarations that could impact this behaviour\n$ declare -p|grep -i ssl\ndeclare -x CURL_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\"\ndeclare -x REQUESTS_CA_BUNDLE=\"/etc/ssl/certs/ca-certificates.crt\"\ndeclare -x SSL_CERT_FILE=\"/home/guillaume/miniconda/lib/python3.9/site-packages/certifi/cacert.pem\"\nInitially I thought of this issue as fixed in WSL installation (setup_wsl_user.sh / “3. update certificates”).\nBut the workaround/fix is still active\n$ cat /etc/ssl/openssl.cnf|grep -i unsafe\nOptions = UnsafeLegacyRenegotiation\n[FIX]\nJust had to export OPENSSL_CONF\nexport OPENSSL_CONF=/etc/ssl/openssl.cnf\nModifying .bashrc to integrated thie environment variable.\n\n\n\nStart of lesson 4"
  },
  {
    "objectID": "posts/2022-11-01-logbook-November-22.html#monday-1114",
    "href": "posts/2022-11-01-logbook-November-22.html#monday-1114",
    "title": "Logbook for November 22",
    "section": "Monday 11/14",
    "text": "Monday 11/14\n\nfastai course lesson 4 - nlp, lesson 5 - from-scratch model\nEnding lesson 4\nStarting lesson 5"
  },
  {
    "objectID": "posts/2022-11-01-logbook-November-22.html#wednesday-1116",
    "href": "posts/2022-11-01-logbook-November-22.html#wednesday-1116",
    "title": "Logbook for November 22",
    "section": "Wednesday 11/16",
    "text": "Wednesday 11/16\n\nquarto update\nquarto has been updated to version 1.2.269 as mentioned in fastai forum\nHere the procedure to update."
  },
  {
    "objectID": "posts/2022-11-01-logbook-November-22.html#monday-1128",
    "href": "posts/2022-11-01-logbook-November-22.html#monday-1128",
    "title": "Logbook for November 22",
    "section": "Monday 11/28",
    "text": "Monday 11/28\n\nfastai course lesson 5 - from-scratch model\nEnding lesson 5\nTip: pd.options.display.float_format = '{:.2f}'.format will display all floats from dataframes with 2 digits\nTip2: from fastai.imports import * will import everuthing that we need (numpy, pandas, matplotlib, …)\n\n\nfastai course lesson 6 - Random forests\nRunning through lesson 6"
  },
  {
    "objectID": "posts/2022-11-01-logbook-November-22.html#wednesday-1130",
    "href": "posts/2022-11-01-logbook-November-22.html#wednesday-1130",
    "title": "Logbook for November 22",
    "section": "Wednesday 11/30",
    "text": "Wednesday 11/30\n\nfastai course lesson 7 - Collaborative filtering\nRunning through lesson 7"
  },
  {
    "objectID": "posts/2020-10-07-decorator-trace-variables.html",
    "href": "posts/2020-10-07-decorator-trace-variables.html",
    "title": "Variables traces using show_guts decorator",
    "section": "",
    "text": "show_guts decorator\nAdaptaton from https://stackoverflow.com/questions/24165374/printing-a-functions-local-variable-names-and-values\nUpdate to python 3.\n\nimport sys\nimport threading\n\ndef show_guts(f):\n    sentinel = object()\n    gutsdata = threading.local()\n    gutsdata.captured_locals = None\n    gutsdata.tracing = False\n\n    def trace_locals(frame, event, arg):\n        if event.startswith('c_'):  # C code traces, no new hook\n            return \n        if event == 'call':  # start tracing only the first call\n            if gutsdata.tracing:\n                return None\n            gutsdata.tracing = True\n            return trace_locals\n        if event == 'line':  # continue tracing\n            return trace_locals\n\n        # event is either exception or return, capture locals, end tracing\n        gutsdata.captured_locals = frame.f_locals.copy()\n        return None\n\n    def wrapper(*args, **kw):\n        # preserve existing tracer, start our trace\n        old_trace = sys.gettrace()\n        sys.settrace(trace_locals)\n\n        retval = sentinel\n        try:\n            retval = f(*args, **kw)\n        finally:\n            # reinstate existing tracer, report, clean up\n            sys.settrace(old_trace)\n            for key, val in gutsdata.captured_locals.items():\n                print('{}: {!r}'.format(key, val))\n            if retval is not sentinel:\n                print('Returned: {!r}'.format(retval))\n            gutsdata.captured_locals = None\n            gutsdata.tracing = False\n\n        return retval\n\n    return wrapper\n\n\n\nuse example\n\nimport torch\nfrom torch import nn\nfrom tqdm.auto import tqdm\nfrom torchvision import transforms\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import CelebA\nfrom torch.utils.data import DataLoader\nimport matplotlib.pyplot as plt\n\n\n@show_guts\ndef get_score(current_classifications, original_classifications, target_indices, other_indices, penalty_weight):\n    '''\n    Function to return the score of the current classifications, penalizing changes\n    to other classes with an L2 norm.\n    Parameters:\n        current_classifications: the classifications associated with the current noise\n        original_classifications: the classifications associated with the original noise\n        target_indices: the index of the target class\n        other_indices: the indices of the other classes\n        penalty_weight: the amount that the penalty should be weighted in the overall score\n    '''\n    # Steps: 1) Calculate the change between the original and current classifications (as a tensor)\n    #           by indexing into the other_indices you're trying to preserve, like in x[:, features].\n    #        2) Calculate the norm (magnitude) of changes per example.\n    #        3) Multiply the mean of the example norms by the penalty weight. \n    #           This will be your other_class_penalty.\n    #           Make sure to negate the value since it's a penalty!\n    #        4) Take the mean of the current classifications for the target feature over all the examples.\n    #           This mean will be your target_score.\n    #### START CODE HERE ####\n    change_original_classification = (current_classifications[:,other_indices] - original_classifications[:,other_indices])\n    # Calculate the norm (magnitude) of changes per example and multiply by penalty weight\n    other_class_penalty = - torch.mean(torch.norm(change_original_classification, dim=1) * penalty_weight)\n    # Take the mean of the current classifications for the target feature\n    target_score = torch.mean(current_classifications)\n    #### END CODE HERE ####\n    return target_score + other_class_penalty\n\n\nrows = 10\ncurrent_class = torch.tensor([[1] * rows, [2] * rows, [3] * rows, [4] * rows]).T.float()\noriginal_class = torch.tensor([[1] * rows, [2] * rows, [3] * rows, [4] * rows]).T.float()\n\n# Must be 3\nassert get_score(current_class, original_class, [1, 3] , [0, 2], 0.2).item() == 3\n\ncurrent_classifications: tensor([[1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.]])\noriginal_classifications: tensor([[1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.],\n        [1., 2., 3., 4.]])\ntarget_indices: [1, 3]\nother_indices: [0, 2]\npenalty_weight: 0.2\nchange_original_classification: tensor([[0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.],\n        [0., 0.]])\nother_class_penalty: tensor(-0.)\ntarget_score: tensor(2.5000)\nReturned: tensor(2.5000)\n\n\nAssertionError:"
  },
  {
    "objectID": "posts/2021-05-03-reinforcement-learning-specialization-coursera.html",
    "href": "posts/2021-05-03-reinforcement-learning-specialization-coursera.html",
    "title": "Reinforcement Learning Specialization - Coursera - course 1 - Fundamentals of Reinforcement Learning",
    "section": "",
    "text": "Coursera website: course 1 - Fundamentals of Reinforcement Learning of Reinforcement Learning Specialization\nmy notes on course 2 - Sample-based Learning Methods, course 3 - Prediction and Control with Function Approximation, course 4 - A Complete Reinforcement Learning System (Capstone)\nSyllabus\n4 courses on 16 weeks by Martha White and Adam White.\nspecialization roadmap\ncourse 1 - we begin our study with multi-arm bandit problems. Here, we get our first taste of the complexities of incremental learning, exploration, and exploitation. After that, we move onto Markov decision processes to broaden the class of problems we can solve with reinforcement learning methods. Here we will learn about balancing short-term and long-term reward. We will introduce key ideas like policies and value functions using almost all RL systems. We conclude Course 1 with classic planning methods called dynamic programming. These methods have been used in large industrial control problems and can compute optimal policies given a complete model of the world.\ncourse 2 - In Course 2, we built on these ideas and design algorithms for learning without a model of the world. We study three classes of methods designed for learning from trial and error interaction. We start with Monte Carlo methods and then move on to temporal difference learning, including Q learning. We conclude Course 2 with an investigation of methods for planning with learned models.\ncourse 3 - In Course 3, we leave the relative comfort of small finite MDPs and investigate RL with function approximation. Here we will see that the main concepts from Courses 1 and 2 transferred to problems with larger infinite state spaces. We will cover feature construction, neural network learning, policy gradient methods, and other particularities of the function approximation setting.\ncourse 4 - The final course in this specialization brings everything together in a Capstone project. Throughout this specialization, as in Rich and Andy’s book, we stress a rigorous and scientific approach to RL. We conduct numerous experiments designed to carefully compare algorithms. It takes careful planning and a lot of hard work to produce a meaningful empirical results. In the Capstone, we will walk you through each step of this process so that you can conduct your own scientific experiment. We will explore all the stages from problem specification, all the way to publication quality plots. This is not just academic. In real problems, it’s important to verify and understand your system. After that, you should be ready to test your own new ideas or tackle a new exciting application of RL in your job. We hope you enjoyed the show half as much as we enjoyed making it for you.\nAlberta is in Canada."
  },
  {
    "objectID": "posts/2021-05-03-reinforcement-learning-specialization-coursera.html#course-1---week-1---an-introduction-to-sequential-decision-making",
    "href": "posts/2021-05-03-reinforcement-learning-specialization-coursera.html#course-1---week-1---an-introduction-to-sequential-decision-making",
    "title": "Reinforcement Learning Specialization - Coursera - course 1 - Fundamentals of Reinforcement Learning",
    "section": "5/3/21 - Course 1 - Week 1 - An introduction to Sequential Decision-Making",
    "text": "5/3/21 - Course 1 - Week 1 - An introduction to Sequential Decision-Making\nI have set recommended goals 3 times a week.\nabout supervised learning, unsupervised learning and RL\nYou might wonder what’s the difference between supervised learning, unsupervised learning, and reinforcement learning? The differences are quite simple. In supervised learning we assume the learner has access to labeled examples giving the correct answer. In RL, the reward gives the agent some idea of how good or bad its recent actions were. You can think of supervised learning as requiring a teacher that helps you by telling you the correct answer. A reward on the other hand, is like having someone who can identify what good behavior looks like but can’t tell you exactly how to do it. Unsupervised learning sounds like it could be related but really has a very different goal. Unsupervised learning is about extracting underlying structure in data. It’s about the data representation. It can be used to construct representations that make a supervised or RL system better. In fact, as you’ll see later in this course, techniques from both supervised learning and unsupervised learning can be used within RL to aid generalization\nindustrial control\nSo I think the place we’re really going to see it take off is an industrial control. In industrial control, we have experts that are really looking for ways to improve the optimal- how well their systems work. So we’re going to see it do things like reduce energy costs or save on other types of costs that we have in these industrial control systems. In the hands of experts, we can really make these algorithms work well in the near future. So I really see it as a tool that’s going to facilitate experts in their work rather than say, doing something like replacing people or automating them away.\nReinforcement Learning Textbook\nas always, Reinforcement Learning: An introduction (Second Edition) by Richard S. Sutton and Andrew G. Barto is THE reference. I didn’t know that Adam White was student from Sutton. Lucky guy ;)\nK-armed Bandit problem\n\nStarts with reading of RLbook p25-36 (Chapter 2 Multi-armed Bandits)\nEvaluative vs instructive feedback. Nonassociative refers to cases where you take one action per state. At the end there is a generalization where bandit problem becomes associative, that is, when actions are taken in more than one situation.\nIt is a stationary case meaning that value of actions are fixed during experiences. If the bandit task were nonstationary, that is, the true values of the actions changed over time. In this case exploration is needed even in the deterministic case to make sure one of the nongreedy actions has not changed to become better than the greedy one.\nsample-average action-value estimates\n\\[\nQ_t(a) = \\frac{\\text{sum of rewards when } \\mathit{a} \\text{ taken prior to }\\mathit{t}}{\\text{number of times } \\mathit{a} \\text{ taken prior to }\\mathit{t}} \\\\\nQ_t(a)  = \\frac{\\displaystyle\\sum_{i=1}^{t-1} R_i.\\mathcal{1}_{A_i=a}}{\\displaystyle\\sum_{i=1}^{t-1} \\mathcal{1}_{A_i=a}}\n\\]\n\\(\\epsilon\\)-greedy action selection\n\\[\nA_t=\\underset{a}{\\mathrm{argmax}}{\\text{ }Q_t(a)}\n\\]\nWith nonstationary problem, we want to give more weights to recent rewards. It can be done with \\[\nQ_{n+1}=Q_n+\\alpha[R_n-Q_n]\n\\] Where \\[\\alpha\\] is a constant step-size parameter, \\[\\alpha \\in [0,1]\\]. So it can be written that way \\[\nQ_{n+1}=(1-\\alpha)^nQ_1+\\displaystyle\\sum_{i=1}^{n} \\alpha(1-\\alpha)^{n-i}R_i\n\\] . Weighted average because the sum of the weights is 1.\n2 other topics are discussed: optimistic initial values (that can push exploration in 1st steps) and upper-confidence-bound (UCB) action selection. With optimistic initial values the idea is too have high initial value for reward so that the 1st actions are disappointing pushing for explorations. With UCB\n\\[\nA_t= \\underset{a} {\\mathrm{argmax}} {\\text{ }\\bigg[Q_t(a)+c\\sqrt{\\frac{\\ln t}{N_t(a)}}\\bigg]}\n\\]\n\nThe idea of this upper confidence bound (UCB) action selection is that the square-root term is a measure of the uncertainty or variance in the estimate of a’s value. The quantity being max’ed over is thus a sort of upper bound on the possible true value of action a, with c determining the confidence level. Each time a is selected the uncertainty is presumably reduced: N t (a) increments, and, as it appears in the denominator, the uncertainty term decreases. On the other hand, each time an action other than a is selected, t increases but N t (a) does not; because t appears in the numerator, the uncertainty estimate increases. The use of the natural logarithm means that the increases get smaller over time, but are unbounded; all actions will eventually be selected, but actions with lower value estimates, or that have already been selected frequently, will be selected with decreasing frequency over time.\n\nExploration vs Exploitation trade-off\nHow do we choose when to explore, and when to exploit? Randomly\n\nAssignement\nimplementation of greedy agent, \\(\\epsilon\\)-greedy agent. Comparisons. Various \\(\\epsilon\\) values, various step-sizes (1/N(a), …)\nnotebooks in github\nend of C1W1 (course 1 week 1)"
  },
  {
    "objectID": "posts/2021-05-03-reinforcement-learning-specialization-coursera.html#course-1---week-2---markov-decision-process",
    "href": "posts/2021-05-03-reinforcement-learning-specialization-coursera.html#course-1---week-2---markov-decision-process",
    "title": "Reinforcement Learning Specialization - Coursera - course 1 - Fundamentals of Reinforcement Learning",
    "section": "5/7/21 - Course 1 - Week 2 - Markov Decision Process",
    "text": "5/7/21 - Course 1 - Week 2 - Markov Decision Process\n\nModule 2 Learning Objectives\nLesson 1: Introduction to Markov Decision Processes\n\nUnderstand Markov Decision Processes, or MDPs\nDescribe how the dynamics of an MDP are defined\nUnderstand the graphical representation of a Markov Decision Process\nExplain how many diverse processes can be written in terms of the MDP framework\n\nLesson 2: Goal of Reinforcement Learning\n\nDescribe how rewards relate to the goal of an agent\nUnderstand episodes and identify episodic tasks\n\nLesson 3: Continuing Tasks\n\nFormulate returns for continuing tasks using discounting\nDescribe how returns at successive time steps are related to each other\nUnderstand when to formalize a task as episodic or continuing\n\n\n\nLesson 1: Introduction to Markov Decision Processes\nReading chapter 3.1 to 3.3 (p47-56) in Sutton’s book\nFinite Markov Decision Processes\n\n3.1 - the Agent-Environment Interface\n3.2 - Goals and Rewards\n3.3 - Returns and Episodes\n\nIn a Markov decision process, the probabilities given by p completely characterize the environment’s dynamics. That is, the probability of each possible value for \\(S_t\\) and \\(R_t\\) depends only on the immediately preceding state and action, \\(S_{t-1}\\) and \\(A_{t-1}\\) , and, given them, not at all on earlier states and actions.\n\\[\np(s',r|s,a) \\doteq Pr\\{S_t=s', R_t=r|S_{t-1}=s, A_{t-1}=a\\}\n\\]\nThe state must include information about all aspects of the past agent–environment interaction that make a difference for the future. In general, actions can be any decisions we want to learn how to make, and the states can be anything we can know that might be useful in making them.\nThe agent–environment boundary represents the limit of the agent’s absolute control, not of its knowledge.\nGoal can be well thought of as the maximization of the expected value of the cumulative sum of a received scalar signal (called reward). The reward signal is your way of communicating to the agent what you want it to achieve, not how you want it achieved.\nExpected return \\(G_t\\) is defined as some specific function of the reward sequence. In the simplest case the return is the sum of the rewards: \\[\nG_t \\doteq R_{t+1}+R_{t+2}+R_{t+3}+...+R_{T}\n\\] where \\(T\\) is the final time step.\nWith continuing tasks, we can have \\(T=\\infty\\), we can then introduce discounting. Agent chooses \\(A_t\\) to maximize the expected discounted return: \\[\nG_t \\doteq R_{t+1}+\\gamma R_{t+2}+\\gamma^2 R_{t+3}+...=\\displaystyle\\sum_{k=0}^{\\infty} \\gamma^k R_{t+k+1}\n\\] where \\(\\gamma\\) is called the discount rate. \\[\nG_t = R_{t+1}+\\gamma G_{t+1}\n\\] Video MDP by Martha. By the end of this video: Understand Markov Decision Process (MDP), Describe how the dynamics of an MDP are defined.\nMartha highlights differences between k-armed bandit and MDP. The k-armed bandit agent is presented with the same situation at each time and the same action is always optimal. In many problems, different situations call for different responses. The actions we choose now affect the amount of reward we can get into the future. In particular if state changes, k-armed bandit don’t adapt. It is why we need MDP.\nVideo examples of MDPs by Adam . By the end of this video: Gain experience formalizing decision-making problems as MDPs, Appreciate the flexibility of the MDP formalism.\nAdam uses 2 examples: robot recycling cans and robot arm.\n\n\nLesson 2: Goal of Reinforcement Learning\nVideo the Goal of Reinforcement Learning by Adam. By the end of this video: Describe how rewards relate to the goal of an agent, Identify episodic tasks.\nWith MDP, agents can have long-term goals.\nVideo the Reward Hypothesis by Michael Littman.\nHe gives a nice idea when defining reward hypothesis: a contrast between the simplicity of the idea of rewards with the complexity of the real world.\n\n\nLesson 3: Continuing Tasks\nVideo Continuing Tasks by Martha. By the end of this video: Differentiate between episodic and continuing tasks. Formulate returns for continuing tasks using discounting. Describe how returns at successive time steps are related to each other.\nAdam uses a link to Sutton’s book., This is a 2020 version of this book.\nVideo Examples of Episodic and Continuing Tasks by Martha. By the end of this video: Understand when to formalize a task as episodic or continuing.\nMartha gives 2 examples: one of an episodic tasks where episode ends when player is touched by an enemy, one of continuous tasks where an agent accepts or rejects tasks depending on priority and servers available (never ending episode).\nWeekly assessment.\nThis is a quizz and a peer-graded assignment. I had to describe 3 MDPs with all its detail (states actions, rewards)."
  },
  {
    "objectID": "posts/2021-05-03-reinforcement-learning-specialization-coursera.html#course-1---week-3---value-functions-bellman-equations",
    "href": "posts/2021-05-03-reinforcement-learning-specialization-coursera.html#course-1---week-3---value-functions-bellman-equations",
    "title": "Reinforcement Learning Specialization - Coursera - course 1 - Fundamentals of Reinforcement Learning",
    "section": "5/10/21 - Course 1 - Week 3 - Value Functions & Bellman Equations",
    "text": "5/10/21 - Course 1 - Week 3 - Value Functions & Bellman Equations\n\nModule 3 Learning Objectives\nLesson 1: Policies and Value Functions\n\nRecognize that a policy is a distribution over actions for each possible state\nDescribe the similarities and differences between stochastic and deterministic policies\nIdentify the characteristics of a well-defined policy\nGenerate examples of valid policies for a given MDP\nDescribe the roles of state-value and action-value functions in reinforcement learning\nDescribe the relationship between value functions and policies\nCreate examples of valid value functions for a given MDP\n\nLesson 2: Bellman Equations\n\nDerive the Bellman equation for state-value functions\nDerive the Bellman equation for action-value functions\nUnderstand how Bellman equations relate current and future values\nUse the Bellman equations to compute value functions\n\nLesson 3: Optimality (Optimal Policies & Value Functions)\n\nDefine an optimal policy\nUnderstand how a policy can be at least as good as every other policy in every state\nIdentify an optimal policy for given MDPs\nDerive the Bellman optimality equation for state-value functions\nDerive the Bellman optimality equation for action-value functions\nUnderstand how the Bellman optimality equations relate to the previously introduced Bellman equations\nUnderstand the connection between the optimal value function and optimal policies\nVerify the optimal value function for given MDPs\n\n\n\nLesson 1: Policies and Value Functions\nReading chapter 3.5 to 3.8 (p58-67) in Sutton’s book\nAlmost all reinforcement learning algorithms involve estimating value functions—functions of states (or of state–action pairs) that estimate how good it is for the agent to be in a given state (or how good it is to perform a given action in a given state).\nSearching for additional informations, I have fallen into ShangtongZhang page and repos. Only 2 of them but seem to be great: reinforcement-learning-an-introduction contains implementations in Python of all concepts from Sutton’s book. DeepRL seems to be a pytorch implementations (DQN, A2C, PPO, …)\nHere we see Bellman equation for state-value function \\(v_\\pi(s)\\)\n\\[\nv_\\pi(s) \\doteq \\mathbb{E}[G_t|S_t=s]\n\\\\\nv_\\pi(s) = \\displaystyle\\sum_{a} \\pi(a|s) \\displaystyle\\sum_{s',r} p(s', r|s, a)\\big[r+\\gamma.v_\\pi(s')\\big]\n\\]\nBellman equation for action-value function \\(q_\\pi(s,a)\\)\n\\[\nq_\\pi(s,a) \\doteq \\mathbb{E}[R_{t+1}+\\gamma.G_{t+1}|S_t=s, A_t=a]\n\\\\\nq_\\pi(s, a) = \\displaystyle\\sum_{s',r} p(s', r|s, a) \\big[ r + \\gamma\\displaystyle\\sum_{a'} \\pi(s', a')q_\\pi(s',a') \\big]\n\\]\nOptimal state-value function \\(v_*\\):\n\\[\nv_*(s)\\doteq \\max\\limits_{\\pi} v_\\pi(s), \\forall s \\in S\n\\]\nOptimal action-value function \\(q_*\\): \\[\nq_*(s,a) \\doteq \\max\\limits_{\\pi} q_\\pi(s,a) = \\mathbb{E}[R_{t+1}+\\gamma.v_*(S_{t+1})|S_t=s, A_t=a]\n\\]\nWe denote all optimal policies by \\(\\pi_*\\)\nBellman optimality equation for \\(v_*\\)\n\\[\nv_*(s) = \\max\\limits_{a} \\displaystyle\\sum_{s', r} p(s',r|s, a)\\big[ r + \\gamma .v_*(s') \\big]\n\\]\nBellman optimality equation for \\(q_*\\)\n\\[\nq_*(s,a) = \\displaystyle\\sum_{s',r} p(s', r|s, a) \\big[ r + \\gamma.\\max\\limits_{a'} q_*(s',a') \\big]\n\\]\n\nVideo Specifying Policies by Adam.\nBy the end of this video, you’ll be able to\nRecognize that a policy is a distribution over actions for each possible state, describe the similarities and differences between stochastic and deterministic policies, and generate examples of valid policies for a given MDP or Markup Decision Process.\nVideo Value Functions by Adam.\nBy the end of this video, you’ll be able to\ndescribe the roles of the state-value and action-value functions in reinforcement learning, describe the relationship between value-functions and policies, and create examples of value-functions for a given MDP.\nVideo Rich Sutton and Andy Barto: A brief History of RL\n\n\nLesson 2: Bellman Equations\nVideo Bellman Equation Derivation by Martha\nBy the end of this video, you’ll be able to derive the Bellman equation for state-value functions, derive the Bellman equation for action-value functions, and understand how Bellman equations relate current and future values.\nVideo Why Bellman Equations? by Martha\nBy the end of this video, you’ll be able to use the Bellman equations to compute value functions\n\n\nLesson 3: Optimality (Optimal Policies & Value Functions)\nVideo Optimal Policies by Martha\nBy the end of this video, you will be able to define an optimal policy, understand how policy can be at least as good as every other policy in every state, and identify an optimal policy for a given MDP.\nVideo Optimal Value Functions by Martha\nBy the end of this video, you will be able to derive the Bellman optimality equation for the state-value function, derive the Bellman optimality equation for the action-value function, and understand how the Bellman optimality equations relate to the previously introduced Bellman equations.\nVideo Using Optimal Value Functions to Get Optimal Policies by Martha\nBy the end of this video, you’ll be able to understand the connection between the optimal value function and optimal policies and verify the optimal value function for a given MDP\nVideo week 3 summary by Adam\n\n\n\nPolicies"
  },
  {
    "objectID": "posts/2021-05-03-reinforcement-learning-specialization-coursera.html#course-1---week-4---dynamic-programming",
    "href": "posts/2021-05-03-reinforcement-learning-specialization-coursera.html#course-1---week-4---dynamic-programming",
    "title": "Reinforcement Learning Specialization - Coursera - course 1 - Fundamentals of Reinforcement Learning",
    "section": "5/18/21 - Course 1 - Week 4 - Dynamic Programming",
    "text": "5/18/21 - Course 1 - Week 4 - Dynamic Programming\n\nModule 4 Learning Objectives\nLesson 1: Policy Evaluation (Prediction)\n\nUnderstand the distinction between policy evaluation and control\nExplain the setting in which dynamic programming can be applied, as well as its limitations\nOutline the iterative policy evaluation algorithm for estimating state values under a given policy\n\nApply iterative policy evaluation to compute value functions\n\nLesson 2: Policy Iteration (Control)\n\nUnderstand the policy improvement theorem\nUse a value function for a policy to produce a better policy for a given MDP\nOutline the policy iteration algorithm for finding the optimal policy\nUnderstand “the dance of policy and value”\nApply policy iteration to compute optimal policies and optimal value functions\n\nLesson 3: Generalized Policy Iteration\n\nUnderstand the framework of generalized policy iteration\nOutline value iteration, an important example of generalized policy iteration\nUnderstand the distinction between synchronous and asynchronous dynamic programming methods\nDescribe brute force search as an alternative method for searching for an optimal policy\nDescribe Monte Carlo as an alternative method for learning a value function\nUnderstand the advantage of Dynamic programming and “bootstrapping” over these alternative strategies for finding the optimal policy\n\n\n\nLesson 1: Policy Evaluation (Prediction)\nReading chapter 4.1, 4.2, 4.3, 4.4, 4.6, 4.7 (pages 73-88) in Sutton’s book (with the help of Solutions_to_Reinforcement_Learning_by_Sutton_Chapter_4_r5.pdf)\nA common way of obtaining approximate solutions for tasks with continuous states and actions is to quantize the state and action spaces and then apply finite-state DP methods.\nVideo Policy Evaluation vs. Control by Martha\nBy the end of this video you will be able to understand the distinction between policy evaluation and control, and explain the setting in which dynamic programming can be applied as well as its limitations.\nVideo Iterative Policy Evaluation by Martha\nBy the end of this video you will be able to outline the iterative policy evaluation algorithm for estimating state values for a given policy, and apply iterative policy evaluation to compute value functions.\nThe magic here is to turn the bellman equation into an iterative evaluation which converges to \\(v_\\pi\\).\n\n\n\nLesson 2: Policy Iteration (Control)\nVideo Policy Improvement by Marta\nBy the end of this video, you will be able to understand the policy improvement theorem, and how it can be used to construct improved policies, and use the value function for a policy to produce a better policy for a given MDP.\nGreedified policy is a strict improvement.\n\nVideo Policy Iteration by Marta\nBy the end of this video, you will be able to outline the policy iteration algorithm for finding the optimal policy, understand the dance of policy and value, how policy iteration reaches the optimal policy by alternating between evaluating policy and improving it, and apply policy iteration to compute optimal policies and optimal value functions.\n\n\n\n\nLesson 3: Generalized Policy Iteration\nVideo Flexibility of the Policy Iteration Framework by Adam\nBy the end of this video, you’ll be able to understand the framework of generalized policy iteration, outline value iteration and important special case of generalized policy iteration, and differentiate synchronous and asynchronous dynamic programming methods.\nVideo Efficiency of Dynamic Programming by Adam\nBy the end of this video, you’ll be able to describe Monte Carlo sampling as an alternative method for learning a value function. Describe brute force-search as an alternative method for finding an optimal policy. And understand the advantages of dynamic programming and bootstrapping over these alternatives.\nThe most important takeaway is that bootstrapping can save us from performing a huge amount of unnecessary work by exploiting the connection between the value of a state and its possible successors.\nVideo Warren Powell: Approximate Dynamic Programming for Fleet Management (Short)\nVideo Week 4 Summary by Adam\nReading chapter summary Chapter 4.8, (pages 88-89)\n\n\nAssignment\nOptimal Policies with Dynamic Programming\nnotebooks in github\nend of C1W4 (course 1 week 4)\nend of course 1 (and with a certificate ;) )"
  },
  {
    "objectID": "posts/2021-09-28-Fix-pythoncom37.dll-Jupyter-Notebook.html",
    "href": "posts/2021-09-28-Fix-pythoncom37.dll-Jupyter-Notebook.html",
    "title": "Fix pythoncom37.dll popup when launching Jupyter Notebook",
    "section": "",
    "text": "when having this popup\n\n\n\nhttps://i.stack.imgur.com/2tQoH.png\n\n\nin my case it refers to stablebaselines3 conda environment.\nI just rename pythoncom37.dllto pythoncom37.dll.old in"
  },
  {
    "objectID": "posts/2023-03-03-icon-support-in-wsl.html",
    "href": "posts/2023-03-03-icon-support-in-wsl.html",
    "title": "Icon support in WSL / WSLg with native linux applications [fixed with WSL v1.1.7, broken again with WSL v1.2.x]",
    "section": "",
    "text": "As I have explained in https://github.com/microsoft/wslg/issues/944\nsome icons are missing and defaulting to Tux\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2023-03-03-icon-support-in-wsl.html#in-start-menu",
    "href": "posts/2023-03-03-icon-support-in-wsl.html#in-start-menu",
    "title": "Icon support in WSL / WSLg with native linux applications [fixed with WSL v1.1.7, broken again with WSL v1.2.x]",
    "section": "In Start Menu",
    "text": "In Start Menu\nNow that X11 apps are inserted into Windows Start Menu\n\n\n\nimage.png\n\n\n\nshortcuts to X11 apps\nThose entries are like other native windows ones.\nThey are located at %USERPROFILE%\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\ubuntu-22.04 (where ubuntu-22.04 is the name of my distrib)\nand we can update those icons (right click &gt; Plus &gt; Open file location)\n %USERPROFILE%\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\ubuntu-22.04\n\n\nadd new icons\nWe can now right click these entries, update icon. When installing apps, WSLg is creating icon entries into %USERPROFILE%\\AppData\\Local\\Temp\\WSLDVCPlugin\\ubuntu-22.04\\ (where ubuntu-22.04 is still the name of my distrib) I can add mine in that location\n %USERPROFILE%\\AppData\\Local\\Temp\\WSLDVCPlugin\\ubuntu-22.04\\\n\n\n(optional) from png to icon with zsh\nI can’t believe we cannot use png files as icon in Windows.\nHowever how to easily turn png file to ico file using zsh?\nCreate png2ico.zsh in ~/bin\n#!/usr/bin/zsh\npng2ico () {\n    local i=\"${1}\" o=\"${2:-${1:r}.ico}\" \n    convert \"$i\" -define icon:auto-resize=256,128,64,48,32,16 \"$o\"\n}\nCreate ico from png\nsource ~/bin/png2ico.zsh\npng2ico tilix_icon.png\n ico file created\nYou can move it to %USERPROFILE%\\AppData\\Local\\Temp\\WSLDVCPlugin\\ubuntu-22.04\\, and update Tilix entry from %USERPROFILE%\\AppData\\Roaming\\Microsoft\\Windows\\Start Menu\\Programs\\ubuntu-22.04 to use this new ico file\nWe can pin them in the Task bar, and in the Start screen\n\n\n\nimage.png\n\n\n\n\n\nimage.png\n\n\nbut when running them, this is a different story\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter-sans-images.html",
    "href": "posts/2020-09-10-blog-from-jupyter-sans-images.html",
    "title": "Blog from jupyter notebook",
    "section": "",
    "text": "That will be great if I can simply write blog entries using Jupyter Notebook.\nI usually paste inner images into jupyter cells. But this feature is not available yet into fastpages. So for the moment I won’t include images into these posts.\nThat way I could simply use markdown and insert images\nAnd directly see rendered impact before commiting and pushing to my blog."
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter-sans-images.html#get-local-repo-from-github",
    "href": "posts/2020-09-10-blog-from-jupyter-sans-images.html#get-local-repo-from-github",
    "title": "Blog from jupyter notebook",
    "section": "get local repo from github",
    "text": "get local repo from github\nAs I am behind a proxy most of my time when working from office, the easiest way for me is to work from WSL.\n\nWSL\nI won’t detail how to install WSL on Windows.\nI use ubuntu images (18.04) on my PC.\n\n\nset unset proxy in WSL\nI have just added some bash commands at the end of my .bashrc file.\n# Set Proxy\nfunction setproxy() {\n    export {http,https,ftp}_proxy=\"http://&lt;my proxy ip address&gt;:80\"\n    export {HTTP,HTTPS,FTP}_PROXY=\"http://&lt;my proxy ip address&gt;:80\"\n}\n\n# Unset Proxy\nfunction unsetproxy() {\n    unset {http,https,ftp}_proxy\n    unset {HTTP,HTTPS,FTP}_PROXY\n}\n\n\ngit clone castorfou.github.io\nI keep most of my local repos under ~/git/\ncd ~/git\nsetproxy\ngit clone https://github.com/castorfou/castorfou.github.io.git"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter-sans-images.html#create-a-blog-entry-with-jupyter-notebook",
    "href": "posts/2020-09-10-blog-from-jupyter-sans-images.html#create-a-blog-entry-with-jupyter-notebook",
    "title": "Blog from jupyter notebook",
    "section": "create a blog entry with Jupyter Notebook",
    "text": "create a blog entry with Jupyter Notebook"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter-sans-images.html#commit-and-push-to-github",
    "href": "posts/2020-09-10-blog-from-jupyter-sans-images.html#commit-and-push-to-github",
    "title": "Blog from jupyter notebook",
    "section": "commit and push to github",
    "text": "commit and push to github\n(base) guillaume@LL11LPC0PQARQ:~$ cd git\n(base) guillaume@LL11LPC0PQARQ:~/git$ cd castorfou.github.io/\n(base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git add .\n(base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git commit -m 'new blog entry: blog from jupyter'\n[master 6b7460a] new blog entry: blog from jupyter\n 4 files changed, 516 insertions(+)\n create mode 100644 _posts/.ipynb_checkpoints/2020-09-10-blog-from-jupyter-checkpoint.ipynb\n create mode 100644 _posts/2020-09-10-blog-from-jupyter.ipynb\n create mode 100644 _posts/2020-09-10-blog-from-jupyter.py\n create mode 100644 _posts/Untitled.txt\n(base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git push\nfatal: unable to access 'https://github.com/castorfou/castorfou.github.io.git/': gnutls_handshake() failed: The TLS connection was non-properly terminated.\n\nerror: gnutls_handshake() failed: The TLS connection was non-properly terminated.\nJust googling this error gives some insight: https://github.community/t/unable-to-push-to-repo-gnutls-handshake-failed/885\nIt is likely some local firewell issue.\n{% include alert.html text=“To be fixed later” %}\n\n\nswitch to mobile wifi without need of proxy\n(base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ unsetproxy\n(base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git push\nUsername for 'https://github.com': castorfou\nPassword for 'https://castorfou@github.com':\nCounting objects: 7, done.\nDelta compression using up to 8 threads.\nCompressing objects: 100% (6/6), done.\nWriting objects: 100% (7/7), 141.26 KiB | 10.09 MiB/s, done.\nTotal 7 (delta 1), reused 0 (delta 0)\nremote: Resolving deltas: 100% (1/1), completed with 1 local object.\nremote:\nremote: GitHub found 3 vulnerabilities on castorfou/castorfou.github.io's default branch (2 high, 1 moderate). To find out more, visit:\nremote:      https://github.com/castorfou/castorfou.github.io/network/alerts\nremote:\nTo https://github.com/castorfou/castorfou.github.io.git\n   6adeb02..6b7460a  master -&gt; master"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter-sans-images.html#check-entries-into-blog",
    "href": "posts/2020-09-10-blog-from-jupyter-sans-images.html#check-entries-into-blog",
    "title": "Blog from jupyter notebook",
    "section": "check entries into blog",
    "text": "check entries into blog\n\ndouble entries\nDouble entries: one for the notebook (.ipynb) and one for the auto python export (.py). I will have to update my jupyter settings to avoid this python file creation. In the meantime I can just delete the python file, and commit.\n{% include alert.html text=“Change settings of jupyter + .gitignore to avoid these double entries” %}\n\n\ncannot open notebook into browser\nClicking just ask me to download the notebook, it doesn’t display it into the browser.\n\n\nchecking .gitignore\nJust by looking into .gitignore, there is an interesting entry:\n*.swp\n~*\n*~\n_site\n.sass-cache\n.jekyll-cache\n.jekyll-metadata\nvendor\n_notebooks/.ipynb_checkpoints\nWait what is in this last line.\nLet’s create _notebooks directory and move my notebook in that directory.\n\n\nnotebooks from _notebooks not rendered\nNo entries, I guess there is some additional settings to do…\n{% include alert.html text=“Why notebooks are not rendered by Jekyl” %}\n\n\ntest entry from md using local repo\nThere is no problem with that.\nCreating a local md file in _poststhen pushing to github is creating the right entry blog.\n\n\nfollowing fastpages troubleshooting guide\n\nupgrade fastpages\nTry the automated upgrade as described in https://github.com/fastai/fastpages/blob/master/_fastpages_docs/UPGRADE.md\nUnfortunately I don’t see\nI have to follow the manual upgrade.\n\n\nmanual fastpages upgrade\nI am surprised because the 1st step from manual upgrade is to copy the fastpages repo. It is what I did 2 days ago. I doubt having an outdated version of fastpages.\n\n\n\nfastai forum: fastpages category\nI will browse through nbdev & faspages category in fastai forums. I should see people with the same issue.\nI have created an entry, into fastai forums: Fastpages - cannot see build process of GitHub Actions\nAnd quite immediately Hamel Hussain answered guiding to the write direction:\nI misread the Settings instruction: my github repo should explicitely NOT include my github username and I did exactly the opposite.\n{% include alert.html text=“I have to create a new repo: guillaume_blog” %}\n\n\nnothing visible from Actions tab\nAnd another surprising subject: at github in Actions tab. I have a kind of default page. I expect something like an execution journal of Actions.\n\n\nPage build failure\nReceived a notification by email:\nThe page build failed for the master branch with the following error:\nPage build failed. For more information, see https://docs.github.com/github/working-with-github-pages/troubleshooting-jekyll-build-errors-for-github-pages-sites#troubleshooting-build-errors.\nFor information on troubleshooting Jekyll see:\nhttps://docs.github.com/articles/troubleshooting-jekyll-builds\nIf you have any questions you can submit a request on the Contact GitHub page at https://support.github.com/contact?repo_id=293820308&page_build_id=202240535"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter-sans-images.html#move-to-another-repo",
    "href": "posts/2020-09-10-blog-from-jupyter-sans-images.html#move-to-another-repo",
    "title": "Blog from jupyter notebook",
    "section": "Move to another repo",
    "text": "Move to another repo\n\nrepo creation\nIt was just a matter of creating a new repo:\n\n\nactions monitoring\nMonitoring is effective\n\n\nmerge pull request\n\nactions around ssh keys\nFollowing the steps: - Create keys using ssh utility - Enter Secret Key - Enter Deploy Key\n\n\nmerge PR\nThere are conflicts to be fixed before that.\n\n\n\nAnd it works: https://castorfou.github.io/guillaume_blog/"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter-sans-images.html#get-local-repo",
    "href": "posts/2020-09-10-blog-from-jupyter-sans-images.html#get-local-repo",
    "title": "Blog from jupyter notebook",
    "section": "Get local repo",
    "text": "Get local repo\ncd ~/git\nunsetproxy\ngit clone https://github.com/castorfou/guillaume_blog.git"
  },
  {
    "objectID": "posts/2022-10-12-gradio_huggingface.html",
    "href": "posts/2022-10-12-gradio_huggingface.html",
    "title": "gradio and huggingface - handson",
    "section": "",
    "text": "HF news of the week early october\nThere is a new version of Gradio announced. Have to try it.\nThese apps can then be hosted on huggingface. Let’s try that."
  },
  {
    "objectID": "posts/2022-10-12-gradio_huggingface.html#source-of-inspiration",
    "href": "posts/2022-10-12-gradio_huggingface.html#source-of-inspiration",
    "title": "gradio and huggingface - handson",
    "section": "",
    "text": "HF news of the week early october\nThere is a new version of Gradio announced. Have to try it.\nThese apps can then be hosted on huggingface. Let’s try that."
  },
  {
    "objectID": "posts/2022-10-12-gradio_huggingface.html#how-to-do-it",
    "href": "posts/2022-10-12-gradio_huggingface.html#how-to-do-it",
    "title": "gradio and huggingface - handson",
    "section": "How to do it",
    "text": "How to do it\nI have a small need that gradio could fit perfectly.\nI am in the board of a badminton club. We have list of members given by one source. And updated rankings given by another source (these rankings can evolve during the year, actually after each game)\n\n\n\nimage.png\n\n\nThis project is in gh rbc\n\nGet rankings\nRankings are taken from badmania website at https://badmania.fr/club-joueurs-2254-riom-badminton-club.html\nIt is as easy as:\n\nimport pandas as pd\npd.read_html('https://badmania.fr/club-joueurs-2254-riom-badminton-club.html')[0].head()\n\n\n\n\n\n\n\n\nNom ▼▲\nNom ▼▲.1\nPrénom ▼▲\nPrénom ▼▲.1\nSexe\nLicence\nCatégorie ▼▲\nClassement ▼▲\nClass.\n\n\n\n\n0\nANDRAL\nAnthony\nANDRAL\nAnthony\nNaN\n7354056\nSenior\nP11/P10/P10\nP11/P10/P10\n\n\n1\nAVARGUEZ\nEric\nAVARGUEZ\nEric\nNaN\n6630518\nVeteran 6\nP11/D9/P10\nP11/D9/P10\n\n\n2\nBARBIER DARDARE\nLéna\nBARBIER...\nLéna\nNaN\n7454028\nMinibad\n-/-/-\n-/-/-\n\n\n3\nBARDEL\nDamien\nBARDEL\nDamien\nNaN\n7250210\nVeteran 1\nP12/P12/P11\nP12/P12/P11\n\n\n4\nBARRAUD\nInes\nBARRAUD\nInes\nNaN\n7354562\nNaN\n-/-/-\n-/-/-\n\n\n\n\n\n\n\nBecause list of members provide ‘Licence’ column (License), it is easy to link the 2 files together\nEverything is under update_classement.ipynb: * get_classement to extract ranking from a given license * add_classements to add all the ranking to the members list (using apply(lambda x: get_classement(x))\n\n\nExport rankings function with nbdev\nHere I am using the basic export function from nbdev2.\n\ndeclare filename to export to\nJust by inserting\n#|default_exp rbc\nat the top of notebook. It means it will export rbc.py\n\n\ndeclare what to export\nThis is the standard way using quarto directives.\nJust by inserting\n#| export\nin front of each cell of interest\n\n\ndeclare where to export, and export\nAt the bottom of notebook.\n#| hide\n\nimport nbdev; nbdev.export.nb_export('update_classement.ipynb', lib_path='.')\nIt creates rbc.py in the same directory as ‘update_classement.ipynb’. (lib_path)\n\n\n\nCreate gradio interface\n\nHere is a small example.\n\nimport gradio as gr\n\ndef greet(name):\n    return \"Hello \" + name + \"!\"\n\ndemo = gr.Interface(\n    fn=greet,\n    inputs=gr.Textbox(lines=2, placeholder=\"Name Here...\"),\n    outputs=\"text\",\n)\ndemo.launch()\n\nRunning on local URL:  http://127.0.0.1:7860\n\nTo create a public link, set `share=True` in `launch()`.\n\n\n\n\n\n(&lt;gradio.routes.App at 0x7ff6b688a310&gt;, 'http://127.0.0.1:7860/', None)\n\n\n\n\nOur interface\nEverything is in main.ipynb\nQuite simple, the gradio interface as Blocks,\nwith 2 file zones, one button and one action (click to send file content to a function analyse_fichier)\nanalyse_fichier which takes the file, use add_classements from rbc, save the new content in a temporary file, and return it as the 2nd file block output.\n\n\n\nimage.png\n\n\n\n\nexport to main.py\nThis is the same logic as earlier.\n\ndeclare export name with #|default_exp app\ndeclare cells to export with #| export\nexport from main.ipynb to main.py with import nbdev; nbdev.export.nb_export('main.ipynb', lib_path='.')\n\nJust by launching Restart kernel and run all cells, everything is run smoothly and main.py is created\n\n\n\nimage.png\n\n\n\n\n\nPublish to huggingface\nWe publish to Spaces in huggingface\nYou need an huggingface account. And created a space which is almost like creating a git repo.\n\n\n\nimage.png\n\n\nThen you can drag and drop main.py or git push to this location. This last option is what I used.\nI have just created a new space called rbc at https://huggingface.co/spaces/Guillaume63/rbc\nI can now git clone this repo to a folder aside my current project (I used rbc_hugginface)\ncd ~/git\ngit clone https://huggingface.co/spaces/Guillaume63/rbc rbc_huggingface\nI can now copy these files to it, git add, commit, push, and voila - requirements.txt - app.py - main.py\nI have stored that in the pubglish_to_hf.sh bash script\n#!/bin/bash\n# git clone https://huggingface.co/spaces/Guillaume63/rbc rbc_huggingface\nNOW=`date '+%F_%H:%M'`;\ncp *.py ../rbc_huggingface\ncp requirements.txt ../rbc_huggingface\ncd ../rbc_huggingface\ngit add .\ngit commit -am\"$NOW\"\ngit push\ncd ../rbc\nDemo recorded with peek (peek -b ffmpeg)\n\n\nTODO using gh actions\nA nicer approach would be to use github actions to publish to huggingface.\nAt each commit on github, actions would run to commit our 3 files to huggingface.\nhttps://huggingface.co/docs/hub/spaces-github-actions"
  },
  {
    "objectID": "posts/2021-05-25-reinforcement-learning-specialization-coursera-course2.html",
    "href": "posts/2021-05-25-reinforcement-learning-specialization-coursera-course2.html",
    "title": "Reinforcement Learning Specialization - Coursera - course 2 - Sample-based Learning Methods",
    "section": "",
    "text": "Coursera website: course 2 - Sample-based Learning Methods of Reinforcement Learning Specialization\nmy notes on course 1 - Fundamentals of Reinforcement Learning, course 3 - Prediction and Control with Function Approximation, course 4 - A Complete Reinforcement Learning System (Capstone)\nspecialization roadmap - course 2 - Sample-based Learning Methods\ncourse 2 - In Course 2, we built on these ideas and design algorithms for learning without a model of the world. We study three classes of methods designed for learning from trial and error interaction. We start with Monte Carlo methods and then move on to temporal difference learning, including Q learning. We conclude Course 2 with an investigation of methods for planning with learned models.\nWeek 1 - Monte-Carlo Methods for Prediction & Control\nWeek 2 - Temporal Difference Learning Methods for Prediction\nWeek 3 - Temporal Difference Learning Methods for Control\nWeek 4 - Planning, Learning & Acting"
  },
  {
    "objectID": "posts/2021-05-25-reinforcement-learning-specialization-coursera-course2.html#course-2---week-1---monte-carlo-methods-for-prediction-control",
    "href": "posts/2021-05-25-reinforcement-learning-specialization-coursera-course2.html#course-2---week-1---monte-carlo-methods-for-prediction-control",
    "title": "Reinforcement Learning Specialization - Coursera - course 2 - Sample-based Learning Methods",
    "section": "Course 2 - Week 1 - Monte-Carlo Methods for Prediction & Control",
    "text": "Course 2 - Week 1 - Monte-Carlo Methods for Prediction & Control\n\nModule 1 Learning Objectives\nLesson 1: Introduction to Monte-Carlo Methods\n\nUnderstand how Monte-Carlo methods can be used to estimate value functions from sampled interaction\nIdentify problems that can be solved using Monte-Carlo methods\nUse Monte-Carlo prediction to estimate the value function for a given policy.\n\nLesson 2: Monte-Carlo for Control\n\nEstimate action-value functions using Monte-Carlo\nUnderstand the importance of maintaining exploration in Monte-Carlo algorithms\nUnderstand how to use Monte-Carlo methods to implement a GPI algorithm\nApply Monte-Carlo with exploring starts to solve an MDP\n\nLesson 3: Exploration Methods for Monte-Carlo\n\nUnderstand why exploring starts can be problematic in real problems\nDescribe an alternative exploration method for Monte-Carlo control\n\nLesson 4: Off-policy learning for prediction\n\nUnderstand how off-policy learning can help deal with the exploration problem\nProduce examples of target policies and examples of behavior policies\nUnderstand importance sampling\nUse importance sampling to estimate the expected value of a target distribution using samples from a different distribution\nUnderstand how to use importance sampling to correct returns\nUnderstand how to modify the Monte-Carlo prediction algorithm for off-policy learning.\n\n\n\nLesson 1: Introduction to Monte Carlo Methods\nReading Chapter 5.0-5.5 (pp. 91-104) in the Reinforcement Learning textbook\n\nAlthough a model is required, the model need only generate sample transitions, not the complete probability distributions of all possible transitions that is required for dynamic programming (DP).\n\nVideo What is Monte Carlo by Martha\nBy the end of this video you will be able to understand how Monte Carlo methods can be used to estimate value functions from sampled interaction and identify problems that can be solved using Monte Carlo methods.\nVideo Using Monte Carlo for Prediction by Martha\nBy the end of this video, you will be able to use Monte Carlo prediction to estimate the value function for a given policy.\n\n\n\nLesson 2: Monte Carlo for Control\nVideo Using Monte Carlo for Action Values by Adam\nBy the end of this video, you’ll be able to estimate action-value functions using Monte Carlo and understand the importance of maintaining exploration in Monte Carlo algorithms.\nVideo Using Monte Carlo methods for generalized policy iteration by Adam\nBy the end of this video, you will understand how to use Monte Carlo methods to implement a generalized policy iteration GPI algorithm.\n\nVideo Solving the BlackJack Example by Adam\nBy the end of this video, you’ll be able to apply Monte Carlo with Exploring Starts to solve an example MDP.\n\n\nLesson 3: Exploration Methods for Monte Carlo\nVideo Epsilon-soft policies by Adam\nBy the end of this video you will understand why exploring starts can be problematic in real problems and you will be able to describe an alternative expiration method to maintain exploration in Monte Carlo control.\n\n\nLesson 4: Off-policy Learning for Prediction\nVideo Why does off-policy learning matter? by Martha\nBy the end of this video you will be able to understand how off policy learning can help deal with the expiration problem. You will also be able to produce examples of Target policies and examples of behavior policies.\nThe key points to take away from today are that off policy learning is another way to obtain continual exploration. The policy that we are learning is called the target policy and the policy that we are choosing actions from is the behavior policy.\nVideo Importance Sampling by Martha\nBy the end of this video, you will be able to use importance sampling to estimate the expected value of a target distribution using samples from a different distribution.\nVideo Off-Policy Monte Carlo Prediction by Martha\nBy the end of this video, you will be able to understand how to use important sampling to correct returns, and you will understand how to modify the Monte Carlo prediction algorithm for off-policy learning.\nVideo Emma Brunskill: Batch Reinforcement Learning\nVideo Week 1 Summary by Martha\nReading Chapter 5.10 (pp. 115-116) in the Reinforcement Learning textbook"
  },
  {
    "objectID": "posts/2021-05-25-reinforcement-learning-specialization-coursera-course2.html#course-2---week-2---temporal-difference-learning-methods-for-prediction",
    "href": "posts/2021-05-25-reinforcement-learning-specialization-coursera-course2.html#course-2---week-2---temporal-difference-learning-methods-for-prediction",
    "title": "Reinforcement Learning Specialization - Coursera - course 2 - Sample-based Learning Methods",
    "section": "Course 2 - Week 2 - Temporal Difference Learning Methods for Prediction",
    "text": "Course 2 - Week 2 - Temporal Difference Learning Methods for Prediction\n\nModule 2 Learning Objectives\nLesson 1: Introduction to Temporal Difference Learning\n\nDefine temporal-difference learning\nDefine the temporal-difference error\nUnderstand the TD(0) algorithm\n\nLesson 2: Advantages of TD\n\nUnderstand the benefits of learning online with TD\nIdentify key advantages of TD methods over Dynamic Programming and Monte Carlo methods\nIdentify the empirical benefits of TD learning\n\n\n\nLesson 1: Introduction to Temporal Difference Learning\nReading Chapter 6-6.3 (pp. 116-128) in the Reinforcement Learning textbook\nVideo What is Temporal Difference (TD) learning? by Adam\nBy the end of this video, you’ll be able to define temporal difference learning, define the temporal difference error, and understand the TD(0) algorithm.\n\nVideo Rich Sutton: The Importance of TD Learning by Richard Sutton\n\n\nLesson 2: Advantages of TD\nVideo The advantages of temporal difference learning by Martha\nBy the end of this video, you will be able to understand the benefits of learning online with TD and identify key advantages of TD methods over dynamic programming and Monte Carlo.\nVideo Comparing TD and Monte Carlo by Adam\nBy the end of this video, you’ll be able to identify the empirical benefits of TD Learning.\nVideo Andy Barto and Rich Sutton: More on the History of RL\nVideo Week 2 Summary by Adam\n\n\nAssignment\nPolicy Evaluation in Cliff Walking Environment\nnotebooks in github"
  },
  {
    "objectID": "posts/2021-05-25-reinforcement-learning-specialization-coursera-course2.html#course-2---week-3---temporal-difference-learning-methods-for-control",
    "href": "posts/2021-05-25-reinforcement-learning-specialization-coursera-course2.html#course-2---week-3---temporal-difference-learning-methods-for-control",
    "title": "Reinforcement Learning Specialization - Coursera - course 2 - Sample-based Learning Methods",
    "section": "Course 2 - Week 3 - Temporal Difference Learning Methods for Control",
    "text": "Course 2 - Week 3 - Temporal Difference Learning Methods for Control\n\nModule 3 Learning Objectives\nLesson 1: TD for Control\n\nExplain how generalized policy iteration can be used with TD to find improved policies\nDescribe the Sarsa control algorithm\nUnderstand how the Sarsa control algorithm operates in an example MDP\nAnalyze the performance of a learning algorithm\n\nLesson 2: Off-policy TD Control: Q-learning\n\nDescribe the Q-learning algorithm\nExplain the relationship between Q-learning and the Bellman optimality equations.\nApply Q-learning to an MDP to find the optimal policy\nUnderstand how Q-learning performs in an example MDP\nUnderstand the differences between Q-learning and Sarsa\nUnderstand how Q-learning can be off-policy without using importance sampling\nDescribe how the on-policy nature of Sarsa and the off-policy nature of Q-learning affect their relative performance\n\nLesson 3: Expected Sarsa\n\nDescribe the Expected Sarsa algorithm\nDescribe Expected Sarsa’s behaviour in an example MDP\nUnderstand how Expected Sarsa compares to Sarsa control\nUnderstand how Expected Sarsa can do off-policy learning without using importance sampling\nExplain how Expected Sarsa generalizes Q-learning\n\n\n\nLesson 1: TD for Control\nReading Chapter 6.4-6.6 (pp. 129-134) in the Reinforcement Learning textbook\n\n\nVideo Sarsa: GPI with TD by Martha\nBy the end of this video, you’ll be able to explain how generalized policy iteration can be used with TD to find improved policies, as well as describe the Sarsa control algorithm\nVideo Sarsa in the Windy Grid World by Adam\nBy the end of this video, you will understand how the Sarsa control algorithm operates in an example MDP. You will also gain experience analyzing the performance of a learning algorithm.\n\n\nLesson 2: Off-policy TD Control: Q-learning\nVideo What is Q-learning? by Martha\nBy the end of this video, you will be able to describe the Q-learning algorithm, and explain the relationship between Q-learning and the Bellman optimality equations.\nVideo Q-learning in the Windy Grid World by Adam\nBy the end of this video, you will gain insight into how Q-Learning performs in an example MDP. And gain experience comparing the performance of multiple learning algorithms on a single MDP.\nVideo How is Q-learning off-policy? by Martha\nBy the end of this video, you will understand how Q-learning can be off-policy without using important sampling and be able to describe how learning on-policy or off-policy might affect performance in control.\n\n\nLesson 3: Expected Sarsa\nVideo Expected Sarsa by Martha\nBy the end of this video, you will be able to explain the expected Sarsa algorithm.\nVideo Expected Sarsa in the Cliff World by Adam\nBy the end of this video, you will be able to describe expected Sarsas’s behavior in an example MDP and empirically compare expected Sarsa and Sarsa.\nVideo Generality of Expected Sarsa by Martha\nBy the end of this video, you will understand how Expected Sarsa can do off-policy learning without using importance sampling and explain how Expected Sarsa generalizes Q-learning.\nVideo Week 3 summary by Adam\n\nSarsa uses a sample based version of the Bellman equation. It learns Q-pi.\nQ-learning uses the Bellman optimality equation. It learns Q-star.\nExpected sarsa uses the same Bellman equation as Sarsa, but samples it differently. It takes an expectation over the next action values.\nWhat’s the story with on-policy and off-policy learning?\nSarsa is a on-policy algorithm that learns the action values for the policy it’s currently following. Q-learning is an off-policy algorithm that learns the optimal action values. And Expected Sarsa is both an on-policy and an off-policy algorithm that can learn the action values for any policy.\n\n\nAssignment\nQ-Learning and Expected Sarsa\nnotebooks in github"
  },
  {
    "objectID": "posts/2021-05-25-reinforcement-learning-specialization-coursera-course2.html#course-2---week-4---planning-learning-acting",
    "href": "posts/2021-05-25-reinforcement-learning-specialization-coursera-course2.html#course-2---week-4---planning-learning-acting",
    "title": "Reinforcement Learning Specialization - Coursera - course 2 - Sample-based Learning Methods",
    "section": "Course 2 - Week 4 - Planning, Learning & Acting",
    "text": "Course 2 - Week 4 - Planning, Learning & Acting\n\nModule 4 Learning Objectives\nLesson 1: What is a model?\n\nDescribe what a model is and how they can be used\nClassify models as distribution models or sample models\nIdentify when to use a distribution model or sample model\nDescribe the advantages and disadvantages of sample models and distribution models\nExplain why sample models can be represented more compactly than distribution models\n\nLesson 2: Planning\n\nExplain how planning is used to improve policies\nDescribe random-sample one-step tabular Q-planning\n\nLesson 3: Dyna as a formalism for planning\n\nRecognize that direct RL updates use experience from the environment to improve a policy or value function\nRecognize that planning updates use experience from a model to improve a policy or value function\nDescribe how both direct RL and planning updates can be combined through the Dyna architecture\nDescribe the Tabular Dyna-Q algorithm\nIdentify the direct-RL and planning updates in Tabular Dyna-Q\nIdentify the model learning and search control components of Tabular Dyna-Q\nDescribe how learning from both direct and simulated experience impacts performance\nDescribe how simulated experience can be useful when the model is accurate\n\nLesson 4: Dealing with inaccurate models\n\nIdentify ways in which models can be inaccurate\nExplain the effects of planning with an inaccurate model\nDescribe how Dyna can plan successfully with a partially inaccurate model\nExplain how model inaccuracies produce another exploration-exploitation trade-off\nDescribe how Dyna-Q+ proposes a way to address this trade-off\n\nLesson 5: Course wrap-up\n\n\nLesson 1: What is a model?\nReading Chapter 8.1-8.3 (pp. 159-166) in the Reinforcement Learning textbook\n\nModel-based methods rely on planning as their primary component, while model-free methods primarily rely on learning.\n\nVideo What is a Model? by Martha\nBy the end of the video, you will be able to describe a model and how it can be used, classify models as distribution models or sample models, and identify when to use a distribution model or sample model.\nVideo Comparing Sample and Distribution Models by Martha\nBy the end of this video, you will be able to describe the advantages and disadvantages of sample models and distribution models, and you will also be able to explain why sample models can be represented more compactly than distribution models.\n\n\nLesson 2: Planning\nVideo Random Tabular Q-planning by Martha\nBy the end of this video, you’ll be able to explain how planning is used to improve policies and describe random-sample one-step tabular Q-planning.\n\n\nLesson 3: Dyna as a formalism for planning\nVideo The Dyna Architecture by Adam\nBy the end of this video, you will be able to understand how simulate experience from the model differs from interacting with the environment. You will also understand how the Dyna architecture mixes direct RL updates and planning updates.\n\nVideo The Dyna Algorithm by Adam\nBy the end of this video, you should be able to describe how Tabular Dyna-Q works. You will also be able to identify the direct-RL, planning updates in Tabular Dyna-Q, and identify the model learning and search control components of Tabular Dyna-Q.\n\nVideo Dyna & Q-learning in a Simple Maze by Adam\nBy the end of this video you will be able to describe how learning from both environment-real and model experience impacts performance. You will also be able to explain how an accurate model allows the agent to learn from fewer environment interactions.\n\n\nLesson 4: Dealing with inaccurate models\nVideo What if the model is inaccurate? by Martha\nBy the end of this video you will be able to identify ways in which models can be inaccurate, explain the effects of planning with an inaccurate model, and describe how Dyna can plan successfully with an incomplete model.\nVideo In-depth with changing environments by Adam\nBy the end of this video, you’ll be able to explain how model inaccuracies produce another exploration-exploitation trade-off, and describe how Dyna-Q+ addresses this trade-off.\n\nVideo Drew Bagnell: self-driving, robotics, and Model Based RL\nVideo week 4 summary by Martha\n\n\nAssignment\nDyna-Q and Dyna-Q+\nnotebooks in github\nChapter summary Chapter 8.12 (pp. 188)\n\n\nPlanning, acting, and model-learning interact in a circular fashion (as in the figure above), each producing what the other needs to improve; no other interaction among them is either required or prohibited.\n\n\nText Book Part 1 Summary\n\nFor a summary of what we’ve covered in the specialization so far, read: pp. 189-191 in Reinforcement Learning: an introduction .\n\nAll of the methods we have explored so far in this book have three key ideas in common: first, they all seek to estimate value functions; second, they all operate by backing up values along actual or possible state trajectories; and third, they all follow the general strategy of generalized policy iteration (GPI), meaning that they maintain an approximate value function and an approximate policy, and they continually try to improve each on the basis of the other. These three ideas are central to the subjects covered in this book. We suggest that value functions, backing up value updates, and GPI are powerful organizing principles potentially relevant to any model of intelligence, whether artificial or natural.\n\n\nCourse wrap-up"
  },
  {
    "objectID": "posts/2022-10-13-dockerdss.html",
    "href": "posts/2022-10-13-dockerdss.html",
    "title": "Run dataiku with docker",
    "section": "",
    "text": "Would like to play with dataiku to do some dataprep\nBut I don’t want to install it."
  },
  {
    "objectID": "posts/2022-10-13-dockerdss.html#source-of-inspiration",
    "href": "posts/2022-10-13-dockerdss.html#source-of-inspiration",
    "title": "Run dataiku with docker",
    "section": "",
    "text": "Would like to play with dataiku to do some dataprep\nBut I don’t want to install it."
  },
  {
    "objectID": "posts/2022-10-13-dockerdss.html#install-docker-run-docker-service",
    "href": "posts/2022-10-13-dockerdss.html#install-docker-run-docker-service",
    "title": "Run dataiku with docker",
    "section": "Install docker, run docker service",
    "text": "Install docker, run docker service\n\nfor WSL\nEverything explained at Docker for wsl\n\n\nfor linux\nI guess this is the same logic\nsudo apt list --installed |grep docker\ndocker-ce-cli/focal,now 5:20.10.18~3-0~ubuntu-focal amd64 [installed]\ndocker-ce-rootless-extras/focal,now 5:20.10.18~3-0~ubuntu-focal amd64 [installed,automatic]\ndocker-ce/focal,now 5:20.10.18~3-0~ubuntu-focal amd64 [installed]\ndocker-compose-plugin/focal,now 2.10.2~ubuntu-focal amd64 [installed]\ndocker-scan-plugin/focal,now 0.17.0~ubuntu-focal amd64 [installed,automatic]\nsudo apt install -y docker-ce docker-ce-cli containerd.io \nsudo usermod -aG docker $USER\nsudo service docker start\nsudo curl -L \"https://github.com/docker/compose/releases/download/v2.11.2/docker-compose-linux-x86_64\" -o /usr/local/bin/docker-compose\nsudo chmod +x /usr/local/bin/docker-compose\n\n\ndocker service status\nsudo service docker status\n● docker.service - Docker Application Container Engine\n     Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled)\n     Active: active (running) since Tue 2022-10-11 10:26:23 CEST; 2 days ago\nTriggeredBy: ● docker.socket\n       Docs: https://docs.docker.com\n   Main PID: 2231 (dockerd)\n      Tasks: 18\n     Memory: 120.5M\n        CPU: 1min 4.466s\n     CGroup: /system.slice/docker.service\n             └─2231 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock"
  },
  {
    "objectID": "posts/2022-10-13-dockerdss.html#useful-commands",
    "href": "posts/2022-10-13-dockerdss.html#useful-commands",
    "title": "Run dataiku with docker",
    "section": "Useful commands",
    "text": "Useful commands\n\nlist images\ndocker ps\ndocker images\n\n!docker images\n\nREPOSITORY               TAG             IMAGE ID       CREATED         SIZE\nevalai_worker            latest          dba6096090fb   2 months ago    2.58GB\nevalai_django            latest          ae485874e456   2 months ago    1.52GB\nevalai_nodejs_v2         latest          2c31d7c19b50   2 months ago    2GB\nevalai_nodejs            latest          870941d3fc88   2 months ago    1.98GB\nsoftwaremill/elasticmq   latest          b722353e4eaa   2 months ago    648MB\nnode                     14.20.0         326f034bd14b   3 months ago    914MB\nprom/statsd-exporter     latest          a52efa669891   3 months ago    17MB\n&lt;none&gt;                   &lt;none&gt;          5b8afa69cc58   11 months ago   422MB\n&lt;none&gt;                   &lt;none&gt;          66a693993cdc   11 months ago   422MB\n&lt;none&gt;                   &lt;none&gt;          5db5659b96f2   11 months ago   422MB\n&lt;none&gt;                   &lt;none&gt;          7bd2798881a8   11 months ago   422MB\n&lt;none&gt;                   &lt;none&gt;          a1753859aadb   11 months ago   422MB\n&lt;none&gt;                   &lt;none&gt;          adea02a35542   11 months ago   559MB\ndebian                   bullseye-slim   dd984c2cf05c   12 months ago   80.4MB\npython                   3.7.5           fbf9f709ca9f   2 years ago     917MB\nnode                     12.2.0          502d06d3bfdf   3 years ago     906MB\npostgres                 10.4            978b82dc00dc   4 years ago     236MB\n\n\nHere we can see I played with evalai…\n\n\nrun image\nTo enter into an image in interactive mode\ndocker run -ti &lt;REPO&gt;:&lt;TAG&gt;\nas an example\ndocker run -it python:3.7.5 \nPython 3.7.5 (default, Nov 23 2019, 05:59:34) \n[GCC 8.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n&gt;&gt;&gt; \n\n\nstop image\ndocker stop &lt;Container_ID&gt;\ndocker rm &lt;Container_ID&gt;"
  },
  {
    "objectID": "posts/2022-10-13-dockerdss.html#dataiku-dss",
    "href": "posts/2022-10-13-dockerdss.html#dataiku-dss",
    "title": "Run dataiku with docker",
    "section": "Dataiku DSS",
    "text": "Dataiku DSS\nhttps://hub.docker.com/r/dataiku/dss/\nStart a DSS instance on the default internal data directory, exposing DSS on the default port (10000)\ndocker run -p 10000:10000 -d dataiku/dss\nAlternatively, you can start a DSS instance on a mounted data directory or Docker volume, exposing DSS on the default port (10000).\nmkdir ~/dss\ndocker run -p 10000:10000 -v /home/explore/dss:/home/dataiku/dss -d dataiku/dss\nOpen DSS in your browser (Chrome or Firefox)\nFor Linux, open http://localhost:10000\nDefault login/password (admin/admin)\n\n\n\nimage.png\n\n\nAnd I can start it just from lunching start.sh from Appliations/dataiku\n\n\n\nimage.png\n\n\nMounting with volume configuration will keep all modifications.\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-10-13-dockerdss.html#portainer",
    "href": "posts/2022-10-13-dockerdss.html#portainer",
    "title": "Run dataiku with docker",
    "section": "Portainer",
    "text": "Portainer\nI will use the community edition which is open source.\nBut portainer.io is providing nice documentation on:\n\ndocker and container: https://install.portainer.io/containers-101\nportainer: https://install.portainer.io/portainer-101\n\nFor CE installation, everything is detailed at https://docs.portainer.io/v/ce-2.9/start/install/server/docker/wsl\ndocker volume create portainer_data\ndocker run -d -p 8000:8000 -p 9443:9443 --name portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce:2.9.3\nhttps://localhost:9443\ncreate admin user (admin/adminadmin)\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2020-10-09-gan-course2-week2-disadventages-bias.html",
    "href": "posts/2020-10-09-gan-course2-week2-disadventages-bias.html",
    "title": "GAN Specialization course 2 week 2 - Disadvantages and Bias",
    "section": "",
    "text": "Notes\n\n\n\nalt text"
  },
  {
    "objectID": "posts/2020-12-08-share-github-repo-on-2-pc.html",
    "href": "posts/2020-12-08-share-github-repo-on-2-pc.html",
    "title": "Repo with 2 remote-urls",
    "section": "",
    "text": "from github\nI have just created this empty repo: https://github.com/castorfou/data-scientist-skills\n\n\nfrom existing local repo connected to gitlab\nAdd the new remote url to github, name it github\n(base) guillaume@LL11LPC0PQARQ:~/git/data-scientist-skills$ git remote add github https://github.com/castorfou/data-scientist-skills.git\nOr this is possible to use ssh protocol: git remote add origin git@github.com:castorfou/data-scientist-skills.git\nPush repo to this new remote url: git push -u github\n(base) guillaume@LL11LPC0PQARQ:~/git/data-scientist-skills$ git push -u github\nUsername for 'https://github.com': castorfou\nPassword for 'https://castorfou@github.com':\nCounting objects: 4736, done.\nDelta compression using up to 8 threads.\nCompressing objects: 100% (3171/3171), done.\nWriting objects: 100% (4736/4736), 630.97 MiB | 9.08 MiB/s, done.\nTotal 4736 (delta 1549), reused 4538 (delta 1458)\nremote: Resolving deltas: 100% (1549/1549), done.\nTo https://github.com/castorfou/data-scientist-skills.git\n * [new branch]      master -&gt; master\nBranch 'master' set up to track remote branch 'master' from 'github'.\n\n\nfor new local repo\nClone the new repo: git clone git@github.com:castorfou/data-scientist-skills.git\nAnd I want to have same names for same remotes: git remote rename origin github\nSo now it is quite easy to update from different remote repo:\ncat refresh_from_github.sh \n#!/bin/bash\ngit fetch github\ngit pull"
  },
  {
    "objectID": "posts/2023-09-01-logbook-September-23.html",
    "href": "posts/2023-09-01-logbook-September-23.html",
    "title": "Logbook for September 23",
    "section": "",
    "text": "wslg x11 apps freeze, video compression"
  },
  {
    "objectID": "posts/2023-09-01-logbook-September-23.html#monday-0911",
    "href": "posts/2023-09-01-logbook-September-23.html#monday-0911",
    "title": "Logbook for September 23",
    "section": "Monday 09/11",
    "text": "Monday 09/11\nI have just opened an issue at wslg GUI apps freeze as soon as detecting network change\nAfter inactivity or network change, x11 apps freeze.\nHave not yet identified why."
  },
  {
    "objectID": "posts/2023-09-01-logbook-September-23.html#tuesday-0913",
    "href": "posts/2023-09-01-logbook-September-23.html#tuesday-0913",
    "title": "Logbook for September 23",
    "section": "Tuesday 09/13",
    "text": "Tuesday 09/13\nVideo compression with ffmpeg\nI have used standard Windows screenshot tool to record a video illsutrating GUI apps freeze as soon as detecting network change issue.\nIt is short and its size is 175 MB. A little bit to much to add it to github issue.\nI used ffmpeg to compress it.\nffmpeg -i input.mp4 -vcodec libx265 -crf 20 output.mp4\n-crf 20 is a compression parameter. Higher parameter will result a lighter video but with negative quality impact.\nCompressed video is 5 MB. (30x size reduction, not that bad)\nI can use it in github issues."
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter.html",
    "href": "posts/2020-09-10-blog-from-jupyter.html",
    "title": "Blog from jupyter notebook",
    "section": "",
    "text": "That will be great if I can simply write blog entries using Jupyter Notebook.\nThat way I could simply use markdown and insert images\nAnd directly see rendered impact before commiting and pushing to my blog."
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter.html#get-local-repo-from-github",
    "href": "posts/2020-09-10-blog-from-jupyter.html#get-local-repo-from-github",
    "title": "Blog from jupyter notebook",
    "section": "get local repo from github",
    "text": "get local repo from github\nAs I am behind a proxy most of my time when working from office, the easiest way for me is to work from WSL.\n\nWSL\nI won’t detail how to install WSL on Windows.\nI use ubuntu images (18.04) on my PC.\n\n\n\nimage.png\n\n\n\n\nset unset proxy in WSL\nI have just added some bash commands at the end of my .bashrc file.\n# Set Proxy\nfunction setproxy() {\n    export {http,https,ftp}_proxy=\"http://&lt;my proxy ip address&gt;:80\"\n    export {HTTP,HTTPS,FTP}_PROXY=\"http://&lt;my proxy ip address&gt;:80\"\n}\n\n# Unset Proxy\nfunction unsetproxy() {\n    unset {http,https,ftp}_proxy\n    unset {HTTP,HTTPS,FTP}_PROXY\n}\n\n\ngit clone castorfou.github.io\nI keep most of my local repos under ~/git/\ncd ~/git\nsetproxy\ngit clone https://github.com/castorfou/castorfou.github.io.git\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter.html#create-a-blog-entry-with-jupyter-notebook",
    "href": "posts/2020-09-10-blog-from-jupyter.html#create-a-blog-entry-with-jupyter-notebook",
    "title": "Blog from jupyter notebook",
    "section": "create a blog entry with Jupyter Notebook",
    "text": "create a blog entry with Jupyter Notebook"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter.html#commit-and-push-to-github",
    "href": "posts/2020-09-10-blog-from-jupyter.html#commit-and-push-to-github",
    "title": "Blog from jupyter notebook",
    "section": "commit and push to github",
    "text": "commit and push to github\n(base) guillaume@LL11LPC0PQARQ:~$ cd git\n(base) guillaume@LL11LPC0PQARQ:~/git$ cd castorfou.github.io/\n(base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git add .\n(base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git commit -m 'new blog entry: blog from jupyter'\n[master 6b7460a] new blog entry: blog from jupyter\n 4 files changed, 516 insertions(+)\n create mode 100644 _posts/.ipynb_checkpoints/2020-09-10-blog-from-jupyter-checkpoint.ipynb\n create mode 100644 _posts/2020-09-10-blog-from-jupyter.ipynb\n create mode 100644 _posts/2020-09-10-blog-from-jupyter.py\n create mode 100644 _posts/Untitled.txt\n(base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git push\nfatal: unable to access 'https://github.com/castorfou/castorfou.github.io.git/': gnutls_handshake() failed: The TLS connection was non-properly terminated.\n\nerror: gnutls_handshake() failed: The TLS connection was non-properly terminated.\nJust googling this error gives some insight: https://github.community/t/unable-to-push-to-repo-gnutls-handshake-failed/885\nIt is likely some local firewell issue.\n{% include alert.html text=“To be fixed later” %}\n\n\nswitch to mobile wifi without need of proxy\n(base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ unsetproxy\n(base) guillaume@LL11LPC0PQARQ:~/git/castorfou.github.io$ git push\nUsername for 'https://github.com': castorfou\nPassword for 'https://castorfou@github.com':\nCounting objects: 7, done.\nDelta compression using up to 8 threads.\nCompressing objects: 100% (6/6), done.\nWriting objects: 100% (7/7), 141.26 KiB | 10.09 MiB/s, done.\nTotal 7 (delta 1), reused 0 (delta 0)\nremote: Resolving deltas: 100% (1/1), completed with 1 local object.\nremote:\nremote: GitHub found 3 vulnerabilities on castorfou/castorfou.github.io's default branch (2 high, 1 moderate). To find out more, visit:\nremote:      https://github.com/castorfou/castorfou.github.io/network/alerts\nremote:\nTo https://github.com/castorfou/castorfou.github.io.git\n   6adeb02..6b7460a  master -&gt; master"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter.html#check-entries-into-blog",
    "href": "posts/2020-09-10-blog-from-jupyter.html#check-entries-into-blog",
    "title": "Blog from jupyter notebook",
    "section": "check entries into blog",
    "text": "check entries into blog\n\ndouble entries\n\n\n\nimage.png\n\n\nDouble entries: one for the notebook (.ipynb) and one for the auto python export (.py). I will have to update my jupyter settings to avoid this python file creation. In the meantime I can just delete the python file, and commit.\n{% include alert.html text=“Change settings of jupyter + .gitignore to avoid these double entries” %}\n\n\ncannot open notebook into browser\n\n\n\nimage.png\n\n\nClicking just ask me to download the notebook, it doesn’t display it into the browser.\n\n\nchecking .gitignore\nJust by looking into .gitignore, there is an interesting entry:\n*.swp\n~*\n*~\n_site\n.sass-cache\n.jekyll-cache\n.jekyll-metadata\nvendor\n_notebooks/.ipynb_checkpoints\nWait what is in this last line.\nLet’s create _notebooks directory and move my notebook in that directory.\n\n\nnotebooks from _notebooks not rendered\n No entries, I guess there is some additional settings to do…\n{% include alert.html text=“Why notebooks are not rendered by Jekyl” %}\n\n\ntest entry from md using local repo\nThere is no problem with that.\nCreating a local md file in _poststhen pushing to github is creating the right entry blog.\n\n\n\nimage.png\n\n\n\n\nfollowing fastpages troubleshooting guide\n\nupgrade fastpages\nTry the automated upgrade as described in https://github.com/fastai/fastpages/blob/master/_fastpages_docs/UPGRADE.md\nUnfortunately I don’t see \nI have to follow the manual upgrade.\n\n\nmanual fastpages upgrade\nI am surprised because the 1st step from manual upgrade is to copy the fastpages repo. It is what I did 2 days ago. I doubt having an outdated version of fastpages.\n\n\n\nfastai forum: fastpages category\nI will browse through nbdev & faspages category in fastai forums. I should see people with the same issue.\nI have created an entry, into fastai forums: Fastpages - cannot see build process of GitHub Actions\nAnd quite immediately Hamel Hussain answered guiding to the write direction:\nI misread the Settings instruction: my github repo should explicitely NOT include my github username and I did exactly the opposite.\n{% include alert.html text=“I have to create a new repo: guillaume_blog” %}\n\n\nnothing visible from Actions tab\nAnd another surprising subject: at github in Actions tab. I have a kind of default page. I expect something like an execution journal of Actions. \n\n\nPage build failure\nReceived a notification by email:\n\n\n\nimage.png\n\n\nThe page build failed for the master branch with the following error:\nPage build failed. For more information, see https://docs.github.com/github/working-with-github-pages/troubleshooting-jekyll-build-errors-for-github-pages-sites#troubleshooting-build-errors.\nFor information on troubleshooting Jekyll see:\nhttps://docs.github.com/articles/troubleshooting-jekyll-builds\nIf you have any questions you can submit a request on the Contact GitHub page at https://support.github.com/contact?repo_id=293820308&page_build_id=202240535"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter.html#move-to-another-repo",
    "href": "posts/2020-09-10-blog-from-jupyter.html#move-to-another-repo",
    "title": "Blog from jupyter notebook",
    "section": "Move to another repo",
    "text": "Move to another repo\n\nrepo creation\nIt was just a matter of creating a new repo: \n\n\nactions monitoring\nMonitoring is effective \n\n\nmerge pull request\n\n\n\nimage.png\n\n\n\nactions around ssh keys\nFollowing the steps: - Create keys using ssh utility - Enter Secret Key - Enter Deploy Key\n\n\nmerge PR\nThere are conflicts to be fixed before that.\n\n\n\nAnd it works: https://castorfou.github.io/guillaume_blog/\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2020-09-10-blog-from-jupyter.html#get-local-repo",
    "href": "posts/2020-09-10-blog-from-jupyter.html#get-local-repo",
    "title": "Blog from jupyter notebook",
    "section": "Get local repo",
    "text": "Get local repo\ncd ~/git\nunsetproxy\ngit clone https://github.com/castorfou/guillaume_blog.git"
  },
  {
    "objectID": "posts/2021-07-09-git-ignore-large-files.html",
    "href": "posts/2021-07-09-git-ignore-large-files.html",
    "title": "git ignore large files",
    "section": "",
    "text": "$ ll .gitignore* update_git_ignore.sh\n .gitignore\n .gitignore_bigfiles\n .gitignore_static\n update_git_ignore.sh\n\n\nHere is my standard entries for .gitignore\n$ cat .gitignore_static\n*.history\n*/.ipynb_checkpoints/*\n.ipynb_checkpoints/*\nmlflow/*\nmlruns/*\n\n\n\nThose are filed created by update_git_ignore.sh\n\n\nadd all files &gt; 100MB in .gitignore_bigfiles\nmerge .gitignore_static and .gitignore_bigfiles as .gitignore\ndisplay .gitignore\n$ cat update_git_ignore.sh\n#!/bin/bash\n\n#update gitignore_bigfiles\nfind . -size +100M -not -path \"./.git*\"| sed 's|^\\./||g' | cat &gt; .gitignore_bigfiles\n\n# create gitignore as concat of gitingore_static and gitignore_bigfiles\ncat .gitignore_static .gitignore_bigfiles &gt; .gitignore\n\n# print content of .gitignore_bigfiles\ncat .gitignore_bigfiles"
  },
  {
    "objectID": "posts/2021-07-09-git-ignore-large-files.html#files-used",
    "href": "posts/2021-07-09-git-ignore-large-files.html#files-used",
    "title": "git ignore large files",
    "section": "",
    "text": "$ ll .gitignore* update_git_ignore.sh\n .gitignore\n .gitignore_bigfiles\n .gitignore_static\n update_git_ignore.sh\n\n\nHere is my standard entries for .gitignore\n$ cat .gitignore_static\n*.history\n*/.ipynb_checkpoints/*\n.ipynb_checkpoints/*\nmlflow/*\nmlruns/*\n\n\n\nThose are filed created by update_git_ignore.sh\n\n\nadd all files &gt; 100MB in .gitignore_bigfiles\nmerge .gitignore_static and .gitignore_bigfiles as .gitignore\ndisplay .gitignore\n$ cat update_git_ignore.sh\n#!/bin/bash\n\n#update gitignore_bigfiles\nfind . -size +100M -not -path \"./.git*\"| sed 's|^\\./||g' | cat &gt; .gitignore_bigfiles\n\n# create gitignore as concat of gitingore_static and gitignore_bigfiles\ncat .gitignore_static .gitignore_bigfiles &gt; .gitignore\n\n# print content of .gitignore_bigfiles\ncat .gitignore_bigfiles"
  },
  {
    "objectID": "posts/2021-07-09-git-ignore-large-files.html#usage",
    "href": "posts/2021-07-09-git-ignore-large-files.html#usage",
    "title": "git ignore large files",
    "section": "Usage",
    "text": "Usage\nLaunch ./update_git_ignore.shbefore adding files to git\n$ ./update_git_ignore.sh\nmlflow/1/5699a81e1a6a44ef8afecd98fff987fc/artifacts/Data Profile.html\n$ git add .\n$ git commit -m 'example without large files'"
  },
  {
    "objectID": "posts/2021-01-13-pandas-cheatsheet.html",
    "href": "posts/2021-01-13-pandas-cheatsheet.html",
    "title": "pandas cheatsheet",
    "section": "",
    "text": "# Exploring a DataFrame: .head()\ndogs.head()\n\n# Exploring a DataFrame: .info()\ndogs.info()\n\n# Exploring a DataFrame: .shape\ndogs.shape\n\n# Exploring a DataFrame: .describe()\ndogs.describe()\n\n# Components of a DataFrame: .values\ndogs.values\n\n# Components of a DataFrame: .columns and .index\ndogs.columns\n\ndogs.index\n\n\n\n#Sorting by multiple variables\ndogs.sort_values([\"weight_kg\", \"height_cm\"], ascending=[True, False])\n\n#Subsetting based on dates\ndogs[dogs[\"date_of_birth\"] &gt; \"2015-01-01\"]\n\n#Subsetting based on multiple conditions\nis_lab = dogs[\"breed\"] == \"Labrador\"\nis_brown = dogs[\"color\"] == \"Brown\"\ndogs[is_lab & is_brown]\ndogs[ (dogs[\"breed\"] == \"Labrador\") & (dogs[\"color\"] == \"Brown\") ]\n\n#Subsetting using .isin()\nis_black_or_brown = dogs[\"color\"].isin([\"Black\", \"Brown\"])\ndogs[is_black_or_brown]\n\n\n\n# Adding a new column\ndogs[\"height_m\"] = dogs[\"height_cm\"] / 100\n\n\n\n\n\n\n#Summarizing numerical data\ndogs[\"height_cm\"].mean()\n\n.median() , .mode()\n.min() , .max()\n.var() , .std()\n.sum()\n.quantile()\n\n#The .agg() method\ndef pct30(column):\nreturn column.quantile(0.3)\ndogs[\"weight_kg\"].agg(pct30)\n\n#Multiple summaries\ndef pct40(column):\nreturn column.quantile(0.4)\ndogs[\"weight_kg\"].agg([pct30, pct40])\n\n#Cumulative sum\ndogs[\"weight_kg\"].cumsum()\n\n#Cumulative statistics\n.cummax()\n.cummin()\n.cumprod()\n\n\n\n#Dropping duplicate names\nvet_visits.drop_duplicates(subset=\"name\")\n\n#Dropping duplicate pairs\nunique_dogs = vet_visits.drop_duplicates(subset=[\"name\", \"breed\"])\n\n#Counting\nunique_dogs[\"breed\"].value_counts(sort=True)\n\n\n\n\n#Summaries by group\ndogs[dogs[\"color\"] == \"Black\"][\"weight_kg\"].mean()\ndogs[dogs[\"color\"] == \"Brown\"][\"weight_kg\"].mean()\n\n#Grouped summaries\ndogs.groupby(\"color\")[\"weight_kg\"].mean()\n\n#Multiple grouped summaries\ndogs.groupby(\"color\")[\"weight_kg\"].agg([min, max, sum])\n\n#Grouping by multiple variables\ndogs.groupby([\"color\", \"breed\"])[\"weight_kg\"].mean()\n\n#Many groups, many summaries\ndogs.groupby([\"color\", \"breed\"])[[\"weight_kg\", \"height_cm\"]].mean()\n\n\n\n\n#pivot table\ndogs.pivot_table(values=\"weight_kg\",index=\"color\")\n\n#Different statistics\nimport numpy as np\ndogs.pivot_table(values=\"weight_kg\", index=\"color\", aggfunc=np.median)\n\n#Multiple statistics\ndogs.pivot_table(values=\"weight_kg\", index=\"color\", aggfunc=[np.mean, np.median])\n\n#Pivot on two variables\ndogs.groupby([\"color\", \"breed\"])[\"weight_kg\"].mean()\ndogs.pivot_table(values=\"weight_kg\", index=\"color\", columns=\"breed\")\n\n#Filling missing values in pivot tables\ndogs.pivot_table(values=\"weight_kg\", index=\"color\", columns=\"breed\", fill_value=0)\n\n# Summing with pivot tables\ndogs.pivot_table(values=\"weight_kg\", index=\"color\", columns=\"breed\",\nfill_value=0, margins=True)\n\n\n\n\n\n\n\n# Setting a column as the index\ndogs_ind = dogs.set_index(\"name\")\n\n# Removing an index\ndogs_ind.reset_index()\n\n# Dropping an index\ndogs_ind.reset_index(drop=True)\n\n# Indexes make subsetting simpler\ndogs[dogs[\"name\"].isin([\"Bella\", \"Stella\"])]\n# versus\ndogs_ind.loc[[\"Bella\", \"Stella\"]]\n\n# Multi-level indexes a.k.a. hierarchical indexes\ndogs_ind3 = dogs.set_index([\"breed\", \"color\"])\n\n# Subset the outer level with a list\ndogs_ind3.loc[[\"Labrador\", \"Chihuahua\"]]\n\n# Subset inner levels with a list of tuples\ndogs_ind3.loc[[(\"Labrador\", \"Brown\"), (\"Chihuahua\", \"Tan\")]]\n\n# Sorting by index values\ndogs_ind3.sort_index()\n\n# Controlling sort_index\ndogs_ind3.sort_index(level=[\"color\", \"breed\"], ascending=[True, False])\n\n\n\n\n# Sort the index before you slice\ndogs_srt = dogs.set_index([\"breed\", \"color\"]).sort_index()\n\n# Slicing the outer index level\ndogs_srt.loc[\"Chow Chow\":\"Poodle\"]\n\n# Slicing the inner index levels correctly\ndogs_srt.loc[(\"Labrador\", \"Brown\"):(\"Schnauzer\", \"Grey\")]\n\n# Slicing columns\ndogs_srt.loc[:, \"name\":\"height_cm\"]\n\n# Slice twice\ndogs_srt.loc[\n(\"Labrador\", \"Brown\"):(\"Schnauzer\", \"Grey\"),\n\"name\":\"height_cm\"]\n\n# Dog days\ndogs = dogs.set_index(\"date_of_birth\").sort_index()\n\n# Slicing by dates\n# Get dogs with date_of_birth between 2014-08-25 and 2016-09-16\ndogs.loc[\"2014-08-25\":\"2016-09-16\"]\n\n# Slicing by partial dates\n# Get dogs with date_of_birth between 2014-01-01 and 2016-12-31\ndogs.loc[\"2014\":\"2016\"]\n\n# Subsetting by row/column number\nprint(dogs.iloc[2:5, 1:4])\n\n\n\n\n# Pivoting the dog pack\ndogs_height_by_breed_vs_color = dog_pack.pivot_table(\n\"height_cm\", index=\"breed\", columns=\"color\")\n\n# The axis argument\ndogs_height_by_breed_vs_color.mean(axis=\"index\")\n\n# Calculating summary stats across columns\ndogs_height_by_breed_vs_color.mean(axis=\"columns\")\n\n\n\n\n\n\n\n# Histograms\nimport matplotlib.pyplot as plt\ndog_pack[\"height_cm\"].hist(bins=20)\n\n# Bar plots\navg_weight_by_breed = dog_pack.groupby(\"breed\")[\"weight_kg\"].mean()\navg_weight_by_breed.plot(kind=\"bar\", title=\"Mean Weight by Dog Breed\")\n\n# Line plots\nsully.head()\nsully.plot(x=\"date\", y=\"weight_kg\", kind=\"line\")\n\n# Rotating axis labels\nsully.plot(x=\"date\", y=\"weight_kg\", kind=\"line\", rot=45)\n\n# Scatter plots\ndog_pack.plot(x=\"height_cm\", y=\"weight_kg\", kind=\"scatter\")\n\n# Layering plots\ndog_pack[dog_pack[\"sex\"]==\"F\"][\"height_cm\"].hist()\ndog_pack[dog_pack[\"sex\"]==\"M\"][\"height_cm\"].hist()\n\n# Add a legend\nplt.legend([\"F\", \"M\"])\n\n# Transparency\ndog_pack[dog_pack[\"sex\"]==\"F\"][\"height_cm\"].hist(alpha=0.7)\ndog_pack[dog_pack[\"sex\"]==\"M\"][\"height_cm\"].hist(alpha=0.7)\nplt.legend([\"F\", \"M\"])\n\n\n\n\n# Detecting missing values\ndogs.isna()\n\n# Detecting any missing values\ndogs.isna().any()\n\n# Counting missing values\ndogs.isna().sum()\n\n# Plotting missing values\nimport matplotlib.pyplot as plt\ndogs.isna().sum().plot(kind=\"bar\")\nplt.show()\n\n# Removing rows containing missing values\ndogs.dropna()\n\n# Replacing missing values\ndogs.fillna(0)\n\n\n\n\n# CSV to DataFrame\nimport pandas as pd\nnew_dogs = pd.read_csv(\"new_dogs.csv\")\n\n# DataFrame to CSV\nnew_dogs.to_csv(\"new_dogs_with_bmi.csv\")\n\n# CSV to dataframe parsing dates, and having date as index\nclimate_change = pd.read_csv(prefix+'climate_change.csv', parse_dates=['date'], index_col='date')"
  },
  {
    "objectID": "posts/2021-01-13-pandas-cheatsheet.html#transforming-data",
    "href": "posts/2021-01-13-pandas-cheatsheet.html#transforming-data",
    "title": "pandas cheatsheet",
    "section": "",
    "text": "# Exploring a DataFrame: .head()\ndogs.head()\n\n# Exploring a DataFrame: .info()\ndogs.info()\n\n# Exploring a DataFrame: .shape\ndogs.shape\n\n# Exploring a DataFrame: .describe()\ndogs.describe()\n\n# Components of a DataFrame: .values\ndogs.values\n\n# Components of a DataFrame: .columns and .index\ndogs.columns\n\ndogs.index\n\n\n\n#Sorting by multiple variables\ndogs.sort_values([\"weight_kg\", \"height_cm\"], ascending=[True, False])\n\n#Subsetting based on dates\ndogs[dogs[\"date_of_birth\"] &gt; \"2015-01-01\"]\n\n#Subsetting based on multiple conditions\nis_lab = dogs[\"breed\"] == \"Labrador\"\nis_brown = dogs[\"color\"] == \"Brown\"\ndogs[is_lab & is_brown]\ndogs[ (dogs[\"breed\"] == \"Labrador\") & (dogs[\"color\"] == \"Brown\") ]\n\n#Subsetting using .isin()\nis_black_or_brown = dogs[\"color\"].isin([\"Black\", \"Brown\"])\ndogs[is_black_or_brown]\n\n\n\n# Adding a new column\ndogs[\"height_m\"] = dogs[\"height_cm\"] / 100"
  },
  {
    "objectID": "posts/2021-01-13-pandas-cheatsheet.html#aggregating-data",
    "href": "posts/2021-01-13-pandas-cheatsheet.html#aggregating-data",
    "title": "pandas cheatsheet",
    "section": "",
    "text": "#Summarizing numerical data\ndogs[\"height_cm\"].mean()\n\n.median() , .mode()\n.min() , .max()\n.var() , .std()\n.sum()\n.quantile()\n\n#The .agg() method\ndef pct30(column):\nreturn column.quantile(0.3)\ndogs[\"weight_kg\"].agg(pct30)\n\n#Multiple summaries\ndef pct40(column):\nreturn column.quantile(0.4)\ndogs[\"weight_kg\"].agg([pct30, pct40])\n\n#Cumulative sum\ndogs[\"weight_kg\"].cumsum()\n\n#Cumulative statistics\n.cummax()\n.cummin()\n.cumprod()\n\n\n\n#Dropping duplicate names\nvet_visits.drop_duplicates(subset=\"name\")\n\n#Dropping duplicate pairs\nunique_dogs = vet_visits.drop_duplicates(subset=[\"name\", \"breed\"])\n\n#Counting\nunique_dogs[\"breed\"].value_counts(sort=True)\n\n\n\n\n#Summaries by group\ndogs[dogs[\"color\"] == \"Black\"][\"weight_kg\"].mean()\ndogs[dogs[\"color\"] == \"Brown\"][\"weight_kg\"].mean()\n\n#Grouped summaries\ndogs.groupby(\"color\")[\"weight_kg\"].mean()\n\n#Multiple grouped summaries\ndogs.groupby(\"color\")[\"weight_kg\"].agg([min, max, sum])\n\n#Grouping by multiple variables\ndogs.groupby([\"color\", \"breed\"])[\"weight_kg\"].mean()\n\n#Many groups, many summaries\ndogs.groupby([\"color\", \"breed\"])[[\"weight_kg\", \"height_cm\"]].mean()\n\n\n\n\n#pivot table\ndogs.pivot_table(values=\"weight_kg\",index=\"color\")\n\n#Different statistics\nimport numpy as np\ndogs.pivot_table(values=\"weight_kg\", index=\"color\", aggfunc=np.median)\n\n#Multiple statistics\ndogs.pivot_table(values=\"weight_kg\", index=\"color\", aggfunc=[np.mean, np.median])\n\n#Pivot on two variables\ndogs.groupby([\"color\", \"breed\"])[\"weight_kg\"].mean()\ndogs.pivot_table(values=\"weight_kg\", index=\"color\", columns=\"breed\")\n\n#Filling missing values in pivot tables\ndogs.pivot_table(values=\"weight_kg\", index=\"color\", columns=\"breed\", fill_value=0)\n\n# Summing with pivot tables\ndogs.pivot_table(values=\"weight_kg\", index=\"color\", columns=\"breed\",\nfill_value=0, margins=True)"
  },
  {
    "objectID": "posts/2021-01-13-pandas-cheatsheet.html#slicing-and-indexing",
    "href": "posts/2021-01-13-pandas-cheatsheet.html#slicing-and-indexing",
    "title": "pandas cheatsheet",
    "section": "",
    "text": "# Setting a column as the index\ndogs_ind = dogs.set_index(\"name\")\n\n# Removing an index\ndogs_ind.reset_index()\n\n# Dropping an index\ndogs_ind.reset_index(drop=True)\n\n# Indexes make subsetting simpler\ndogs[dogs[\"name\"].isin([\"Bella\", \"Stella\"])]\n# versus\ndogs_ind.loc[[\"Bella\", \"Stella\"]]\n\n# Multi-level indexes a.k.a. hierarchical indexes\ndogs_ind3 = dogs.set_index([\"breed\", \"color\"])\n\n# Subset the outer level with a list\ndogs_ind3.loc[[\"Labrador\", \"Chihuahua\"]]\n\n# Subset inner levels with a list of tuples\ndogs_ind3.loc[[(\"Labrador\", \"Brown\"), (\"Chihuahua\", \"Tan\")]]\n\n# Sorting by index values\ndogs_ind3.sort_index()\n\n# Controlling sort_index\ndogs_ind3.sort_index(level=[\"color\", \"breed\"], ascending=[True, False])\n\n\n\n\n# Sort the index before you slice\ndogs_srt = dogs.set_index([\"breed\", \"color\"]).sort_index()\n\n# Slicing the outer index level\ndogs_srt.loc[\"Chow Chow\":\"Poodle\"]\n\n# Slicing the inner index levels correctly\ndogs_srt.loc[(\"Labrador\", \"Brown\"):(\"Schnauzer\", \"Grey\")]\n\n# Slicing columns\ndogs_srt.loc[:, \"name\":\"height_cm\"]\n\n# Slice twice\ndogs_srt.loc[\n(\"Labrador\", \"Brown\"):(\"Schnauzer\", \"Grey\"),\n\"name\":\"height_cm\"]\n\n# Dog days\ndogs = dogs.set_index(\"date_of_birth\").sort_index()\n\n# Slicing by dates\n# Get dogs with date_of_birth between 2014-08-25 and 2016-09-16\ndogs.loc[\"2014-08-25\":\"2016-09-16\"]\n\n# Slicing by partial dates\n# Get dogs with date_of_birth between 2014-01-01 and 2016-12-31\ndogs.loc[\"2014\":\"2016\"]\n\n# Subsetting by row/column number\nprint(dogs.iloc[2:5, 1:4])\n\n\n\n\n# Pivoting the dog pack\ndogs_height_by_breed_vs_color = dog_pack.pivot_table(\n\"height_cm\", index=\"breed\", columns=\"color\")\n\n# The axis argument\ndogs_height_by_breed_vs_color.mean(axis=\"index\")\n\n# Calculating summary stats across columns\ndogs_height_by_breed_vs_color.mean(axis=\"columns\")"
  },
  {
    "objectID": "posts/2021-01-13-pandas-cheatsheet.html#creating-and-visualizing-dataframes",
    "href": "posts/2021-01-13-pandas-cheatsheet.html#creating-and-visualizing-dataframes",
    "title": "pandas cheatsheet",
    "section": "",
    "text": "# Histograms\nimport matplotlib.pyplot as plt\ndog_pack[\"height_cm\"].hist(bins=20)\n\n# Bar plots\navg_weight_by_breed = dog_pack.groupby(\"breed\")[\"weight_kg\"].mean()\navg_weight_by_breed.plot(kind=\"bar\", title=\"Mean Weight by Dog Breed\")\n\n# Line plots\nsully.head()\nsully.plot(x=\"date\", y=\"weight_kg\", kind=\"line\")\n\n# Rotating axis labels\nsully.plot(x=\"date\", y=\"weight_kg\", kind=\"line\", rot=45)\n\n# Scatter plots\ndog_pack.plot(x=\"height_cm\", y=\"weight_kg\", kind=\"scatter\")\n\n# Layering plots\ndog_pack[dog_pack[\"sex\"]==\"F\"][\"height_cm\"].hist()\ndog_pack[dog_pack[\"sex\"]==\"M\"][\"height_cm\"].hist()\n\n# Add a legend\nplt.legend([\"F\", \"M\"])\n\n# Transparency\ndog_pack[dog_pack[\"sex\"]==\"F\"][\"height_cm\"].hist(alpha=0.7)\ndog_pack[dog_pack[\"sex\"]==\"M\"][\"height_cm\"].hist(alpha=0.7)\nplt.legend([\"F\", \"M\"])\n\n\n\n\n# Detecting missing values\ndogs.isna()\n\n# Detecting any missing values\ndogs.isna().any()\n\n# Counting missing values\ndogs.isna().sum()\n\n# Plotting missing values\nimport matplotlib.pyplot as plt\ndogs.isna().sum().plot(kind=\"bar\")\nplt.show()\n\n# Removing rows containing missing values\ndogs.dropna()\n\n# Replacing missing values\ndogs.fillna(0)\n\n\n\n\n# CSV to DataFrame\nimport pandas as pd\nnew_dogs = pd.read_csv(\"new_dogs.csv\")\n\n# DataFrame to CSV\nnew_dogs.to_csv(\"new_dogs_with_bmi.csv\")\n\n# CSV to dataframe parsing dates, and having date as index\nclimate_change = pd.read_csv(prefix+'climate_change.csv', parse_dates=['date'], index_col='date')"
  },
  {
    "objectID": "posts/2021-01-13-pandas-cheatsheet.html#data-merging-basics",
    "href": "posts/2021-01-13-pandas-cheatsheet.html#data-merging-basics",
    "title": "pandas cheatsheet",
    "section": "Data merging basics",
    "text": "Data merging basics\n\nInner join\n# Inner join\nwards_census = wards.merge(census, on='ward')\n\n# Suffixes\nwards_census = wards.merge(census, on='ward', suffixes=('_ward','_cen'))\n\n\nOne-to-many relationships\n\n# One-to-many example\nward_licenses = wards.merge(licenses, on='ward', suffixes=('_ward','_lic'))\n\n\nMerging multiple DataFrames\n# Single merge\ngrants.merge(licenses, on=['address','zip'])\n\n# Merging multiple tables\ngrants_licenses_ward = grants.merge(licenses, on=['address','zip']) \\\n.merge(wards, on='ward', suffixes=('_bus','_ward'))\n\n\n# Plot Results\nimport matplotlib.pyplot as plt\ngrant_licenses_ward.groupby('ward').agg('sum').plot(kind='bar', y='grant')"
  },
  {
    "objectID": "posts/2021-01-13-pandas-cheatsheet.html#merging-tables-with-different-join-types",
    "href": "posts/2021-01-13-pandas-cheatsheet.html#merging-tables-with-different-join-types",
    "title": "pandas cheatsheet",
    "section": "Merging Tables With Different Join Types",
    "text": "Merging Tables With Different Join Types\n\nLeft join\n\n# Merge with left join\nmovies_taglines = movies.merge(taglines, on='id', how='left')\n\n\nOther joins\n\n# Merge with right join\ntv_movies = movies.merge(tv_genre, how='right',\nleft_on='id', right_on='movie_id')\n\n# Merge with outer join\nfamily_comedy = family.merge(comedy, on='movie_id', how='outer',\nsuffixes=('_fam', '_com'))\n\n\nMerging a table to itself\n\n# Merging a table to itself\noriginal_sequels = sequels.merge(sequels, left_on='sequel', right_on='id',\nsuffixes=('_org','_seq'))\n\n\nMerging on indexes\n\n# Setting an index\nmovies = pd.read_csv('tmdb_movies.csv', index_col=['id'])\n\n# Merging on index\nmovies_taglines = movies.merge(taglines, on='id', how='left')\n\n# MultiIndex merge\nsamuel_casts = samuel.merge(casts, on=['movie_id','cast_id'])\n\n# Index merge with left_on and right_on\nmovies_genres = movies.merge(movie_to_genres, left_on='id', left_index=True,\nright_on='movie_id', right_index=True)"
  },
  {
    "objectID": "posts/2021-01-13-pandas-cheatsheet.html#advanced-merging-and-concatenating",
    "href": "posts/2021-01-13-pandas-cheatsheet.html#advanced-merging-and-concatenating",
    "title": "pandas cheatsheet",
    "section": "Advanced Merging and Concatenating",
    "text": "Advanced Merging and Concatenating\n\nFiltering joins\n\n###########\n# semi-join\n\n# Step 1 - semi-join\ngenres_tracks = genres.merge(top_tracks, on='gid')\n\n# Step 2 - semi-join\ngenres['gid'].isin(genres_tracks['gid'])\n\n# Step 3 - semi-join\ngenres_tracks = genres.merge(top_tracks, on='gid')\ntop_genres = genres[genres['gid'].isin(genres_tracks['gid'])]\n\n###########\n# anti-join\n\n# Step 1 - anti-join\ngenres_tracks = genres.merge(top_tracks, on='gid', how='left', indicator=True)\n\n# Step 2 - anti-join\ngid_list = genres_tracks.loc[genres_tracks['_merge'] == 'left_only', 'gid']\n\n# Step 3 - anti-join\ngenres_tracks = genres.merge(top_tracks, on='gid', how='left', indicator=True)\ngid_list = genres_tracks.loc[genres_tracks['_merge'] == 'left_only','gid']\nnon_top_genres = genres[genres['gid'].isin(gid_list)]\n\n\nConcatenate DataFrames together vertically\n# Basic concatenation\npd.concat([inv_jan, inv_feb, inv_mar])\n\n# Ignoring the index\npd.concat([inv_jan, inv_feb, inv_mar],\nignore_index=True)\n\n# Setting labels to original tables\npd.concat([inv_jan, inv_feb, inv_mar],\nignore_index=False,\nkeys=['jan','feb','mar'])\n\n# Concatenate tables with different column names\npd.concat([inv_jan, inv_feb],\nsort=True)\n\n# Concatenate tables with different column names\npd.concat([inv_jan, inv_feb],\njoin='inner')\n\n# Append the tables\ninv_jan.append([inv_feb, inv_mar],\nignore_index=True, \nsort=True)\n\n\nVerifying integrity\n\n# Validating merges\n.merge(validate=None) :\nChecks if merge is of specified type\n'one_to_one'\n'one_to_many'\n'many_to_one'\n'many_to_many'\n\n# Merge validate: one_to_one\ntracks.merge(specs, on='tid',\nvalidate='one_to_one')\n\n# Merge validate: one_to_many\nalbums.merge(tracks, on='aid',\nvalidate='one_to_many')\n\n# Verifying concatenations\n.concat(verify_integrity=False) :\nCheck whether the new concatenated index contains duplicates\nDefault value is False"
  },
  {
    "objectID": "posts/2021-01-13-pandas-cheatsheet.html#merging-ordered-and-time-series-data",
    "href": "posts/2021-01-13-pandas-cheatsheet.html#merging-ordered-and-time-series-data",
    "title": "pandas cheatsheet",
    "section": "Merging Ordered and Time-Series Data",
    "text": "Merging Ordered and Time-Series Data\n\nUsing merge_ordered()\n# Merging stock data\nimport pandas as pd\npd.merge_ordered(appl, mcd, on='date', suffixes=('_aapl','_mcd'))\n\n# Forward fill example\npd.merge_ordered(appl, mcd, on='date',\nsuffixes=('_aapl','_mcd'),\nfill_method='ffill')\n\n\nUsing merge_asof()\n\n# merge_asof() example\npd.merge_asof(visa, ibm, on='date_time',\nsuffixes=('_visa','_ibm'))\n\n# merge_asof() example with direction\npd.merge_asof(visa, ibm, on=['date_time'],\nsuffixes=('_visa','_ibm'),\ndirection='forward')\n\n\nSelecting data with .query()\n\n# Querying on a single condition\nstocks.query('nike &gt;= 90')\n\n# Querying on a multiple conditions, \"and\", \"or\"\nstocks.query('nike &gt; 90 and disney &lt; 140')\nstocks.query('nike &gt; 96 or disney &lt; 98')\n\n# Using .query() to select text\nstocks_long.query('stock==\"disney\" or (stock==\"nike\" and close &lt; 90)')\n\n\nReshaping data with .melt()\n\n# Example of .melt()\nsocial_fin_tall = social_fin.melt(id_vars=['financial','company'])\n\n# Melting with value_vars\nsocial_fin_tall = social_fin.melt(id_vars=['financial','company'],\nvalue_vars=['2018','2017'])\n\n# Melting with column names\nsocial_fin_tall = social_fin.melt(id_vars=['financial','company'],\nvalue_vars=['2018','2017'],\nvar_name=['year'], value_name='dollars')"
  },
  {
    "objectID": "posts/2023-09-04-wsl-no-space-left.html",
    "href": "posts/2023-09-04-wsl-no-space-left.html",
    "title": "WSL no space left",
    "section": "",
    "text": "From time to time I get this alert usually when saving data or installing softwares, creation python environments: no space left"
  },
  {
    "objectID": "posts/2023-09-04-wsl-no-space-left.html#baobab",
    "href": "posts/2023-09-04-wsl-no-space-left.html#baobab",
    "title": "WSL no space left",
    "section": "baobab",
    "text": "baobab\nbaobab\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2023-09-04-wsl-no-space-left.html#pip",
    "href": "posts/2023-09-04-wsl-no-space-left.html#pip",
    "title": "WSL no space left",
    "section": "pip",
    "text": "pip\nif ~/.cache/pip is the culprit.\none can run pip cache purge"
  },
  {
    "objectID": "posts/2023-09-04-wsl-no-space-left.html#cache",
    "href": "posts/2023-09-04-wsl-no-space-left.html#cache",
    "title": "WSL no space left",
    "section": ".cache",
    "text": ".cache\nSome folders can be deleted from .cache such as huggingface which caches models or datasets"
  },
  {
    "objectID": "posts/2023-09-04-wsl-no-space-left.html#conda",
    "href": "posts/2023-09-04-wsl-no-space-left.html#conda",
    "title": "WSL no space left",
    "section": "conda",
    "text": "conda\n\npkgs\nconda clean -a\n\n\nenvs\nconda env can take huge spaces.\nWhen unused, I can simply remove them:\nconda remove --name &lt;env_name&gt; --all\n\n\n\nimage.png\n\n\njust looking at Size and last modified date is enough to filter what has to be kept and pruned."
  },
  {
    "objectID": "posts/2023-01-11-zotero-manage-datascience-paper.html",
    "href": "posts/2023-01-11-zotero-manage-datascience-paper.html",
    "title": "Zotero",
    "section": "",
    "text": "I have been using Zotero for a year now.\nHere is the process I use."
  },
  {
    "objectID": "posts/2023-01-11-zotero-manage-datascience-paper.html#zotero-account",
    "href": "posts/2023-01-11-zotero-manage-datascience-paper.html#zotero-account",
    "title": "Zotero",
    "section": "zotero account",
    "text": "zotero account\n1st step is to create a zotero account from zotero website, quite usefull to sync libraries between multiple zotero installations."
  },
  {
    "objectID": "posts/2023-01-11-zotero-manage-datascience-paper.html#zotero-app",
    "href": "posts/2023-01-11-zotero-manage-datascience-paper.html#zotero-app",
    "title": "Zotero",
    "section": "zotero app",
    "text": "zotero app\nI have installed zotero app within WSL. For a reason the app on my Windows corporate is not the last one, and cannot sync anymore (I think due to too old chrome version).\nsudo snap install zotero-snap\n# to use CA certificates\nFIREFOX_PROFILE=`find ~/snap/firefox/common/.mozilla/ -name *.default`\nZOTERO_PROFILE=`find ~/snap/zotero-snap/common/.zotero/ -name *.default`\ncp $FIREFOX_PROFILE/cert9.db $ZOTERO_PROFILE\ncp $FIREFOX_PROFILE/key4.db $ZOTERO_PROFILE\ncp $FIREFOX_PROFILE/pkcs11.txt $ZOTERO_PROFILE"
  },
  {
    "objectID": "posts/2023-01-11-zotero-manage-datascience-paper.html#zotero-browser-extension",
    "href": "posts/2023-01-11-zotero-manage-datascience-paper.html#zotero-browser-extension",
    "title": "Zotero",
    "section": "zotero browser extension",
    "text": "zotero browser extension\nFrom zotero website, install connectors\n\n\n\nimage.png\n\n\nFor a reason, install browser connector from zotero app doesn’t do anything here.\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2023-01-11-zotero-manage-datascience-paper.html#note",
    "href": "posts/2023-01-11-zotero-manage-datascience-paper.html#note",
    "title": "Zotero",
    "section": "Note",
    "text": "Note\nWe should have the same behaviour from app by using the magic wand but for a certificate reason it fails \nAnd doing the same from zotero website gets metadata but not the pdfs.\nBecause of that I will focus on this process based on browser add-on."
  },
  {
    "objectID": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html",
    "href": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html",
    "title": "Reinforcement Learning Specialization - Coursera - course 4 - A Complete Reinforcement Learning System (Capstone)",
    "section": "",
    "text": "Coursera website: course 4 - A Complete Reinforcement Learning System (Capstone) of Reinforcement Learning Specialization\nmy notes on course 1 - Fundamentals of Reinforcement Learning, course 2 - Sample-based Learning Methods, course 3 - Prediction and Control with Function Approximation\nspecialization roadmap - course 4 - A Complete Reinforcement Learning System (Capstone) (syllabus)\nWeek 1 - Welcome to the Course Week 2 - Formalize Word Problem as MDP Week 3 - Choosing The Right Algorithm Week 4 - Identify Key Performance Parameters Week 5 - Implement Your Agent Week 6 - Submit Your Parameter Study!"
  },
  {
    "objectID": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html#course-4---week-2---formalize-word-problem-as-mdp",
    "href": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html#course-4---week-2---formalize-word-problem-as-mdp",
    "title": "Reinforcement Learning Specialization - Coursera - course 4 - A Complete Reinforcement Learning System (Capstone)",
    "section": "Course 4 - Week 2 - Formalize Word Problem as MDP",
    "text": "Course 4 - Week 2 - Formalize Word Problem as MDP\n\nFinal Project: Milestone 1\nVideo Initial Project Meeting with Martha: Formalizing the Problem\n\nVideo Andy Barto on What are Eligibility Traces and Why are they so named?\nBy the end of this video, you’ll understand the origin of the idea of eligibility traces and you’ll actually see that you’ve been using a variant of eligibility traces all along.\n\n\n\nProject Resources\nVideo Let’s Review: Markov Decision Processes\nBy the end of this video, you’ll be able to understand Markov decision processes or MDPs and describe how the dynamics of MDP are defined.\nVideo Let’s Review: Examples of Episodic and Continuing Tasks\nBy the end of this video, you will be able to understand when to formalize a task as episodic or continuing.\n\n\nAssignment\nMoonShot Technologies\nnotebooks in github"
  },
  {
    "objectID": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html#course-4---week-3---choosing-the-right-algorithm",
    "href": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html#course-4---week-3---choosing-the-right-algorithm",
    "title": "Reinforcement Learning Specialization - Coursera - course 4 - A Complete Reinforcement Learning System (Capstone)",
    "section": "Course 4 - Week 3 - Choosing The Right Algorithm",
    "text": "Course 4 - Week 3 - Choosing The Right Algorithm\n\nWeekly Learning Goals\nVideo Meeting with Niko: Choosing the Learning Algorithm\n\n\n\nProject Resources\nVideo Let’s Review: Expected Sarsa\n\nVideo Let’s Review: What is Q-learning?\nVideo Let’s Review: Average Reward- A New Way of Formulating Control Problems\nVideo Let’s Review: Actor-Critic Algorithm\nVideo Csaba Szepesvari on Problem Landscape\nVideo Andy and Rich: Advice for Students"
  },
  {
    "objectID": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html#course-4---week-4---identify-key-performance-parameters",
    "href": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html#course-4---week-4---identify-key-performance-parameters",
    "title": "Reinforcement Learning Specialization - Coursera - course 4 - A Complete Reinforcement Learning System (Capstone)",
    "section": "Course 4 - Week 4 - Identify Key Performance Parameters",
    "text": "Course 4 - Week 4 - Identify Key Performance Parameters\n\nWeekly Learning Goals\nVideo Agent Architecture Meeting with Martha: Overview of Design Choices\nNow, let’s discuss the meta parameter choices that you will have to make to fully implement the agent. This means we need to decide on the function approximator, choices in the optimizer for updating the action values, and how to do exploration.\n\n\nProject Resources\nVideo Let’s Review: Non-linear Approximation with Neural Networks\nBy the end of this video, you will understand how neural networks do feature construction, and you will understand how neural networks are a non-linear function of state.\nVideo Drew Bagnell on System ID + Optimal Control\nVideo Susan Murphy on RL in Mobile Health"
  },
  {
    "objectID": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html#course-4---week-5---implement-your-agent",
    "href": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html#course-4---week-5---implement-your-agent",
    "title": "Reinforcement Learning Specialization - Coursera - course 4 - A Complete Reinforcement Learning System (Capstone)",
    "section": "Course 4 - Week 5 - Implement your agent",
    "text": "Course 4 - Week 5 - Implement your agent\n\nWeekly Learning Goals\nVideo Meeting with Adam: Getting the Agent Details Right\n\n\nProject Resources\nVideo Let’s Review: Optimization Strategies for NNs\nBy the end of this video, you will be able to understand the importance of initialization for neural networks and describe optimization techniques for training neural networks.\nOne simple yet effective initialization strategy, is to randomly sample the initial weights from a normal distribution with small variance. This way, each neuron has a different output from other neurons within its layer. This provides a more diverse set of potential features. By keeping the variants small, we ensure that the output of each neuron is within the same range as its neighbors. One downside to this strategy is that, as we add more inputs to a neuron, the variance of the output grows. We can get around this issue by scaling the variance of the weights, by one over the square root of the number of inputs.\n\nHere’s the stochastic gradient descent update rule and here’s the update modified to include momentum. Notice, it is similar to the regular stochastic gradient descent update plus an extra term called the momentum M. The momentum term summarizes the history of the gradients using a decaying sum of gradients with decay rate Lambda. If recent gradients have all been in similar directions, then we gained momentum in that direction. This means, we make a large step in that direction. If recent updates have conflicting directions, then it kills the momentum. The momentum term will have little impact on the update and we will make a regular gradient descent step. Momentum provably accelerates learning, meaning it gets to a stationary point more quickly.\n\nSo far, we have only talked about a global scalar step size. This is well-known to be problematic because this can result in updates that are too big for some weights and too small for other weights. Adapting the step sizes for each weight, based on statistics about the learning process in practice results in much better performance. Now, how does the update change? The change is very simple. Instead of updating with a scalar Alpha, there’s a vector of step sizes indexed by t to indicate that it can change on each time-step. Each dimension of the gradient, is scaled by its corresponding step size instead of the global step size. There are a variety of methods to adapt a vector of step sizes. You’ll get to implement one in your assignment.\n\nVideo Let’s Review: Expected Sarsa with Function Approximation\nBy the end of this video, you’ll be able to explain the update for expected Sarsa with function approximation, and explain the update for Q-learning with function approximation.\n\n\nVideo Let’s Review: Dyna & Q-learning in a Simple Maze\nBy the end of this video you will be able to describe how learning from both real and model experience impacts performance. You will also be able to explain how a model allows the agent to learn from fewer interactions with the environment.\nVideo Meeting with Martha: In-depth on Experience Replay\nIn Course 3, the agents you implemented update the value function or policy only once with each sample. But this is likely not the most sample efficient way to use our data. You have actually seen a smarter approach in Course 2 where we talked about Dyna as a way to be more sample efficient. But we only talked about Dyna for the tabular setting.\nIn this video, we will talk about how to make your agent more sample efficient when using function approximation. We will discuss a simple method called experience replay and how it relates to Dyna. To get some intuition for experience replay, let’s first remember a method that we know well, Dyna-Q. The idea is to learn a model using sample experience. Then simulated experience can be obtained from this model to update the values. This procedure of using simulated experience to improve the value estimates is called planning.\nExperience replay is a simple method for trying to get the advantages of Dyna. The basic idea is to save a buffer of experience and let the data be the model. We sample experience from this buffer and update the value function with those samples similarly to how we sample from the model and update the values in Dyna.\n\nVideo Martin Riedmiller on The ‘Collect and Infer’ framework for data-efficient RL\nMartin Riedmiller, head of the control team at Deepmind has been working for more than 20 years on New Reinforcement Learning Agents for the control of dynamical systems.\nThe control of dynamical systems is an attractive application area for reinforcement learning controllers. They all share the same principle feedback control structure, a controller gets the observation, computes an action and applies it to the environment. Classical control theory would first model the process as a set of differential equations for which then a control law must be analytically derived. A tedious job in particular if the systems are complex or highly nonlinear. Reinforcement learning in contrast promises to be able to learn the controller autonomously. If only the overall control goal is specified. This is typically done by defining the immediate reward. The RL controller optimizes the expected cumulated sum of rewards over time.\n\nThese two steps together build the so-called collecting and infer framework of reinforcement learning. This perspective keeps us focused on the two main question of data efficient RL. Infer, which means squeezing out the most of a given set of transition data. And collect, which means sampling the most formative data from the environment.\n\n\n\n\nAssignment\nImplement your agent\nnotebooks in github"
  },
  {
    "objectID": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html#course-4---week-6---submit-your-parameter-study",
    "href": "posts/2021-06-14-reinforcement-learning-specialization-coursera-course4.html#course-4---week-6---submit-your-parameter-study",
    "title": "Reinforcement Learning Specialization - Coursera - course 4 - A Complete Reinforcement Learning System (Capstone)",
    "section": "Course 4 - Week 6 - Submit your Parameter Study!",
    "text": "Course 4 - Week 6 - Submit your Parameter Study!\n\nWeekly Learning Goals\nVideo Meeting with Adam: Parameter Studies in RL\n\n\nProject Resources\nVideo Let’s Review: Comparing TD and Monte Carlo\nVideo Joelle Pineau about RL that Matters\n\n\nAssignment\nCompleting the parameter study\nnotebooks in github\n\n\nCongratulations!\nVideo Meeting with Martha: Discussing Your Results\nVideo Course Wrap-up\nVideo Specialization Wrap-up"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html",
    "href": "posts/2022-10-17-fastai-2022-courses.html",
    "title": "Practical Deep Learning for Coders",
    "section": "",
    "text": "Many sources about that, pointing all to https://course.fast.ai/\nThis is version 5 of this course."
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#conda-environment",
    "href": "posts/2022-10-17-fastai-2022-courses.html#conda-environment",
    "title": "Practical Deep Learning for Coders",
    "section": "conda environment",
    "text": "conda environment\n\n!cat ~/_conda_env/fastai.txt\n\nconda create -n fastai python=3.9\nconda activate fastai\nconda install ipykernel\npython -m ipykernel install --user --name=fastai\nconda install -c fastchan fastai nbdev\npip install gradio\npip install kaggle\n\n\n# update\nconda activate fastai\nconda update -c fastchan fastai nbdev\npip install -U gradio"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#setup-kaggle",
    "href": "posts/2022-10-17-fastai-2022-courses.html#setup-kaggle",
    "title": "Practical Deep Learning for Coders",
    "section": "setup kaggle",
    "text": "setup kaggle\nAnd I have to setup kaggle locally:\n\n[already done] pip install kaggle inside my fastai env\ncreate a token from my kaggle profile page\nmove this kaggle.json into ~/.kaggle/kaggle.json\nchmod 600 /home/guillaume/.kaggle/kaggle.json\n\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#get-materials-from-github",
    "href": "posts/2022-10-17-fastai-2022-courses.html#get-materials-from-github",
    "title": "Practical Deep Learning for Coders",
    "section": "get materials from github",
    "text": "get materials from github\nGithub fastai/course22 is where you’ll find the notebooks, slides, and spreadsheets for the 2022 edition of Practical Deep Learning for Coders. we can get a local version from .\ncd ~/git\ngit clone https://github.com/fastai/course22.git \ncd course22\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#deep-learning-introduction",
    "href": "posts/2022-10-17-fastai-2022-courses.html#deep-learning-introduction",
    "title": "Practical Deep Learning for Coders",
    "section": "Deep learning introduction",
    "text": "Deep learning introduction\n\n\n\nimage.png\n\n\nIn 2015, nearly impossible to recognize a bird with CS. And Jeremy doing that in 2 minutes ;)"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#recent-progress",
    "href": "posts/2022-10-17-fastai-2022-courses.html#recent-progress",
    "title": "Practical Deep Learning for Coders",
    "section": "Recent progress",
    "text": "Recent progress\nAfter this brief demonstration, Jeremy shared what he remmbers about recent progress in AI such as:\n\nartworks: Dall-e, midjourney to create images from text\nexplaining jokes: Google Pathways Language Model (PaLM) to explain jokes or run mathematical proof"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#self-learning-of-features",
    "href": "posts/2022-10-17-fastai-2022-courses.html#self-learning-of-features",
    "title": "Practical Deep Learning for Coders",
    "section": "Self learning of features",
    "text": "Self learning of features\nThen classical but nice explanation that NN learns features (features are not given or coded) and illustrates that with Matt Zeiler and Rob Fergus works\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#vision-can-be-used-in-many-different-ways",
    "href": "posts/2022-10-17-fastai-2022-courses.html#vision-can-be-used-in-many-different-ways",
    "title": "Practical Deep Learning for Coders",
    "section": "Vision can be used in many different ways",
    "text": "Vision can be used in many different ways\nAnd it is of course used to classify images, but all these techniques can be combined out of this field for example:\n\nrecognize sound by transforming sound waves into pictures (Ethan Sutin)\n\n\n\n\nimage.png\n\n\n\nturn timeseries into pictures (Ignacio Oguiza)\n\n\n\n\nimage.png\n\n\n\npictures from mouse movements (Gleb Esman)\n\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#tools---pytorch-jupyter-notebooks-kaggle",
    "href": "posts/2022-10-17-fastai-2022-courses.html#tools---pytorch-jupyter-notebooks-kaggle",
    "title": "Practical Deep Learning for Coders",
    "section": "Tools - pytorch, jupyter notebooks, kaggle",
    "text": "Tools - pytorch, jupyter notebooks, kaggle\nFor this course Jeremy suggests to use the kaggle cloud server.\nIf using someone else notebook, just upvote and click Copy & Edit\nhttps://www.kaggle.com/code/guillaumeramelet/jupyter-notebook-101/edit\nAnd now some hands-on starting with Is it a bird? notebook.\nAnd aside note: Jeremy is running all the presentation through Jupyter notebook and RISE\nIt’s a good idea to ensure you’re running the latest version of any libraries you need.\n!pip install -Uqq libraries upgrades to the latest version of libraries (fastai for example)"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#going-through-this-is-it-a-bird-notebook",
    "href": "posts/2022-10-17-fastai-2022-courses.html#going-through-this-is-it-a-bird-notebook",
    "title": "Practical Deep Learning for Coders",
    "section": "Going through this “is it a bird?” notebook",
    "text": "Going through this “is it a bird?” notebook\nJeremy shares best practices and steps\nSuch as viewing your data between each steps\nJeremy uses a lot of functional programming it is why we see things like map used a lot.\n\nDataBlock\nUsing Datablocks API\n\nTo train a model, we’ll need DataLoaders, which is an object that contains a training set (the images used to create a model) and a validation set (the images used to check the accuracy of a model – not used during training). In fastai we can create that easily using a DataBlock, and view sample images from it:\n\nAnd Jeremy explains the logic between the 5 arguments needed to create a DataBlock:\n\nblocks: tupple with type of inputs and output\nget_items: to get all data, here it points to a function to get list of image fileS\nsplitter: method to split between training set and validation set\nget_y: to kown labels, here it is a function\nitem_tfms: which transformation to apply\n\nAnd from a DataBlock you create dataloaders (dls) provding (path for images; and bs (batch size))\n\n\nlearners\nThis is a key part.\nLearners are taking 3 arguments: dataloaders, model, metric\nAnd vision models can be from timm.\nHere we train a pre-trained model, which is called fine_tune and we do it on 3 epochs.\n\n\npredict\nJust providing an item to lean.predict will return label, tensor value, probability\nAnd it is why we have such outputs\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#and-beyond-image-recognition",
    "href": "posts/2022-10-17-fastai-2022-courses.html#and-beyond-image-recognition",
    "title": "Practical Deep Learning for Coders",
    "section": "and beyond image recognition",
    "text": "and beyond image recognition\n\nSegmentation\n\n\n\nimage.png\n\n\nAnd here we don’t have datablock but direclty dataloaders\n\n\nTabular analysis\nHere again no need for DataBlock but a direct use of TabularDataLoaders\n\n\n\nimage.png\n\n\nAnd the tabular_learner wich takes dls and metric.\n\n\nCollaborative filtering (recommandation system)"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#gradio-huggingface-spaces",
    "href": "posts/2022-10-17-fastai-2022-courses.html#gradio-huggingface-spaces",
    "title": "Practical Deep Learning for Coders",
    "section": "Gradio + HuggingFace Spaces",
    "text": "Gradio + HuggingFace Spaces\n\ncreate HF repo\nCreate this minima space from HF.\nAside the explanation on HF, Jeremy shares how useful Github Desktop is.\n\n\n\nimage.png\n\n\n\n\ncreate 1st gradio app and host it\nCreate app.py as instructed in our freshly created HF space. Commit Push (using github desktop). Back to HF interface, something is being built. and voila\n\n\n\nimage.png\n\n\nNothing new because I played with gradio and HF couple of weeks ago.\nWe know have a basic app hosted. We can just integrate a deep learning model.\n\n\ntrain and export a DL model\nAnd for that Jeremy has setup something on kaggle\nThey key (and new) part here is\nlearn.export('model.pkl')\nFinally, open the Kaggle sidebar on the right if it’s not already, and find the section marked “Output”. Open the /kaggle/working folder, and you’ll see model.pkl. Click on it, then click on the menu on the right that appears, and choose “Download”. After a few seconds, your model will be downloaded to your computer, where you can then create your app that uses the model.\n\n\n\nimage.png\n\n\nAnd copy/past it to your local minima repo. Push it to HF.\n\n\nintegrate it with gradio\n\n\n\nimage.png\n\n\nAnd Jeremy illustrates how to do it with a notebook and nbdev. Exactly as I did in gradio and huggingface - handson\n\nload model\nMain parts are to load the model with\nlearn = load_learner('model.pkl')\n\n\nrun prediction\nto run a prediction with\npred, idx, probs = learn.predict(img)\n\n\ncall prediction through a function\nand to create the classify_image function as expected by gradio\ncategories = ('Dog', 'Cat')\n\ndef classify_image(img):\n    pred, idx, probs = learn.predict(img)\n    return dict(zip(categories, map(float, probs))))\nand this return part is quite complex because gradio cannot deal with Tensors.\n\n\ncreate gradio UI\nThere is now the gradio interface that takes image and returns dictionary.\nimage = gr.inputs.Image(shape=(192, 192))\nlabel = gr.outputs.Label()\nexamples = ['dog.jpg', 'cat.jpg', 'dunno.jpg']\n\nintf = gr.Interface(fn=classify_image, inputs=image, outputs=label, examples=examples)\nintf.launch(inline=False)\n\n\nexport as app.py\nAnd export as app.py and for that Jeremy uses a slightly different version that I used\nMine;\nimport nbdev; nbdev.export.nb_export('app.ipynb', lib_path='.')\nHis:\nfrom nbdev.export import notebook2script\nnotebook2script('app.ipynb')\nhttps://huggingface.co/spaces/jph00/testing\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#fastsetup",
    "href": "posts/2022-10-17-fastai-2022-courses.html#fastsetup",
    "title": "Practical Deep Learning for Coders",
    "section": "fastsetup",
    "text": "fastsetup\nhttps://github.com/fastai/fastsetup\nclone it with github desktop (will do cmd line I don’t have the option Jeremy has)\ninstall conda mamba (if needed)\n./setup-conda.sh\ninstall fastai from scratch\nconda create -n fastai python=3.9\nconda activate fastai\nconda install -c fastchan fastai nbdev\npip install gradio\nupdate to up-to-date versions\nconda activate fastai\nconda update -c fastchan fastai nbdev\npip install -U gradio"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#api",
    "href": "posts/2022-10-17-fastai-2022-courses.html#api",
    "title": "Practical Deep Learning for Coders",
    "section": "API",
    "text": "API\n\ngradio, streamlit\n2 options within HF to build app:\n\ngradio. Lot of widgets, reasonably flexible to allow prototyping.\nstreamlit. More flexible. Not so easy to start with.\n\n\n\ngradio, hf API\nand with gradio + HF you have automatically an API available \nBy clicking it you get the documentation of this API.\nIt can then be used by any JS interface you would like to develop.\nAnd HF is nice enought to provide examples (live demo) in Python, curl (command line) and javascript\n\n\n\nimage.png\n\n\n\n\nexample from js\nJeremy uses this to develop a small JS interface in https://fastai.github.io/tinypets/1single.html\nAnd the code is quite minimum: https://github.com/fastai/tinypets/blob/master/1single.html\n---\ntitle: 1. Single file\nlayout: page\n---\n\n&lt;input id=\"photo\" type=\"file\"&gt;\n&lt;div id=\"results\"&gt;&lt;/div&gt;\n&lt;script&gt;\n  async function loaded(reader) {\n    const response = await fetch('https://hf.space/embed/jph00/pets/+/api/predict/', {\n      method: \"POST\", body: JSON.stringify({ \"data\": [reader.result] }),\n      headers: { \"Content-Type\": \"application/json\" }\n    });\n    const json = await response.json();\n    const label = json['data'][0]['confidences'][0]['label'];\n    results.innerHTML = `&lt;br/&gt;&lt;img src=\"${reader.result}\" width=\"300\"&gt; &lt;p&gt;${label}&lt;/p&gt;`\n  }\n  function read() {\n    const reader = new FileReader();\n    reader.addEventListener('load', () =&gt; loaded(reader))\n    reader.readAsDataURL(photo.files[0]);\n  }\n  photo.addEventListener('input', read);\n&lt;/script&gt;"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#gh-pages",
    "href": "posts/2022-10-17-fastai-2022-courses.html#gh-pages",
    "title": "Practical Deep Learning for Coders",
    "section": "GH pages",
    "text": "GH pages\nIt can run locally of course, and can be hosted with gh pages.\n\nby generating from fastpages\nJeremy suggests to use fastpages. In the doc at the bottom there is a link to generate a website from fastapages\nfastai/fastpages: An easy to use blogging platform, with enhanced support for Jupyter Notebooks.\n\nSetup Instructions\n\nGenerate a copy of this repo by clicking on this link. Make sure to sign in to your account, or you will see a 404 error. Name your repo anything you like except {your-username}.github.io.\n\n\nApply a theme (to be setup in _config.yml)\nCreate an index.md file which is the landing page.\n\n\nor by forking an existing one (e.g. tinypets)\nand in that case we have to turn on gh pages\nSettings &gt; Pages &gt; Enable gh pages (select branch and save)\nWe can now switch to different theme.\nFrom remote_theme: daviddarnes/alembic@main to remote_theme: pages-themes/hacker\nit provides a complete different look\n\n\n\nimage.png\n\n\nLooks like we can browse through these jekyll themes at http://jekyllthemes.org/"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#timm",
    "href": "posts/2022-10-17-fastai-2022-courses.html#timm",
    "title": "Practical Deep Learning for Coders",
    "section": "timm",
    "text": "timm\nTo use it we have to install it: pip install timm\nJeremy illsutrates how to switch model architecture. And for that uses timm fastai. He has created a notebook on kaggle to rank vision models https://www.kaggle.com/code/jhoward/which-image-models-are-best/\n\n\n\nimage.png\n\n\nConvnext models seem to be a good fit.\n\nimport timm\n\ntimm.list_models('convnext*')\n\n['convnext_atto',\n 'convnext_atto_ols',\n 'convnext_base',\n 'convnext_base_384_in22ft1k',\n 'convnext_base_in22ft1k',\n 'convnext_base_in22k',\n 'convnext_femto',\n 'convnext_femto_ols',\n 'convnext_large',\n 'convnext_large_384_in22ft1k',\n 'convnext_large_in22ft1k',\n 'convnext_large_in22k',\n 'convnext_nano',\n 'convnext_nano_ols',\n 'convnext_pico',\n 'convnext_pico_ols',\n 'convnext_small',\n 'convnext_small_384_in22ft1k',\n 'convnext_small_in22ft1k',\n 'convnext_small_in22k',\n 'convnext_tiny',\n 'convnext_tiny_384_in22ft1k',\n 'convnext_tiny_hnf',\n 'convnext_tiny_in22ft1k',\n 'convnext_tiny_in22k',\n 'convnext_xlarge_384_in22ft1k',\n 'convnext_xlarge_in22ft1k',\n 'convnext_xlarge_in22k']\n\n\nAnd to use one it is just a matter of calling\nlearn = vision_learner(dls, 'convnext_tiny_in22k', metrics=error_rate).to_fp16()"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#using-in-an-app",
    "href": "posts/2022-10-17-fastai-2022-courses.html#using-in-an-app",
    "title": "Practical Deep Learning for Coders",
    "section": "Using in an app",
    "text": "Using in an app\nWhen dealing with categories, fastai keep category names in the dataloader under vocab\ncategories = learn.dls.vocab\n\ndef classify_image(img):\n    pred, idx, probs = learn.predict(img)\n    return dict(zip(categories, map(float, probs)))"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#applying-this-on-my-own-app-cheeses",
    "href": "posts/2022-10-17-fastai-2022-courses.html#applying-this-on-my-own-app-cheeses",
    "title": "Practical Deep Learning for Coders",
    "section": "Applying this on my own app: cheeses",
    "text": "Applying this on my own app: cheeses\nAll notebooks from these courses are at https://github.com/fastai/course22\nAnd my app is at https://huggingface.co/spaces/Guillaume63/cheeses\nI had to configure this repo to use git-lfs to store large binary files:\ngit lfs install\n#if needed reset the last commit\ngit reset --soft HEAD^\ngit status\n#if offeneded files ar already staged, restore them\ngit restore --staged *.jpg\ngit status\n#add them back\ngit add -A\n#check they are managed by git lfs\ngit lfs ls-files\ngit commit -am'recommit after lfs install'\ngit push\nand I pushed it to fastai forum"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#inside-nn",
    "href": "posts/2022-10-17-fastai-2022-courses.html#inside-nn",
    "title": "Practical Deep Learning for Coders",
    "section": "Inside NN",
    "text": "Inside NN\nhttps://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work\nIllustration of a powerfull python function partial\n\nfrom functools import partial\ndef mk_quad(a, b, c): return partial(quad, a, b, c)\n\n\nf = mk_quad(3,2,1)\nf(1.5)\n\n10.75\n\n\nI think I will reuse that!\nJeremy explains NN in 3 steps:\n\nloss caculation (with nice simulator to manually approach better paameters)\ngrad calculation, adjustment (with learning rate) and loop\nwe can use combination of relu to be as close as possible to any function (whatever the dimension)"
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#using-microsoft-excel",
    "href": "posts/2022-10-17-fastai-2022-courses.html#using-microsoft-excel",
    "title": "Practical Deep Learning for Coders",
    "section": "Using Microsoft excel",
    "text": "Using Microsoft excel\nThis is fun. Not as surpising as the one from 3-4 years ago but Jeremy is very good at explaining it. Excel spreadsheet is here."
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#next-lesson",
    "href": "posts/2022-10-17-fastai-2022-courses.html#next-lesson",
    "title": "Practical Deep Learning for Coders",
    "section": "Next lesson",
    "text": "Next lesson\nWill practice nlp using huggingface api."
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#linear-model-then-deep-learning-model",
    "href": "posts/2022-10-17-fastai-2022-courses.html#linear-model-then-deep-learning-model",
    "title": "Practical Deep Learning for Coders",
    "section": "linear model then deep learning model",
    "text": "linear model then deep learning model\nJust restarting from titanic dataset and exactly as what was made in excel, now we do it with PyTorch.\nIt is good to see how much fiddling it requires. This is good to develop intuititions but defintely it is not what you want to implement when exploring a question."
  },
  {
    "objectID": "posts/2022-10-17-fastai-2022-courses.html#why-you-should-use-a-framework",
    "href": "posts/2022-10-17-fastai-2022-courses.html#why-you-should-use-a-framework",
    "title": "Practical Deep Learning for Coders",
    "section": "Why you should use a framework",
    "text": "Why you should use a framework\nIt is in kaggle Why you should use a framework. As usually upvote & copy/edit to start using it. Or get the notebooks from github.\nJeremy used TabularPandas, lr_find, ensemble\n\nlearn.lr_find(suggest_funcs=(slide, valley))\n\n\n\n\nSuggestedLRs(slide=0.0831763744354248, valley=0.007585775572806597)\n\n\n\n\n\nI could try this for autoencoders: https://alanbertl.com/autoencoder-with-fast-ai/ (this is v1 but should be easy to adapt to v2)\nAnd then ends with How random forests really work. Or get the notebooks from github.\nTip: pd.options.display.float_format = '{:.2f}'.format will display all floats from dataframes with 2 digits\nTip2: from fastai.imports import * will import everything that we need (numpy, pandas, matplotlib, …)\nJeremy illustrates binary split and mentions OneR classifier (paper from 1993)"
  },
  {
    "objectID": "posts/2020-12-02-push-big-files-to-github.html",
    "href": "posts/2020-12-02-push-big-files-to-github.html",
    "title": "Push large files to github: git-lfs",
    "section": "",
    "text": "Where is the problem\nI am currently following deep learning specialization from Andrew Ng on coursera.\nIn the course 4 about CNNs, there are some pre-trained yolo models that we use to do object detection. And these models come as large .h5 files.\nBecause I run all programming assignments locally and keep everything (lectures + codes) on my local repo, when I pushed to github I got this error:\n(base) explore@explore-ThinkPad-P53:~/git/guillaume/deeplearning_specialization$ git push\nEnumerating objects: 247, done.\nCounting objects: 100% (247/247), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (239/239), done.\nWriting objects: 100% (242/242), 707.06 MiB | 4.74 MiB/s, done.\nTotal 242 (delta 6), reused 0 (delta 0)\nremote: Resolving deltas: 100% (6/6), completed with 3 local objects.\nremote: warning: File notebooks/C4W3/nb_images/pred_video.mp4 is 85.44 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\nremote: warning: File notebooks/C4W3/nb_images/road_video.mp4 is 81.71 MB; this is larger than GitHub's recommended maximum file size of 50.00 MB\nremote: error: GH001: Large files detected. You may want to try Git Large File Storage - https://git-lfs.github.com.\nremote: error: Trace: 2d1944991c30279b831124b51e4aac57a17a860f2ef789b4e32801fb65282244\nremote: error: See http://git.io/iEPt8g for more information.\nremote: error: File notebooks/C4W2/ResNet50.h5 is 270.32 MB; this exceeds GitHub's file size limit of 100.00 MB\nremote: error: File notebooks/C4W3/model_data/yolo.h5 is 194.69 MB; this exceeds GitHub's file size limit of 100.00 MB\nTo github.com:castorfou/deeplearning_specialization.git\n ! [remote rejected] master -&gt; master (pre-receive hook declined)\n\n\nSolution: git-lfs\nAs explained in https://github.com/git-lfs/git-lfs/wiki/Tutorial, there is (always) a way to do it properly.\nFirst it is a matter of installing git-lfs:\nsudo apt-get install git-lfs\nThen to setup git lfs\ngit lfs install\nAnd then to “migrate” big files to lfs:\ngit lfs migrate import --include=\"*.mp4\"\ngit lfs migrate import --include=\"*.h5\"\nAnd now to git push\n(base) explore@explore-ThinkPad-P53:~/git/guillaume/deeplearning_specialization$ git push\nUploading LFS objects: 100% (25/25), 954 MB | 37 MB/s, done.                                                                 \nEnumerating objects: 311, done.\nCounting objects: 100% (311/311), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (273/273), done.\nWriting objects: 100% (276/276), 60.49 MiB | 5.59 MiB/s, done.\nTotal 276 (delta 18), reused 0 (delta 0)\nremote: Resolving deltas: 100% (18/18), completed with 16 local objects.\nTo github.com:castorfou/deeplearning_specialization.git\n   d0d2dc2..004fa09  master -&gt; master"
  },
  {
    "objectID": "posts/2021-11-01-logbook-November.html",
    "href": "posts/2021-11-01-logbook-November.html",
    "title": "Logbook for November 21",
    "section": "",
    "text": "Monday 11/22\nback after a nice vacation break + some catchup to do for work.\nto use iphone as a webcam on linux or windows: https://www.iriun.com/ (but not detected as a webcam in linux)\nWednesday 11/24\ngetting this message when pushing to gitlab: remote: GitLab: File  is larger than the allowed size of 100 MB\nif from the most recent commit:\ngit rm --cached &lt;my large file&gt;\ngit commit --amend -C HEAD\notherwise follow Tutorial: Removing Large Files from Git on medium (or git clean repo with BFG on this blog)\nThursday 11/25\nwhen exporting notebooks with plotly graphs, it can help to use\nimport plotly\nplotly.offline.init_notebook_mode()\nexporting to html will integrate these plotly graphs (but not exporting to pdf)"
  },
  {
    "objectID": "posts/2021-11-01-logbook-November.html#week-47---november-21",
    "href": "posts/2021-11-01-logbook-November.html#week-47---november-21",
    "title": "Logbook for November 21",
    "section": "",
    "text": "Monday 11/22\nback after a nice vacation break + some catchup to do for work.\nto use iphone as a webcam on linux or windows: https://www.iriun.com/ (but not detected as a webcam in linux)\nWednesday 11/24\ngetting this message when pushing to gitlab: remote: GitLab: File  is larger than the allowed size of 100 MB\nif from the most recent commit:\ngit rm --cached &lt;my large file&gt;\ngit commit --amend -C HEAD\notherwise follow Tutorial: Removing Large Files from Git on medium (or git clean repo with BFG on this blog)\nThursday 11/25\nwhen exporting notebooks with plotly graphs, it can help to use\nimport plotly\nplotly.offline.init_notebook_mode()\nexporting to html will integrate these plotly graphs (but not exporting to pdf)"
  },
  {
    "objectID": "posts/2020-10-15-gan-course2-week3-certificate.html",
    "href": "posts/2020-10-15-gan-course2-week3-certificate.html",
    "title": "GAN Specialization course 2 week 3 - Apply and certificate",
    "section": "",
    "text": "Notes\ntbd later\n# Certificate\n\n\n\nalt text\n\n\n\n\nAbout next steps\nFor the moment I am hesitating to follow last course for gans. This is a deep dive into gan, with lots of theory (papers) associated to it. My 1st goal was to know better about it and this is met. My 2nd one was to figure out how to use this kind of generative networks for other area such as tabular data + prescription issues. I am not sure this is applicable (or not yet).\nMaybe it is better for now to resume my learning sessions with Jeremy Howard on fastai v2."
  },
  {
    "objectID": "posts/2021-12-01-logbook-December.html",
    "href": "posts/2021-12-01-logbook-December.html",
    "title": "Logbook for December 21",
    "section": "",
    "text": "Thursday 12/9\nA deep learning course using PyTorch including Transformers, Generative models and self-supervised learning: https://deeplearning.neuromatch.io/tutorials/intro.html - W1D1 - Gradient Descent and AutoGrad done\nNeurIPS workshop on RL next Monday. https://sites.google.com/view/deep-rl-workshop-neurips2021. List of posters is just impressive.\nAnd best fastai sources compiled by Tanishq Mathew Abraham.\nFrom @paperswithcode, Deep learning models for tabular data continue to improve. What are the latest methods and recent progress? https://twitter.com/paperswithcode/status/1458433653269205002\nFriday 12/10\nRegistration for neurips 2021 taken. Specially interested by RL workshop on Monday."
  },
  {
    "objectID": "posts/2021-12-01-logbook-December.html#week-49---december-21",
    "href": "posts/2021-12-01-logbook-December.html#week-49---december-21",
    "title": "Logbook for December 21",
    "section": "",
    "text": "Thursday 12/9\nA deep learning course using PyTorch including Transformers, Generative models and self-supervised learning: https://deeplearning.neuromatch.io/tutorials/intro.html - W1D1 - Gradient Descent and AutoGrad done\nNeurIPS workshop on RL next Monday. https://sites.google.com/view/deep-rl-workshop-neurips2021. List of posters is just impressive.\nAnd best fastai sources compiled by Tanishq Mathew Abraham.\nFrom @paperswithcode, Deep learning models for tabular data continue to improve. What are the latest methods and recent progress? https://twitter.com/paperswithcode/status/1458433653269205002\nFriday 12/10\nRegistration for neurips 2021 taken. Specially interested by RL workshop on Monday."
  },
  {
    "objectID": "posts/2021-12-01-logbook-December.html#week-50---december-21",
    "href": "posts/2021-12-01-logbook-December.html#week-50---december-21",
    "title": "Logbook for December 21",
    "section": "Week 50 - December 21",
    "text": "Week 50 - December 21\nMonday 12/13\nNeurIPS tutorial: Real-Time Optimization for Fast and Complex Control Systems"
  },
  {
    "objectID": "posts/2022-07-21-jupyter-export-lab-as-py.html",
    "href": "posts/2022-07-21-jupyter-export-lab-as-py.html",
    "title": "Auto export python code from jupyter lab",
    "section": "",
    "text": "This hack comes from EASIER CODE REVIEWS FOR JUPYTER NOTEBOOKS WITH NBAUTOEXPORT.\nAnd this is an updated version for Jupyter lab when Auto export python code from jupyter notebooks was specifically for Jupyter notebook.\n\nInstall NBAUTOEXPORT\nYou should install it in the same virtual environment that you are running Jupyter Notebook or JupyterLab from.\n# in base (from in _conda_env/base.txt)\npip install nbautoexport\n\n!cat ~/_conda_env/base.txt\n\nconda install -y mamba -n base -c conda-forge\nmamba init\nmamba install -y nb_conda_kernels\nmamba install -y -c conda-forge jupyterlab jupyterlab-git\nmamba install -y ipywidgets\n\nmamba install -y -c conda-forge jupyterlab_execute_time\n#and change in jupyter lab : Settings- &gt; Advanced Settings Editor -&gt; Notebook: {\"recordTiming\": true} \n\npip install --upgrade nvitop\n\njupyter labextension install jupyterlab-spreadsheet\npip install jupyterlab-tabular-data-editor\npip install nbautoexport\n\n\nThere are two main steps to setting up nbautoexport:\n\nInstall nbautoexport as a post-save hook with Jupyter (once per machine you use it on)\nConfigure a notebooks directory (once per project you are working on)\n\n\n\nInstall nbautoexport as a post-save hook\n# from base environment\nnbautoexport install\n\n&gt; nbautoexport post-save hook successfully installed with Jupyter.\n&gt; If a Jupyter server is already running, you will need to restart it for nbautoexport to work.\n\n\nConfigure a notebooks directory\n# from your notebooks directory\nnbautoexport configure .\nIt creates this file .nbautoexport\n───────┬───────────────────────────────────────────────────────────\n       │ File: .nbautoexport\n───────┼───────────────────────────────────────────────────────────\n   1   │ {\n   2   │   \"export_formats\": [\n   3   │     \"script\"\n   4   │   ],\n   5   │   \"organize_by\": \"extension\",\n   6   │   \"clean\": {\n   7   │     \"exclude\": []\n   8   │   }\n   9   │ }\n───────┴───────────────────────────────────────────────────────────\n\n\nTest\nAfter running it in my blog _notebooks directory, and saving a notebook; a script directory and .py file with notebook content are created\n(base) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog/_notebooks$ tree\n.\n├── .nbautoexport\n├── 2022-07-21-jupyter-export-lab-as-py.ipynb\n├── README.md\n└── script\n    └── 2022-07-21-jupyter-export-lab-as-py.py\n2022-07-21-jupyter-export-lab-as-py.py has been created as expected\nI can now delete .nbautoexport and it won’t happen in that directory"
  },
  {
    "objectID": "posts/2021-01-19-seaborn-cheatsheet.html",
    "href": "posts/2021-01-19-seaborn-cheatsheet.html",
    "title": "seaborn cheatsheet",
    "section": "",
    "text": "pdf lectures in github\n\n\n\n\n# Getting started\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Example 1: Scatter plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nheight = [62, 64, 69, 75, 66, 68, 65, 71, 76, 73]\nweight = [120, 136, 148, 175, 137, 165, 154, 172, 200, 187]\nsns.scatterplot(x=height, y=weight)\nplt.show()\n\n# Example 2: Create a count plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ngender = [\"Female\", \"Female\", \"Female\", \"Female\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\"]\nsns.countplot(x=gender)\nplt.show()\n\n\n\n\n# Using DataFrames with countplot()\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv(\"masculinity.csv\")\nsns.countplot(x=\"how_masculine\", data=df)\nplt.show()\n\n\n\n# Tips dataset\nimport pandas as pd\nimport seaborn as sns\ntips = sns.load_dataset(\"tips\")\ntips.head()\n\n# A basic scatter plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips)\nplt.show()\n\n# A scatter plot with hue\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips, hue=\"smoker\")\nplt.show()\n\n# Setting hue order\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips, hue=\"smoker\", hue_order=[\"Yes\",\"No\"])\nplt.show()\n\n# Specifying hue colors\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nhue_colors = {\"Yes\": \"black\", \"No\": \"red\"}\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips, hue=\"smoker\", palette=hue_colors)\nplt.show()\n\n# Using HTML hex color codes with hue\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nhue_colors = {\"Yes\": \"#808080\", \"No\": \"#00FF00\"}\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips, hue=\"smoker\", palette=hue_colors)\nplt.show()\n\n# Using hue with count plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.countplot(x=\"smoker\", data=tips, hue=\"sex\")\nplt.show()\n\n\n\n\n\n\n\n# Using relplot()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"scatter\")\nplt.show()\n\n# Subplots in columns\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"scatter\", col=\"smoker\")\nplt.show()\n\n# Subplots in rows\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"scatter\", row=\"smoker\")\nplt.show()\n\n# Subplots in rows and columns\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"scatter\", col=\"smoker\", row=\"time\")\nplt.show()\n\n# Wrapping columns\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",col=\"day\",col_wrap=2)\nplt.show()\n\n# Ordering columns\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",col=\"day\",col_wrap=2,col_order=[\"Thur\",\"Fri\",\"Sat\",\"Sun\"])\nplt.show()\n\n\n\n\n# Subgroups with point size\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",size=\"size\")\nplt.show()\n\n# Point size and hue\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",size=\"size\",hue=\"size\")\nplt.show()\n\n# Subgroups with point style\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",hue=\"smoker\",style=\"smoker\")\nplt.show()\n\n# Changing point transparency\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Set alpha to be between 0 and 1\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",alpha=0.4)\nplt.show()\n\n\n\n# Line plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2_mean\",data=air_df_mean,kind=\"line\")\nplt.show()\n\n# Subgroups by location\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2_mean\",data=air_df_loc_mean,kind=\"line\",style=\"location\",hue=\"location\")\nplt.show()\n\n# Adding markers\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2_mean\",data=air_df_loc_mean,kind=\"line\",style=\"location\",hue=\"location\",markers=True)\nplt.show()\n\n# Turning off line style\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2_mean\",data=air_df_loc_mean,kind=\"line\",style=\"location\",hue=\"location\",markers=True,dashes=False)\nplt.show()\n\n# Multiple observations per x-value\n# Line plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2\",data=air_df,kind=\"line\")\nplt.show()\n\n# Replacing confidence interval with standard deviation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2\",data=air_df,kind=\"line\",ci=\"sd\")\nplt.show()\n\n# Turning off confidence interval\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2\",data=air_df,kind=\"line\",ci=None)\nplt.show()\n\n\n\n\n\n\n\n# countplot() vs. catplot()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"how_masculine\",data=masculinity_data,kind=\"count\")\nplt.show()\n\n# Changing the order\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncategory_order = [\"No answer\",\"Not at all\",\"Not very\",\"Somewhat\",\"Very\"]\nsns.catplot(x=\"how_masculine\",data=masculinity_data,kind=\"count\",order=category_order)\nplt.show()\n\n# Bar plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"day\",y=\"total_bill\",data=tips,kind=\"bar\")\nplt.show()\n\n# Turning off confidence intervals\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"day\",y=\"total_bill\",data=tips,kind=\"bar\",ci=None)\nplt.show()\n\n# Changing the orientation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"total_bill\",y=\"day\",data=tips,kind=\"bar\")\nplt.show()\n\n\n\n# How to create a box plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ng = sns.catplot(x=\"time\",y=\"total_bill\",data=tips,kind=\"box\")\nplt.show()\n\n# Change the order of categories\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ng = sns.catplot(x=\"time\",y=\"total_bill\",data=tips,kind=\"box\",order=[\"Dinner\",\"Lunch\"])\nplt.show()\n\n# Omitting the outliers using `sym`\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ng = sns.catplot(x=\"time\",y=\"total_bill\",data=tips,kind=\"box\",sym=\"\")\nplt.show()\n\n# Changing the whiskers using `whis`\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ng = sns.catplot(x=\"time\",y=\"total_bill\",data=tips,kind=\"box\",whis=[0, 100])\nplt.show()\n\n\n\n# Creating a point plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"age\",y=\"masculinity_important\",data=masculinity_data,hue=\"feel_masculine\",kind=\"point\")\nplt.show()\n\n# Disconnecting the points\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"age\",y=\"masculinity_important\",data=masculinity_data,hue=\"feel_masculine\",kind=\"point\",join=False)\nplt.show()\n\n# Displaying the median\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import median\nsns.catplot(x=\"smoker\",y=\"total_bill\",data=tips,kind=\"point\",estimator=median)\nplt.show()\n\n# Customizing the confidence intervals\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"smoker\",y=\"total_bill\",data=tips,kind=\"point\",capsize=0.2)\nplt.show()\n\n# Turning off confidence intervals\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"smoker\",y=\"total_bill\",data=tips,kind=\"point\",ci=None)\nplt.show()\n\n\n\n\n\n\n\n# Figure style: \"whitegrid\"\nsns.set_style(\"whitegrid\")\nsns.catplot(x=\"age\",y=\"masculinity_important\",data=masculinity_data,hue=\"feel_masculine\",kind=\"point\")\nplt.show()\n\n# Other styles:\nsns.set_style(\"ticks\")\nsns.set_style(\"dark\")\nsns.set_style(\"darkgrid\")\n\n# Example (diverging palette)\nsns.set_palette(\"RdBu\")\ncategory_order = [\"No answer\",\"Not at all\",\"Not very\",\"Somewhat\",\"Very\"]\nsns.catplot(x=\"how_masculine\",data=masculinity_data,kind=\"count\",order=category_order)\nplt.show()\n\n# Custom palettes\ncustom_palette = [\"red\", \"green\", \"orange\", \"blue\",\"yellow\", \"purple\"]\nsns.set_palette(custom_palette)\n\n# Custom palettes\ncustom_palette = ['#FBB4AE', '#B3CDE3', '#CCEBC5','#DECBE4', '#FED9A6', '#FFFFCC','#E5D8BD', '#FDDAEC', '#F2F2F2']\nsns.set_palette(custom_palette)\n\n# Larger context: \"talk\"\n#Smallest to largest: \"paper\", \"notebook\", \"talk\", \"poster\"\nsns.set_context(\"talk\")\n\n\n\n\n# Adding a title to FacetGrid\ng = sns.catplot(x=\"Region\",y=\"Birthrate\",data=gdp_data,kind=\"box\")\ng.fig.suptitle(\"New Title\")\nplt.show()\n\n# Adjusting height of title in FacetGrid\ng = sns.catplot(x=\"Region\",y=\"Birthrate\",data=gdp_data,kind=\"box\")\ng.fig.suptitle(\"New Title\",y=1.03)\nplt.show()\n\n\n\n# Adding a title to AxesSubplot\ng = sns.boxplot(x=\"Region\",y=\"Birthrate\",data=gdp_data)\ng.set_title(\"New Title\",y=1.03)\n\n# Titles for subplots\ng = sns.catplot(x=\"Region\",y=\"Birthrate\",data=gdp_data,kind=\"box\",col=\"Group\")\ng.fig.suptitle(\"New Title\",y=1.03)\ng.set_titles(\"This is {col_name}\")\n\n# Adding axis labels\ng = sns.catplot(x=\"Region\",y=\"Birthrate\",data=gdp_data,kind=\"box\")\ng.set(xlabel=\"New X Label\",ylabel=\"New Y Label\")\nplt.show()\n\n# Rotating x-axis tick labels\ng = sns.catplot(x=\"Region\",y=\"Birthrate\",data=gdp_data,kind=\"box\")\nplt.xticks(rotation=90)\nplt.show()"
  },
  {
    "objectID": "posts/2021-01-19-seaborn-cheatsheet.html#introduction-to-seaborn",
    "href": "posts/2021-01-19-seaborn-cheatsheet.html#introduction-to-seaborn",
    "title": "seaborn cheatsheet",
    "section": "",
    "text": "# Getting started\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Example 1: Scatter plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nheight = [62, 64, 69, 75, 66, 68, 65, 71, 76, 73]\nweight = [120, 136, 148, 175, 137, 165, 154, 172, 200, 187]\nsns.scatterplot(x=height, y=weight)\nplt.show()\n\n# Example 2: Create a count plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\ngender = [\"Female\", \"Female\", \"Female\", \"Female\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\", \"Male\"]\nsns.countplot(x=gender)\nplt.show()\n\n\n\n\n# Using DataFrames with countplot()\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndf = pd.read_csv(\"masculinity.csv\")\nsns.countplot(x=\"how_masculine\", data=df)\nplt.show()\n\n\n\n# Tips dataset\nimport pandas as pd\nimport seaborn as sns\ntips = sns.load_dataset(\"tips\")\ntips.head()\n\n# A basic scatter plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips)\nplt.show()\n\n# A scatter plot with hue\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips, hue=\"smoker\")\nplt.show()\n\n# Setting hue order\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips, hue=\"smoker\", hue_order=[\"Yes\",\"No\"])\nplt.show()\n\n# Specifying hue colors\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nhue_colors = {\"Yes\": \"black\", \"No\": \"red\"}\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips, hue=\"smoker\", palette=hue_colors)\nplt.show()\n\n# Using HTML hex color codes with hue\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nhue_colors = {\"Yes\": \"#808080\", \"No\": \"#00FF00\"}\nsns.scatterplot(x=\"total_bill\", y=\"tip\", data=tips, hue=\"smoker\", palette=hue_colors)\nplt.show()\n\n# Using hue with count plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.countplot(x=\"smoker\", data=tips, hue=\"sex\")\nplt.show()"
  },
  {
    "objectID": "posts/2021-01-19-seaborn-cheatsheet.html#visualizing-two-quantitative-variables",
    "href": "posts/2021-01-19-seaborn-cheatsheet.html#visualizing-two-quantitative-variables",
    "title": "seaborn cheatsheet",
    "section": "",
    "text": "# Using relplot()\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"scatter\")\nplt.show()\n\n# Subplots in columns\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"scatter\", col=\"smoker\")\nplt.show()\n\n# Subplots in rows\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"scatter\", row=\"smoker\")\nplt.show()\n\n# Subplots in rows and columns\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\", y=\"tip\", data=tips, kind=\"scatter\", col=\"smoker\", row=\"time\")\nplt.show()\n\n# Wrapping columns\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",col=\"day\",col_wrap=2)\nplt.show()\n\n# Ordering columns\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",col=\"day\",col_wrap=2,col_order=[\"Thur\",\"Fri\",\"Sat\",\"Sun\"])\nplt.show()\n\n\n\n\n# Subgroups with point size\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",size=\"size\")\nplt.show()\n\n# Point size and hue\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",size=\"size\",hue=\"size\")\nplt.show()\n\n# Subgroups with point style\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",hue=\"smoker\",style=\"smoker\")\nplt.show()\n\n# Changing point transparency\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n# Set alpha to be between 0 and 1\nsns.relplot(x=\"total_bill\",y=\"tip\",data=tips,kind=\"scatter\",alpha=0.4)\nplt.show()\n\n\n\n# Line plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2_mean\",data=air_df_mean,kind=\"line\")\nplt.show()\n\n# Subgroups by location\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2_mean\",data=air_df_loc_mean,kind=\"line\",style=\"location\",hue=\"location\")\nplt.show()\n\n# Adding markers\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2_mean\",data=air_df_loc_mean,kind=\"line\",style=\"location\",hue=\"location\",markers=True)\nplt.show()\n\n# Turning off line style\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2_mean\",data=air_df_loc_mean,kind=\"line\",style=\"location\",hue=\"location\",markers=True,dashes=False)\nplt.show()\n\n# Multiple observations per x-value\n# Line plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2\",data=air_df,kind=\"line\")\nplt.show()\n\n# Replacing confidence interval with standard deviation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2\",data=air_df,kind=\"line\",ci=\"sd\")\nplt.show()\n\n# Turning off confidence interval\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.relplot(x=\"hour\", y=\"NO_2\",data=air_df,kind=\"line\",ci=None)\nplt.show()"
  },
  {
    "objectID": "posts/2021-01-19-seaborn-cheatsheet.html#visualizing-a-categorical-and-a-quantitative-variable",
    "href": "posts/2021-01-19-seaborn-cheatsheet.html#visualizing-a-categorical-and-a-quantitative-variable",
    "title": "seaborn cheatsheet",
    "section": "",
    "text": "# countplot() vs. catplot()\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"how_masculine\",data=masculinity_data,kind=\"count\")\nplt.show()\n\n# Changing the order\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ncategory_order = [\"No answer\",\"Not at all\",\"Not very\",\"Somewhat\",\"Very\"]\nsns.catplot(x=\"how_masculine\",data=masculinity_data,kind=\"count\",order=category_order)\nplt.show()\n\n# Bar plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"day\",y=\"total_bill\",data=tips,kind=\"bar\")\nplt.show()\n\n# Turning off confidence intervals\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"day\",y=\"total_bill\",data=tips,kind=\"bar\",ci=None)\nplt.show()\n\n# Changing the orientation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"total_bill\",y=\"day\",data=tips,kind=\"bar\")\nplt.show()\n\n\n\n# How to create a box plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ng = sns.catplot(x=\"time\",y=\"total_bill\",data=tips,kind=\"box\")\nplt.show()\n\n# Change the order of categories\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ng = sns.catplot(x=\"time\",y=\"total_bill\",data=tips,kind=\"box\",order=[\"Dinner\",\"Lunch\"])\nplt.show()\n\n# Omitting the outliers using `sym`\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ng = sns.catplot(x=\"time\",y=\"total_bill\",data=tips,kind=\"box\",sym=\"\")\nplt.show()\n\n# Changing the whiskers using `whis`\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ng = sns.catplot(x=\"time\",y=\"total_bill\",data=tips,kind=\"box\",whis=[0, 100])\nplt.show()\n\n\n\n# Creating a point plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"age\",y=\"masculinity_important\",data=masculinity_data,hue=\"feel_masculine\",kind=\"point\")\nplt.show()\n\n# Disconnecting the points\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"age\",y=\"masculinity_important\",data=masculinity_data,hue=\"feel_masculine\",kind=\"point\",join=False)\nplt.show()\n\n# Displaying the median\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom numpy import median\nsns.catplot(x=\"smoker\",y=\"total_bill\",data=tips,kind=\"point\",estimator=median)\nplt.show()\n\n# Customizing the confidence intervals\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"smoker\",y=\"total_bill\",data=tips,kind=\"point\",capsize=0.2)\nplt.show()\n\n# Turning off confidence intervals\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.catplot(x=\"smoker\",y=\"total_bill\",data=tips,kind=\"point\",ci=None)\nplt.show()"
  },
  {
    "objectID": "posts/2021-01-19-seaborn-cheatsheet.html#customizing-seaborn-plots",
    "href": "posts/2021-01-19-seaborn-cheatsheet.html#customizing-seaborn-plots",
    "title": "seaborn cheatsheet",
    "section": "",
    "text": "# Figure style: \"whitegrid\"\nsns.set_style(\"whitegrid\")\nsns.catplot(x=\"age\",y=\"masculinity_important\",data=masculinity_data,hue=\"feel_masculine\",kind=\"point\")\nplt.show()\n\n# Other styles:\nsns.set_style(\"ticks\")\nsns.set_style(\"dark\")\nsns.set_style(\"darkgrid\")\n\n# Example (diverging palette)\nsns.set_palette(\"RdBu\")\ncategory_order = [\"No answer\",\"Not at all\",\"Not very\",\"Somewhat\",\"Very\"]\nsns.catplot(x=\"how_masculine\",data=masculinity_data,kind=\"count\",order=category_order)\nplt.show()\n\n# Custom palettes\ncustom_palette = [\"red\", \"green\", \"orange\", \"blue\",\"yellow\", \"purple\"]\nsns.set_palette(custom_palette)\n\n# Custom palettes\ncustom_palette = ['#FBB4AE', '#B3CDE3', '#CCEBC5','#DECBE4', '#FED9A6', '#FFFFCC','#E5D8BD', '#FDDAEC', '#F2F2F2']\nsns.set_palette(custom_palette)\n\n# Larger context: \"talk\"\n#Smallest to largest: \"paper\", \"notebook\", \"talk\", \"poster\"\nsns.set_context(\"talk\")\n\n\n\n\n# Adding a title to FacetGrid\ng = sns.catplot(x=\"Region\",y=\"Birthrate\",data=gdp_data,kind=\"box\")\ng.fig.suptitle(\"New Title\")\nplt.show()\n\n# Adjusting height of title in FacetGrid\ng = sns.catplot(x=\"Region\",y=\"Birthrate\",data=gdp_data,kind=\"box\")\ng.fig.suptitle(\"New Title\",y=1.03)\nplt.show()\n\n\n\n# Adding a title to AxesSubplot\ng = sns.boxplot(x=\"Region\",y=\"Birthrate\",data=gdp_data)\ng.set_title(\"New Title\",y=1.03)\n\n# Titles for subplots\ng = sns.catplot(x=\"Region\",y=\"Birthrate\",data=gdp_data,kind=\"box\",col=\"Group\")\ng.fig.suptitle(\"New Title\",y=1.03)\ng.set_titles(\"This is {col_name}\")\n\n# Adding axis labels\ng = sns.catplot(x=\"Region\",y=\"Birthrate\",data=gdp_data,kind=\"box\")\ng.set(xlabel=\"New X Label\",ylabel=\"New Y Label\")\nplt.show()\n\n# Rotating x-axis tick labels\ng = sns.catplot(x=\"Region\",y=\"Birthrate\",data=gdp_data,kind=\"box\")\nplt.xticks(rotation=90)\nplt.show()"
  },
  {
    "objectID": "posts/2021-01-19-seaborn-cheatsheet.html#seaborn-introduction",
    "href": "posts/2021-01-19-seaborn-cheatsheet.html#seaborn-introduction",
    "title": "seaborn cheatsheet",
    "section": "Seaborn Introduction",
    "text": "Seaborn Introduction\n\nIntroduction to Seaborn\n# Seaborn distplot \nimport seaborn as sns\nsns.distplot(df['alcohol'])\n\n\nUsing the distribution plot\n# Creating a histogram\nsns.distplot(df['alcohol'], kde=False, bins=10)\n\n# Alternative data distributions\nsns.distplot(df['alcohol'], hist=False, rug=True)\n\n# Further Customizations\nsns.distplot(df['alcohol'], hist=False,rug=True, kde_kws={'shade':True})\n\n\nRegression Plots in Seaborn\n# Introduction to regplot\nsns.regplot(x=\"alcohol\", y=\"pH\", data=df)\n\n# lmplot faceting\nsns.lmplot(x=\"quality\", y=\"alcohol\",data=df, hue=\"type\") \nsns.lmplot(x=\"quality\", y=\"alcohol\",data=df, col=\"type\")"
  },
  {
    "objectID": "posts/2021-01-19-seaborn-cheatsheet.html#customizing-seaborn-plots-1",
    "href": "posts/2021-01-19-seaborn-cheatsheet.html#customizing-seaborn-plots-1",
    "title": "seaborn cheatsheet",
    "section": "Customizing Seaborn Plots",
    "text": "Customizing Seaborn Plots\n\nUsing Seaborn Styles\n# Setting Styles\n# Seaborn has default configurations that can be applied with sns.set()\n# These styles can override matplotlib and pandas plots as well\nsns.set()\n\n# Theme examples with sns.set_style()\nfor style in ['white','dark','whitegrid','darkgrid','ticks']:\n    sns.set_style(style)\n    sns.distplot(df['Tuition'])\n    plt.show()\n\n# Removing axes with despine()\nsns.set_style('white')\nsns.distplot(df['Tuition'])\nsns.despine(left=True)\n\n\nColors in Seaborn\n# Defining a color for a plot\nsns.set(color_codes=True)\nsns.distplot(df['Tuition'], color='g')\n\n# Palettes\nfor p in sns.palettes.SEABORN_PALETTES:\n    sns.set_palette(p)\n    sns.distplot(df['Tuition'])\n    \n# Displaying Palettes\nfor p in sns.palettes.SEABORN_PALETTES:\n    sns.set_palette(p)\n    sns.palplot(sns.color_palette())\n    plt.show()\n    \n# Defining Custom Palettes\n# Circular colors = when the data is not ordered \nsns.palplot(sns.color_palette(\"Paired\", 12))\n\n# Sequential colors = when the data has a consistent range from high to low\nsns.palplot(sns.color_palette(\"Blues\", 12))\n\n# Diverging colors = when both the low and high values are interesting\nsns.palplot(sns.color_palette(\"BrBG\", 12))\n\n\nCustomizing with matplotlib\n\n# Matplotlib Axes\nfig, ax = plt.subplots()\nsns.distplot(df['Tuition'], ax=ax)\nax.set(xlabel=\"Tuition 2013-14\")\n\n# Further Customizations\nfig, ax = plt.subplots()\nsns.distplot(df['Tuition'], ax=ax)\nax.set(xlabel=\"Tuition 2013-14\",ylabel=\"Distribution\", xlim=(0, 50000),title=\"2013-14 Tuition and Fees Distribution\")\n\n# Combining Plots\nfig, (ax0, ax1) = plt.subplots(nrows=1,ncols=2, sharey=True, figsize=(7,4))\nsns.distplot(df['Tuition'], ax=ax0)\nsns.distplot(df.query('State == \"MN\"')['Tuition'], ax=ax1)\nax1.set(xlabel=\"Tuition (MN)\", xlim=(0, 70000))\nax1.axvline(x=20000, label='My Budget', linestyle='--')\nax1.legend()"
  },
  {
    "objectID": "posts/2021-01-19-seaborn-cheatsheet.html#additional-plot-types",
    "href": "posts/2021-01-19-seaborn-cheatsheet.html#additional-plot-types",
    "title": "seaborn cheatsheet",
    "section": "Additional Plot Types",
    "text": "Additional Plot Types\n\nCategorical Plot Types\n# Plots of each observation - stripplot\nsns.stripplot(data=df, y=\"DRG Definition\",\nx=\"Average Covered Charges\",\njitter=True)\n\n# Plots of each observation - swarmplot\nsns.swarmplot(data=df, y=\"DRG Definition\",\nx=\"Average Covered Charges\")\n\n# Abstract representations - boxplot\nsns.boxplot(data=df, y=\"DRG Definition\",\nx=\"Average Covered Charges\")\n\n# Abstract representation - violinplot\nsns.violinplot(data=df, y=\"DRG Definition\",\nx=\"Average Covered Charges\")\n\n# Abstract representation - lvplot\nsns.lvplot(data=df, y=\"DRG Definition\",\nx=\"Average Covered Charges\")\n\n# Statistical estimates - barplot\nsns.barplot(data=df, y=\"DRG Definition\",\nx=\"Average Covered Charges\",\nhue=\"Region\")\n\n# Statistical estimates - pointplot\nsns.pointplot(data=df, y=\"DRG Definition\",\nx=\"Average Covered Charges\",\nhue=\"Region\")\n\n# Statistical estimates - countplot\nsns.countplot(data=df, y=\"DRG_Code\", hue=\"Region\")\n\n\nRegression Plots\n# Plotting with regplot()\nsns.regplot(data=df, x='temp',\ny='total_rentals', marker='+')\n\n# Evaluating regression with residplot()\nsns.residplot(data=df, x='temp', y='total_rentals')\n\n# Polynomial regression\nsns.regplot(data=df, x='temp',\ny='total_rentals', order=2)\n\n# residplot with polynomial regression\nsns.residplot(data=df, x='temp',\ny='total_rentals', order=2)\n\n# Categorical values\nsns.regplot(data=df, x='mnth', y='total_rentals',\nx_jitter=.1, order=2)\n\n# Estimators\nsns.regplot(data=df, x='mnth', y='total_rentals',\nx_estimator=np.mean, order=2)\n\n# Binning the data\nsns.regplot(data=df,x='temp',y='total_rentals',\nx_bins=4)\n\n\nMatrix plots\n\n# Getting data in the right format\npd.crosstab(df[\"mnth\"], df[\"weekday\"],\nvalues=df[\"total_rentals\"],aggfunc='mean').round(0)\n\n# Build a heatmap\nsns.heatmap(pd.crosstab(df[\"mnth\"], df[\"weekday\"],\nvalues=df[\"total_rentals\"], aggfunc='mean')\n)\n\n# Customize a heatmap\nsns.heatmap(df_crosstab, annot=True, fmt=\"d\",\ncmap=\"YlGnBu\", cbar=False, linewidths=.5)\n\n# Centering a heatmap\nsns.heatmap(df_crosstab, annot=True, fmt=\"d\",\ncmap=\"YlGnBu\", cbar=True,\ncenter=df_crosstab.loc[9, 6])\n\n# Plotting a correlation matrix\nsns.heatmap(df.corr())"
  },
  {
    "objectID": "posts/2021-01-19-seaborn-cheatsheet.html#creating-plots-on-data-aware-grids",
    "href": "posts/2021-01-19-seaborn-cheatsheet.html#creating-plots-on-data-aware-grids",
    "title": "seaborn cheatsheet",
    "section": "Creating Plots on Data Aware Grids",
    "text": "Creating Plots on Data Aware Grids\n\nUsing FacetGrid, factorplot and lmplot\n# FacetGrid Categorical Example\ng = sns.FacetGrid(df, col=\"HIGHDEG\")\ng.map(sns.boxplot, 'Tuition',\norder=['1', '2', '3', '4'])\n\n# factorplot()\nsns.factorplot(x=\"Tuition\", data=df,\ncol=\"HIGHDEG\", kind='box')\n\n# FacetGrid for regression\n# FacetGrid() can also be used for sca er or regression plots\ng = sns.FacetGrid(df, col=\"HIGHDEG\")\ng.map(plt.scatter, 'Tuition', 'SAT_AVG_ALL')\n\n\n# lmplot\n# lmplot plots sca er and regression plots on a FacetGrid\nsns.lmplot(data=df, x=\"Tuition\", y=\"SAT_AVG_ALL\",\ncol=\"HIGHDEG\", fit_reg=False)\n\n# lmplot with regression\nsns.lmplot(data=df, x=\"Tuition\", y=\"SAT_AVG_ALL\",\ncol=\"HIGHDEG\", row='REGION')\n\n\nUsing PairGrid and pairplot\n# Creating a PairGrid\ng = sns.PairGrid(df, vars=[\"Fair_Mrkt_Rent\", \"Median_Income\"])\ng = g.map(plt.scatter)\n\n# Customizing the PairGrid diagonals\ng = sns.PairGrid(df, vars=[\"Fair_Mrkt_Rent\", \"Median_Income\"])\ng = g.map_diag(plt.hist)\ng = g.map_offdiag(plt.scatter)\n\n# Pairplot\nsns.pairplot(df, vars=[\"Fair_Mrkt_Rent\", \"Median_Income\"], kind='reg', diag_kind='hist')\n\n# Customizing a pairplot\nsns.pairplot(df.query('BEDRMS &lt; 3'),vars=[\"Fair_Mrkt_Rent\",\"Median_Income\", \"UTILITY\"],hue='BEDRMS', palette='husl', plot_kws={'alpha': 0.5})\n\n\nUsing JointGrid and jointplot\n# Basic JointGrid\ng = sns.JointGrid(data=df, x=\"Tuition\",y=\"ADM_RATE_ALL\")\ng.plot(sns.regplot, sns.distplot)\n\n# Advanced JointGrid\ng = sns.JointGrid(data=df, x=\"Tuition\",y=\"ADM_RATE_ALL\")\ng = g.plot_joint(sns.kdeplot)\ng = g.plot_marginals(sns.kdeplot, shade=True)\ng = g.annotate(stats.pearsonr)\n\n# jointplot()\nsns.jointplot(data=df, x=\"Tuition\",y=\"ADM_RATE_ALL\", kind='hex')\n\n# Customizing a jointplot\ng = (sns.jointplot(x=\"Tuition\",\n                   y=\"ADM_RATE_ALL\", kind='scatter',\n                   xlim=(0, 25000),\n                   marginal_kws=dict(bins=15,rug=True),\n                   data=df.query('UG &lt; 2500 & Ownership == \"Public\"'))\n     .plot_joint(sns.kdeplot))"
  },
  {
    "objectID": "posts/2022-07-26-install ubuntu 18.04 on WSL.html",
    "href": "posts/2022-07-26-install ubuntu 18.04 on WSL.html",
    "title": "install ubuntu 18.04 on WSL and then evalai",
    "section": "",
    "text": "install ubuntu 22.04 on WSL\ninstall evalai in ubuntu"
  },
  {
    "objectID": "posts/2022-07-26-install ubuntu 18.04 on WSL.html#source-of-inspiration",
    "href": "posts/2022-07-26-install ubuntu 18.04 on WSL.html#source-of-inspiration",
    "title": "install ubuntu 18.04 on WSL and then evalai",
    "section": "",
    "text": "install ubuntu 22.04 on WSL\ninstall evalai in ubuntu"
  },
  {
    "objectID": "posts/2022-07-26-install ubuntu 18.04 on WSL.html#installation-ubuntu-18.04",
    "href": "posts/2022-07-26-install ubuntu 18.04 on WSL.html#installation-ubuntu-18.04",
    "title": "install ubuntu 18.04 on WSL and then evalai",
    "section": "Installation ubuntu-18.04",
    "text": "Installation ubuntu-18.04\n\nuninstall image (if needed)\n# wsl --unregister &lt;distroName&gt;\nwsl --unregister ubuntu-18.04\n\n\ndownload images\nFrom cloud images ubuntu (cloud-images &gt; bionic&gt; current), now there are wsl images:\n\n\n\nubuntu cloud images\n\n\nI just have to download the last bionic (18.04) image bionic-server-cloudimg-amd64-wsl.rootfs.tar.gz\n\n\ninstall and setup from powershell\nI have downloaded this ubuntu image to D:\\wsl\\ubuntu-18.04\\download\n(base) guillaume@LL11LPC0PQARQ:/mnt/d/wsl$ tree\n.\n├── Ubuntu-20.04\n│   └── ext4.vhdx\n├── Ubuntu-22.04\n│   ├── download\n│   │   └── jammy-server-cloudimg-amd64-wsl.rootfs.tar.gz\n│   └── instance\nand my ubuntu-18.04 instance will stand in D:\\wsl\\ubuntu-18.04\\instance\nInstall with this command from powershell\n# wsl --import &lt;distroname&gt; &lt;location of instance&gt; &lt;location of download&gt;\nwsl --import ubuntu-18.04 D:\\wsl\\ubuntu-18.04\\instance D:\\wsl\\ubuntu-18.04\\download\\bionic-server-cloudimg-amd64-wsl.rootfs.tar.gz\nIt takes 3-4 minutes to install. and should be visible in your wsl instances.\n wsl --list --all -v\n  NAME            STATE           VERSION\n  ubuntu-22.04    Stopped         2\nthen to run it\n# wsl -d &lt;distroname&gt;\nwsl -d ubuntu-18.04\nor\n\nuse Windows Terminal as a launcher\nWindows Terminal is a smart way to group all terminals (powershell, and all your wsl instances)\n\n\n\nwindows terminal\n\n\nIt can be installed even with limited windows store access by clicking install in Installer le Terminal Windows et commencer à le configurer\nAutomatically all wsl instances appear in Settings."
  },
  {
    "objectID": "posts/2022-07-26-install ubuntu 18.04 on WSL.html#automatic-setup",
    "href": "posts/2022-07-26-install ubuntu 18.04 on WSL.html#automatic-setup",
    "title": "install ubuntu 18.04 on WSL and then evalai",
    "section": "Automatic setup",
    "text": "Automatic setup\ncopy these 2 scripts in /root/ (given they are in D:\\wsl\\ubuntu-18.04\\download)\ncp /mnt/d/wsl/Ubuntu-18.04/download/setup_wsl_* .\nsetup_wsl_root.sh download\n#!/bin/bash\n\necho \"0. get username: \"\nread user_name\n\n. /etc/lsb-release\n\necho Configuration for user [$user_name]\necho of distribution $DISTRIB_CODENAME\necho\n\necho \"1. create user and add in sudo\"\n#adduser --disabled-password --gecos \"\" $user_name\nadduser --gecos \"\" $user_name\nusermod -aG sudo $user_name\necho\n\necho \"2. create wsl.conf file\"\nrm -rf /etc/wsl.conf\ntee /etc/wsl.conf &lt;&lt; EOF\n# Set the user when launching a distribution with WSL.\n[user]\ndefault=$user_name\nEOF\necho\n\necho \"3. prepare setup by user\"\ncp setup_wsl_user.sh /home/$user_name\nchown $user_name:users /home/$user_name/setup_wsl_user.sh\nchmod 750  /home/$user_name/setup_wsl_user.sh\ntee -a /home/$user_name/.bashrc &lt;&lt; EOF\nif [ ! -e \".wsl_configured\" ]; then\n        ./setup_wsl_user.sh\n        touch .wsl_configured\nfi\nEOF\necho\n\necho \"end of configuration for root\"\necho \"stop wsl instance by running 'wsl -t &lt;distro-name&gt;' from powershell\"\necho \"and start from Windows Terminal\"\nsetup_wsl_user.sh download\n#!/bin/bash\n\necho \"1. setup wsl-vpnkit\"\nif grep -Fxq \"wsl-vpnkit\" ~/.profile\nthen\n    # code if found\n    echo \"   wsl-vpnkit already setup\"\nelse\n    # code if not found\n    echo 'wsl.exe -d wsl-vpnkit service wsl-vpnkit start' &gt;&gt; ~/.profile\nfi\nwsl.exe -d wsl-vpnkit service wsl-vpnkit start\nsource ./.bashrc\necho\n\necho \"2. create ssh key to copy to gitlab\"\n. /etc/lsb-release\nif [ ! -e \".ssh/id_rsa.pub\" ]; then\n        ssh-keygen -t rsa -b 4096 -C \"WSL2 ubuntu $DISTRIB_RELEASE\"\n        cat .ssh/id_rsa.pub\n        echo \"copy this content to gitlab &gt; preferences &gt; SSH Keys\"\n        read -p \"Press any key to resume ...\"\nfi\necho\n\necho \"3. update certificates\"\ngit clone git@gitlab.michelin.com:devops-foundation/devops_environment.git /tmp/devops_environment\nsudo cp /tmp/devops_environment/certs/* /usr/local/share/ca-certificates/\nsudo update-ca-certificates\nrm -rf /tmp/devops_environment\nif [ $DISTRIB_RELEASE == \"22.04\" ]\nthen\necho 'bug SSL with ubuntu 22.04 - https://bugs.launchpad.net/ubuntu/+source/openssl/+bug/1963834/comments/7'\nsudo tee -a /etc/ssl/openssl.cnf &lt;&lt; EOF\n[openssl_init]\nssl_conf = ssl_sect\n\n[ssl_sect]\nsystem_default = system_default_sect\n\n[system_default_sect]\nOptions = UnsafeLegacyRenegotiation\nEOF\nfi\necho\n\necho \"4. update apt sources with artifactory\"\necho 'Acquire { http::User-Agent \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:13.37) Gecko/20100101 Firefox/31.33.7\"; };' | sudo tee /etc/apt/apt.conf.d/90globalprotectconf\nsudo sed -i 's,http://archive.ubuntu.com/ubuntu,https://artifactory.michelin.com/artifactory/ubuntu-archive-remote,g' /etc/apt/sources.list\nsudo sed -i 's,http://security.ubuntu.com/ubuntu,https://artifactory.michelin.com/artifactory/ubuntu-archive-remote,g' /etc/apt/sources.list\nsudo apt update\nsudo apt upgrade -y\necho\nThen\nchmod +x setup_wsl_root.sh\n./setup_wsl_root.sh\nAs explained stop wsl instance by running wsl --shutdown ubuntu-22.04 from powershell and start from Windows Terminal\nIt restarts from your user and it will install:\n\nsetup wsl-vpnkit\ncreate ssh key to copy to gitlab\nupdate certificates\nupdate apt sources with artifactory"
  },
  {
    "objectID": "posts/2022-07-26-install ubuntu 18.04 on WSL.html#installation-evalai",
    "href": "posts/2022-07-26-install ubuntu 18.04 on WSL.html#installation-evalai",
    "title": "install ubuntu 18.04 on WSL and then evalai",
    "section": "Installation EvalAI",
    "text": "Installation EvalAI\n\nStep 1: Install prerequisites\n\nInstall git - postgres\n\nsudo apt-get install git postgresql libpq-dev\n\ninstall rabbit-mq\n\nsudo apt-get -y install socat logrotate init-system-helpers adduser erlang-base \n# download the package\nwget https://github.com/rabbitmq/rabbitmq-server/releases/download/v3.10.6/rabbitmq-server_3.10.6-1_all.deb\n\n# install the package with dpkg\nsudo dpkg -i rabbitmq-server_3.10.6-1_all.deb\nrm rabbitmq-server_3.10.6-1_all.deb\n\ninstall python 3.7\n\nsudo apt install python3.7\nsudo update-alternatives --install /usr/bin/python python /usr/bin/python3.7 1\nsudo update-alternatives --install /usr/bin/python python /usr/bin/python3.6 2\nupdate-alternatives --list python\nsudo update-alternatives --config python\n\ninstall virtualenv\n\n# only if pip is not installed\nsudo apt-get install python3-pip build-essential\n# upgrade pip\npip3 install --upgrade pip\n# upgrade virtualenv\npip --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org install --upgrade virtualenv\nsource .profile\n\n\nStep 2: Get EvalAI code\ngit clone https://github.com/Cloud-CV/EvalAI.git evalai\n\n\nStep 3: Setup codebase\n\nCreate a python virtual environment and install python dependencies.\n\n#pour curl-config\nsudo apt install libcurl4-openssl-dev libssl-dev\n\ncd evalai\nvirtualenv -p python3.7 venv\nsource venv/bin/activate\n\npip --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org install -r requirements/dev.txt\n# issue on django-autofixture \n# https://github.com/gregmuellegger/django-autofixture/issues/117\n\ncannot go further due to this error. at some time in setuptools, dist.py has been introduced long_description ends-with, and it is not managed by ‘UltraMagicString’ in django-autofixture\n\n\nRename settings/dev.sample.py as dev.py\n\ncp settings/dev.sample.py settings/dev.py\n\nCreate an empty postgres database and run database migration.\n\ncreatedb evalai -U postgres\n# update postgres user password\npsql -U postgres -c \"ALTER USER postgres PASSWORD 'postgres';\"\n# run migrations\npython manage.py migrate\n\nFor setting up frontend, please make sure that node(&gt;=7.x.x), npm(&gt;=5.x.x) and bower(&gt;=1.8.x) are installed globally on your machine. Install npm and bower dependencies by running\n\nnpm install\nbower install"
  },
  {
    "objectID": "posts/2022-07-29-evalai and gitlab.html",
    "href": "posts/2022-07-29-evalai and gitlab.html",
    "title": "EvalAI and gitlab",
    "section": "",
    "text": "Deploy evalai docker images by copying from another PC\nHost challenge using github"
  },
  {
    "objectID": "posts/2022-07-29-evalai and gitlab.html#source-of-inspiration",
    "href": "posts/2022-07-29-evalai and gitlab.html#source-of-inspiration",
    "title": "EvalAI and gitlab",
    "section": "",
    "text": "Deploy evalai docker images by copying from another PC\nHost challenge using github"
  },
  {
    "objectID": "posts/2022-07-29-evalai and gitlab.html#run-docker-from-wsl",
    "href": "posts/2022-07-29-evalai and gitlab.html#run-docker-from-wsl",
    "title": "EvalAI and gitlab",
    "section": "Run docker from wsl",
    "text": "Run docker from wsl\ncd ~/evalai\ndocker-compose up\nIn case of errors:\n\nERROR: for nodejs UnixHTTPConnectionPool(host='localhost', port=None): Read timed out. Restart docker service and rerun evalai: sudo service docker restart"
  },
  {
    "objectID": "posts/2020-10-19-test-inner-images_in-jupyter.html",
    "href": "posts/2020-10-19-test-inner-images_in-jupyter.html",
    "title": "Validation of jupyter inner images with fastpages",
    "section": "",
    "text": "When this page will appear it will mean this feature has been implemented!\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2020-09-08-becoming-datascientist.html",
    "href": "posts/2020-09-08-becoming-datascientist.html",
    "title": "Becoming a datascientist",
    "section": "",
    "text": "This journey has started about 1 year ago.\nNo wait, that was dormant for a long time before that. I guess I have to go back to my studying time: at that time my days were full of maths and computers. And my days were flying as crazy. It happens to me (to you?) when you’re just in a middle of something you like very much. 10 hours looks like 1. And the opposite is true as well.\n\n\nMost of my days and weekends at that time were dedicated to code in Java and bash. Java mainly for server-side developpement in J2EE at Unilog Management. Bash from time to time to automate some tasks on my personal PC. At that time it was mainly about learning what is an operating system. I had started with LFS (Linux From Scratch). And in 2002 with Gentoo which was a much more powerful way to mimic LFS.\n\n\n\nStrange period. I don’t remember exactly why but I had a shift in my professional orientation. I moved away from software development and turned into a project manager. In 2005 I entered into Michelin company. And sofwtare technical matters at that time were considered as unimportant (and embarrassing subjects) Fortunately in 2009 I have been started my agile journey. A lot to learn, and it was less about software than human relations and empathy. It was like a start from scratch.\n\n\n\nQuite a new world for me. I had some basic knowledge by following Jono Bacon. At that time he was a community manager|release leader at Ubuntu. And was reporting progress using burndown charts. In 2009 I launched a project to create an employee portal (closed to what netvibes and igoogle were at that time). Using standard java portal technologies and more importantly using agile approach. A lot to learn about Agile, Scrum, and endless discussions about how to introduce Agile into a non-Agile organization. In 2010 I started another more ambitious project, with many colleagues (~30 persons) and a vague vision. It was about to create a product lifecycle management solution for semi-finished products.\n\n\n\nIn 2015, I met lean approaches for office. I was immediately convinced there was powerful and deep roots within lean. And it could bring a lot to people and organizations. I turned into a lean coach, to work with teams identifying what they could improve, how they could work better, with more pleasure.\n\n\n\nNice opportunity at that time to move from Clermont-Ferrand (France) to Greenville, South Carolina (USA). I have loved every part of it. Except maybe that 2 years were too short to make a full tour of this amazing country. It is crazy to think how different we are when we look like the same.\n\n\n\nSept 2019 - back to France and for 4 months to prepare for a complete new position: datascientist for Manufacturing within Michelin. I spent many days to learn from various sources specially datacamp and Andrew Ng. That was just the beginning. My intent was to move away from project management, team leadership and focus about what I can do by myself. I wanted to return to math domains without giving up an IT landscape. My colleague Francois Deheeger told me about data science and Artificial Intelligence. That looked as interesting as terrifying. I was in. I was not afraid to learn a new language, and to restart my career from scratch."
  },
  {
    "objectID": "posts/2020-09-08-becoming-datascientist.html#march-2019",
    "href": "posts/2020-09-08-becoming-datascientist.html#march-2019",
    "title": "Becoming a datascientist",
    "section": "",
    "text": "This journey has started about 1 year ago.\nNo wait, that was dormant for a long time before that. I guess I have to go back to my studying time: at that time my days were full of maths and computers. And my days were flying as crazy. It happens to me (to you?) when you’re just in a middle of something you like very much. 10 hours looks like 1. And the opposite is true as well.\n\n\nMost of my days and weekends at that time were dedicated to code in Java and bash. Java mainly for server-side developpement in J2EE at Unilog Management. Bash from time to time to automate some tasks on my personal PC. At that time it was mainly about learning what is an operating system. I had started with LFS (Linux From Scratch). And in 2002 with Gentoo which was a much more powerful way to mimic LFS.\n\n\n\nStrange period. I don’t remember exactly why but I had a shift in my professional orientation. I moved away from software development and turned into a project manager. In 2005 I entered into Michelin company. And sofwtare technical matters at that time were considered as unimportant (and embarrassing subjects) Fortunately in 2009 I have been started my agile journey. A lot to learn, and it was less about software than human relations and empathy. It was like a start from scratch.\n\n\n\nQuite a new world for me. I had some basic knowledge by following Jono Bacon. At that time he was a community manager|release leader at Ubuntu. And was reporting progress using burndown charts. In 2009 I launched a project to create an employee portal (closed to what netvibes and igoogle were at that time). Using standard java portal technologies and more importantly using agile approach. A lot to learn about Agile, Scrum, and endless discussions about how to introduce Agile into a non-Agile organization. In 2010 I started another more ambitious project, with many colleagues (~30 persons) and a vague vision. It was about to create a product lifecycle management solution for semi-finished products.\n\n\n\nIn 2015, I met lean approaches for office. I was immediately convinced there was powerful and deep roots within lean. And it could bring a lot to people and organizations. I turned into a lean coach, to work with teams identifying what they could improve, how they could work better, with more pleasure.\n\n\n\nNice opportunity at that time to move from Clermont-Ferrand (France) to Greenville, South Carolina (USA). I have loved every part of it. Except maybe that 2 years were too short to make a full tour of this amazing country. It is crazy to think how different we are when we look like the same.\n\n\n\nSept 2019 - back to France and for 4 months to prepare for a complete new position: datascientist for Manufacturing within Michelin. I spent many days to learn from various sources specially datacamp and Andrew Ng. That was just the beginning. My intent was to move away from project management, team leadership and focus about what I can do by myself. I wanted to return to math domains without giving up an IT landscape. My colleague Francois Deheeger told me about data science and Artificial Intelligence. That looked as interesting as terrifying. I was in. I was not afraid to learn a new language, and to restart my career from scratch."
  },
  {
    "objectID": "posts/2023-01-12-fastai-stable-diffusion.html",
    "href": "posts/2023-01-12-fastai-stable-diffusion.html",
    "title": "Deep Learning Foundations to Stable Diffusion",
    "section": "",
    "text": "A good entry point is here in fastai forum: Lesson 9 (part 2) preview\nThis is not yet part 2 but will be a good playground waiting for it."
  },
  {
    "objectID": "posts/2023-01-12-fastai-stable-diffusion.html#under-wsl",
    "href": "posts/2023-01-12-fastai-stable-diffusion.html#under-wsl",
    "title": "Deep Learning Foundations to Stable Diffusion",
    "section": "under WSL",
    "text": "under WSL\nI start from this fastai_hf environnement\n\n!cat /home/guillaume/_conda_env/fastai_hf.txt\n\nconda remove --name fastai_hf --all\nconda create --name fastai_hf --clone fastai\nconda activate fastai_hf\npip install -Uq diffusers transformers fastcore\nmamba install ipykernel\npython -m ipykernel install --user --name=fastai_hf\nmamba install matplotlib\nmamba install -c conda-forge ipywidgets\n\n\n#il faut ajouter les certificats Michelin à certifi\n#pour cela lancer ~/bin/certifi.sh\n#depuis l'environnement fastai_hf\n#et verifier que ça marche en lancant python certify_validation.py\n\n\nwhich is a clone of fastai environement\n\n!cat /home/guillaume/_conda_env/fastai.txt\n\nmamba create -n fastai python=3.9\nconda activate fastai\nmamba install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\nmamba install -c fastchan fastai nbdev \n\n\nFor a reason, it fails directly when running pipe = StableDiffusionPipeline.from_pretrained(\"CompVis/stable-diffusion-v1-4\", revision=\"fp16\", torch_dtype=torch.float16).to(\"cuda\")\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2023-01-12-fastai-stable-diffusion.html#under-linux",
    "href": "posts/2023-01-12-fastai-stable-diffusion.html#under-linux",
    "title": "Deep Learning Foundations to Stable Diffusion",
    "section": "under linux",
    "text": "under linux\nAs a workaround, I can execute from my full linux box.\nBut because it has less GPU memory (8 GB), I need to run pipe.enable_attention_slicing()\nIf your GPU is not big enough to use pipe, run pipe.enable_attention_slicing()\nAs described in the docs:\n&gt; When this option is enabled, the attention module will split the input tensor in slices, to compute attention in several steps. This is useful to save some memory in exchange for a small speed decrease.\n\npipe.enable_attention_slicing()\n\nand now it works quite well\n\n\n\nimage.png\n\n\nBut I don’t remember exactly how my fastai environment has been installed. Because I see a reference to fastchan, I guess it was something like conda install -c fastchan fastai\n\n!mamba list|grep torch\n\npytorch                   1.12.1          py3.8_cuda10.2_cudnn7.6.5_0    fastchan\npytorch-mutex             1.0                        cuda    fastchan\ntorchvision               0.13.1               py38_cu102    fastchan"
  },
  {
    "objectID": "posts/2023-01-12-fastai-stable-diffusion.html#different-features",
    "href": "posts/2023-01-12-fastai-stable-diffusion.html#different-features",
    "title": "Deep Learning Foundations to Stable Diffusion",
    "section": "different features",
    "text": "different features\n\nprompt\nDirect prompt and prompt with style are quite well known\n\n\n\nimage.png\n\n\n\n\nnegative prompt\nBut I didn’t know about negative prompt\n\n\n\nimage.png\n\n\nHere all reference to blue have been removded. Quite neat\n\n\nsketch - image to image\nAnd with another model image to image,\nyou can give an initial image, and this image is then noised and used as a starting point such as in\n\n\n\nimage.png\n\n\nAnd then we can iterate by picking one of these 3 images and use it as an init image\ninit_image2 = images[2]\nprompt = \"Oil painting of wolf howling at the moon by Van Gogh\"\nimages = pipe(prompt=prompt, num_images_per_prompt=3, init_image=init_image2, strength=1, num_inference_steps=70).images\nimage_grid(images, rows=1, cols=3)\n\n\nadd your own tokens\n\nTextual inversion is a process where you can quickly “teach” a new word to the text model and plain its embeddings close to some visual representation. This is achieved by adding a new token to the vocabulary, freezing the weights of all the models (except the text encoder), and train with a few representative images.\nThis is a schematic representation of the process by the authors of the paper.\n\n\n\nor retrain existing ones\n\nFor example, we fine-tuned a model with a prompt like \"photo of a sks person\", using the rare sks token to qualify the term person, and using photos of Jeremy as the targets. Let’s see how it works.\n\nWe don’t have the detail about how to retrain it though. This is what is used in Dreambooth."
  },
  {
    "objectID": "posts/2023-01-12-fastai-stable-diffusion.html#the-autoencoder",
    "href": "posts/2023-01-12-fastai-stable-diffusion.html#the-autoencoder",
    "title": "Deep Learning Foundations to Stable Diffusion",
    "section": "the autoencoder",
    "text": "the autoencoder\nThis is quite impressive that vae can compress/decompress with such a factor (/48) and keep this level of quality\n\n\n\nimage.png\n\n\nI have to watch this video again to propose a fair understanding of it"
  },
  {
    "objectID": "posts/2023-01-12-fastai-stable-diffusion.html#forward-diffusion",
    "href": "posts/2023-01-12-fastai-stable-diffusion.html#forward-diffusion",
    "title": "Deep Learning Foundations to Stable Diffusion",
    "section": "forward diffusion",
    "text": "forward diffusion\nSo the forward diffusion will follow this process\n\n\n\nimage.png\n\n\nThis is a Markow Process with Gaussians transitions\nby Process we can understand a sequence (t) is involved\nby Markov, the things at time t \\(X^{t}\\) depends only on the thing at time t-1 \\(X^{t-1}\\)\nby transitions it is following the \\(q\\) function \\(q(X^{(t)}|X^{(t-1)})\\)\nby Gaussian, this function is the normal distribution \\(\\mathcal{N}(X^{(t)}; X^{(t-1)}\\sqrt{I-\\beta_t}; I\\beta_t)\\)\nAnd by process we mean that we apply baby steps, a high number of times. Maybe 1000 times."
  },
  {
    "objectID": "posts/2023-01-12-fastai-stable-diffusion.html#backward-diffusion",
    "href": "posts/2023-01-12-fastai-stable-diffusion.html#backward-diffusion",
    "title": "Deep Learning Foundations to Stable Diffusion",
    "section": "backward diffusion",
    "text": "backward diffusion\nWe can now think about the backward diffusion process, by going backward with exactly the same logic.\n\\(p(X^{(t-1)}|X^{(t)}) = \\mathcal{N}(X^{(t-1)}; \\Box ; \\Delta )\\)\nwhere p is the here the conditionnal probability to get clearer and clearer, and \\(\\Box\\) is the mean, \\(\\Delta\\) is the variance. Those are unknown but can be fit.\nWe can fit this model by maximizing the likelihood function. Practically we prefer to use log likelihood. (we like its properties to turn products to sums, and by taking exponential such as in normal distribution we get identity which is quite convenient) And more recent works showed that we can use one particular loss to dot it which is ELBO (evidence lower bound, evidence is another name for likelihood). elbo being easily calculated, one can use it as a loss function. You can now train a NN to get \\(\\Box\\) and \\(\\Delta\\).\nTo match distributions between the forward process and the backward process, we will use special function KL divergence. KL divergence of gaussians can be calculated analytically so it eases the process.\nIn 2020, a paper introduced a new model DDPM (Denoising Diffusion Probabilistic model). Main idea is to simplify diffusion processes by considering only mean. Variance is set as a constant. In that case we can just use mse(noise) as a loss.\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-09-23-inline-images-with-quarto.html",
    "href": "posts/2022-09-23-inline-images-with-quarto.html",
    "title": "inline images from jupyter with quarto",
    "section": "",
    "text": "using jupyter lab\nHere is the 1st image inline\n\n\n\nimage.png\n\n\nand here the second one\n\n\n\nimage.png\n\n\nif we see a the same image, we have a problem\n\n\nusing jupyter notebook\n1st image\n\n\n\nimage.png\n\n\n2nd image\n\n\n\nimage.png\n\n\nif we see a the same image, we have a problem\n\n\nanalysis\nwhen using jupyter lab, cell code for images are like that\n![image.png](attachment:71a4fc95-5776-4180-ae3a-b815bbf1b7a0.png)\nand with jupyter notebook or vscode, it is like that\n![image.png](attachment:image.png)\nThere is an enhancement request at vscode to support it\nhttps://github.com/microsoft/vscode/issues/151408\nand quarto when creating _site, is saving these images in this structure:\n\n!tree ../_site/posts/2022-09-23-inline-images-with-quarto_files/\n\n../_site/posts/2022-09-23-inline-images-with-quarto_files/\n└── figure-html\n    ├── 71a4fc95-5776-4180-ae3a-b815bbf1b7a0.png\n    ├── 74e0d8d8-ad0f-4eca-b52b-167ac518d0e9.png\n    └── image.png\n\n1 directory, 3 files\n\n\nonly one image.png for 2 files, that cannot work :(\n\n\nworkaround\nuse jupyter lab to blog"
  },
  {
    "objectID": "posts/2022-05-03-save git https credentials under wsl.html",
    "href": "posts/2022-05-03-save git https credentials under wsl.html",
    "title": "save git https credentials under wsl",
    "section": "",
    "text": "Microsoft has released a tool to securely keep https credentials:\ngit-credential-manager\nUsefull when one has to use https instead of git(ssl) to connect to git repos. My case when I am behing my corporate firewall and has to link to github repos (such as this blog)"
  },
  {
    "objectID": "posts/2022-05-03-save git https credentials under wsl.html#source-of-inspiration",
    "href": "posts/2022-05-03-save git https credentials under wsl.html#source-of-inspiration",
    "title": "save git https credentials under wsl",
    "section": "",
    "text": "Microsoft has released a tool to securely keep https credentials:\ngit-credential-manager\nUsefull when one has to use https instead of git(ssl) to connect to git repos. My case when I am behing my corporate firewall and has to link to github repos (such as this blog)"
  },
  {
    "objectID": "posts/2022-05-03-save git https credentials under wsl.html#how-to-setup-it",
    "href": "posts/2022-05-03-save git https credentials under wsl.html#how-to-setup-it",
    "title": "save git https credentials under wsl",
    "section": "How to setup it",
    "text": "How to setup it\n\ncreate token in github\nI have to create a token at Settings &gt; Developer Settings &gt; Personal Access Tokens\n\n\ninstallation of git-credential-manager inside WSL\nDownload the latest (v2.0.696 at May/3rd 2022) .deb package, and run the following:\nsudo dpkg -i &lt;path-to-package&gt;\ngit-credential-manager-core configure\ngit config --global credential.credentialStore gpg\nexport GPG_TTY=$(tty)\ngpg --full-generate-key\nsudo apt install -y pass\nkey_id=`gpg --list-keys | awk -F: '/^ / { print $0 }' | cut -d\" \" -f7`\npass init $key_id\nor see the step 06 in install ubuntu 22.04 on WSL"
  },
  {
    "objectID": "posts/2021-07-07-deep-neural-network-coursera.html",
    "href": "posts/2021-07-07-deep-neural-network-coursera.html",
    "title": "Deep Neural Network with PyTorch - Coursera",
    "section": "",
    "text": "Coursera website: Deep Neural Networks with PyTorch\nCourse certificate\n\nWeek 1 - Tensor and Datasets\n\nLearning Objectives\n\nTensors 1D\nTwo-Dimensional Tensors\nData Set\nDifferentiation in PyTorch\n\n\n\nnotebook\nnotebook\n\n\nTensors 1D\n\nThe basics\n#initialize\nimport torch\na=torch.tensor([7,4,3,2,6])\n\n#dtype, type()\na.dtype\na.type()\n\n#convert with type\na=a.type(torch.FloatTensor)\n\n#size, ndimension\na.size()\na.ndimension()\n\n#convert to 2D\na_2D=a.view(-1, 1)\n\n#from_numpy, to numpy\nimport numpy as np\nnumpy_array = np.array([0.0, 1.0, 2.0, 3.0, 4.0])\ntorch_tensor = torch.from_numpy(numpy_array)\nback_to_numpy = torch_tensor.numpy()\n\n#from pandas\nimport pandas as pd\npandas_series = pd.Series([0.1, 2, 0.3, 10.1])\npandas_to_torch = torch.from_numpy(pandas_series.values)\n\n#to list\nthis_tensor = torch.tensor([0, 1, 2, 3])\ntorch_to_list = this_tensor.tolist()\n\n#item\nnew_tensor = torch.tensor([5, 2, 6, 1])\nnew_tensor[0].item()\n\n#indexing and slicing\nc[3:5]=torch.tensor([300.0, 4.0])\n\n\nbasic operations\n#hadamard product\nz = u*v\n\n#dot product, (produit scalaire)\nresult = torch.dot(u, v)\n\n\nuniversal functions, mean, max, mathematical functions, plot with linspace\n#mean\na.mean()\n\n#max\nb.max()\n\n#plot y=sin(x)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nx = torch.linspace(0, 2 * np.pi, 100)\ny = torch.sin(x)\nplt.plot(x.numpy(), y.numpy())\n\n\nUngraded lab\n1.1_1Dtensors_v2.ipynb\n\n\n\nTensors 2D\nnotebook\n\nTensor creation in 2D\na = [ [11, 12, 13], [21, 22, 23], [31, 32, 33] ]\nA = torch.tensor(a)\n\nA.ndimension()\n&gt;&gt; 2\n\nA.shape\n&gt;&gt; torch.Size([3, 3])\n\nA.size()\n&gt;&gt; torch.Size([3, 3])\n\n#number of elements\nA.numel()\n&gt;&gt; 9\n\n\nIndexing and slicing in 2D\nA[0, 0:2]\n&gt;&gt; tensor([11, 12])\n\nA[1:3, 2]\n&gt;&gt; tensor([23, 33])\n\n\nBasic operations in 2D: hadamard product, matrix multiplication\nX = torch.tensor([[1,0], [0,1]])\nY = torch.tensor([[2,1], [1,2]])\n\n#hadamard product\nZ = X*Y\nZ\n&gt;&gt; tensor([[2, 0],\n           [0, 2]])\n\nA = torch.tensor([ [0, 1, 1], [1, 0, 1]])\nB = torch.tensor([ [1, 1], [1, 1], [-1, 1]])\n\n#matrix multiplication\nC = torch.mm(A, B)\nC\n&gt;&gt; tensor([[0, 2],\n           [0, 2]])\n\n\nUngraded lab\n1.1_2 Two-Dimensional Tensors_v2.ipynb\n\n\n\nDerivatives in Pytorch\n\nDerivatives\nusing \\(y(x)=x^2\\)\nx = torch.tensor(2., requires_grad=True)\ny = x ** 2\n\n#calculate derivative df/dx\ny.backward()\n#evaluate at x : df/dx(x)\nx.grad\n&gt;&gt; tensor(4.)\nusing \\(z(x)=x^2+2x+1\\)\nx = torch.tensor(2., requires_grad=True)\nz = x**2 + 2*x + 1\nz.backward()\nx.grad\n&gt;&gt; tensor(6.)\nNote: in my version of pytorch (1.7.1), I cannot use torch.int dtypes.\n---------------------------------------------------------------------------\nRuntimeError                              Traceback (most recent call last)\n&lt;ipython-input-92-979d0f10c1e7&gt; in &lt;module&gt;\n----&gt; 3 x = torch.tensor(2, requires_grad=True)\n      4 z = x**2 + 2*x + 1\n      5 z.backward()\nRuntimeError: Only Tensors of floating point and complex dtype can require gradients\n\n\nPartial derivatives\nusing \\(f(u, v)=uv+u^2\\), \\(\\frac{\\partial f(u,v)}{\\partial u} = v+2u\\), \\(\\frac{\\partial f(u,v)}{\\partial v} = u\\)\nu = torch.tensor(1., requires_grad=True)\nv = torch.tensor(2., requires_grad=True)\n\nf = u*v + u**2\n\n#calculate all partial derivatives df/du and df/dv\nf.backward()\n#evaluate partial derivative with respect to u df/du at u, v : df/du(u, v)\nu.grad\n&gt;&gt; tensor(4.)\n#evaluate partial derivative with respect to v df/dv at u, v : df/dv(u, v)\nv.grad\n&gt;&gt; tensor(1.)\n\n\nUngraded lab\n1.2derivativesandGraphsinPytorch_v2.ipynb\nWith some explanation about .detach() pointing to torch.autograd documentation. In this page, there is a link to walkthrough of backprop video.\nWill have to go back to .detach()\n\n\n\nSimple Dataset\n\nBuild a Dataset Class and Object\nfrom torch.utils.data import Dataset\n\nclass toy_set(Dataset):\n    def __init__(self, length=100, transform=None):\n        self.x = 2*torch.ones(length, 2)\n        self.y = torch.ones(length, 1)\n        self.len = length\n        self.transform = transform\n    def __getitem__(self, index):\n        sample=self.x[index], self.y[index]\n        if self.transform:\n            sample = self.transform(sample)\n        return sample\n    def __len__(self):\n        return self.len\n    \ndataset = toy_set()\nlen(dataset)\n&gt;&gt; 100\ndataset[0]\n(tensor([2., 2.]), tensor([1.]))\n\n\nBuild a Dataset Transform (e.g. normalize or standardize)\nclass add_mult(object):\n    def __init__(self, addx=1, muly=1):\n        self.addx = addx\n        self.muly = muly\n    def __call__(self, sample):\n        x=sample[0]\n        y=sample[1]\n        x=x+self.addx\n        y=y*self.muly\n        sample=x, y\n        return sample\n    \n    \n# automatically apply the transform\na_m = add_mult()\ndataset_ = toy_set(transform=a_m)\ndataset_[0]\n&gt;&gt; (tensor([3., 3.]), tensor([1.]))\n\n\nCompose Transforms\nclass mult(object):\n    def __init__(self, mul=100):\n        self.mul = mul\n\n    def __call__(self, sample):\n        x = sample[0]\n        y = sample[1]\n        x = x * self.mul\n        y = y * self.mul\n        sample = x, y\n        return sample\n    \nfrom torchvision import transforms\ndata_transform = transforms.Compose([add_mult(), mult()])\n\n# automatically apply the composed transform\ndataset_tr = toy_set(transform=data_transform)\ndataset_tr[0]\n&gt;&gt; (tensor([300., 300.]), tensor([100.]))\n\n\nUngraded lab\n1.3.1_simple_data_set_v2.ipynb\n\n\n\nDataset\n\nDataset Class for Images\nfrom PIL import Image\nimport pandas as pd\nimport os\nfrom matplotlib.pyplot import imshow\nfrom torch.utils.data import Dataset, DataLoader\nclass Dataset(Dataset):\n    def __init__(self, csv_file, data_dir, transform=None):\n        self.transform = transform\n        self.data_dir = data_dir\n        data_dir_csv_file = os.path.join(self.data_dir, csv_file)\n        self.data_name = pd.read_csv(data_dir_csv_file)\n        self.len = self.data_name.shape[0]\n    def __len__(self):\n        return self.len\n    def __getitem__(self, idx):\n        img_name=os.path.join(self.data_dir, self.data_name.iloc[idx, 1])\n        image = Image.open(img_name)\n        y = self.data_name.iloc[idx, 0]\n        if self.transform:\n            image = self.transform(image)\n        return image, y\n    \ndef show_data(data_sample, shape = (28, 28)):\n    plt.imshow(data_sample[0].numpy().reshape(shape), cmap='gray')\n    plt.title('y = ' + data_sample[1])\ndataset = Dataset(csv_file=csv_file, data_dir=directory)\nshow_data(dataset[0])\n\n\nTorch Vision Transforms\nimport torchvision.transforms as transforms\ntransforms.CenterCrop(20)\ntransforms.ToTensor()\ncroptensor_data_transform = transforms.Compose( [ transforms.CenterCrop(20), transforms.ToTensor() ] )\ndataset = Dataset(csv_file=csv_file, data_dir=directory, transform=croptensor_data_transform)\ndataset[0][0].shape\n&gt;&gt; torch.Size([1, 20, 20])\n\n\nTorch Vision Datasets\nMNIST example\nimport torchvision.datasets as dsets\ndataset = dsets.MNIST(root='./data', train = False, download = True, transform = transforms.ToTensor())\n\n\nUngraded lab\n1.3.2_Datasets_and_transforms.ipynb\n1.3.3_pre-Built Datasets_and_transforms_v2.ipynb\n\n\n\n\nWeek 2 - Linear Regression\n\nLearning Objectives\n\nLinear Regression Prediction\nLinear Regression Training\nLoss\nGradient Descent\nCost\nLinear Regression Training PyTorch\n\n\n\nnotebook\nnotebook\n\n\nLinear Regression in 1D - Prediction\n\nSimple linear regression - prediction\nimport torch\nw = torch.tensor(2.0, requires_grad=True)\nb = torch.tensor(-1.0, requires_grad=True)\ndef forward(x):\n    y=w*x+b\n    return y\nx=torch.tensor([1.0])\nyhat=forward(x)\nyhat\n&gt;&gt; tensor([1.], grad_fn=&lt;AddBackward0&gt;)\nx=torch.tensor([[1.0],[2.0]])\nforward(x)  \n&gt;&gt; tensor([[1.],\n        [3.]], grad_fn=&lt;AddBackward0&gt;)\n\n\nPyTorch - Class Linear\nfrom torch.nn import Linear\ntorch.manual_seed(1)\nmodel = Linear(in_features=1, out_features=1)\nlist(model.parameters())\n&gt;&gt; [Parameter containing:\n     tensor([[0.5153]], requires_grad=True),\n     Parameter containing:\n     tensor([-0.4414], requires_grad=True)]\nx=torch.tensor([[1.0],[2.0]])\nmodel(x)\n&gt;&gt; tensor([[0.0739],\n        [0.5891]], grad_fn=&lt;AddmmBackward&gt;)\n\n\nPyTorch - Custom Modules\nimport torch.nn as nn\n\nclass LR(nn.Module):\n    def __init__(self, in_size, output_size):\n        super(LR, self).__init__()\n        self.linear = nn.Linear(in_size, output_size)\n    def forward(self, x):\n        out = self.linear(x)\n        return out\nmodel = LR(1, 1)\nlist(model.parameters())\n&gt;&gt; [Parameter containing:\n     tensor([[-0.9414]], requires_grad=True),\n     Parameter containing:\n     tensor([0.5997], requires_grad=True)]\nx=torch.tensor([[1.0],[2.0]])\nmodel(x)\n&gt;&gt; tensor([[-0.3417],\n        [-1.2832]], grad_fn=&lt;AddmmBackward&gt;)\nModel state_dict()\nthis returns a python dictionary. We will use it as our models get more complex. One Function is to map the relationship of the linear layers to its parameters. we can print out the keys and values.\nmodel.state_dict()\n&gt;&gt; OrderedDict([('linear.weight', tensor([[-0.9414]])),\n             ('linear.bias', tensor([0.5997]))])\n\n\nUngraded lab\n2.1Prediction1Dregression_v3.ipynb\n\n\n\nLinear Regression Training\nloss function presented is mean squared error\n\\(l(w,b)=\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}(y_n-(wx_n+b))^2\\)\n\n\nGradient Descent and cost\n\n\nPyTorch Slope\nimport torch\nw=torch.tensor(-10.0, requires_grad=True)\nX=torch.arange(-3,3,0.1).view(-1, 1)\nf = -3*X\nimport matplotlib.pyplot as plt\nplt.plot(X.numpy(), f.numpy())\nplt.show()\nY = f+0.1*torch.randn(X.size())\nplt.plot(X.numpy(), Y.numpy(), 'ro')\nplt.show()\ndef forward(x):\n    return w*x\n\ndef criterion(yhat, y):\n    return torch.mean((yhat-y)**2)\nlr = 0.1\nfor epoch in range(4):\n    Yhat = forward(X)\n    loss= criterion(Yhat, Y)\n    loss.backward()\n    w.data = w.data - lr*w.grad.data\n    w.grad.data.zero_()\n\nUngraded lab\n2.2_linear_regression_one_parameter_v3.ipynb\n\n\n\nLinear Regression Training in PyTorch\n\nCost surface\n# The class for plot the diagram\n\nclass plot_error_surfaces(object):\n    \n    # Constructor\n    def __init__(self, w_range, b_range, X, Y, n_samples = 30, go = True):\n        W = np.linspace(-w_range, w_range, n_samples)\n        B = np.linspace(-b_range, b_range, n_samples)\n        w, b = np.meshgrid(W, B)    \n        Z = np.zeros((30,30))\n        count1 = 0\n        self.y = Y.numpy()\n        self.x = X.numpy()\n        for w1, b1 in zip(w, b):\n            count2 = 0\n            for w2, b2 in zip(w1, b1):\n                Z[count1, count2] = np.mean((self.y - w2 * self.x + b2) ** 2)\n                count2 += 1\n            count1 += 1\n        self.Z = Z\n        self.w = w\n        self.b = b\n        self.W = []\n        self.B = []\n        self.LOSS = []\n        self.n = 0\n        if go == True:\n            plt.figure()\n            plt.figure(figsize = (7.5, 5))\n            plt.axes(projection='3d').plot_surface(self.w, self.b, self.Z, rstride = 1, cstride = 1,cmap = 'viridis', edgecolor = 'none')\n            plt.title('Cost/Total Loss Surface')\n            plt.xlabel('w')\n            plt.ylabel('b')\n            plt.show()\n            plt.figure()\n            plt.title('Cost/Total Loss Surface Contour')\n            plt.xlabel('w')\n            plt.ylabel('b')\n            plt.contour(self.w, self.b, self.Z)\n            plt.show()\n    \n    # Setter\n    def set_para_loss(self, W, B, loss):\n        self.n = self.n + 1\n        self.W.append(W)\n        self.B.append(B)\n        self.LOSS.append(loss)\n    \n    # Plot diagram\n    def final_plot(self): \n        ax = plt.axes(projection = '3d')\n        ax.plot_wireframe(self.w, self.b, self.Z)\n        ax.scatter(self.W,self.B, self.LOSS, c = 'r', marker = 'x', s = 200, alpha = 1)\n        plt.figure()\n        plt.contour(self.w,self.b, self.Z)\n        plt.scatter(self.W, self.B, c = 'r', marker = 'x')\n        plt.xlabel('w')\n        plt.ylabel('b')\n        plt.show()\n    \n    # Plot diagram\n    def plot_ps(self):\n        plt.subplot(121)\n        plt.ylim\n        plt.plot(self.x, self.y, 'ro', label=\"training points\")\n        plt.plot(self.x, self.W[-1] * self.x + self.B[-1], label = \"estimated line\")\n        plt.xlabel('x')\n        plt.ylabel('y')\n        plt.ylim((-10, 15))\n        plt.title('Data Space Iteration: ' + str(self.n))\n\n        plt.subplot(122)\n        plt.contour(self.w, self.b, self.Z)\n        plt.scatter(self.W, self.B, c = 'r', marker = 'x')\n        plt.title('Total Loss Surface Contour Iteration' + str(self.n))\n        plt.xlabel('w')\n        plt.ylabel('b')\n        plt.show()\n        \nget_surface = plot_error_surfaces(15, 15, X, Y, 30)\n\n\n\nimg\n\n\n\n\n\nimg\n\n\n\n\nPyTorch (hard way)\ndef forward(x):\n    y=w*x+b\n    return y\ndef criterion(yhat, y):\n    return torch.mean((yhat-y)**2)\n\nw = torch.tensor(-15.0, requires_grad=True)\nb = torch.tensor(-10.0, requires_grad=True)\nX = torch.arange(-3, 3, 0.1).view(-1, 1)\nf = 1*X-1\nY = f+0.1*torch.rand(X.size())\nlr = 0.1\nfor epoch in range(15):\n    Yhat=forward(X)\n    loss=criterion(Yhat, Y)\n    loss.backward()\n    w.data=w.data-lr*w.grad.data\n    w.grad.data.zero_()\n    b.data=b.data-lr*b.grad.data\n    b.grad.data.zero_()\n\n\nUngraded lab\n2.3_training_slope_and_bias_v3.ipynb\n\n\n\nStochastic Gradient Descent and the Data Loader\n\nStochastic Gradient Descent in PyTorch\nw = torch.tensor(-15.0, requires_grad=True)\nb = torch.tensor(-10.0, requires_grad=True)\nX = torch.arange(-3, 3, 0.1).view(-1, 1)\nf = -3*X\nY=f+0.1*torch.randn(X.size())\n\ndef forward(x):\n    y=w*x+b\n    return y\ndef criterion(yhat, y):\n    return torch.mean((yhat-y)**2)\nlr = 0.1\nfor epoch in range(4):\n    for x, y in zip(X, Y):\n        yhat=forward(x)\n        loss=criterion(yhat, y)\n        loss.backward()\n        w.data=w.data-lr*w.grad.data\n        w.grad.data.zero_()\n        b.data=b.data-lr*b.grad.data\n        b.grad.data.zero_()\n\n\nStochastic Gradient Descent DataLoader\ndataset\nfrom torch.utils.data import Dataset\n\nclass Data(Dataset):\n    def __init__(self):\n        self.x = torch.arange(-3, 3, 0.1).view(-1, 1)\n        self.y = -3*X+1\n        self.len = self.x.shape[0]\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n    def __len__(self):\n        return self.len\n    \ndataset = Data()\ndataloader\nfrom torch.utils.data import DataLoader\n\ndataset=Data()\ntrainloader = DataLoader(dataset=dataset, batch_size=1)\nstochastic gradient descent\nfor x, y in trainloader:\n    yhat = forward(x)\n    loss = criterion(yhat, y)\n    loss.backward()\n    w.data=w.data-lr*w.grad.data\n    b.data=b.data-lr*b.grad.data\n    w.grad.data.zero_()\n    b.grad.data.zero_()\n\n\nUngraded lab\n3.1_stochastic_gradient_descent_v3.ipynb\n\n\n\nMini-Batch Gradient Descent\nIterations = \\(\\frac{\\text{training size}}{\\text{batch size}}\\)\n\nMini-Batch Gradient Descent in Pytorch\ndataset = Data()\ntrainloader = DataLoader(dataset=dataset, batch_size=5)\n\nlr=0.1\nLOSS = []\nfor epoch in range(4):\n    for x, y in trainloader:\n        yhat=forward(x)\n        loss = criterion(yhat, y)\n        loss.backward()\n        w.data=w.data-lr*w.grad.data\n        b.data=b.data-lr*b.grad.data\n        w.grad.data.zero_()\n        b.grad.data.zero_()      \n        LOSS.append(loss.item())\n\n\n\nOptimization in PyTorch\ncriterion = nn.MSELoss()\ntrainloader = DataLoader(dataset=dataset, batch_size=1)\nmodel = LR(1,1)\nfrom torch import nn, optim\noptimizer = optim.SGD(model.parameters(), lr = 0.01)\noptimizer.state_dict()\n&gt;&gt; {'state': {},\n 'param_groups': [{'lr': 0.01,\n   'momentum': 0,\n   'dampening': 0,\n   'weight_decay': 0,\n   'nesterov': False,\n   'params': [0, 1]}]}\nfor epoch in range(100):\n    for x, y in trainloader:\n        yhat = model(x)\n        loss = criterion(yhat, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n\n\nimage.png\n\n\n\nUngraded lab\n3.3_PyTorchway_v3.ipynb\n\n\n\nTraining, Validation and Test Split\nstandard explanation about Train, Validation, Test\n\nTraining, Validation and Test Split in PyTorch\nDataset to generate train_data and val_data\nfrom torch.utils.data import Dataset, DataLoader\n\nclass Data(Dataset):\n    def __init__(self, train = True):\n        self.x = torch.arange(-3, 3, 0.1).view(-1, 1)\n        self.f = -3*self.x+1\n        self.y = self.f+0.1*torch.randn(self.x.size())\n        self.len = self.x.shape[0]\n        if train == True:\n            self.y[0] = 0\n            self.y[50:55] = 20\n        else:\n            pass\n        \n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n    \n    def __len__(self):\n        return self.len\n                \n        \ntrain_data = Data()\nval_data = Data(train=False)\nLR model\nimport torch.nn as nn\n\nclass LR(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(LR, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n    def forward(self, x):\n        out=self.linear(x)\n        return out\ncriterion = nn.MSELoss()\n\ntrainloader = DataLoader(dataset=train_data, batch_size=1)\nepochs = 10\nlearning_rates = [0.0001, 0.001, 0.01, 0.1, 1]\nvalidation_error = torch.zeros(len(learning_rates))\ntest_error=torch.zeros(len(learning_rates))\nMODELS=[]\nfrom torch import optim\nfrom tqdm import tqdm\nfor i, learning_rate in tqdm(enumerate(learning_rates)):\n    model = LR(1,1)\n    optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n    \n    for epoch in range(epochs):\n        for x, y in trainloader:\n            yhat = model(x)\n            loss = criterion(yhat, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n    yhat=model(train_data.x)\n    loss=criterion(yhat, train_data.y)\n    test_error[i]=loss.item()\n\n    yhat=model(val_data.x)\n    loss=criterion(yhat, val_data.y)\n    validation_error[i]=loss.item()\n    MODELS.append(model)\nimport numpy as np\nplt.semilogx(np.array(learning_rates), validation_error.numpy(), label='training cost/total loss')\nplt.semilogx(np.array(learning_rates), test_error.numpy(), label='validation cost/total loss')\nplt.ylabel('Cost Total loss')\nplt.xlabel('learning rate')\nplt.legend()\nplt.show()\n\n\n\nimg\n\n\n\n\n\n\nWeek 3 - Multiple Input Output Linear Regression - Logistic Regression for Classification\n\nLearning Objectives\n\nMultiple Linear Regression\nMultiple Linear Regression Training\nLinear Regression Multiple Outputs\nLinear Regression Multiple Outputs Training\n\n\n\nnotebook\nnotebook\n\n\nMultiple Input Linear Regression Prediction\n\nClass Linear\nimport torch\nfrom torch.nn import Linear\ntorch.manual_seed(1)\nmodel = Linear(in_features=2, out_features=1)\nlist(model.parameters())\n&gt;&gt; [Parameter containing:\n tensor([[ 0.3643, -0.3121]], requires_grad=True),\n Parameter containing:\n tensor([-0.1371], requires_grad=True)]\nmodel.state_dict()\n&gt;&gt; OrderedDict([('weight', tensor([[ 0.3643, -0.3121]])),\n             ('bias', tensor([-0.1371]))])\n#predictions for multiple samples\nX = torch.tensor([[1.0, 1.0], [1.0, 2.0], [1.0, 3.0]])\nyhat = model(X)\nyhat\n&gt;&gt; tensor([[-0.0848],\n        [-0.3969],\n        [-0.7090]], grad_fn=&lt;AddmmBackward&gt;)\n\n\nCustom Modules\nimport torch.nn as nn\n\nclass LR(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(LR, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n    def forward(self, x):\n        out = self.linear(x)\n        return out\n\n\nUngraded lab\n4.1.multiple_linear_regression_prediction_v2.ipynb\n\n\n\nMultiple Input Linear Regression Training\n\nCost function and Gradient Descent for Multiple Linear Regression\nCost function\n\\[l(w,b)=\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}(y_n-(x_nw+b))^2\\]\nGradient of loss function with respect to the weights\n\\[\\nabla l(w,b) = \\begin{bmatrix}\\frac{\\partial l(w,b)}{\\partial w_1}\\\\ \\vdots \\\\\\frac{\\partial l(w,b)}{\\partial w_d}\\end{bmatrix}\\]\nGradient of loss function with respect to the bias\n\\[\\frac{\\partial l(w,b)}{\\partial b}\\]\nUpdate of weights\n\\[w^{k+1} = w^k-\\eta \\nabla l(w^k,b^k)\\]\n\\[\\begin{bmatrix} w_1^{k+1}\\\\ \\vdots\\\\ w_d^{k+1}\\\\\\end{bmatrix}=\\begin{bmatrix} w_1^{k}\\\\ \\vdots\\\\ w_d^{k}\\\\\\end{bmatrix}-\\eta \\begin{bmatrix}\\frac{\\partial l(w^k,b^k)}{\\partial w_1}\\\\ \\vdots \\\\\\frac{\\partial l(w^k,b^k)}{\\partial w_d}\\end{bmatrix}\\]\nand update of bias\n\\[b^{k+1}=b^k-\\eta \\frac{\\partial l(w^k,b^k)}{\\partial b}\\]\n\n\nTrain the model in PyTorch\nfrom torch import nn, optim\nimport torch\n\nclass LR(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(LR, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n    def forward(self, x):\n        out = self.linear(x)\n        return out\nfrom torch.utils.data import Dataset, DataLoader\n\nclass Data2D(Dataset):\n    def __init__(self):\n        self.x = torch.zeros(20,2)\n        self.x[:, 0] = torch.arange(-1,1,0.1)\n        self.x[:, 1] = torch.arange(-1,1,0.1)\n        self.w = torch.tensor([ [1.0], [1.0]])\n        self.b = 1\n        self.f = torch.mm(self.x, self.w)+self.b\n        self.y = self.f + 0.1*torch.randn((self.x.shape[0], 1))\n        self.len = self.x.shape[0]\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n    def __len__(self):\n        return self.len\ndata_set = Data2D()\ncriterion = nn.MSELoss()\ntrainloader = DataLoader(dataset=data_set, batch_size=2)\nmodel = LR(input_size=2, output_size=1)\noptimizer = optim.SGD(model.parameters(), lr=0.1)\nfor epoch in range(100):\n    for x, y in trainloader:\n        yhat = model(x)\n        loss = criterion(yhat, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()   \n\n\nUngraded lab\n4.2.multiple_linear_regression_training_v2.ipynb\n\n\n\nMultiple Output Linear Regression\n\nLinear regression with multiple outputs\n\n\n\nimage.png\n\n\n\n\nCustom Modules\nimport torch.nn as nn\nimport torch\nclass LR(nn.Module):\n    def __init__(self, input_size, output_size):\n        super(LR, self).__init__()\n        self.linear = nn.Linear(input_size, output_size)\n    def forward(self, x):\n        out = self.linear(x)\n        return out\n    \ntorch.manual_seed(1)\nmodel = LR(input_size=2, output_size=2)\n\nlist(model.parameters())\n&gt;&gt; [Parameter containing:\n tensor([[ 0.3643, -0.3121],\n         [-0.1371,  0.3319]], requires_grad=True),\n Parameter containing:\n tensor([-0.6657,  0.4241], requires_grad=True)]\n\n#with 2 columns and 3 rows\nX=torch.tensor([[1.0, 1.0], [1.0,2.0], [1.0, 3.0]])\nYhat = model(X)\nYhat\n&gt;&gt; tensor([[-0.6135,  0.6189],\n        [-0.9256,  0.9508],\n        [-1.2377,  1.2827]], grad_fn=&lt;AddmmBackward&gt;)\n\n\nUngraded lab\n4.3.multi-target_linear_regression.ipynb\n\n\n\nMultiple Output Linear Regression Training\n\nTraining in PyTorch\nTraining is the same, what changes is Dataset:\nfrom torch.utils.data import Dataset, DataLoader\n\nclass Data2D(Dataset):\n    def __init__(self):\n        self.x = torch.zeros(20,2)\n        self.x[:, 0] = torch.arange(-1,1,0.1)\n        self.x[:, 1] = torch.arange(-1,1,0.1)\n        self.w = torch.tensor([ [1.0, -1.0], [1.0, -1.0]])\n        self.b = torch.tensor([[1.0, -1.0]])\n        self.f = torch.mm(self.x, self.w)+self.b\n        self.y = self.f + 0.1*torch.randn((self.x.shape[0], 1))\n        self.len = self.x.shape[0]\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n    def __len__(self):\n        return self.len\nand model instantiation\nfrom torch import nn, optim\n\ndata_set = Data2D()\ncriterion = nn.MSELoss()\ntrainloader = DataLoader(dataset=data_set, batch_size=1)\nmodel = LR(input_size=2, output_size=2)\noptimizer = optim.SGD(model.parameters(), lr=0.001)\nTraining:\nfor epoch in range(100):\n    for x, y in trainloader:\n        yhat = model(x)\n        loss = criterion(yhat, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n\nUngraded lab\n4.4.training_multiple_output_linear_regression.ipynb\n\n\n\nLinear Classifier and Logistic Regression\n\\[\\sigma(z)=\\frac{1}{1+e^{-z}}\\]\nsigmoid is used as the threshold function in logistic regression\n\n\nLogistic Regression: Prediction\n\nlogistic function in PyTorch\nas a function: torch.sigmoid\nimport torch\nimport matplotlib.pyplot as plt\n\nz = torch.arange(-100, 100, 0.1).view(-1, 1)\nyhat = torch.sigmoid(z)\nplt.plot(z.numpy(), yhat.numpy())\n\n\n\nimg\n\n\nas a class: nn.Signmoid()\nimport torch\nimport torch.nn as nn\nimport matplotlib.pyplot as plt\n\nz = torch.arange(-100, 100, 0.1).view(-1, 1)\nsig = nn.Sigmoid()\nyhat = sig(z)\nplt.plot(z.numpy(), yhat.numpy())\ntorch.nn.Sigmoid vs torch.sigmoid - PyTorch Forums\n\ntorch.nn.Sigmoid (note the capital “S”) is a class. When you\ninstantiate it, you get a function object, that is, an object that you\ncan call like a function. In contrast, torch.sigmoid is a function.\n\n\n\nnn.Sequential\n\n\n\nimage.png\n\n\nsequential_model = nn.Sequential(nn.Linear(1,1), nn.Sigmoid())\n\n\nnn.Module\nimport torch.nn as nn\n\nclass logistic_regression(nn.Module):\n    def __init__(self, in_size):\n        super(logistic_regression, self).__init__()\n        self.linear = nn.Linear(in_size, 1)\n    def forward(self, x):\n        z = torch.sigmoid(self.linear(x))\n        return z\n    \ncustom_model = logistic_regression(1)\n\n\nMaking a prediction\nx=torch.tensor([[1.0], [2.0]])\ncustom_model(x)\n&gt;&gt; tensor([[0.4129],\n        [0.3936]], grad_fn=&lt;SigmoidBackward&gt;)\nsequential_model(x)\n&gt;&gt; tensor([[0.2848],\n        [0.2115]], grad_fn=&lt;SigmoidBackward&gt;)\n\n\nMultidimensional Logistic Regression\ncustom_2D_model = logistic_regression(2)\nsequential_2D_model = nn.Sequential(nn.Linear(2, 1), nn.Sigmoid())\n\nx=torch.tensor([[1.0, 2.0]])\nyhat = sequential_2D_model(x)\nyhat\n&gt;&gt; tensor([[0.7587]], grad_fn=&lt;SigmoidBackward&gt;)\n\n\nUngraded lab\n5.1logistic_regression_prediction_v2.ipynb\n\n\n\nBernoulli Distribution and Maximum Likelihood Estimation\nTo fine the parameter values of the Bernoulli distribution, we do not maximize the likelihood function but the log of the likelihood function: Loss likelihood which is given by\n\\[l(\\theta) = \\ln(p(Y|\\theta))=\\displaystyle\\sum_{n=1}^{N}y_n \\ln(\\theta)+(1-y_n) \\ln(1-\\theta)\\]\nNote: We want to get\n\\[\\hat\\theta = argmax_\\theta(P(Y|\\theta))\\]\nwhere\n\\[P(Y|\\theta) = \\displaystyle\\prod_{n=1}^{N}\\theta^{y_n}(1-\\theta)^{1-y_n}\\]\n\n\nLogistic Regression Cross Entropy Loss\nLoss function \\(l(w,b)=\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}(y_n-\\sigma(wx_n+b))^2\\)\n\nCross entropy loss\n\\[l(\\theta)=-\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}y_n \\ln(\\sigma(wx_n+b))+(1-y_n)\\ln(1-\\sigma(wx_n+b))\\]\ndef criterion(yhat, y):\n    out = -1 * torch.mean(y * torch.log(yhat) + (1-y) * torch.log(1-yhat))\n    return out\n\n\nLogistic Regression in PyTorch\nCreate a model (using Sequential)\nmodel = nn.Sequential(nn.Linear(1, 1), nn.Sigmoid())\nor create a custom one\nimport torch.nn as nn\n\nclass logistic_regression(nn.Module):\n    def __init__(self, in_size):\n        super(logistic_regression, self).__init__()\n        self.linear = nn.Linear(in_size, 1)\n    def forward(self, x):\n        z = torch.sigmoid(self.linear(x))\n        return z\nThen define our loss function\ndef criterion(yhat, y):\n    out = -1 * torch.mean(y * torch.log(yhat) + (1-y) * torch.log(1-yhat))\n    return out\nor simply BCE (binary cross entropy)\ncriterion = nn.BCELoss()\nPutting all pieces together:\n#dataset\n\nimport torch\nfrom torch.utils.data import Dataset\n\nclass Data(Dataset):\n    def __init__(self):\n        self.x = torch.arange(-1, 1, 0.1).view(-1, 1)\n        self.y = torch.zeros(self.x.shape[0], 1)\n        self.y[self.x[:, 0] &gt; 0.2] = 1\n        self.len = self.x.shape[0]\n    def __getitem__(self, index):      \n        return self.x[index], self.y[index]\n    def __len__(self):\n        return self.len\n    \ndataset = Data()\n\n# dataloader\n\nfrom torch.utils.data import DataLoader\ntrainloader = DataLoader(dataset=dataset, batch_size=1)\n\n# model\n\nimport torch.nn as nn\nmodel = nn.Sequential(nn.Linear(1, 1), nn.Sigmoid())\n\n# optimizer\n\nfrom torch import optim\noptimizer = optim.SGD(model.parameters(), lr = 0.01)\n\n# loss\n\ncriterion = nn.BCELoss()\n\n# training\n\nfor epoch in range(100):\n    for x, y in trainloader:\n        yhat = model(x)\n        loss = criterion(yhat, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n\nUngraded lab\n5.2.2bad_inshilization_logistic_regression_with_mean_square_error_v2.ipynb\n\n\n\n\nWeek 4 - Softmax regression\n\nLearning Objectives\n\nUsing Lines to Classify Data\nSoftmax Prediction \u000bin PyTorch\nSoftmax Pytorch MNIST\n\n\n\nnotebook\nnotebook\n\n\nSoftmax Prediction\nSoftmax is a combination of logistic regression and argmax\n\n\n\nimage.png\n\n\n\n\nSoftmax function\n\nCustom module using nn.module\nimport torch.nn as nn\n\nclass Softmax(nn.Module):\n    def __init__(self, in_size, out_size):\n        super(Softmax, self).__init__()\n        self.linear = nn.Linear(in_size, out_size)\n    def forward(self, x):\n        out = self.linear(x)\n        return out\nimport torch\ntorch.manual_seed(1)\n# 2 dimensions input samples and 3 output classes\nmodel = Softmax(2,3)\n\nx = torch.tensor([[1.0, 2.0]])\nz = model(x)\nz\n&gt;&gt; tensor([[-0.4053,  0.8864,  0.2807]], grad_fn=&lt;AddmmBackward&gt;)\n\n_, yhat = z.max(1)\nyhat\n&gt;&gt; tensor([1])\nand with multiple samples\nX=torch.tensor([[1.0, 1.0],[1.0, 2.0],[1.0, -3.0]])\nz = model(X)\nz\n&gt;&gt; tensor([[-0.0932,  0.5545, -0.1433],\n        [-0.4053,  0.8864,  0.2807],\n        [ 1.1552, -0.7730, -1.8396]], grad_fn=&lt;AddmmBackward&gt;)\n\n_, yhat = z.max(1)\nyhat\n&gt;&gt; tensor([1, 1, 0])\n\n\n\nSoftmax PyTorch\n\nLoad Data\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nimport torchvision.datasets as dsets\n\ntrain_dataset = dsets.MNIST(root='./data', train = True, download = True, transform=transforms.ToTensor())\n\nvalidation_dataset = dsets.MNIST(root='./data', train = False, download = True, transform=transforms.ToTensor())\ntrain_dataset[0] is a tuple with the image and the class:\n\n\nCreate Model\nimport torch.nn as nn\n\nclass Softmax(nn.Module):\n    def __init__(self, in_size, out_size):\n        super(Softmax, self).__init__()\n        self.linear = nn.Linear(in_size, out_size)\n    def forward(self, x):\n        out = self.linear(x)\n        return out\n    \ninput_dim = 28 * 28\noutput_dim = 10\nmodel = Softmax(input_dim, output_dim)\ncriterion = nn.CrossEntropyLoss()\n\nimport torch.optim as optim\noptimizer = optim.SGD(model.parameters(), lr=0.01)\n\nn_epochs = 100\naccuracy_list = []\n\ntrain_loader = torch.utils.data.DataLoader(dataset = train_dataset, batch_size = 100)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=5000)\n\n\nTrain Model\nfrom tqdm import tqdm\n\nfor epoch in tqdm(range(n_epochs)):\n    for x, y in train_loader:\n        optimizer.zero_grad()\n        z = model(x.view(-1, 28 * 28))\n        loss = criterion(z, y)\n        loss.backward()\n        optimizer.step()\n    correct = 0\n    for x_test, y_test in validation_loader:\n        z = model(x_test.view(-1, 28 * 28))\n        _, yhat = torch.max(z.data, 1)\n        correct = correct+(yhat == y_test).sum().item()\n    accuracy = correct / y.shape[0]\n    accuracy_list.append(accuracy)\n\n\nUngraded lab\n5.4softmax_in_one_dimension_v2.ipynb\n\n\nUngraded lab\n6.2lab_predicting _MNIST_using_Softmax_v2.ipynb\n# The function to plot parameters\n\ndef PlotParameters(model): \n    W = model.state_dict()['linear.weight'].data\n    w_min = W.min().item()\n    w_max = W.max().item()\n    fig, axes = plt.subplots(2, 5)\n    fig.subplots_adjust(hspace=0.01, wspace=0.1)\n    for i, ax in enumerate(axes.flat):\n        if i &lt; 10:\n            \n            # Set the label for the sub-plot.\n            ax.set_xlabel(\"class: {0}\".format(i))\n\n            # Plot the image.\n            ax.imshow(W[i, :].view(28, 28), vmin=w_min, vmax=w_max, cmap='seismic')\n\n            ax.set_xticks([])\n            ax.set_yticks([])\n\n        # Ensure the plot is shown correctly with multiple plots\n        # in a single Notebook cell.\n    plt.show()\n    \n# Plot the parameters\n\nPlotParameters(model)\n\n\n\nimg\n\n\n\n\n\n\nWeek 4 - Shallow neural networks\n\nLearning Objectives\n\nSimple Neural Networks\nMore Hidden Neurons\nNeural Networks with Multiple Dimensional\nMulti-Class Neural Networks\nBackpropagation\nActivation Functions\n\n\n\nnotebook\nnotebook\n\n\nNeural networks in One Dimension\n\nusing nn.Module\nimport torch\nimport torch.nn as nn\nfrom torch import sigmoid\n\nclass Net(nn.Module):\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n    def forward(self, x):\n        x=sigmoid(self.linear1(x))\n        x=sigmoid(self.linear2(x))\n        return x\nmodel = Net(1, 2, 1)\nx = torch.tensor([0.0])\nyhat = model(x)\nyhat\n&gt;&gt; tensor([0.5972], grad_fn=&lt;SigmoidBackward&gt;)\n\n# multiple samples\nx = torch.tensor([[0.0], [2.0], [3.0]])\nyhat = model(x)\nyhat\n&gt;&gt; tensor([[0.5972],\n        [0.5925],\n        [0.5894]], grad_fn=&lt;SigmoidBackward&gt;)\n\n# to get a discrete value we apply a threshold\nyhat = yhat &lt; 0.59\nyhat\n&gt;&gt; tensor([[False],\n           [False],\n           [ True]])\nmodel.state_dict()\n&gt;&gt; OrderedDict([('linear1.weight',\n              tensor([[0.3820],\n                      [0.4019]])),\n             ('linear1.bias', tensor([-0.7746, -0.3389])),\n             ('linear2.weight', tensor([[-0.3466,  0.2201]])),\n             ('linear2.bias', tensor([0.4115]))])\n\n\nusing nn.Sequential\nmodel = nn.Sequential(nn.Linear(1, 2), nn.Sigmoid(), nn.Linear(2, 1), nn.Sigmoid())\n\n\ntrain the model\nwe create the data\nX = torch.arange(-20, 20, 1).view(-1, 1).type(torch.FloatTensor)\nY = torch.zeros(X.shape[0])\nY[(X[:, 0]&gt;-4) & (X[:, 0] &lt;4)] = 1.0\nwe create a training function\nfrom tqdm import tqdm\n\ndef train(Y, X, model, optimizer, criterion, epochs=1000):\n    cost = []\n    total = 0\n    for epoch in tqdm(range(epochs)):\n        total = 0\n        for x, y in zip(X, Y):\n            yhat = model(x)\n            loss = criterion(yhat, y.view(-1))\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            total+=loss.item()\n        cost.append(total)\n    return cost\nand the training process is now\n#loss\ncriterion = nn.BCELoss()\n\n#data\nX = torch.arange(-20, 20, 1).view(-1, 1).type(torch.FloatTensor)\nY = torch.zeros(X.shape[0])\nY[(X[:, 0]&gt;-4) & (X[:, 0] &lt;4)] = 1.0\n\n#model\nmodel = Net(1, 2, 1)\n\n#optimizer\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\n\n#train the model\ncost = train(Y, X, model, optimizer, criterion, epochs=1000)\n&gt;&gt; 100%|██████████| 1000/1000 [00:12&lt;00:00, 76.96it/s]\n\n\nUngraded lab\n7.1_simple1hiddenlayer.ipynb\nI like how to display intermediate representations of learning performance:\n\n\n\nimg\n\n\n# The function for plotting the model\n\ndef PlotStuff(X, Y, model, epoch, leg=True):\n    \n    plt.plot(X.numpy(), model(X).detach().numpy(), label=('epoch ' + str(epoch)))\n    plt.plot(X.numpy(), Y.numpy(), 'r')\n    plt.xlabel('x')\n    if leg == True:\n        plt.legend()\n    else:\n        pass\nactivation values (called in the training loop). Using model variables (model.a1) which seems a bad practice.\n\n\n\nimg\n\n\nplt.scatter(model.a1.detach().numpy()[:, 0], model.a1.detach().numpy()[:, 1], c=Y.numpy().reshape(-1))\nplt.title('activations')\nplt.show()\nand final loss curve\n\n\n\nimg\n\n\n\n\n\nNeural Networks More Hidden Neurons\n\nusing nn.Module\nimport torch\nimport torch.nn as nn\nfrom torch import sigmoid\nfrom torch.utils.data import Dataset, DataLoader\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nclass to get our dataset\nclass Data(Dataset):\n    def __init__(self):\n        self.x = torch.linspace(-20, 20, 100).view(-1, 1)\n        self.y = torch.zeros(self.x.shape[0])\n        self.y[(self.x[:, 0]&gt;-10) & (self.x[:, 0]&lt;-5)] = 1\n        self.y[(self.x[:, 0]&gt;5) & (self.x[:, 0]&lt;10)] = 1\n        self.y = self.y.view(-1, 1)\n        self.len = self.x.shape[0]\n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n    def __len__(self):\n        return self.len\nclass for creating our model\nclass Net(nn.Module):\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n    def forward(self, x):\n        x=sigmoid(self.linear1(x))\n        x=sigmoid(self.linear2(x))\n        return x\nand the function to train our model\n# The function for plotting the model\ndef PlotStuff(X, Y, model):  \n    plt.plot(X.numpy(), model(X).detach().numpy())\n    plt.plot(X.numpy(), Y.numpy(), 'r')\n    plt.xlabel('x')\n    \ndef train(data_set, model, criterion, train_loader, optimizer, epochs=5):\n    cost = []\n    total=0\n    for epoch in tqdm(range(epochs)):\n        total=0\n        for x, y in train_loader:\n            optimizer.zero_grad()\n            yhat = model(x)\n            loss = criterion(yhat, y)\n            loss.backward()\n            optimizer.step()\n            total+=loss.item() \n            PlotStuff(data_set.x, data_set.y, model)\n        cost.append(total)\n    return cost\nprocess for training is identical to logistic regression\ncriterion = nn.BCELoss()\ndata_set = Data()\ntrain_loader = DataLoader(dataset=data_set, batch_size=100)\nmodel = Net(1, 6, 1)\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\ntrain(data_set, model, criterion, train_loader, optimizer, epochs=1000)\n\n\nusing nn.Sequential\nmodel = nn.Sequential(\n    nn.Linear(1, 7),\n    nn.Sigmoid(),\n    nn.Linear(7, 1),\n    nn.Sigmoid()\n)\n\n\nUngraded lab\n7.2multiple_neurons.ipynb\n\n\n\nNeural Networks with Multiple Dimensional Input\n\nimplementation\nimport torch\nimport torch.nn as nn\nfrom torch import sigmoid\nfrom torch.utils.data import Dataset, DataLoader\nfrom tqdm import tqdm\nimport numpy as np\nwe create a dataset class\nclass XOR_Data(Dataset):\n    def __init__(self, N_s=100):\n        self.x = torch.zeros((N_s, 2))\n        self.y = torch.zeros((N_s, 1))\n        for i in range(N_s // 4):\n            self.x[i, :] = torch.Tensor([0.0, 0.0])\n            self.y[i, 0] = torch.Tensor([0.0])\n            self.x[i + N_s // 4, :] = torch.Tensor([0.0, 1.0])\n            self.y[i + N_s // 4, 0] = torch.Tensor([1.0])\n            self.x[i + N_s // 2, :] = torch.Tensor([1.0, 0.0])\n            self.y[i + N_s // 2, 0] = torch.Tensor([1.0])\n            self.x[i + 3 * N_s // 4, :] = torch.Tensor([1.0, 1.0])\n            self.y[i + 3 * N_s // 4, 0] = torch.Tensor([0.0])\n            self.x = self.x + 0.01 * torch.randn((N_s, 2))\n        self.len = N_s\n            \n    def __getitem__(self, index):\n        return self.x[index], self.y[index]\n    def __len__(self):\n        return self.len      \n    # Plot the data\n    def plot_stuff(self):\n        plt.plot(self.x[self.y[:, 0] == 0, 0].numpy(), self.x[self.y[:, 0] == 0, 1].numpy(), 'o', label=\"y=0\")\n        plt.plot(self.x[self.y[:, 0] == 1, 0].numpy(), self.x[self.y[:, 0] == 1, 1].numpy(), 'ro', label=\"y=1\")\n        plt.legend()\n\n\n\nimg\n\n\nWe create a class for creating our model\nclass Net(nn.Module):\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n    def forward(self, x):\n        x=sigmoid(self.linear1(x))\n        x=sigmoid(self.linear2(x))\n        return x\nWe create a function to train our model\n# Calculate the accuracy\n\ndef accuracy(model, data_set):\n    return np.mean(data_set.y.view(-1).numpy() == (model(data_set.x)[:, 0] &gt; 0.5).numpy())\n\ndef train(data_set, model, criterion, train_loader, optimizer, epochs=5):\n    COST = []\n    ACC = []\n    for epoch in tqdm(range(epochs)):\n        total=0\n        for x, y in train_loader:\n            optimizer.zero_grad()\n            yhat = model(x)\n            loss = criterion(yhat, y)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            #cumulative loss \n            total+=loss.item()\n        ACC.append(accuracy(model, data_set))\n        COST.append(total)\n        \n    return COST\nprocess for training is identical to logistic regression\ncriterion = nn.BCELoss()\ndata_set = XOR_Data()\ntrain_loader = DataLoader(dataset=data_set, batch_size=1)\nmodel = Net(2, 4, 1)\noptimizer = torch.optim.SGD(model.parameters(), lr = 0.01)\ntrain(data_set, model, criterion, train_loader, optimizer, epochs=500)\n\n\noverfitting and underfitting\nSolution:\n\nuse validation data to determine optimum number of neurons\nget more data\nregularization: for example dropout\n\n\n\nUngraded lab\n7.3xor_v2.ipynb\n\n\n\nMulti-Class Neural Networks\n\nusing nn.Module\nwe don’t have sigmoid for the output, and D_out is our number of classes\nclass Net(nn.Module):\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n    def forward(self, x):\n        x=sigmoid(self.linear1(x))\n        x=(self.linear2(x))\n        return x\n\n\nusing nn.Sequential\ninput_dim = 2\nhidden_dim = 6\noutput_dim = 3\nmodel = nn.Sequential(\n    nn.Linear(input_dim, hidden_dim),\n    nn.Sigmoid(),\n    nn.Linear(hidden_dim, output_dim)\n)\n\n\ntraining\nwe create a validation and training dataset\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\ntrain_dataset = dsets.MNIST(root='./data', train = True, download = True, transform=transforms.ToTensor())\nvalidation_dataset = dsets.MNIST(root='./data', train = False, download = True, transform=transforms.ToTensor())\nwe create a validation and training loader\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=2000)\ncriterion = nn.CrossEntropyLoss()\nwe create the training function\nfrom tqdm import tqdm\ndef train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n    i = 0\n    useful_stuff = {'training_loss': [],'validation_accuracy': []}  \n    for epoch in tqdm(range(epochs)):\n        for i, (x, y) in enumerate(train_loader): \n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n             #loss for every iteration\n            useful_stuff['training_loss'].append(loss.data.item())\n        correct = 0\n        for x, y in validation_loader:\n            #validation \n            z = model(x.view(-1, 28 * 28))\n            _, label = torch.max(z, 1)\n            correct += (label == y).sum().item()\n        accuracy = 100 * (correct / len(validation_dataset))\n        useful_stuff['validation_accuracy'].append(accuracy)\n    return useful_stuff\nWe instantiate and train the model\ninput_dim = 28 * 28\nhidden_dim = 100\noutput_dim = 10\n\nmodel = Net(input_dim, hidden_dim, output_dim)\ntraining_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=30)\nTo plot accuracy and lost\n# Define a function to plot accuracy and loss\n\ndef plot_accuracy_loss(training_results): \n    plt.subplot(2, 1, 1)\n    plt.plot(training_results['training_loss'], 'r')\n    plt.ylabel('loss')\n    plt.title('training loss iterations')\n    plt.subplot(2, 1, 2)\n    plt.plot(training_results['validation_accuracy'])\n    plt.ylabel('accuracy')\n    plt.xlabel('epochs')   \n    plt.show()\n    \nplot_accuracy_loss(training_results)\n\n\n\nimg\n\n\nTo plot improper classified items\ncount = 0\nfor x, y in validation_dataset:\n    z = model(x.reshape(-1, 28 * 28))\n    _,yhat = torch.max(z, 1)\n    if yhat != y:\n        show_data(x)\n        count += 1\n    if count &gt;= 5:\n        break\n\n\n\nimg\n\n\n\n\nUngraded lab\n7.4one_layer_neural_network_MNIST.ipynb\n\n\n\nBackpropagation\nFollowing the chain rule in gradient calculation, it happens that gradient results are getting closer and closer to 0. (i.e. vanishing gradient) therefore we cannot improve model parameters.\nOne way to deal with that is to change activation function.\n\n\nActivation functions\n\nsigmoid, tanh, relu\n\n\n\nimg\n\n\n\n\nsigmoid, tanh, relu in PyTorch\nclass Net_sigmoid(nn.Module):\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n    def forward(self, x):\n        x=sigmoid(self.linear1(x))\n        x=(self.linear2(x))\n        return x\nclass Net_tanh(nn.Module):\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n    def forward(self, x):\n        x=torch.tanh(self.linear1(x))\n        x=(self.linear2(x))\n        return x\nclass Net_relu(nn.Module):\n    def __init__(self, D_in, H, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H)\n        self.linear2 = nn.Linear(H, D_out)\n    def forward(self, x):\n        x=torch.relu(self.linear1(x))\n        x=(self.linear2(x))\n        return x\nusing nn.Sequential\nmodel_tanh = nn.Sequential(\n    nn.Linear(input_dim, hidden_dim),\n    nn.Tanh(),\n    nn.Linear(hidden_dim, output_dim)\n)\n\nmodel_relu = nn.Sequential(\n    nn.Linear(input_dim, hidden_dim),\n    nn.ReLU(),\n    nn.Linear(hidden_dim, output_dim)\n)\n\n\nUngraded lab\n7.5.1activationfuction_v2.ipynb\n\n\nUngraded lab\n7.5.2mist1layer_v2.ipynb\nto monitor gpu usage: nvidia-smi -l 1\n\n\n\nimage.png\n\n\n\n\n\n\nWeek 5 - Deep neural networks\n\nLearning Objectives\n\nbuilding deep networks\nDropout\nNeural Network initialization weights\nGradient Descent with Momentum\n\n\n\nnotebook\nnotebook\n\n\nDeep Neural Networks\nDeep, following this course definition, is when number of hidden layers &gt; 1.\n\nusing nn.Module\nimport torch\nimport torch.nn as nn\nfrom torch import sigmoid\nclass Net(nn.Module):\n    def __init__(self, D_in, H1, H2, D_out):\n        super(Net, self).__init__()\n        self.linear1 = nn.Linear(D_in, H1)\n        self.linear2 = nn.Linear(H1, H2)\n        self.linear3 = nn.Linear(H2, D_out)\n    def forward(self, x):\n        x=sigmoid(self.linear1(x))       \n        x=sigmoid(self.linear2(x))\n        x=self.linear3(x)\n        return x\n\n\nusing nn.Sequential\ninput_dim = 2\nhidden_dim1 = 6\nhidden_dim2 = 4\noutput_dim = 3\nmodel = nn.Sequential(\n    nn.Linear(input_dim, hidden_dim1),\n    nn.Sigmoid(),\n    nn.Linear(hidden_dim1, hidden_dim2),\n    nn.Sigmoid(),    \n    nn.Linear(hidden_dim2, output_dim)\n)\n\n\ntraining\nthere is no change compare to other networks\nwe create a validation and training dataset\nimport torchvision.datasets as dsets\nimport torchvision.transforms as transforms\ntrain_dataset = dsets.MNIST(root='./data', train = True, download = True, transform=transforms.ToTensor())\nvalidation_dataset = dsets.MNIST(root='./data', train = False, download = True, transform=transforms.ToTensor())\nwe create a validation and training loader\ntrain_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=2000)\nvalidation_loader = torch.utils.data.DataLoader(dataset=validation_dataset, batch_size=2000)\ncriterion = nn.CrossEntropyLoss()\nwe create the training function\nfrom tqdm import tqdm\ndef train(model, criterion, train_loader, validation_loader, optimizer, epochs=100):\n    i = 0\n    useful_stuff = {'training_loss': [],'validation_accuracy': []}  \n    for epoch in tqdm(range(epochs)):\n        for i, (x, y) in enumerate(train_loader): \n            optimizer.zero_grad()\n            z = model(x.view(-1, 28 * 28))\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n             #loss for every iteration\n            useful_stuff['training_loss'].append(loss.data.item())\n        correct = 0\n        for x, y in validation_loader:\n            #validation \n            z = model(x.view(-1, 28 * 28))\n            _, label = torch.max(z, 1)\n            correct += (label == y).sum().item()\n        accuracy = 100 * (correct / len(validation_dataset))\n        useful_stuff['validation_accuracy'].append(accuracy)\n    return useful_stuff\nWe instantiate and train the model\ninput_dim = 28 * 28\nhidden_dim1 = 50\nhidden_dim2 = 50\noutput_dim = 10\n\nmodel = Net(input_dim, hidden_dim1, hidden_dim2, output_dim)\noptimizer = torch.optim.SGD(model.parameters(), lr=0.01)\ntraining_results = train(model, criterion, train_loader, validation_loader, optimizer, epochs=30)\n\n\nUngraded lab - deep neural networks\n8.1.1mist2layer_v2.ipynb\n\n\n\nimg\n\n\n\n\n\nDeep Neural Networks : nn.ModuleList()\n\njdc\nthis is a nice library to allow breaking down definition of classes in separate notebook cells\nInstallation is as simple as pip install jdc\nand usage is\nimport jdc\nand start a cell with %%add_to &lt;your class name&gt;\n\n\npython implementation\nimport torch\nimport torch.nn as nn\nfrom torch import sigmoid\nimport jdc\nclass Net(nn.Module):\n    def __init__(self, Layers):\n        super(Net, self).__init__()\n        self.hidden = nn.ModuleList()\n        for input_size, output_size in zip(Layers, Layers[1:]):\n            self.hidden.append(nn.Linear(input_size, output_size))\nLayers = [2, 3, 4, 3]\nmodel = Net(Layers)\n%%add_to Net\n\ndef forward(self, x):\n    L = len(self.hidden)\n    for (l, linear_transform) in zip(range(L), self.hidden):\n        if (l &lt; L-1):\n            x = torch.relu(linear_transform(x))\n        else:\n            x = linear_transform(x)\n    return x\n\n\nUngraded lab - nn.ModuleList()\n8.1.2mulitclassspiralrulu_v2.ipynb\n\n\n\nimg\n\n\n\n\n\nDropout\n\nusing nn.Module\nclass Net(nn.Module):\n    def __init__(self, in_size, n_hidden, out_size, p=0):\n        super(Net, self).__init__()\n        self.drop = nn.Dropout(p=p)\n        self.linear1 = nn.Linear(in_size, n_hidden)\n        self.linear2 = nn.Linear(n_hidden, n_hidden)\n        self.linear3 = nn.Linear(n_hidden, out_size)\n    def forward(self, x):\n        x=torch.relu(self.linear1(x))       \n        x=self.drop(x)\n        x=torch.relu(self.linear2(x))\n        x=self.drop(x)\n        x=self.linear3(x)\n        return x\n\n\nusing nn.Sequential\nmodel = nn.Sequential(\n    nn.Linear(1, 10),\n    nn.Dropout(0.5),\n    nn.ReLU(),\n    nn.Linear(10, 12),\n    nn.Dropout(0.5),\n    nn.ReLU(),\n    nn.Linear(12, 1),\n)\n\n\ntraining\ncreate data\nfrom torch.utils.data import Dataset, DataLoader \nimport numpy as np\n# Create data class for creating dataset object\n\nclass Data(Dataset):\n    \n    # Constructor\n    def __init__(self, N_SAMPLES=1000, noise_std=0.15, train=True):\n        a = np.matrix([-1, 1, 2, 1, 1, -3, 1]).T\n        self.x = np.matrix(np.random.rand(N_SAMPLES, 2))\n        self.f = np.array(a[0] + (self.x) * a[1:3] + np.multiply(self.x[:, 0], self.x[:, 1]) * a[4] + np.multiply(self.x, self.x) * a[5:7]).flatten()\n        self.a = a\n       \n        self.y = np.zeros(N_SAMPLES)\n        self.y[self.f &gt; 0] = 1\n        self.y = torch.from_numpy(self.y).type(torch.LongTensor)\n        self.x = torch.from_numpy(self.x).type(torch.FloatTensor)\n        self.x = self.x + noise_std * torch.randn(self.x.size())\n        self.f = torch.from_numpy(self.f)\n        self.a = a\n        if train == True:\n            torch.manual_seed(1)\n            self.x = self.x + noise_std * torch.randn(self.x.size())\n            torch.manual_seed(0)\n        \n    # Getter        \n    def __getitem__(self, index):    \n        return self.x[index], self.y[index]\n    \n    # Get Length\n    def __len__(self):\n        return self.len\n    \n    # Plot the diagram\n    def plot(self):\n        X = data_set.x.numpy()\n        y = data_set.y.numpy()\n        h = .02\n        x_min, x_max = X[:, 0].min(), X[:, 0].max()\n        y_min, y_max = X[:, 1].min(), X[:, 1].max() \n        xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n        Z = data_set.multi_dim_poly(np.c_[xx.ravel(), yy.ravel()]).flatten()\n        f = np.zeros(Z.shape)\n        f[Z &gt; 0] = 1\n        f = f.reshape(xx.shape)\n        \n        plt.title('True decision boundary  and sample points with noise ')\n        plt.plot(self.x[self.y == 0, 0].numpy(), self.x[self.y == 0,1].numpy(), 'bo', label='y=0') \n        plt.plot(self.x[self.y == 1, 0].numpy(), self.x[self.y == 1,1].numpy(), 'ro', label='y=1')\n        plt.contour(xx, yy, f,cmap=plt.cm.Paired)\n        plt.xlim(0,1)\n        plt.ylim(0,1)\n        plt.legend()\n    \n    # Make a multidimension ploynomial function\n    def multi_dim_poly(self, x):\n        x = np.matrix(x)\n        out = np.array(self.a[0] + (x) * self.a[1:3] + np.multiply(x[:, 0], x[:, 1]) * self.a[4] + np.multiply(x, x) * self.a[5:7])\n        out = np.array(out)\n        return out\n\n\n\nimg\n\n\ninstantiate the model\nmodel_drop = Net(2, 300, 2, p=0.5)\ntrain method tells the model we are in the training phase which will implement the dropout method, later we use the eval method to tell the model it is in the evaluation phase and that will turn off the dropout method\nmodel_drop.train()\noptimizer = torch.optim.Adam(model_drop.parameters(), lr = 0.01)\ncriterion = nn.CrossEntropyLoss()\ndata_set = Data()\nvalidation_set = Data(train=False)\n# Initialize the LOSS dictionary to store the loss\n\nLOSS = {}\nLOSS['training data dropout'] = []\nLOSS['validation data dropout'] = []\ntrain the model\n# Train the model\nfrom tqdm import tqdm\n\nepochs = 500\n\ndef train_model(epochs):\n    \n    for epoch in tqdm(range(epochs)):\n        #all the samples are used for training \n        yhat_drop = model_drop(data_set.x)\n        loss_drop = criterion(yhat_drop, data_set.y)\n\n        #store the loss for both the training and validation data for both models \n        LOSS['training data dropout'].append(loss_drop.item())\n        model_drop.eval()\n        LOSS['validation data dropout'].append(criterion(model_drop(validation_set.x), validation_set.y).item())\n        model_drop.train()\n\n        optimizer.zero_grad()\n        loss_drop.backward()\n        optimizer.step()\n        \ntrain_model(epochs)\n# The function for calculating accuracy\n\ndef accuracy(model, data_set):\n    _, yhat = torch.max(model(data_set.x), 1)\n    return (yhat == data_set.y).numpy().mean()\n\n# Print out the accuracy of the model with dropout\n\nprint(\"The accuracy of the model with dropout: \", accuracy(model_drop, validation_set))\n&gt;&gt; The accuracy of the model with dropout:  0.866\n\n\nUngraded lab - dropout classification\n8.2.1dropoutPredictin_v2.ipynb\n\n\nUngraded lab - dropout regression\n8.2.2dropoutRegression_v2.ipynb\n\n\n\nNeural Network initialization weights\nDifferent methods exist:\n\nuniform distribution for parameters: we simply make the lower bound of the range of the distribution the negative of the inverse of square root of L in. the upper bound of the range of the distribution is the positive of the inverse of square root of L in. See this paper for more details. LeCun, Yann A., et al. “Efficient backprop.” Neural networks: Tricks of the trade. Springer, Berlin, Heidelberg, 2012. 9-48\n\nlinear=nn.Linear(input_size,output_size)\nlinear.weight.data.uniform_(0, 1)\n\nxavier method: Xavier Initialization is another popular method and is used in conjunction with the tanh activation. It takes into consideration the number of input neurons “Lin” as well as the number of neuron in the next layer “L out”. This paper for more details: Glorot, Xavier and Yoshua Bengio. “Understanding the difficulty of training deep feedforward neural networks” 2010.\n\nlinear=nn.Linear(input_size,output_size)\ntorch.nn.init.xavier_uniform_(linear.weight)\n\nHe method: For relu we use the He initialize method, after we create a linear object, We use the following method to initialize the weights, for more info check out the following paper. He, Kaiming, et al. “Delving deep into rectifiers: surpassing human-level performance in imagenet classification”\n\nlinear = nn.Linear(input_size, output_size)\ntorch.nn.init.kaiming_uniform_(linear.weight, nonlinearity='relu')\n\nUngraded lab - initialization\n8.3.1.initializationsame.ipynb\n\n\nUngraded lab - Xavier initialization\n8.3.2Xaviermist1layer_v2.ipynb\n\n\nUngraded lab - He initialization\n8.3.3.He_Initialization_v2.ipynb\n\n\n\nGradient Descent with Momentum\n\nPyTorch implementation\nIn PyTorch, this is just defined at optim level\noptimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum = 0.4)\n\n\nUngraded lab - momentum with different polynomial\n8.4.1_MomentumwithPolynomialFunctions_v2.ipynb\n\n\nUngraded lab - Neural Network momentum\n8.4.2_NeuralNetworkswithMomentum_v2.ipynb\n\n\n\nBatch Normalization\n\n\n\nimage.png\n\n\n𝛾, 𝛽 parameters are are actually scale and shift parameters, which we’re going to learn via training.\n\nusing nn.Module\nclass Net_BatchNorm(nn.Module):\n    def __init__(self, in_size, n_hidden1, n_hidden2, out_size):\n        super(Net_BatchNorm, self).__init__()\n\n        self.linear1 = nn.Linear(in_size, n_hidden1)\n        self.linear2 = nn.Linear(n_hidden1, n_hidden2)\n        self.linear3 = nn.Linear(n_hidden2, out_size)\n        \n        self.bn1 = nn.BatchNorm1d(n_hidden1)\n        self.bn2 = nn.BatchNorm1d(n_hidden2)\n        \n    def forward(self, x):\n        x=torch.sigmoid(self.bn1(self.linear1(x)))\n        x=torch.sigmoid(self.bn2(self.linear2(x)))\n        x=self.linear3(x)\n        return x\n\n\nUngraded lab - Batch normalization\n8.5.1BachNorm_v2.ipynb\ncomparing training loss for each iteration and accuracy on validation data for both Batch / No Batch normalization.\n\n\n\nimg\n\n\n\n\n\nimg\n\n\n\n\n\n\nWeek 6 - Convolutional neural networks\n\nLearning Objectives\n\nConvolution\nActivation Functions\nMax Pooling\nConvolution: Multiple Channels\nConvolutional Neural Network\nTORCH-VISION MODELS\n\n\n\nnotebook\nnotebook\n\n\nConvolution\nconvolution explanation from stanford course CS231\n\nconvolution\nconv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\nimage = torch.zeros(1,1,5,5)\nimage[0,0,:,2] = 1\nimage\n&gt;&gt; tensor([[[[0., 0., 1., 0., 0.],\n          [0., 0., 1., 0., 0.],\n          [0., 0., 1., 0., 0.],\n          [0., 0., 1., 0., 0.],\n          [0., 0., 1., 0., 0.]]]])\nz=conv(image)\n&gt;&gt; tensor([[[[ 0.6065,  0.0728, -0.7915],\n          [ 0.6065,  0.0728, -0.7915],\n          [ 0.6065,  0.0728, -0.7915]]]], grad_fn=&lt;ThnnConv2DBackward&gt;)\nconv.state_dict()\n&gt;&gt; OrderedDict([('weight',\n              tensor([[[[ 0.1132, -0.0418,  0.3140],\n                        [-0.2261, -0.1528, -0.3270],\n                        [-0.2140, -0.1900,  0.2127]]]])),\n             ('bias', tensor([0.0423]))])\n\n\nstride\nconv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride = 2)\n\n\nzeros padding\nconv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride = 2, padding = 1)\n\n\nsize of activation map\n\n\nFeature size = ((Image size + 2 * Padding size − Kernel size) / Stride)+1\n\n\nUngraded lab - What’s convolution\n9.1What_is_Convolution.ipynb\n\n\n\nActivation Functions and Max Polling\n\nActivation function using nn.Module\nimport torch\nimage = torch.zeros(1,1,5,5)\nimage[0,0,:,2] = 1\nconv = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3)\nz=conv(image)\nA = torch.relu(z)\n\n\nActivation function using nn.Sequential\nrelu = nn.ReLU()\nA = relu(z)\n\n\nMax pooling\nmax = nn.MaxPool2d(2, stride=1)\nmax(image)\ntorch.max_pool2d(image, stride=1, kernel_size=2)\n\n\nUngraded lab - Activation Functions and Max Polling\n9.2Activation_max_pooling.ipynb\n\n\n\nMultiple Input and Output Channels\n\nUngraded lab - Activation Functions and Max Polling\n9.3Multiple Channel Convolution.ipynb\n\n\n\nConvolutional Neural Network\n\nusing nn.Module\nclass CNN(nn.Module):\n    def __init__(self,out_1=2,out_2=1):\n        \n        super(CNN,self).__init__()\n        #first Convolutional layers \n        self.cnn1=nn.Conv2d(in_channels=1,out_channels=out_1,kernel_size=2,padding=0)\n        self.maxpool1=nn.MaxPool2d(kernel_size=2 ,stride=1)\n\n        #second Convolutional layers\n        self.cnn2=nn.Conv2d(in_channels=out_1,out_channels=out_2,kernel_size=2,stride=1,padding=0)\n        self.maxpool2=nn.MaxPool2d(kernel_size=2 ,stride=1)\n        #max pooling \n\n        #fully connected layer \n        self.fc1=nn.Linear(out_2*7*7,2)\n        \n    def forward(self,x):\n        #first Convolutional layers\n        x=self.cnn1(x)\n        #activation function \n        x=torch.relu(x)\n        #max pooling \n        x=self.maxpool1(x)\n        #first Convolutional layers\n        x=self.cnn2(x)\n        #activation function\n        x=torch.relu(x)\n        #max pooling\n        x=self.maxpool2(x)\n        #flatten output \n        x=x.view(x.size(0),-1)\n        #fully connected layer\n        x=self.fc1(x)\n        return x\n\n\ntraining\nn_epochs=10\ncost_list=[]\naccuracy_list=[]\nN_test=len(validation_dataset)\ncost=0\n#n_epochs\nfor epoch in range(n_epochs):\n    cost=0    \n    for x, y in train_loader:\n        #clear gradient \n        optimizer.zero_grad()\n        #make a prediction \n        z=model(x)\n        # calculate loss \n        loss=criterion(z,y)\n        # calculate gradients of parameters \n        loss.backward()\n        # update parameters \n        optimizer.step()\n        cost+=loss.item()\n    cost_list.append(cost)\n    correct=0\n    #perform a prediction on the validation  data  \n    for x_test, y_test in validation_loader:\n        z=model(x_test)\n        _,yhat=torch.max(z.data,1)\n        correct+=(yhat==y_test).sum().item()\n    accuracy=correct/N_test\n    accuracy_list.append(accuracy)\n\n\nUngraded lab - Convolutional Neural Network Simple example\n9.4.1ConvolutionalNeralNetworkSimple example.ipynb\ndef conv_output_shape(h_w, kernel_size=1, stride=1, pad=0, dilation=1):\n    #by Duane Nielsen\n    from math import floor\n    if type(kernel_size) is not tuple:\n        kernel_size = (kernel_size, kernel_size)\n    h = floor( ((h_w[0] + (2 * pad) - ( dilation * (kernel_size[0] - 1) ) - 1 )/ stride) + 1)\n    w = floor( ((h_w[1] + (2 * pad) - ( dilation * (kernel_size[1] - 1) ) - 1 )/ stride) + 1)\n    return h, w\nout=conv_output_shape((11,11), kernel_size=2, stride=1, pad=0, dilation=1)\nprint(out)\nout1=conv_output_shape(out, kernel_size=2, stride=1, pad=0, dilation=1)\nprint(out1)\nout2=conv_output_shape(out1, kernel_size=2, stride=1, pad=0, dilation=1)\nprint(out2)\n\nout3=conv_output_shape(out2, kernel_size=2, stride=1, pad=0, dilation=1)\nprint(out3)\n&gt;&gt; (10, 10)\n(9, 9)\n(8, 8)\n(7, 7)\n\n\nUngraded lab - Convolutional Neural Network MNIST\n9.4.2CNN_Small_Image.ipynbb\n\n\nUngraded lab - Convolutional Neural Networks with Batch Norm\n9.4.3CNN_Small_Image_batch.ipynb\n\n\nGPU in PyTorch\ntorch.cuda.is_available()\n&gt;&gt; True\n\ndevice = torch.device('cuda:0')\n\ntorch.tensor([1,2,32,4]).to(device)\n&gt;&gt; tensor([ 1,  2, 32,  4], device='cuda:0')\n\nmodel = CNN()\nmodel.to(device)\n\n\nTraining on GPU\nfor epoch in range(num_epochs):\n    for features, labels in train_loader:\n        features, labels = features.to(device), labels.to(device)\n        optimizer.zero_grad()\n        predictions = model(features)\n        loss = criterion(predictions, labels)\n        loss.backward()\n        optimizer.step()\n\n\n\nTORCH-VISION MODELS\nload resnet18 with pretrained parameters\nimport torch\nimport torchvision.models as models\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nimport torch.nn as nn\ntorch.manual_seed(0)\n\nmodel = models.resnet18(pretrained=True)\n\nmean = [0.485, 0.456, 0.406]\nstd = [0.229, 0.224, 0.225]\n\ncomposed = transforms.Compose([transforms.Resize(224),\n                              transforms.ToTensor(),\n                              transforms.Normalize(mean, std)])\n\ntrain_dataset = Dataset(transform=composed, train = True)\nvalidation_dataset = Dataset(transform=composed)\nfreeze parameters and add a final layer to be trained\nfor param in model.parameters():\n    param.requires_grad=False\nmodel.fc = nn.Linear(512, 7)\ntrain_loader = DataLoader(dataset=train_loader, batch_size=15)\nvalidation_loader = DataLoader(dataset=validation_loader, batch_size=10)\nprovides only parameters to be trained to optim\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam([parameters for parameters in model.parameters() if parameters.requires_grad], lr = 0.003)\n\nN_EPOCHS = 20\nloss_list = []\naccuracy_list = []\ncorrect = 0\nn_test = len(validation_dataset)\ntrain the model, switching to model.train and model.eval\nfor epoch in range(N_EPOCHS):\n    loss_sublist = []\n    for x, y in train_loader:\n        model.train()\n        optimizer.zero_grad()\n        z = model(x)\n        loss = criterion(z, y)\n        loss_sublist.append(loss.data.item())\n        loss.backward()\n        optimizer.step()\n    loss_list.append(np.mean(loss_sublist))\n    correct = 0\n    for x_test, y_test in validation_loader:\n        model.eval()\n        z = model(x_test)\n        _, yhat = torch.max(z.data, 1)\n        correct += (yhat == y_test).sum().item()\n    accuracy = correct / n_test\n    accuracy_list.append(accuracy)\n\n\n\nWeek 7 - Fashion MNIST\n\nLearning Objectives\n\nApply all you have learned to train a Convolutional Neural Network\n\n\n\nnotebook\nnotebook"
  },
  {
    "objectID": "posts/2021-03-03-gpg-linux.html",
    "href": "posts/2021-03-03-gpg-linux.html",
    "title": "Use of gpg under linux",
    "section": "",
    "text": "from best ways to encrypt files on linux"
  },
  {
    "objectID": "posts/2021-03-03-gpg-linux.html#gpg",
    "href": "posts/2021-03-03-gpg-linux.html#gpg",
    "title": "Use of gpg under linux",
    "section": "gpg",
    "text": "gpg\n\nsetup the key\ngpg --gen-key\nand enter a strong passphrase.\n\n\nexport public key\ngpg --armor --output mypubkey.gpg --export &lt;E-mail that you registered&gt;\n\n\nimport from windows box\ngpg --import mypubkey.gpg\n\n\nencrypt files from windows box\ngpg --output test.txt.gpg --encrypt --recipient &lt;Receiver's E-Mail ID&gt; test.txt\n\n\ndecrypt files on linux box\ngpg --output test.txt --decrypt test.txt.gpg"
  },
  {
    "objectID": "posts/2021-03-03-gpg-linux.html#find-gpg-tmpfs",
    "href": "posts/2021-03-03-gpg-linux.html#find-gpg-tmpfs",
    "title": "Use of gpg under linux",
    "section": "find + gpg + tmpfs",
    "text": "find + gpg + tmpfs\nencrypt from Windows\nfind . -name 'df_76*.csv' -exec gpg --output {}.gpg --encrypt --recipient guillaume.ramelet@michelin.com {} \\;\ndecrypt from Linux\nThere should be better ways to do it.\nHere is my process:\n\nBefore starting: call mount_decrypt.sh. It mounts a tmpfs in secured_data/data, and decrypt all gpg files to this directory\n\nAfter work is done: call umount_decrypt.sh\n\ngpg_decrypt.sh\n#!/bin/bash\ngpg_name=\"$1\"\nsrc_name=${gpg_name%.*}\nTARGET_DATA=/home/explore/git/guillaume/d059/secured_data/data\necho \"gpg decrypt $gpg_name -&gt; $src_name\"\ngpg --output $TARGET_DATA/$src_name --decrypt $gpg_name(base)\nmount_decrypt.sh\n#!/bin/bash\nGPG_DEC_CMD=/home/explore/git/guillaume/d059/secured_data/gpg_decrypt.sh\nTARGET_DATA=/home/explore/git/guillaume/d059/secured_data/data\nsudo mount -t tmpfs -o size=1G tmpfs $TARGET_DATA\ncd /media/explore/CHACLEF/janus\nfind . -name 'df_76*.csv.gpg' -exec $GPG_DEC_CMD {} \\;\numount_decrypt.sh\n#!/bin/bash\nTARGET_DATA=/home/explore/git/guillaume/d059/secured_data/data\nsudo umount $TARGET_DATA"
  },
  {
    "objectID": "posts/2021-01-05-jupyter-export-notebook-as-py.html",
    "href": "posts/2021-01-05-jupyter-export-notebook-as-py.html",
    "title": "Auto export python code from jupyter notebooks",
    "section": "",
    "text": "This hack comes from https://github.com/jupyter/notebook/blob/master/docs/source/extending/savehooks.rst.\n\njupyter_notebook_config.py\nHere is the code:\n# Based off of https://github.com/jupyter/notebook/blob/master/docs/source/extending/savehooks.rst\n\nimport io\nimport os\nfrom notebook.utils import to_api_path\n\n_script_exporter = None\n_html_exporter = None\n\ndef script_post_save(model, os_path, contents_manager, **kwargs):\n    \"\"\"convert notebooks to Python script after save with nbconvert\n\n    replaces `ipython notebook --script`\n    \"\"\"\n    from nbconvert.exporters.script import ScriptExporter\n    from nbconvert.exporters.html import HTMLExporter\n\n    if model['type'] != 'notebook':\n        return\n\n    global _script_exporter\n    if _script_exporter is None:\n        _script_exporter = ScriptExporter(parent=contents_manager)\n    log = contents_manager.log\n\n    global _html_exporter\n    if _html_exporter is None:\n        _html_exporter = HTMLExporter(parent=contents_manager)\n    log = contents_manager.log\n\n    # save .py file\n    base, ext = os.path.splitext(os_path)\n    script, resources = _script_exporter.from_filename(os_path)\n    # si le sous rep eports_py existe, on ecrit dedans, sinon on ecrit à la racine\n    sous_rep=''\n    repertoire=os.path.dirname(base)\n    if os.path.exists(repertoire+'/exports_py'):\n        sous_rep='/exports_py'\n    basename = os.path.basename(base)\n    script_fname = repertoire+ sous_rep+'/'+basename+resources.get('output_extension', '.txt')\n    log.info(\"base: {}, basename: {}, sous_rep: {}, repertoire: {}\".format(base, basename, sous_rep, repertoire))\n    log.info(\"script_fname: {}\".format(script_fname))\n    #script_fname = base + resources.get('output_extension', '.txt')\n    log.info(\"Saving script /%s\", to_api_path(script_fname, contents_manager.root_dir))\n    with io.open(script_fname, 'w', encoding='utf-8') as f:\n        f.write(script)\n\n\"\"\"\n    # save html\n    base, ext = os.path.splitext(os_path)\n    script, resources = _html_exporter.from_filename(os_path)\n    script_fname = base + resources.get('output_extension', '.txt')\n    log.info(\"Saving html /%s\", to_api_path(script_fname, contents_manager.root_dir))\n    with io.open(script_fname, 'w', encoding='utf-8') as f:\n        f.write(script)\n        \n\"\"\"\n\nc.FileContentsManager.post_save_hook = script_post_save\nIn this version, if a subfolder exports_py exists, .py version will be exported in it. Oherwise it will be exported in the notebook folder.\nMaybe in a later version it would be good to export only of this subfolder exists. (for example I don’t need these py files when creating such a blog entry, even if my .gitignore won’t publish .py files)\nAnd to remove the creation of Untitled.txt files when notebooks are just being created (and not yet named).\n\n\ndeployment\nJust save/merge this jupyter_notebook_config.py file (download) to your jupyter home directory.\nAccording to Config file and command line options in jupyter documentation, it is located at ~/.jupyter\nAnd in windows it is at C:\\Users\\&lt;yourID&gt;\\.jupyter\nThis will be valid for all your conda environments.\n\n\ntest\n~/.jupyter$ cp ~/git/guillaume/blog/files/jupyter_notebook_config.py .\nRestart Jupyter notebook server and click save on any notebook:\n\n\n\nvoila"
  },
  {
    "objectID": "posts/2021-04-01-logbook-April.html",
    "href": "posts/2021-04-01-logbook-April.html",
    "title": "Logbook for April 21",
    "section": "",
    "text": "Thursday 4/1\nAniti RLVS - Deep Q-Networks and its variants\nCollège de France - Algorithmes quantiques : quand la physique quantique défie la thèse de Church-Turing Leçon inaugurale\nFriday 4/2\nAniti RLVS - From Policy Gradients to Actor Critic methods\nAniti RLVS - Policy Gradient in pratice\ngit to use socks server to github (to go through local firewall)\nAniti RLVS - Exploration in Deep RL"
  },
  {
    "objectID": "posts/2021-04-01-logbook-April.html#week-13---apr-21",
    "href": "posts/2021-04-01-logbook-April.html#week-13---apr-21",
    "title": "Logbook for April 21",
    "section": "",
    "text": "Thursday 4/1\nAniti RLVS - Deep Q-Networks and its variants\nCollège de France - Algorithmes quantiques : quand la physique quantique défie la thèse de Church-Turing Leçon inaugurale\nFriday 4/2\nAniti RLVS - From Policy Gradients to Actor Critic methods\nAniti RLVS - Policy Gradient in pratice\ngit to use socks server to github (to go through local firewall)\nAniti RLVS - Exploration in Deep RL"
  },
  {
    "objectID": "posts/2021-04-01-logbook-April.html#week-14---apr-21",
    "href": "posts/2021-04-01-logbook-April.html#week-14---apr-21",
    "title": "Logbook for April 21",
    "section": "Week 14 - Apr 21",
    "text": "Week 14 - Apr 21\nWednesday 4/7\ntabnet: pytorch (and fastai with Zach Mueller) implementations\nThursday 4/8\nAniti RLVS - Evolutionary Reinforcement Learning\nJupyter notebook turned into slides with RISE\nAniti RLVS - Micro-data Policy Search\nFriday 4/9\nAniti RLVS - RL in Practice: Tips and Tricks and Practical Session With Stable-Baselines3\nsetup wsl-vpnkit to workaround wsl2 and network issues (explained here)\ninstall wsl2-cuda-conda"
  },
  {
    "objectID": "posts/2021-04-01-logbook-April.html#week-15---apr-21",
    "href": "posts/2021-04-01-logbook-April.html#week-15---apr-21",
    "title": "Logbook for April 21",
    "section": "Week 15 - Apr 21",
    "text": "Week 15 - Apr 21\nThursday 4/15\nMIT 6S191 Learning for Information Extraction (lecture 9)."
  },
  {
    "objectID": "posts/2021-04-01-logbook-April.html#week-16---apr-21",
    "href": "posts/2021-04-01-logbook-April.html#week-16---apr-21",
    "title": "Logbook for April 21",
    "section": "Week 16 - Apr 21",
    "text": "Week 16 - Apr 21\nTuesday 4/20\nHow To run macOS on KVM / QEMU\nWednesday 4/21\nEnrolled to Machine learning in python with scikit-learn by scikit-learn team!\nAudio classification with pytorch"
  },
  {
    "objectID": "posts/2021-04-01-logbook-April.html#week-17---apr-21",
    "href": "posts/2021-04-01-logbook-April.html#week-17---apr-21",
    "title": "Logbook for April 21",
    "section": "Week 17 - Apr 21",
    "text": "Week 17 - Apr 21\nMonday 4/26\ndatacamp - Bayesian Data Analysis in Python, at the end, Think Bayes 2 by Allen B.Downey\nTuesday 4/27\nRL Course by David Silver Value Function Approximation (lecture 6)\nMIT 6S191 Taming Dataset Bias (lecture 10)\nWednesday 4/28\ndatacamp - Exploratory Data Analysis in Python, by Allen B.Downey (that’s why)\nThursday 4/29\ndatacamp - Working with date and time, quite interesting to see timezones considerations.\nFriday 4/30\ndatacamp - Cleaning data. Impressed by fuzzywuzzy and recordlinkage packages. End of this track (Data Scientist - new version)\nMIT 6S191 Towards AI for 3D Content Creation (lecture 11) and AI in Healthcare (lecture 12) and this is the end of this course"
  },
  {
    "objectID": "posts/2021-06-25-slide-show-jupyter.html",
    "href": "posts/2021-06-25-slide-show-jupyter.html",
    "title": "Slideshows from Jupyter notebook",
    "section": "",
    "text": "Installation, configuration\nnice explanation from Mark Roekpe’s blog\nSlide is a native function from Jupyter (through nbconvert). However one can install RISE to get some additional features.\nconda install -c conda-forge rise\n\npip install RISE\n\nAnd then for each cell I can decide if I want: - slide - indicates that the selected cell should be the start of a new slide - sub-slide - indicates that the selected cell should be the start of a new sub-slide, which appears in a new frame beneath the previous slide - fragment - indicates that the selected cell should appear as a build to the previous slide - skip - indicates that the selected cell should be skipped and not be a part of the slideshow - notes - indicates that the selected cell should just be presenter notes - - - indicates that the selected cell should follow the behavior of the previous cell, which is useful when a markdown cell and a code cell should appear simultaneously\nSlides are structured this way. To progress we can go right (for new slides) or bottom (for sub-slides).\nAnd we can decide to have new pages (slides / sub-slides) or new fragment in the same page (fragment).\n\n\nRun slides\nWe can launch slideshow with RISE button (or Alt-R)\nOr we can serve pages through nbconvert:\njupyter nbconvert my_notebook.ipynb --to slides --post serve\n\n!jupyter nbconvert 2021-06-25-slide-show-jupyter.ipynb --to slides --post serve\n\n[NbConvertApp] WARNING | Config option `kernel_spec_manager_class` not recognized by `NbConvertApp`.\n[NbConvertApp] Converting notebook 2021-06-25-slide-show-jupyter.ipynb to slides\nServing your slides at http://127.0.0.1:8000/2021-06-25-slide-show-jupyter.slides.html\nUse Control-C to stop this server\nWARNING:tornado.access:404 GET /favicon.ico (127.0.0.1) 0.41ms\n^C\n\nInterrupted\n\n\n\n\nRISE vs nbconvert\n\n\n\n\n\n\n\n\n\nRISE\nnbconvert\n\n\n\n\nrun\nAlt-R or click Rise icon\ncmd line: jupyter nbconvert &lt;name&gt;.ipynb --to slides --post serve\n\n\nsplit cells\nsupported\nnot supported\n\n\nkeyboard shortcuts\n← → ⇞ ⇟\n← ↑ → ↓\n\n\n\n\n\nsome extensions\ntips from Mark Roekpe’s blog. Valid mainly for RISE.\n\nsplicell\nhide code from slideshow\ncustom css\nopen slides automatically"
  },
  {
    "objectID": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html",
    "href": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html",
    "title": "Autodetect Home / Office network + Proxy",
    "section": "",
    "text": "Command to get IP address is as follow:\nIP=`ifconfig | grep 'inet '| grep -v '127.0.0.1' | cut -d: -f2 | awk '{ print $2}'`\nI can then check how IP is setup: - empty: no network attached, in that case nothing to do - HOME_IP=192.168.1.241: based on MAC I give fixed IP to my computers (out of DHCP scope) - S8_IP=192.168.: hotspot from samsung is using 192.168. addresses - OFFICE_IP=10.: office network uses 10. addresses\nDetect if variable IP is set:\nif [ -z \"$IP\" ]; then\n        echo \"Not connected to any network\"\nfi"
  },
  {
    "objectID": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#ip-detection",
    "href": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#ip-detection",
    "title": "Autodetect Home / Office network + Proxy",
    "section": "",
    "text": "Command to get IP address is as follow:\nIP=`ifconfig | grep 'inet '| grep -v '127.0.0.1' | cut -d: -f2 | awk '{ print $2}'`\nI can then check how IP is setup: - empty: no network attached, in that case nothing to do - HOME_IP=192.168.1.241: based on MAC I give fixed IP to my computers (out of DHCP scope) - S8_IP=192.168.: hotspot from samsung is using 192.168. addresses - OFFICE_IP=10.: office network uses 10. addresses\nDetect if variable IP is set:\nif [ -z \"$IP\" ]; then\n        echo \"Not connected to any network\"\nfi"
  },
  {
    "objectID": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#network-detection-and-proxy-settings",
    "href": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#network-detection-and-proxy-settings",
    "title": "Autodetect Home / Office network + Proxy",
    "section": "Network detection and proxy settings",
    "text": "Network detection and proxy settings\nDepending on my network, I have to set or unset proxy.\nHere is the 1st version:\n(xgboost) guillaume@LL11LPC0PQARQ:~$ cat my_ip.sh\n#!/bin/bash\n\nIP=`ifconfig | grep 'inet '| grep -v '127.0.0.1' | cut -d: -f2 | awk '{ print $2}'`\nHOME_IP=192.168.1.241\nOFFICE_IP=10.\nS8_IP=192.168.\n\n# Set Proxy\nfunction setproxy() {\n     echo \"Calling setproxy\"\n     export {http,https,ftp}_proxy=\"http://proxy_ip:80\"\n     export {HTTP,HTTPS,FTP}_PROXY=\"http://proxy_ip:80\"\n}\n\n# Unset Proxy\nfunction unsetproxy() {\n     echo \"Calling unsetproxy\"\n     unset {http,https,ftp}_proxy\n     unset {HTTP,HTTPS,FTP}_PROXY\n}\n\nif [ -z \"$IP\" ]; then\n        echo \"Not connected to any network\"\nelse\n        echo \"Connected and IP address is: $IP\"\n\n        if [[ \"$IP\" == \"$HOME_IP\" ]]; then\n                echo \"Connected at home from freebox pop --&gt; no proxy\"\n                unsetproxy\n        else\n                if [[ \"$IP\" == \"$S8_IP\"* ]]; then\n                     echo \"Connected with mobile phone --&gt; no proxy\"\n                     unsetproxy\n                fi\n                if [[ \"$IP\" == \"$OFFICE_IP\"* ]]; then\n                        echo \"Connected from Office --&gt; proxy\"\n                        setproxy\n                fi\n        fi\nfi"
  },
  {
    "objectID": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#call-this-script-source",
    "href": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#call-this-script-source",
    "title": "Autodetect Home / Office network + Proxy",
    "section": "Call this script: source",
    "text": "Call this script: source\nIf I want these environment variables to be available from parent shell, I have to call my script with source.\n(xgboost) guillaume@LL11LPC0PQARQ:~$ source my_ip.sh\nConnected and IP address is: 10.xxx.xxx.xxx\n192.168.1.241\nConnected from Office --&gt; proxy\nCalling setproxy\nAnd I will auto launch this script each time I open a terminal by adding source my_ip.sh at the end of .bashrc"
  },
  {
    "objectID": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#git-and-keep-dot-configuration-files-config",
    "href": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#git-and-keep-dot-configuration-files-config",
    "title": "Autodetect Home / Office network + Proxy",
    "section": "git and keep dot configuration files: config",
    "text": "git and keep dot configuration files: config\nAnother great practice from Jeremy Howard: From https://developer.atlassian.com/blog/2016/02/best-way-to-store-dotfiles-git-bare-repo/ and https://www.atlassian.com/git/tutorials/dotfiles\nI will create a blog entry about that later.\nconfig add .bashrc my_ip.sh\nconfig commit -m 'detect network and set proxy'\nconfig push"
  },
  {
    "objectID": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#wget-proxy-no-proxy",
    "href": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#wget-proxy-no-proxy",
    "title": "Autodetect Home / Office network + Proxy",
    "section": "wget: proxy / no proxy",
    "text": "wget: proxy / no proxy\nI store proxy conf files under ~/proxy_files/\nFor wget: 2 files\n$ cat proxy_files/.wgetrc_noproxy\nuse_proxy=no\n$ cat proxy_files/.wgetrc_proxy\nuse_proxy=yes\nhttp_proxy=proxy_ip:80\nhttps_proxy=proxy_ip:80\nAnd enabling proxy for wget: ln -sf ~/proxy_files/.wgetrc_proxy ~/.wgetrc\nDisabling proxy for wget: ln -sf ~/proxy_files/.wgetrc_noproxy ~/.wgetrc\nSo the updated functions setproxy and unsetproxy are:\n# Set Proxy\nfunction setproxy() {\n     echo \"Calling setproxy\"\n     export {http,https,ftp}_proxy=\"http://proxy_ip:80\"\n     export {HTTP,HTTPS,FTP}_PROXY=\"http://proxy_ip:80\"\n     #proxy for wget\n     ln -sf ~/proxy_files/.wgetrc_proxy ~/.wgetrc\n}\n\n# Unset Proxy\nfunction unsetproxy() {\n     echo \"Calling unsetproxy\"\n     unset {http,https,ftp}_proxy\n     unset {HTTP,HTTPS,FTP}_PROXY\n     #no proxy for wget\n     ln -sf ~/proxy_files/.wgetrc_noproxy ~/.wgetrc\n}"
  },
  {
    "objectID": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#apt-get-proxy-no-proxy",
    "href": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#apt-get-proxy-no-proxy",
    "title": "Autodetect Home / Office network + Proxy",
    "section": "apt-get: proxy / no proxy",
    "text": "apt-get: proxy / no proxy\nI store proxy conf files under ~/proxy_files/\nFor apt, 1 file\n$ cat proxy_files/apt_proxy.conf\nAcquire {\n  HTTP::proxy \"http://proxy_ip:80\";\n  HTTPS::proxy \"http://proxy_ip:80\";\n}\nAnd enabling proxy for apt: sudo ln -sf ~/proxy_files/apt_proxy.conf /etc/apt/apt.conf.d/proxy.conf\nDisabling proxy for wget: sudo rm -f /etc/apt/apt.conf.d/proxy.conf\n{% include alert.html text=“Refactor to avoid password request each time it is launched” %}\nfor the moment I have just commented out these lines\nSo the updated functions setproxy and unsetproxy are:\n# Set Proxy\nfunction setproxy() {\n     echo \"Calling setproxy\"\n     export {http,https,ftp}_proxy=\"http://proxy_ip:80\"\n     export {HTTP,HTTPS,FTP}_PROXY=\"http://proxy_ip:80\"\n     #proxy for wget\n     ln -sf ~/proxy_files/.wgetrc_proxy ~/.wgetrc\n     #proxy for apt\n     #sudo ln -sf ~/proxy_files/apt_proxy.conf /etc/apt/apt.conf.d/proxy.conf\n}\n\n# Unset Proxy\nfunction unsetproxy() {\n     echo \"Calling unsetproxy\"\n     unset {http,https,ftp}_proxy\n     unset {HTTP,HTTPS,FTP}_PROXY\n     #no proxy for wget\n     ln -sf ~/proxy_files/.wgetrc_noproxy ~/.wgetrc\n     #no proxy for apt\n     #sudo rm -f /etc/apt/apt.conf.d/proxy.conf\n}"
  },
  {
    "objectID": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#sept-21-2020-ip-detection-to-be-changed-after-wsl2",
    "href": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#sept-21-2020-ip-detection-to-be-changed-after-wsl2",
    "title": "Autodetect Home / Office network + Proxy",
    "section": "Sept-21 2020: IP detection to be changed after WSL2",
    "text": "Sept-21 2020: IP detection to be changed after WSL2\nWith WSL2, IP address is from 172 network.\nThis looks like a virtual internal address. More detail at that address: https://github.com/microsoft/WSL/issues/4150.\n{% include alert.html text=“to update IP detection” %}"
  },
  {
    "objectID": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#oct-21-2020-use-git-with-github-ssh-behind-corporate-proxy",
    "href": "posts/2020-09-15-autodetect-home-office-network-and-proxy-settings.html#oct-21-2020-use-git-with-github-ssh-behind-corporate-proxy",
    "title": "Autodetect Home / Office network + Proxy",
    "section": "Oct-21 2020: Use git with github (ssh) behind corporate proxy",
    "text": "Oct-21 2020: Use git with github (ssh) behind corporate proxy\nHere is the new configuration explained in my blog entry Use git with github (ssh) behind corporate proxy\nIt is just a matter of linking appropriate files when I am in or out of corporate network.\nAs in my_ip.sh:\n# Set Proxy\nfunction setproxy() {\n     echo \"Calling setproxy\"\n     export {http,https,ftp}_proxy=\"http://proxy_ip:80\"\n     export {HTTP,HTTPS,FTP}_PROXY=\"http://proxy_ip:80\"\n     #proxy for wget\n     ln -sf ~/proxy_files/.wgetrc_proxy ~/.wgetrc\n     #proxy for apt\n     #sudo ln -sf ~/proxy_files/apt_proxy.conf /etc/apt/apt.conf.d/proxy.conf\n     #proxy for conda\n     ln -sf ~/proxy_files/.condarc_proxy ~/.condarc\n     #proxy for git\n     git config --global http.proxy http://proxy_ip:80\n     ln -sf ~/proxy_files/ssh_config_proxy ~/.ssh/config\n}\n\n# Unset Proxy\nfunction unsetproxy() {\n     echo \"Calling unsetproxy\"\n     unset {http,https,ftp}_proxy\n     unset {HTTP,HTTPS,FTP}_PROXY\n     #no proxy for wget\n     ln -sf ~/proxy_files/.wgetrc_noproxy ~/.wgetrc\n     #no proxy for apt\n     #sudo rm -f /etc/apt/apt.conf.d/proxy.conf\n     #no proxy for conda\n     ln -sf ~/proxy_files/.condarc_noproxy ~/.condarc\n     #no proxy for git\n     git config --global --unset http.proxy\n     ln -sf ~/proxy_files/ssh_config_noproxy ~/.ssh/config\n}"
  },
  {
    "objectID": "posts/2021-03-09-clustergit.html",
    "href": "posts/2021-03-09-clustergit.html",
    "title": "Git - How to find all unpushed commits for all projects in a directory?",
    "section": "",
    "text": "Very basic question to help keep my repo clean."
  },
  {
    "objectID": "posts/2021-03-09-clustergit.html#installation-clustergit",
    "href": "posts/2021-03-09-clustergit.html#installation-clustergit",
    "title": "Git - How to find all unpushed commits for all projects in a directory?",
    "section": "Installation clustergit",
    "text": "Installation clustergit\nclustergit seems a good candidate\n\ncd ~/Applications\ngit clone git@github.com:mnagel/clustergit.git\n# add export PATH=\"$PATH:$HOME/Applications/clustergit\" to ~.bashrc\nsource ~.bashrc\nor using .local/bin\ncd ~/Applications/\ngit clone git@github.com:castorfou/clustergit.git\ncd ~\nmkdir -p .local/bin\ncd .local/bin/\nln -s ~/Applications/clustergit/clustergit .\nsource .profile"
  },
  {
    "objectID": "posts/2021-03-09-clustergit.html#usage-clustergit",
    "href": "posts/2021-03-09-clustergit.html#usage-clustergit",
    "title": "Git - How to find all unpushed commits for all projects in a directory?",
    "section": "Usage clustergit",
    "text": "Usage clustergit\nclustergit status\n$ clustergit \nScanning sub directories of .\n./Deep-Reinforcement-Learning-Hands-On  : Changesn .    (1/17)\n./Deep_reinforcement_learning_Course    : Changes\n./ReinforcementLearning_references      : On branch main, Untracked files\n./blog                                  : Untracked files\n./d059                                  : On branch main, Changes\n./data-scientist-skills                 : Clean\n./deeplearning_specialization           : Clean\n./fastai                                : Changes\n./fastai_experiments                    : Changes\n./fastbook                              : Changes\n./gan_specialization                    : Clean\n./hello_nbdev                           : Clean\n./introduction-reinforcement-learning-david-silver: On branch main, Untracked files\n./mit_600.2x Introduction to Computational Thinking and Data Science: Clean\n./mit_6S191_Intro_to_deep_learning      : On branch main, No Changes\n./pytorch_tutorial                      : On branch main, Changes\n./squeezebox                            : On branch main, No Changes\nDone\nclustergit status (detailed)\n$ clustergit -v\n[...]\n---------------- ./squeezebox -----------------\nrunning  LC_ALL=C git status\nOn branch main\nYour branch is up to date with 'origin/main'.\n\nnothing to commit, working tree clean\n\n./squeezebox                            : On branch main, No Changes\n---------------- ./squeezebox -----------------\nDone\nclustergit status (less detailed: hide Clean)\n$ clustergit -H\nScanning sub directories of .\n./d059                                  : On branch main, Changes\n./fastai                                : Changes\n./fastai_experiments                    : Changes\n./fastbook                              : Changes\n./introduction-reinforcement-learning-david-silver: On branch main, Untracked files\n./mit_6S191_Intro_to_deep_learning      : On branch main, No Changes\n./pytorch_tutorial                      : On branch main, Changes\n./squeezebox                            : On branch main, No Changes\nDone\nClean vs On branch main, No Changes\nseems related to branch name. If branch is named master, then clean is displayed.\n(Mar/25 21) I have just changed clustergit to have main as default branch name instead of master (github having set main as the new standard)\nRename everything from master to main\nGit pull, push\nI am not sure I will use it. But allows to recursively launch pull commands to update repos (if no local changes)"
  },
  {
    "objectID": "posts/2021-03-09-clustergit.html#rename-branches-from-main-to-master",
    "href": "posts/2021-03-09-clustergit.html#rename-branches-from-main-to-master",
    "title": "Git - How to find all unpushed commits for all projects in a directory?",
    "section": "Rename branches from main to master",
    "text": "Rename branches from main to master\nRenaming a branch from github website.\nRename branch main to master from github website\n\nUpdate local clones\ngit branch -m main master\ngit fetch origin\ngit branch -u origin/master master"
  },
  {
    "objectID": "posts/2021-03-09-clustergit.html#rename-branches-from-master-to-main-i-know",
    "href": "posts/2021-03-09-clustergit.html#rename-branches-from-master-to-main-i-know",
    "title": "Git - How to find all unpushed commits for all projects in a directory?",
    "section": "Rename branches from master to main (I know)",
    "text": "Rename branches from master to main (I know)\nRenaming a branch from github website.\nRename branch master to main from github website\n\nUpdate local clones\ngit branch -m master main\ngit fetch origin\ngit branch -u origin/main main"
  },
  {
    "objectID": "posts/2021-03-09-clustergit.html#rabbitvcs",
    "href": "posts/2021-03-09-clustergit.html#rabbitvcs",
    "title": "Git - How to find all unpushed commits for all projects in a directory?",
    "section": "RabbitVCS",
    "text": "RabbitVCS\nFrom this page\nInstallation\nsudo apt install rabbitvcs-nautilus\nResult\n\nThese overlay icons are not automatically updated (have to hit Ctrl-F5, it is a cache issue?) Which is not a surprise: number of actions are fired based on file modifications, and here status (commited, pushed) is not at all linked to file modifications. The system doesn’t know that overlay icon should be changed because file was not touched."
  },
  {
    "objectID": "posts/2021-03-09-clustergit.html#git-nautilus-icons",
    "href": "posts/2021-03-09-clustergit.html#git-nautilus-icons",
    "title": "Git - How to find all unpushed commits for all projects in a directory?",
    "section": "git-nautilus-icons",
    "text": "git-nautilus-icons\nJust to check if it works better than RabbitVCS regarding overlay icon cache issue.\nNo I didn’t manage to make it work. Back to RabbitVCS."
  },
  {
    "objectID": "posts/2021-03-09-clustergit.html#activate-git-with-globalprotect",
    "href": "posts/2021-03-09-clustergit.html#activate-git-with-globalprotect",
    "title": "Git - How to find all unpushed commits for all projects in a directory?",
    "section": "Activate git with GlobalProtect",
    "text": "Activate git with GlobalProtect\nmove from ssh to https, keeping password\n$ git remote -v\norigin  git@github.com:castorfou/guillaume_blog.git (fetch)\norigin  git@github.com:castorfou/guillaume_blog.git (push)\nmove to https://github.com/castorfou/guillaume_blog.git\ngit remote set-url origin https://github.com/castorfou/guillaume_blog.git\n\nMake Git store the username and password and it will never ask for them.\n\ngit config --global credential.helper store\n\nSave the username and password for a session (cache it);\n\ngit config --global credential.helper cache\nand to activate trace\n$ GIT_TRACE_PACKET=1 GIT_TRACE=1 GIT_CURL_VERBOSE=1 git fetch\nwe can enrich certificates with Global Protect CA\n~/anaconda3/ssl$ sudo cp certPG.pem /etc/ssl/certs/"
  },
  {
    "objectID": "posts/2021-03-09-clustergit.html#add-a-ca-certificate-in-ubuntu",
    "href": "posts/2021-03-09-clustergit.html#add-a-ca-certificate-in-ubuntu",
    "title": "Git - How to find all unpushed commits for all projects in a directory?",
    "section": "Add a ca-certificate in ubuntu",
    "text": "Add a ca-certificate in ubuntu\n\nGo to /usr/local/share/ca-certificates/\nCreate a new folder, i.e. sudo mkdir school\nCopy the . crt file into the school folder.\nMake sure the permissions are OK (755 for the folder, 644 for the file)\nRun sudo update-ca-certificates\n\nWe should see effects in /etc/ssl/certs\n/etc/ssl/certs$ ll -tr\n[..]\nlrwxrwxrwx 1 root root     86 mars  24 10:02  cert_M_X5C_sase-net-sslfwd-trust-ca.pem -&gt; /usr/local/share/ca-certificates/globalprotect/cert_M_X5C_sase-net-sslfwd-trust-ca.crt\nlrwxrwxrwx 1 root root     39 mars  24 10:02  0dc7de9e.0 -&gt; cert_M_X5C_sase-net-sslfwd-trust-ca.pem"
  },
  {
    "objectID": "posts/2021-04-06-git avec proxy socks.html",
    "href": "posts/2021-04-06-git avec proxy socks.html",
    "title": "using SOCKS5 proxy - with git, apt, pip, …",
    "section": "",
    "text": "using dante server\nInstallation\nsudo apt-get install dante-server\nConf file\nsudo nano /etc/danted.conf\n\nlogoutput: stderr\ninternal: enp3s0 port = 1080\nexternal: enp3s0\nsocksmethod: none\nclientmethod: none\nuser.privileged: proxy\nuser.unprivileged: nobody\nuser.libwrap: nobody\nclient pass {\n        from: 0.0.0.0/0 to: 0.0.0.0/0\n        log: error connect disconnect\n}\nclient block {\n        from: 0.0.0.0/0 to: 0.0.0.0/0\n        log: connect error\n}\nsocks pass {\n        from: 0.0.0.0/0 to: 0.0.0.0/0\n        log: error connect disconnect\n}\nsocks block {\n        from: 0.0.0.0/0 to: 0.0.0.0/0\n        log: connect error\n}\nStart and monitor usage\nsudo service danted restart\ntail -f /var/log/syslog"
  },
  {
    "objectID": "posts/2021-04-06-git avec proxy socks.html#setup-socks5-server",
    "href": "posts/2021-04-06-git avec proxy socks.html#setup-socks5-server",
    "title": "using SOCKS5 proxy - with git, apt, pip, …",
    "section": "",
    "text": "using dante server\nInstallation\nsudo apt-get install dante-server\nConf file\nsudo nano /etc/danted.conf\n\nlogoutput: stderr\ninternal: enp3s0 port = 1080\nexternal: enp3s0\nsocksmethod: none\nclientmethod: none\nuser.privileged: proxy\nuser.unprivileged: nobody\nuser.libwrap: nobody\nclient pass {\n        from: 0.0.0.0/0 to: 0.0.0.0/0\n        log: error connect disconnect\n}\nclient block {\n        from: 0.0.0.0/0 to: 0.0.0.0/0\n        log: connect error\n}\nsocks pass {\n        from: 0.0.0.0/0 to: 0.0.0.0/0\n        log: error connect disconnect\n}\nsocks block {\n        from: 0.0.0.0/0 to: 0.0.0.0/0\n        log: connect error\n}\nStart and monitor usage\nsudo service danted restart\ntail -f /var/log/syslog"
  },
  {
    "objectID": "posts/2021-04-06-git avec proxy socks.html#git-setup",
    "href": "posts/2021-04-06-git avec proxy socks.html#git-setup",
    "title": "using SOCKS5 proxy - with git, apt, pip, …",
    "section": "Git setup",
    "text": "Git setup\n$ cat .ssh/config\nHost github.com\nIdentityFile ~/.ssh/id_rsa_gmail\nProxyCommand /bin/nc -X 5 -x 192.168.50.202:1080 %h %p"
  },
  {
    "objectID": "posts/2021-04-06-git avec proxy socks.html#proxychains",
    "href": "posts/2021-04-06-git avec proxy socks.html#proxychains",
    "title": "using SOCKS5 proxy - with git, apt, pip, …",
    "section": "Proxychains",
    "text": "Proxychains\ninstallation\n# to be downloaded from apt mirrors:\n# libproxychains proxychains\nsudo dpkg -i libproxychains3_3.1-7_amd64.deb proxychains_3.1-7_all.deb\nconfiguration\nsudo vi /etc/proxychains.conf\n\n[ProxyList]\n# add proxy here ...\n# meanwile\n# defaults set to \"tor\"\nsocks5          192.168.50.202  1080\nusage\nsudo proxychains apt update\nsudo proxychains apt upgrade\n\nproxychains pip install pycaret"
  },
  {
    "objectID": "posts/2020-09-09-blogging-from-github.html",
    "href": "posts/2020-09-09-blogging-from-github.html",
    "title": "Blogging from github",
    "section": "",
    "text": "I am a big fan of fastai’s spirit and even more of their leaders: - Jeremy Howards - Rachel Thomas - Sylvain Gugger who is know at huggingface.\nThey are commited to beautiful ideas, and are inspiring people. I like their courses. I like their softwares. For sure I will discuss about fastai. They have created fastpages. It turns github into a blogging platform. I don’t have the full detail but it is explained in fastpages github repo It is based on github actions, and by just creating a repo from a fastpages template https://github.com/fastai/fast_template/generate and giving a couple of settings, you are ready to go.\nAnd here I have to thank Hamel Husain. He is from github company and I think he is behing github actions and helped fastai to release fastpages. I don’t know Hamel but he looks like a humble, terribly skilled guy, with tons of energy. Thanks Hamel.\n\n\n\nMy main audience is the future me. (maybe not entirely true otherwise I would have written in French) In 1 year, I want to turn back to this blog and I would like to see all the learning peaces I went through. I want this platform to be as easy as possible.\n\n\nFor the moment it cannot be easier. I have setup the about page. And each blog entry is just a new markdown page into _posts. github _posts:\n\n\n\ngithub _posts\n\n\nBy commiting this page, there are internal actions being run automatically (through github actions magic) and after a couple of minutes the new blog pages are generated (using Jekyl and ruby if I am not wrong). For the moment I use github web interface. But I guess it is easier to have a local repo of my blog, create new entries and when satisfied git push to github. (to be tested later)\n\n\n\nFor a reason I used my personal github account (guillaume.ramelet@gmail.com) and not my professional one (guillaume.ramelet@michelin.com). I will see later if I have to move to another account. I had some troubles to setup actions into github. For a reason I thought it was available only for organization account. So I have turned my michelin github account to an organization, and I cannot login anymore. To be fixed later.\n\n\n\nOk I am not a huge fan of markdown. I use it as a basic text system specially within notebooks. But it is not as easy to insert images. Currently I screenshot what I want to share, insert into images folder of my repo and reference this image from my blog post using markdown language. I definitely have to improve my practice of markdown, and there are multiple cheatsheets to be used.\n\n\n\nThere are options within fastpages to blog from jupyter notebooks. I have to do it. My intent will be to use this place to share my knowledge. Today most of my knowledge comes from experiences I make within jupyter. If I could directly blog from that it will be great.\n\n\n\nOK as the sole reader this is maybe a minor concern but there is no commenting system associated with fastpages. I cannot get any feedback from these entries. Would love to get advices, create discussions within that blog. Not for today."
  },
  {
    "objectID": "posts/2020-09-09-blogging-from-github.html#fastai-and-fastpages",
    "href": "posts/2020-09-09-blogging-from-github.html#fastai-and-fastpages",
    "title": "Blogging from github",
    "section": "",
    "text": "I am a big fan of fastai’s spirit and even more of their leaders: - Jeremy Howards - Rachel Thomas - Sylvain Gugger who is know at huggingface.\nThey are commited to beautiful ideas, and are inspiring people. I like their courses. I like their softwares. For sure I will discuss about fastai. They have created fastpages. It turns github into a blogging platform. I don’t have the full detail but it is explained in fastpages github repo It is based on github actions, and by just creating a repo from a fastpages template https://github.com/fastai/fast_template/generate and giving a couple of settings, you are ready to go.\nAnd here I have to thank Hamel Husain. He is from github company and I think he is behing github actions and helped fastai to release fastpages. I don’t know Hamel but he looks like a humble, terribly skilled guy, with tons of energy. Thanks Hamel."
  },
  {
    "objectID": "posts/2020-09-09-blogging-from-github.html#my-blog",
    "href": "posts/2020-09-09-blogging-from-github.html#my-blog",
    "title": "Blogging from github",
    "section": "",
    "text": "My main audience is the future me. (maybe not entirely true otherwise I would have written in French) In 1 year, I want to turn back to this blog and I would like to see all the learning peaces I went through. I want this platform to be as easy as possible.\n\n\nFor the moment it cannot be easier. I have setup the about page. And each blog entry is just a new markdown page into _posts. github _posts:\n\n\n\ngithub _posts\n\n\nBy commiting this page, there are internal actions being run automatically (through github actions magic) and after a couple of minutes the new blog pages are generated (using Jekyl and ruby if I am not wrong). For the moment I use github web interface. But I guess it is easier to have a local repo of my blog, create new entries and when satisfied git push to github. (to be tested later)\n\n\n\nFor a reason I used my personal github account (guillaume.ramelet@gmail.com) and not my professional one (guillaume.ramelet@michelin.com). I will see later if I have to move to another account. I had some troubles to setup actions into github. For a reason I thought it was available only for organization account. So I have turned my michelin github account to an organization, and I cannot login anymore. To be fixed later.\n\n\n\nOk I am not a huge fan of markdown. I use it as a basic text system specially within notebooks. But it is not as easy to insert images. Currently I screenshot what I want to share, insert into images folder of my repo and reference this image from my blog post using markdown language. I definitely have to improve my practice of markdown, and there are multiple cheatsheets to be used.\n\n\n\nThere are options within fastpages to blog from jupyter notebooks. I have to do it. My intent will be to use this place to share my knowledge. Today most of my knowledge comes from experiences I make within jupyter. If I could directly blog from that it will be great.\n\n\n\nOK as the sole reader this is maybe a minor concern but there is no commenting system associated with fastpages. I cannot get any feedback from these entries. Would love to get advices, create discussions within that blog. Not for today."
  },
  {
    "objectID": "posts/2021-01-07-datacamp.html",
    "href": "posts/2021-01-07-datacamp.html",
    "title": "About my datacamp learning process",
    "section": "",
    "text": "I started learning with Datacamp in March 2019. This is a great resource and I recommend all datascience newcomers to give it a shot.\nWhat I like are the consistent courses content. There is an overall logic between all courses. And content is just incredible: more than 300 interactive courses. OK maybe you won’t find all of them super useful but at least you can pick what is of interest for you. Following my learning process it takes me about 8 hours to complete a course.\n\n\n\nDatacamp courses\n\n\nCareer tracks are a smart way to help you build a 1st tour in your datascience journey. I followed python programmer (old version), data scientist with python (old version) and machine learning scientist with python tracks. Mileage may vary but it is about 20 courses per track. Updated versions of tracks are now online and this is a mix between courses, projects and skills assessments. I have tested one project but it is a little bit too basic for me.\n\n\n\nDatacamp Career tracks\n\n\nThere is a nice and smooth progress tracking system, and as in a game you earn XP for each achivement.\n\n\n\nDatacamp Progress"
  },
  {
    "objectID": "posts/2021-01-07-datacamp.html#starting-a-project",
    "href": "posts/2021-01-07-datacamp.html#starting-a-project",
    "title": "About my datacamp learning process",
    "section": "Starting a project",
    "text": "Starting a project\nAs an example I will use\n\nwhich is a project from the new Data Scientist career track and which is in my ITP:"
  },
  {
    "objectID": "posts/2021-01-07-datacamp.html#git-repo---data-scientist-skills",
    "href": "posts/2021-01-07-datacamp.html#git-repo---data-scientist-skills",
    "title": "About my datacamp learning process",
    "section": "Git repo - data-scientist-skills",
    "text": "Git repo - data-scientist-skills\nIn my data-scientist-skills github repo, I have 2 folders: * Other datacamp courses - where I keep lectures (pdf slides) from datacamp courses * python-sandbox - where I keep notebooks and data from datacamp exercises\n\ncreation of Data Manipulation with pandas folder under Other datacamp courses\ncreation of data-manipulation-with-pandas folder under python-sandbox\ncopy of python-sandbox/_1project-template/ into python-sandbox/data-manipulation-with-pandas"
  },
  {
    "objectID": "posts/2021-01-07-datacamp.html#datacamp-project-template",
    "href": "posts/2021-01-07-datacamp.html#datacamp-project-template",
    "title": "About my datacamp learning process",
    "section": "Datacamp project template",
    "text": "Datacamp project template\nIn this project template, \n\ndata_from_datacamp will store all data needed to launch datacamp exercises\nexports_py will contain exports of notebooks in txt/py format (usefull to search on code patterns)\nstart_env.sh start_env.bat to launch jupyter notebook from the right conda env\ndownloadfromFileIO.py to download data files from my local notebooks (using in the background file.io)\nuploadfromdatacamp.py to upload data files from datacamp\nuploadfromdatacamp_examples.py some examples to transfer dataframes, dataseries, lists, …"
  },
  {
    "objectID": "posts/2021-01-07-datacamp.html#projects-structure",
    "href": "posts/2021-01-07-datacamp.html#projects-structure",
    "title": "About my datacamp learning process",
    "section": "Projects structure",
    "text": "Projects structure\nAfter initialisation, I have the following structure and content:\n\nOn your left lectures (one per chapter) and final certificate.\nOn your right notebooks."
  },
  {
    "objectID": "posts/2021-01-07-datacamp.html#notebooks-for-exercises",
    "href": "posts/2021-01-07-datacamp.html#notebooks-for-exercises",
    "title": "About my datacamp learning process",
    "section": "Notebooks for exercises",
    "text": "Notebooks for exercises\nJust run the jupyter notebook environment by calling start_env.sh.\nGet the chapter title:\n\nAnd name the notebook accordingly:\n\nThen enter interactive instructions. I copy paste instructions using copy selection as markdown firefox add-on.\n\nHere in this example, if I want to follow instructions locally I need to have homelessness dataframe.\nI can use the following code from uploadfromdatacamp_examples.py\n\n###################\n##### Dataframe\n###################\n\n#upload and download\n\nfrom downloadfromFileIO import saveFromFileIO\n\"\"\" à executer sur datacamp: (apres copie du code uploadfromdatacamp.py)\nuploadToFileIO(homelessness)\n\"\"\"\n\ntobedownloaded=\"\"\"\n{pandas.core.frame.DataFrame: {'homelessness.csv': 'https://file.io/vTM1t2ehXds4'}}\n\"\"\"\nprefixToc='1.1'\nprefix = saveFromFileIO(tobedownloaded, prefixToc=prefixToc, proxy=\"\")\n\n#initialisation\n\nimport pandas as pd\nhomelessness = pd.read_csv(prefix+'homelessness.csv',index_col=0)\n\nBefore executing this cell, I have to copy/paste/execute uploadfromdatacamp.py content on datacamp server. And call\nuploadToFileIO(homelessness)\nThen get the results last line\nIn [2]:\nuploadToFileIO(homelessness)\n \n{\"success\":true,\"key\":\"vTM1t2ehXds4\",\"link\":\"https://file.io/vTM1t2ehXds4\",\"expiry\":\"14 days\"}\n{pandas.core.frame.DataFrame: {'homelessness.csv': 'https://file.io/vTM1t2ehXds4'}}\nand copy it in tobedownloaded variable.\nUpdate prefixTOC to the good value (exercise 1.1 is the 1st one in first chapter) which is used as a prefix in data files. And update local variable name and csv file.\nRun the cell\nHere is the result\nTéléchargements à lancer\n{'pandas.core.frame.DataFrame': {'homelessness.csv': 'https://file.io/vTM1t2ehXds4'}}\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100  2528    0  2528    0     0   4870      0 --:--:-- --:--:-- --:--:--  4870\nAnd homelessness is available to be used.\nFiles downloaded are in data_from_datacamp folder.\n\nAnd running again the cell won’t download file from file.io, but will read the cached file. (delete file to force download)\nFull content of this notebook example at the bottom"
  },
  {
    "objectID": "posts/2021-01-07-datacamp.html#keep-content-in-git",
    "href": "posts/2021-01-07-datacamp.html#keep-content-in-git",
    "title": "About my datacamp learning process",
    "section": "keep content in git",
    "text": "keep content in git\n\n~/git/guillaume/data-scientist-skills$ git add .\n\n~/git/guillaume/data-scientist-skills$ git commit -m 'start of data manipulation in pandas course'\n[master c8696ce] start of data manipulation in pandas course\n 45 files changed, 9010 insertions(+)\n create mode 100644 Other datacamp courses/Data Manipulation with pandas/chapter1.pdf\n create mode 100644 python-sandbox/data-manipulation-with-pandas/.ipynb_checkpoints/chapter1 - Transforming Data-checkpoint.ipynb\n create mode 100644 python-sandbox/data-manipulation-with-pandas/__pycache__/downloadfromFileIO.cpython-37.pyc\n create mode 100644 python-sandbox/data-manipulation-with-pandas/chapter1 - Transforming Data.ipynb\n create mode 100644 python-sandbox/data-manipulation-with-pandas/data_from_datacamp/.empty_dir.txt\n create mode 100644 python-sandbox/data-manipulation-with-pandas/data_from_datacamp/chapter1 - Transforming Data-Exercise1.1_3277903540843719836.lock\n create mode 100644 python-sandbox/data-manipulation-with-pandas/data_from_datacamp/chapter1 - Transforming Data-Exercise1.1_homelessness.csv\n create mode 100644 python-sandbox/data-manipulation-with-pandas/downloadfromFileIO.py\n create mode 100644 python-sandbox/data-manipulation-with-pandas/exports_py/.empty_dir.txt\n create mode 100644 python-sandbox/data-manipulation-with-pandas/exports_py/Untitled.py\n create mode 100644 python-sandbox/data-manipulation-with-pandas/exports_py/Untitled.txt\n create mode 100644 python-sandbox/data-manipulation-with-pandas/exports_py/chapter1 - Transforming Data.py\n create mode 100644 python-sandbox/data-manipulation-with-pandas/start_env.bat\n create mode 100755 python-sandbox/data-manipulation-with-pandas/start_env.sh\n create mode 100644 python-sandbox/data-manipulation-with-pandas/uploadfromdatacamp.py\n create mode 100644 python-sandbox/data-manipulation-with-pandas/uploadfromdatacamp_examples.py\n\n~/git/guillaume/data-scientist-skills$ git push\nEnumerating objects: 43, done.\nCounting objects: 100% (43/43), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (38/38), done.\nWriting objects: 100% (40/40), 5.75 MiB | 3.85 MiB/s, done.\nTotal 40 (delta 8), reused 1 (delta 0)\nremote: Resolving deltas: 100% (8/8), completed with 3 local objects.\nTo github.com:castorfou/data-scientist-skills.git\n   89f60e5..c8696ce  master -&gt; master"
  },
  {
    "objectID": "posts/2021-01-07-datacamp.html#update-progress-in-itp",
    "href": "posts/2021-01-07-datacamp.html#update-progress-in-itp",
    "title": "About my datacamp learning process",
    "section": "Update progress in ITP",
    "text": "Update progress in ITP\nDatacamp is giving instant progress\n\nSo I regularly report this progress (here 0.18/4=5%) in ITP."
  },
  {
    "objectID": "posts/2021-01-07-datacamp.html#keep-certificates",
    "href": "posts/2021-01-07-datacamp.html#keep-certificates",
    "title": "About my datacamp learning process",
    "section": "keep certificates",
    "text": "keep certificates\nI download and keep certificates with lectures."
  },
  {
    "objectID": "posts/2020-10-06-gan-specialization-course1-week2-deep_convolutional_gan.html",
    "href": "posts/2020-10-06-gan-specialization-course1-week2-deep_convolutional_gan.html",
    "title": "GAN Specialization course 1 week 2 - Deep Convolutional GAN",
    "section": "",
    "text": "My notes\n\n\n\nalt text"
  },
  {
    "objectID": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html",
    "href": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html",
    "title": "Machine learning in python with scikit-learn",
    "section": "",
    "text": "This is a MOOC by Inria team, in charge of scikit-learn.\nSyllabus\nIntroduction: Machine Learning concepts, then\nModule 1. The Predictive Modeling Pipeline\nModule 2. Selecting the best model\nModule 3. Hyperparameter tuning\nModule 4. Linear Models\nModule 5. Decision tree models\nModule 6. Ensemble of models\nModule 7. Evaluating model performance\nINRIA github contains everything of this mooc: slides, datasets, notebooks (not videos)\nI have forked it, and I use local envt for assignments."
  },
  {
    "objectID": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#introduction---machine-learning-concepts",
    "href": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#introduction---machine-learning-concepts",
    "title": "Machine learning in python with scikit-learn",
    "section": "Introduction - Machine Learning concepts",
    "text": "Introduction - Machine Learning concepts\nslides"
  },
  {
    "objectID": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-1.-the-predictive-modeling-pipeline",
    "href": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-1.-the-predictive-modeling-pipeline",
    "title": "Machine learning in python with scikit-learn",
    "section": "Module 1. The Predictive Modeling Pipeline",
    "text": "Module 1. The Predictive Modeling Pipeline\n\nModule overview\n\nThe objective in the module are the following:\n\nbuild intuitions regarding an unknown dataset;\nidentify and differentiate numerical and categorical features;\ncreate an advanced predictive pipeline with scikit-learn.\n\n\n\n\nTabular data exploration\nexploration of data: 01_tabular_data_exploration.ipynb\nexercise M1.01: 01_tabular_data_exploration_ex_01.ipynb\n\n\nFitting a scikit-learn model on numerical data\nfirst model with scikit-learn: 02_numerical_pipeline_introduction.ipynb\nexercise M1.02: 02_numerical_pipeline_ex_00.ipynb\nworking with numerical data: 02_numerical_pipeline_hands_on.ipynb\nexercise M1.03: 02_numerical_pipeline_ex_01.ipynb\npreprocessing for numerical features: 02_numerical_pipeline_scaling.ipynb\n\n\nHandling categorical data\nEncoding of categorical variables: 03_categorical_pipeline.ipynb\n\nThus, in general OneHotEncoder is the encoding strategy used when the downstream models are linear models while OrdinalEncoder is used with tree-based models.\n\nExercise M1.04: 03_categorical_pipeline_ex_01.ipynb\nUsing numerical and categorical variables together: 03_categorical_pipeline_column_transformer.ipynb\nExercise M1.05: 03_categorical_pipeline_ex_02.ipynb\n\n\nWrap-up quiz\nmodule 1 - wrap-up quizz.ipynb"
  },
  {
    "objectID": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-2.-selecting-the-best-model",
    "href": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-2.-selecting-the-best-model",
    "title": "Machine learning in python with scikit-learn",
    "section": "Module 2. Selecting the best model",
    "text": "Module 2. Selecting the best model\n\nModule overview\n\nThe objective in the module are the following:\n\nunderstand the concept of overfitting and underfitting;\nunderstand the concept of generalization;\nunderstand the general cross-validation framework used to evaluate a model.\n\n\n\n\nOverfitting and Underfitting\nvideo and slides\n\n\nThe framework and why do we need it: cross_validation_train_test.ipynb\n\n\nValidation and learning curves\nvideo and slides\n\n\nOverfit-generalization-underfit: cross_validation_validation_curve.ipynb\nEffect of the sample size in cross-validation: cross_validation_learning_curve.ipynb\nExercise M2.01: cross_validation_ex_01.ipynb solution\n\n\nBias versus variance trade-off\nvideo and slides\n\n\n\n\n\nWrap-up quiz\nmodule 2 - wrap-up quizz.ipynb\n\n\nOverfitting is caused by the limited size of the training set, the noise in the data, and the high flexibility of common machine learning models.\nUnderfitting happens when the learnt prediction functions suffer from systematic errors. This can be caused by a choice of model family and parameters, which leads to a lack of flexibility to capture the repeatable structure of the true data generating process.\nFor a fixed training set, the objective is to minimize the test error by adjusting the model family and its parameters to find the best trade-off between overfitting for underfitting.\nFor a given choice of model family and parameters, increasing the training set size will decrease overfitting but can also cause an increase of underfitting.\nThe test error of a model that is neither overfitting nor underfitting can still be high if the variations of the target variable cannot be fully determined by the input features. This irreducible error is caused by what we sometimes call label noise. In practice, this often happens when we do not have access to important features for one reason or another."
  },
  {
    "objectID": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-3.-hyperparameter-tuning",
    "href": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-3.-hyperparameter-tuning",
    "title": "Machine learning in python with scikit-learn",
    "section": "Module 3. Hyperparameter tuning",
    "text": "Module 3. Hyperparameter tuning\n\nModule overview\n\nThe objective in the module are the following:\n\nunderstand what is a model hyperparameter;\nunderstand how to get and set the value an hyperparameter of a scikit-learn model;\nbe able to fine tune a full predictive modeling pipeline;\nunderstand and visualize the combination of parameters that improves the performance of a model.\n\n\n\n\nManual tuning\nSet and get hyperparameters in scikit-learn: parameter_tuning_manual.ipynb\nExercise M3.01: parameter_tuning_ex_02.ipynb\n\n\nAutomated tuning\nHyperparameter tuning by grid-search: parameter_tuning_grid_search.ipynb\nHyperparameter tuning by randomized-search: parameter_tuning_randomized_search.ipynb\nCross-validation and hyperparameter tuning: parameter_tuning_nested.ipynb\nExercise M3.01: parameter_tuning_ex_03.ipynb solution\n\nNice to play with interactive plotly parallel_coordinates to identify best params.\nimport numpy as np\nimport pandas as pd\nimport plotly.express as px\ndef shorten_param(param_name):\n    if \"__\" in param_name:\n        return param_name.rsplit(\"__\", 1)[1]\n    return param_name\ncv_results = pd.read_csv(\"../figures/randomized_search_results.csv\",\n                         index_col=0)\n\nfig = px.parallel_coordinates(\n    cv_results.rename(shorten_param, axis=1).apply({\n        \"learning_rate\": np.log10,\n        \"max_leaf_nodes\": np.log2,\n        \"max_bins\": np.log2,\n        \"min_samples_leaf\": np.log10,\n        \"l2_regularization\": np.log10,\n        \"mean_test_score\": lambda x: x}),\n    color=\"mean_test_score\",\n    color_continuous_scale=px.colors.sequential.Viridis,\n)\nfig.show()\n\n\nWrap-up quiz\nmodule 3 - wrap-up quizz.ipynb\n\n\nHyperparameters have an impact on the models’ performance and should be wisely chosen;\nThe search for the best hyperparameters can be automated with a grid-search approach or a randomized search approach;\nA grid-search is expensive and does not scale when the number of hyperparameters to optimize increase. Besides, the combination are sampled only on a regular grid.\nA randomized-search allows a search with a fixed budget even with an increasing number of hyperparameters. Besides, the combination are sampled on a non-regular grid."
  },
  {
    "objectID": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-4.-linear-models",
    "href": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-4.-linear-models",
    "title": "Machine learning in python with scikit-learn",
    "section": "Module 4. Linear models",
    "text": "Module 4. Linear models\n\nModule overview\n\nIn this module, your objectives are to:\n\nunderstand the linear models parametrization;\nunderstand the implication of linear models in both regression and classification;\nget intuitions of linear models applied in higher dimensional dataset;\nunderstand the effect of regularization and how to set it;\nunderstand how linear models can be used even with data showing non-linear relationship with the target to be predicted.\n\n\n\n\nIntuitions on linear models\nvideo and slides\n\n\nFor regression: linear regression\nfrom sklearn.linear_model import LinearRegression\nlinear_regression = LinearRegression()\nlinear_regression.fit(X, y)\nFor classification: logistic regression\nfrom sklearn.linear_model import LogisticRegression\nlog_reg = LogisticRegression()\nlog_reg.fit(X, y)\n\n\nLinear regression\nLinear regression without scikit-learn: linear_regression_without_sklearn.ipynb\nExercise M4.01: linear_models_ex_01.ipynb solution\nusage of np.ravel in\ndef goodness_fit_measure(true_values, predictions):\n    # we compute the error between the true values and the predictions of our model\n    errors = np.ravel(true_values) - np.ravel(predictions)\n    return np.mean(np.abs(errors))\nLinear regression using scjkit-learn: linear_regression_in_sklearn.ipynb\nfrom sklearn.metrics import mean_squared_error\ninferred_body_mass = linear_regression.predict(data)\nmodel_error = mean_squared_error(target, inferred_body_mass)\nprint(f\"The mean squared error of the optimal model is {model_error:.2f}\")\n\n\nModeling non-linear features-target relationships\nExercise M4.02: linear_models_ex_02.ipynb solution\nLinear regression with non-linear link between data and target: linear_regression_non_linear_link.ipynb\nExercise M4.03: linear_models_ex_03.ipynb solution\n\n\nRegularization in linear model\nvideo and slides\n\n\nRidge regression\nfrom sklearn.linear_model import Ridge\nmodel = Ridge(alpha=0.01).fit(X, y)\nalways use Ridge with a carefully tuned alpha!\nfrom sklearn.linear_model import RidgeCV\nmodel = RidgeCV( alphas=[0.001, 0.1, 1, 10, 1000] )\nmodel.fit(X, y)\nprint(model.alpha_)\nRegularization of linear regression model: linear_models_regularization.ipynb\nExercise M4.04: linear_models_ex_04.ipynb solution\n\n\nLinear model for classification\nLinear model for classification: logistic_regression.ipynb\nExercise M4.05: linear_models_ex_05.ipynb solution\nBeyond linear separation in classification: logistic_regression_non_linear.ipynb\n\n\nWrap-up quiz\nmodule 4 - wrap-up quizz.ipynb\n\nIn this module, we saw that:\n\nthe predictions of a linear model depend on a weighted sum of the values of the input features added to an intercept parameter;\nfitting a linear model consists in adjusting both the weight coefficients and the intercept to minimize the prediction errors on the training set;\nto train linear models successfully it is often required to scale the input features approximately to the same dynamic range;\nregularization can be used to reduce over-fitting: weight coefficients are constrained to stay small when fitting;\nthe regularization hyperparameter needs to be fine-tuned by cross-validation for each new machine learning problem and dataset;\nlinear models can be used on problems where the target variable is not linearly related to the input features but this requires extra feature engineering work to transform the data in order to avoid under-fitting."
  },
  {
    "objectID": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-5.-decision-tree-models",
    "href": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-5.-decision-tree-models",
    "title": "Machine learning in python with scikit-learn",
    "section": "Module 5. Decision tree models",
    "text": "Module 5. Decision tree models\n\nModule overview\n\nThe objective in the module are the following:\n\nunderstand how decision trees are working in classification and regression;\ncheck which tree parameters are important and their influences.\n\n\n\n\nIntuitions on tree-based models\nvideo and slides\n\n\n\n\nDecision tree in classification\nBuild a classification decision tree: trees_classification.ipynb\nExercise M5.01: trees_ex_01.ipynb solution\nFit and decision boundaries\nfrom sklearn.tree import DecisionTreeClassifier\nimport seaborn as sns\n\n# create a palette to be used in the scatterplot\npalette = [\"tab:red\", \"tab:blue\", \"black\"]\n\ntree = DecisionTreeClassifier(max_depth=2)\ntree.fit(data_train, target_train)\n\nax = sns.scatterplot(data=penguins, x=culmen_columns[0], y=culmen_columns[1],\n                     hue=target_column, palette=palette)\nplot_decision_function(tree, range_features, ax=ax)\nplt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n_ = plt.title(\"Decision boundary using a decision tree\")\nDecision tree\nfrom sklearn.tree import plot_tree\n\n_, ax = plt.subplots(figsize=(17, 12))\n_ = plot_tree(tree, feature_names=culmen_columns,\n              class_names=tree.classes_, impurity=False, ax=ax)\nAccuracy\ntree.fit(data_train, target_train)\ntest_score = tree.score(data_test, target_test)\nprint(f\"Accuracy of the DecisionTreeClassifier: {test_score:.2f}\")\n\n\nDecision tree in regression\nDecision tree for regression: trees_regression.ipynb\nExercise M5.02: trees_ex_02.ipynb solution\n\n\nHyperparameters of decision tree\nImportance of decision tree hyperparameters on generalization: trees_hyperparameters.ipynb\n\n\nWrap-up quiz\nmodule 5 - wrap-up quizz.ipynb\nMain take-away | Main take-away | 41026 Courseware | FUN-MOOC\n\nIn this module, we presented decision trees in details. We saw that they:\n\nare suited for both regression and classification problems;\nare non-parametric models;\nare not able to extrapolate;\nare sensible to hyperparameter tuning."
  },
  {
    "objectID": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-6.-ensemble-of-models",
    "href": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-6.-ensemble-of-models",
    "title": "Machine learning in python with scikit-learn",
    "section": "Module 6. Ensemble of models",
    "text": "Module 6. Ensemble of models\n\nModule overview\n\nThe objective in the module are the following:\n\nunderstanding the principles behind bootstrapping and boosting;\nget intuitions with specific models such as random forest and gradient boosting;\nidentify the important hyperparameters of random forest and gradient boosting decision trees as well as their typical values.\n\n\n\n\nIntuitions on ensemble of tree-based models\nvideo and slides\n\n\n“Bagging” stands for Bootstrap AGGregatING. It uses bootstrap resampling (random sampling with replacement) to learn several models on random variations of the training set. At predict time, the predictions of each learner are aggregated to give the final predictions.\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nRandom Forests are bagged randomized decision trees\n\nAt each split: a random subset of features are selected\nThe best split is taken among the restricted subset\nExtra randomization decorrelates the prediction errors\nUncorrelated errors make bagging work better\n\nGradient Boosting\n\nEach base model predicts the negative error of previous models\nsklearn use decision trees as the base model\n\nfrom sklearn.ensemble import GradientBoostingClassifier\n\nImplementation of the traditional (exact) method\nFine for small data sets\nToo slow for n_samples &gt; 10,000\n\nfrom sklearn.ensemble import HistGradientBoostingClassifier\n\nDiscretize numerical features (256 levels)\nEfficient multi core implementation\nMuch, much faster when n_samples is large\n\nTake away\n\nBagging and random forests fit trees independently\n\neach deep tree overfits individually\naveraging the tree predictions reduces overfitting\n\n(Gradient) boosting fits trees sequentially\n\neach shallow tree underfits individually\nsequentially adding trees reduces underfitting\n\nGradient boosting tends to perform slightly better than bagging and random forest and furthermore shallow trees predict faster.\n\nIntroductory example to ensemble models: ensemble_introduction.ipynb\n\n\nEnsemble method using bootstrapping\nBagging: ensemble_bagging.ipynb\nWikipedia reference to bootstrapping in statistics.\nExercise M6.01: ensemble_ex_01.ipynb (solution)\nRandom Forest: ensemble_random_forest.ipynb\nExercise M6.01: ensemble_ex_02.ipynb (solution)\n\n\nEnsemble method using boosting\nAdaptive Boosting (AdaBoost): ensemble_adaboost.ipynb\nExercise M6.03: ensemble_ex_03.ipynb (solution)\nGradient-boosting decision tree (GBDT): ensemble_gradient_boosting.ipynb\nExercise M6.04: ensemble_ex_04.ipynb (solution)\nSpeeding-up gradient-boosting: ensemble_hist_gradient_boosting.ipynb\n\n\nHyperparameter tuning with ensemble methods\nHyperparameter tuning: ensemble_hyperparameters.ipynb\nExercise M6.05: ensemble_ex_05.ipynb (solution)\n\n\nWrap-up quiz\nmodule 6 - wrap-up quizz.ipynb\nUse of Imbalanced-learn library relying on scikit-learn and provides methods to deal with classification with imbalanced classes."
  },
  {
    "objectID": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-7.-evaluating-model-performance",
    "href": "posts/2021-05-21-Machine-learning-in-python-with-scikit-learn.html#module-7.-evaluating-model-performance",
    "title": "Machine learning in python with scikit-learn",
    "section": "Module 7. Evaluating model performance",
    "text": "Module 7. Evaluating model performance\n\nModule overview\n\nThe objective in the module are the following:\n\nunderstand the necessity of using an appropriate cross-validation strategy depending on the data;\nget the intuitions behind comparing a model with some basic models that can be used as baseline;\nunderstand the principles behind using nested cross-validation when the model needs to be evaluated as well as optimized;\nunderstand the differences between regression and classification metrics;\nunderstand the differences between metrics.\n\n\n\n\nComparing a model with simple baselines\nComparing results with baseline and chance level: cross_validation_baseline.ipynb\nExercise M7.01: cross_validation_ex_02.ipynb (solution)\n\n\nChoice of cross-validation\nIntroductory exercise regarding stratification: cross_validation_ex_03.ipynb\nStratification: cross_validation_stratification.ipynb\nIntroductory exercise for sample grouping: cross_validation_ex_04.ipynb\nSample grouping: cross_validation_grouping.ipynb\nIntroductory exercise for non i.i.d. data: cross_validation_ex_05.ipynb\nNon i.i.d. data: cross_validation_time.ipynb\n\n\nNested cross-validation\nNested cross-validation: cross_validation_nested.ipynb\n\n\nIntroduction of the evaluation metrics: Classification metrics\nClassification: metrics_classification.ipynb\nExercise M7.02: metrics_ex_01.ipynb (solution)\n\n\nIntroduction of the evaluation metrics: Regression metrics\nRegression: metrics_regression.ipynb\nExercise M7.03: metrics_ex_02.ipynb (solution)\n\n\nWrap-up quiz\nmodule 7 - wrap-up quizz.ipynb\nAnd this completes the course"
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html",
    "href": "posts/2021-01-12-nbdev_tutorial.html",
    "title": "Hello nbdev",
    "section": "",
    "text": "Everything is under nbdev website.\n3 resources worth to be mentioning: * nbdev tutorial video on youtube; 1 year old but seems still valid * nbdev tutorial page * nbdev github repo\nWhat I plan to do is to watch the video part, and keep note of my progress in this blog entry."
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#repo-creation",
    "href": "posts/2021-01-12-nbdev_tutorial.html#repo-creation",
    "title": "Hello nbdev",
    "section": "repo creation",
    "text": "repo creation\nAs suggested by Jeremy, I start by creating a github repo named hello_nbdev from a nbdev template.\nIt is just about clicking this link: https://github.com/fastai/nbdev_template/generate. If I am logged in github it will show the proper page."
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#github-pages",
    "href": "posts/2021-01-12-nbdev_tutorial.html#github-pages",
    "title": "Hello nbdev",
    "section": "github pages",
    "text": "github pages\nDocumentation will be hosted at github (can be hosted anywhere but github seems a straightforward option) and to do that we have to setup github pages:\n\nSettings &gt; Options &gt; Github pages &gt; Source &gt; Master (branch) &gt; /docs (folder) &gt; Save\n\nAnd when done \nNow we can insert this doc url as our repo website setting:\n\nrepo home &gt; &lt;&gt; code &gt; about (edit repo details) &gt; Website"
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#edit-settings.ini",
    "href": "posts/2021-01-12-nbdev_tutorial.html#edit-settings.ini",
    "title": "Hello nbdev",
    "section": "Edit settings.ini",
    "text": "Edit settings.ini\nEverything is in this file.\nJust edit directly from github.\nlib_name = nbdev_template\n# For Enterprise Git add variable repo_name and company name\n# repo_name = analytics\n# company_name = nike\n\nuser = fastai\n# description = A description of your project\n# keywords = some keywords\n# author = Your Name\n# author_email = email@example.com\n# copyright = Your Name or Company Name\nto\nlib_name = hello_nbdev\nuser = castorfou\ndescription = A tutorial walkthrough with nbdev\nkeywords = fastai nbdev tutorial\nauthor = Guillaume Ramelet\nauthor_email = guillaume.ramelet@gmail.com\ncopyright = Guillaume R.\nand commit changes"
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#clone-repo",
    "href": "posts/2021-01-12-nbdev_tutorial.html#clone-repo",
    "title": "Hello nbdev",
    "section": "Clone repo",
    "text": "Clone repo\n~/git/guillaume$ git clone git@github.com:castorfou/hello_nbdev.git\nCloning into 'hello_nbdev'...\nremote: Enumerating objects: 106, done.\nremote: Counting objects: 100% (106/106), done.\nremote: Compressing objects: 100% (94/94), done.\nremote: Total 106 (delta 7), reused 81 (delta 4), pack-reused 0\nReceiving objects: 100% (106/106), 1.02 MiB | 2.45 MiB/s, done.\nResolving deltas: 100% (7/7), done."
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#setup-nbdev-python-environment",
    "href": "posts/2021-01-12-nbdev_tutorial.html#setup-nbdev-python-environment",
    "title": "Hello nbdev",
    "section": "Setup nbdev python environment",
    "text": "Setup nbdev python environment\nIt is not specifically mentionned in the video. For this walkthrough I will use my existing fastai environment.\n~/git/guillaume$ conda activate fastai\n~/git/guillaume$ nbdev_\nnbdev_build_docs         nbdev_diff_nbs           nbdev_test_nbs\nnbdev_build_lib          nbdev_fix_merge          nbdev_trust_nbs\nnbdev_bump_version       nbdev_install_git_hooks  nbdev_update_lib\nnbdev_clean_nbs          nbdev_nb2md              nbdev_upgrade\nnbdev_conda_package      nbdev_new                \nnbdev_detach             nbdev_read_nbs\nAs expected nbdev is already integrated in it.\nOtherwise my guess is that I have to run conda install -c fastai nbdev under my python env."
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#install-git-hooks",
    "href": "posts/2021-01-12-nbdev_tutorial.html#install-git-hooks",
    "title": "Hello nbdev",
    "section": "Install git hooks",
    "text": "Install git hooks\n(fastai) ~/git/guillaume/hello_nbdev$ nbdev_install_git_hooks \nExecuting: git config --local include.path ../.gitconfig\nSuccess: hooks are installed and repo's .gitconfig is now trusted\n\ndeal with conflicts\nIf needed in case of conflict, Jeremy explains one can call nbdev_fix_merge filename.ipynb and it will use the standard conflict marker to help you identify and fix the conflict."
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#open-00_core.ipynb",
    "href": "posts/2021-01-12-nbdev_tutorial.html#open-00_core.ipynb",
    "title": "Hello nbdev",
    "section": "Open 00_core.ipynb",
    "text": "Open 00_core.ipynb\n\ncreate lib (we start with a core module)\nJust following Jeremy’s instructions. * Create say_hello function * Use it (example) * Test it (assert)\n\n\nbuild_lib\nWe can call nbdev_build_lib from anywhere in the repo.\n(fastai) ~/git/guillaume/hello_nbdev$ nbdev_build_lib \nConverted 00_core.ipynb.\nConverted index.ipynb.\nand it creates files, under hello_nbdev\nhello_nbdev$ ls hello_nbdev/\ncore.py  __init__.py  _nbdev.py  __pycache__\n\n\nModule Documentation\nThere are 2 levels of documentation. Documentation for your library that will be in index.ipynb and documentation for your modules that will be directly created from your code/notebooks 00_core.ipynb, etc\nAnd to generate this documentation it will be just a matter of calling nbdev_build_docs."
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#library-documentation-into-index.ipynb",
    "href": "posts/2021-01-12-nbdev_tutorial.html#library-documentation-into-index.ipynb",
    "title": "Hello nbdev",
    "section": "Library documentation into index.ipynb",
    "text": "Library documentation into index.ipynb\n\ncreate doc\nDocumentation (what will be puclished) is in index.ipynb.\nThis is an actual documentation. Documentation won’t be written in markdown. It will be executed as code and rendered as such. How great is that.\nTo make it happen we have to import our lib just freshly generated.\nAnd now we can use all the part of our lib to explain how it works and why it is great.\n\nsay_hello(\"Guillaume\")\n\n'Hello Guillaume!'\n\n\n\n\nbuild_docs\nWe have to call nbdev_build_docs from our repo root.\n(fastai) ~/git/guillaume/hello_nbdev$ nbdev_build_docs \nconverting: /home/explore/git/guillaume/hello_nbdev/00_core.ipynb\nconverting /home/explore/git/guillaume/hello_nbdev/index.ipynb to README.md\n\n\ncommit to publish docs\nHere is the list of files to be pushed:\ngit status\n\nChanges to be committed:\n    modified:   00_core.ipynb\n    new file:   00_core.py\n    new file:   Makefile\n    modified:   README.md\n    new file:   docs/_config.yml\n    modified:   docs/_data/sidebars/home_sidebar.yml\n    new file:   docs/_data/topnav.yml\n    new file:   docs/core.html\n    new file:   docs/index.html\n    modified:   docs/sidebar.json\n    new file:   hello_nbdev/__init__.py\n    new file:   hello_nbdev/_nbdev.py\n    new file:   hello_nbdev/core.py\n    modified:   index.ipynb\n    new file:   index.py\n\ninit.py\nJust add from .core import * to __init__.py\n\n!cat /home/explore/git/guillaume/hello_nbdev/hello_nbdev/__init__.py\n\n__version__ = \"0.0.1\"\nfrom .core import *\n\n\nSo that we can easily use hello_nbdev without mentioning core module\n\n\ncommit and push\n(fastai) ~/git/guillaume/hello_nbdev$ git commit -m 'initial commit'\n[master 3484db7] initial commit\n 15 files changed, 520 insertions(+), 31 deletions(-)\n create mode 100644 00_core.py\n create mode 100644 Makefile\n create mode 100644 docs/_config.yml\n create mode 100644 docs/_data/topnav.yml\n create mode 100644 docs/core.html\n create mode 100644 docs/index.html\n create mode 100644 hello_nbdev/__init__.py\n create mode 100644 hello_nbdev/_nbdev.py\n create mode 100644 hello_nbdev/core.py\n create mode 100644 index.py\n(fastai) ~/git/guillaume/hello_nbdev$ git push\nEnumerating objects: 30, done.\nCounting objects: 100% (30/30), done.\nDelta compression using up to 12 threads\nCompressing objects: 100% (19/19), done.\nWriting objects: 100% (21/21), 4.87 KiB | 2.44 MiB/s, done.\nTotal 21 (delta 7), reused 0 (delta 0)\nremote: Resolving deltas: 100% (7/7), completed with 5 local objects.\nremote: \nremote: GitHub found 1 vulnerability on castorfou/hello_nbdev's default branch (1 low). To find out more, visit:\nremote:      https://github.com/castorfou/hello_nbdev/security/dependabot/docs/Gemfile.lock/nokogiri/open\nremote: \nTo github.com:castorfou/hello_nbdev.git\n   3aec9f4..3484db7  master -&gt; master\n\n\n\nAnd documentation is ready\nhttps://castorfou.github.io/hello_nbdev/"
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#classes",
    "href": "posts/2021-01-12-nbdev_tutorial.html#classes",
    "title": "Hello nbdev",
    "section": "Classes",
    "text": "Classes\nFollowing tutorial, we can create class HelloSayer and document our methods by calling show_doc(HelloSayer.say).\nWe can decide to add entries into index.ipynb if this is something worth having at the library level."
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#autoreload",
    "href": "posts/2021-01-12-nbdev_tutorial.html#autoreload",
    "title": "Hello nbdev",
    "section": "autoreload",
    "text": "autoreload\nBy adding these lines\n\n%load_ext autoreload\n%autoreload 2\n\nyour notebook automatically reads in the new modules as soon as the python file changes"
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#launch-nbdev-scripts-directly-from-jupyter",
    "href": "posts/2021-01-12-nbdev_tutorial.html#launch-nbdev-scripts-directly-from-jupyter",
    "title": "Hello nbdev",
    "section": "launch nbdev scripts directly from jupyter",
    "text": "launch nbdev scripts directly from jupyter\nMake it your last cell\n\nfrom nbdev.export import notebook2script; notebook2script()\n\nConverted 00_core.ipynb.\nConverted index.ipynb."
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#run-tests-in-parallel",
    "href": "posts/2021-01-12-nbdev_tutorial.html#run-tests-in-parallel",
    "title": "Hello nbdev",
    "section": "run tests in parallel",
    "text": "run tests in parallel\nJust run nbdev_test_nbs\nIf your notebook starts with _, it will be excluded from the test list."
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#installation-and-setup",
    "href": "posts/2021-01-12-nbdev_tutorial.html#installation-and-setup",
    "title": "Hello nbdev",
    "section": "Installation and setup",
    "text": "Installation and setup\nFrom https://jekyllrb.com/docs/installation/ubuntu/,\nsudo apt-get install ruby-full build-essential zlib1g-dev\nInstall variables to use gem:\necho '# Install Ruby Gems to ~/gems' &gt;&gt; ~/.bashrc\necho 'export GEM_HOME=\"$HOME/gems\"' &gt;&gt; ~/.bashrc\necho 'export PATH=\"$HOME/gems/bin:$PATH\"' &gt;&gt; ~/.bashrc\nsource ~/.bashrc\nInstall Jekyll and Builder:\ngem install jekyll bundler"
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#setup-our-lib-to-use-jekyll",
    "href": "posts/2021-01-12-nbdev_tutorial.html#setup-our-lib-to-use-jekyll",
    "title": "Hello nbdev",
    "section": "Setup our lib to use Jekyll",
    "text": "Setup our lib to use Jekyll\nFrom our docs folder, launch bundle install\n(fastai) ~/git/guillaume/hello_nbdev/docs$ bundle install\nFetching gem metadata from https://rubygems.org/.........\nUsing concurrent-ruby 1.1.7\n....\nBundle complete! 4 Gemfile dependencies, 90 gems now installed.\nUse `bundle info [gemname]` to see where a bundled gem is installed."
  },
  {
    "objectID": "posts/2021-01-12-nbdev_tutorial.html#use-it",
    "href": "posts/2021-01-12-nbdev_tutorial.html#use-it",
    "title": "Hello nbdev",
    "section": "Use it",
    "text": "Use it\nFrom repo root, launch make docs_serve\n(fastai) ~/git/guillaume/hello_nbdev$ make docs_serve\ncd docs && bundle exec jekyll serve\nConfiguration file: /home/explore/git/guillaume/hello_nbdev/docs/_config.yml\n            Source: /home/explore/git/guillaume/hello_nbdev/docs\n       Destination: /home/explore/git/guillaume/hello_nbdev/docs/_site\n Incremental build: disabled. Enable with --incremental\n      Generating... \n   GitHub Metadata: No GitHub API authentication could be found. Some fields may be missing or have incorrect data.\n                    done in 0.098 seconds.\n/home/explore/gems/gems/pathutil-0.16.2/lib/pathutil.rb:502: warning: Using the last argument as keyword parameters is deprecated\n Auto-regeneration: enabled for '/home/explore/git/guillaume/hello_nbdev/docs'\n    Server address: http://127.0.0.1:4000/hello_nbdev//\n  Server running... press ctrl-c to stop.\nIt is available locally at http://127.0.0.1:4000/hello_nbdev/"
  },
  {
    "objectID": "posts/2023-04-24-extract-python-scripts-with-nbdev.html",
    "href": "posts/2023-04-24-extract-python-scripts-with-nbdev.html",
    "title": "Python scripts from notebooks",
    "section": "",
    "text": "I use nbdev to write python libraries (I will create a blog entry explaining that).\nAnd used it to blog (now only using quarto)\nSometimes you need something lighter just to export part of notebooks and reused it elsewhere (in another notebook for example).\nIn the old time of fastai, I used a script from Jeremy Howard (see Generate python modules from jupyter notebooks)\nI want to update this method and use nbdev."
  },
  {
    "objectID": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#installation",
    "href": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#installation",
    "title": "Python scripts from notebooks",
    "section": "installation",
    "text": "installation\nconda activate &lt;my_env&gt;\nconda install -c fastai nbdev"
  },
  {
    "objectID": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#update",
    "href": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#update",
    "title": "Python scripts from notebooks",
    "section": "update",
    "text": "update\nJust re-run conda install -c fastai nbdev"
  },
  {
    "objectID": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#display-version",
    "href": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#display-version",
    "title": "Python scripts from notebooks",
    "section": "display version",
    "text": "display version\n\nimport nbdev\n\nnbdev.__version__\n\n'2.3.12'"
  },
  {
    "objectID": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#create-python-script",
    "href": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#create-python-script",
    "title": "Python scripts from notebooks",
    "section": "create python script",
    "text": "create python script\nStart from a notebook, and\n\nadd #|default_exp app in a cell of your notebook, where app is the name of the module to be extracted\nadd #| export in each cell you want to extract\ninsert this in the last cell of your notebook. ‘path’ will be the module location\n\nimport nbdev\nnbdev.export.nb_export('app.ipynb', 'path')\nExecute the notebook, it will create an app.py file in path"
  },
  {
    "objectID": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#use-this-python-script",
    "href": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#use-this-python-script",
    "title": "Python scripts from notebooks",
    "section": "use this python script",
    "text": "use this python script\nOne can use this in another notebook:\n\nfrom the same directory just by importing this script: import app\nfrom a different directory by setting syspath:\n\nimport os, sys\nfrom pathlib import Path\nhome = str(Path.home())\nsys.path.append(os.path.abspath(os.path.join(home, 'path')))\nand then import app"
  },
  {
    "objectID": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#create-python-script-1",
    "href": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#create-python-script-1",
    "title": "Python scripts from notebooks",
    "section": "create python script",
    "text": "create python script\n#|default_exp example_nbdev\n#|export\n\ndef nbdev_print():\n    print('This is a nbdev example')\nfrom nbdev.export import nb_export\nnb_export('2023-04-24-extract-python-scripts-with-nbdev.ipynb', '.')\n\n!ls -l *.py\n\n-rwxrwxrwx 1 guillaume guillaume 251 Apr 25 10:43 example_nbdev.py"
  },
  {
    "objectID": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#use-this-python-script-1",
    "href": "posts/2023-04-24-extract-python-scripts-with-nbdev.html#use-this-python-script-1",
    "title": "Python scripts from notebooks",
    "section": "use this python script",
    "text": "use this python script\n\nimport example_nbdev\n\nexample_nbdev.nbdev_print()\n\nThis is a nbdev example"
  },
  {
    "objectID": "posts/2021-03-25-headless-raspberry-pi-bridge-network.html",
    "href": "posts/2021-03-25-headless-raspberry-pi-bridge-network.html",
    "title": "Headless raspberry pi: create a wifi to ethernet bridge",
    "section": "",
    "text": "After my internet provider router stopped unexpectedly yesterday, I had to find a solution with internet access from phones and raspberry pi to broadcast internet to full home devices."
  },
  {
    "objectID": "posts/2021-03-25-headless-raspberry-pi-bridge-network.html#headless-raspberry-pi",
    "href": "posts/2021-03-25-headless-raspberry-pi-bridge-network.html#headless-raspberry-pi",
    "title": "Headless raspberry pi: create a wifi to ethernet bridge",
    "section": "Headless raspberry pi",
    "text": "Headless raspberry pi\nInstallation on SD from ubuntu\nfor a reason, raspberry pi imager snap doesn’t work (due to a bug linked to QT+wayland).\nI download deb ubuntu version (imager_1.6_amd64.deb) from https://www.raspberrypi.org/software and install with dpkg. (sudo dpkg -i imager_1.6_amd64.deb)\nWith rpi-imager, I can install by selecting the default OS (raspberry Pi OS 32-bit), and SD card as storage.\nHeadless wifi\nAs explained in https://www.raspberrypi.org/documentation/configuration/wireless/headless.md\nCreate (touch) wpa_supplicant.conf in /boot of SD card and paste this content:\nctrl_interface=DIR=/var/run/wpa_supplicant GROUP=netdev\nupdate_config=1\ncountry=FR\n\nnetwork={\n ssid=\"AndroidAP\"\n psk=\"&lt;Password for your wireless LAN&gt;\"\n}\nHeadless ssh\nAs explained in https://www.raspberrypi.org/documentation/remote-access/ssh/README.md\nCreate (touch) ssh in /boot of SD card\nIf it is found, SSH is enabled and the file is deleted. The content of the file does not matter; it could contain text, or nothing at all."
  },
  {
    "objectID": "posts/2021-03-25-headless-raspberry-pi-bridge-network.html#test-installation",
    "href": "posts/2021-03-25-headless-raspberry-pi-bridge-network.html#test-installation",
    "title": "Headless raspberry pi: create a wifi to ethernet bridge",
    "section": "Test installation",
    "text": "Test installation\nBoot. After a couple of minutes, I have a notification on phone saying a device is connected on my phone hotspot.\n\nAnd ssh raspberry (default username/password are pi/raspberry)\n$ ssh -l pi 192.168.43.179\npi@192.168.43.179's password: \nLinux raspberrypi 5.4.83-v7+ #1379 SMP Mon Dec 14 13:08:57 GMT 2020 armv7l\n\nThe programs included with the Debian GNU/Linux system are free software;\nthe exact distribution terms for each program are described in the\nindividual files in /usr/share/doc/*/copyright.\n\nDebian GNU/Linux comes with ABSOLUTELY NO WARRANTY, to the extent\npermitted by applicable law.\nLast login: Thu Mar 25 06:23:17 2021\n\nSSH is enabled and the default password for the 'pi' user has not been changed.\nThis is a security risk - please login as the 'pi' user and type 'passwd' to set a new password.\nHeadless raspberry is ready to be used."
  },
  {
    "objectID": "posts/2021-03-25-headless-raspberry-pi-bridge-network.html#wifi-to-ethernet-bridge",
    "href": "posts/2021-03-25-headless-raspberry-pi-bridge-network.html#wifi-to-ethernet-bridge",
    "title": "Headless raspberry pi: create a wifi to ethernet bridge",
    "section": "Wifi to ethernet bridge",
    "text": "Wifi to ethernet bridge\nI will use https://willhaley.com/blog/raspberry-pi-wifi-ethernet-bridge/\nThe only package that is needed is dnsmasq however from a clean install it is a good idea to make sure everything is up-to-date:\nget up-to-date system\nsudo apt-get update && sudo apt-get upgrade -y && sudo apt-get install rpi-update dnsmasq -y\nsudo rpi-update\nOption 1 - Same Subnet\nSave this script as a file named bridge.sh on your Pi.\n#!/usr/bin/env bash\n\nset -e\n\n[ $EUID -ne 0 ] && echo \"run as root\" &gt;&2 && exit 1\n\n##########################################################\n# You should not need to update anything below this line #\n##########################################################\n\n# parprouted  - Proxy ARP IP bridging daemon\n# dhcp-helper - DHCP/BOOTP relay agent\n\napt update && apt install -y parprouted dhcp-helper\n\nsystemctl stop dhcp-helper\nsystemctl enable dhcp-helper\n\n# Enable ipv4 forwarding.\nsed -i'' s/#net.ipv4.ip_forward=1/net.ipv4.ip_forward=1/ /etc/sysctl.conf\n\n# Service configuration for standard WiFi connection. Connectivity will\n# be lost if the username and password are incorrect.\nsystemctl restart wpa_supplicant.service\n\n# Enable IP forwarding for wlan0 if it's not already enabled.\ngrep '^option ip-forwarding 1$' /etc/dhcpcd.conf || printf \"option ip-forwarding 1\\n\" &gt;&gt; /etc/dhcpcd.conf\n\n# Disable dhcpcd control of eth0.\ngrep '^denyinterfaces eth0$' /etc/dhcpcd.conf || printf \"denyinterfaces eth0\\n\" &gt;&gt; /etc/dhcpcd.conf\n\n# Configure dhcp-helper.\ncat &gt; /etc/default/dhcp-helper &lt;&lt;EOF\nDHCPHELPER_OPTS=\"-b wlan0\"\nEOF\n\n# Enable avahi reflector if it's not already enabled.\nsed -i'' 's/#enable-reflector=no/enable-reflector=yes/' /etc/avahi/avahi-daemon.conf\ngrep '^enable-reflector=yes$' /etc/avahi/avahi-daemon.conf || {\n  printf \"something went wrong...\\n\\n\"\n  printf \"Manually set 'enable-reflector=yes in /etc/avahi/avahi-daemon.conf'\\n\"\n}\n\n# I have to admit, I do not understand ARP and IP forwarding enough to explain\n# exactly what is happening here. I am building off the work of others. In short\n# this is a service to forward traffic from WiFi to Ethernet.\ncat &lt;&lt;'EOF' &gt;/usr/lib/systemd/system/parprouted.service\n[Unit]\nDescription=proxy arp routing service\nDocumentation=https://raspberrypi.stackexchange.com/q/88954/79866\nRequires=sys-subsystem-net-devices-wlan0.device dhcpcd.service\nAfter=sys-subsystem-net-devices-wlan0.device dhcpcd.service\n\n[Service]\nType=forking\n# Restart until wlan0 gained carrier\nRestart=on-failure\nRestartSec=5\nTimeoutStartSec=30\n# clone the dhcp-allocated IP to eth0 so dhcp-helper will relay for the correct subnet\nExecStartPre=/bin/bash -c '/sbin/ip addr add $(/sbin/ip -4 -br addr show wlan0 | /bin/grep -Po \"\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+\")/32 dev eth0'\nExecStartPre=/sbin/ip link set dev eth0 up\nExecStartPre=/sbin/ip link set wlan0 promisc on\nExecStart=-/usr/sbin/parprouted eth0 wlan0\nExecStopPost=/sbin/ip link set wlan0 promisc off\nExecStopPost=/sbin/ip link set dev eth0 down\nExecStopPost=/bin/bash -c '/sbin/ip addr del $(/sbin/ip -4 -br addr show wlan0 | /bin/grep -Po \"\\\\d+\\\\.\\\\d+\\\\.\\\\d+\\\\.\\\\d+\")/32 dev eth0'\n\n[Install]\nWantedBy=wpa_supplicant.service\nEOF\n\nsystemctl daemon-reload\nsystemctl enable parprouted\nsystemctl start parprouted dhcp-helper\nStep 2: Execute the script on your Pi like so.\nsudo bash bridge.sh\nStep 3: Reboot.\nsudo reboot\nDone!"
  },
  {
    "objectID": "posts/2020-10-21-github-ssh-behind-proxy.html",
    "href": "posts/2020-10-21-github-ssh-behind-proxy.html",
    "title": "Use git with github (ssh) behind corporate proxy",
    "section": "",
    "text": "alt text\n\n\nI use 2 kinds of repo. gitlab for internal/corporate projects, hosted inside my company. github for public/pet projects and as a blogging platform. 3 days a week I am inside company, 4 days a week outside.\nGreen lines are the natural path to collaborate.\nWhen outside I don’t have proxy configuration or firewall, and I can directly access github. I cannot access to gitlab but I don’t want to address it now, this is why it is set as a black line. (if this is really needed I have a vpn access and this is as being inside)\nWhen inside, I use internal proxy. I can directly access gitlab. But I want to access github in a transparent way. And yes from both Windows and Linux (WSL). This is the red line."
  },
  {
    "objectID": "posts/2020-10-21-github-ssh-behind-proxy.html#revert-socks5-for-git",
    "href": "posts/2020-10-21-github-ssh-behind-proxy.html#revert-socks5-for-git",
    "title": "Use git with github (ssh) behind corporate proxy",
    "section": "Revert socks5 for git",
    "text": "Revert socks5 for git\nJust by commenting ProxyCommand in ssh for github\n$ cat .ssh/config\nHost github.com\nIdentityFile ~/.ssh/id_rsa_gmail\n#ProxyCommand /bin/nc -X 5 -x 192.168.50.202:1080 %h %p\n\nHost gitlab.michelin.com\nIdentityFile ~/.ssh/id_rsa\nSecond step is to migrate remote-url from ssh to https:"
  },
  {
    "objectID": "posts/2020-10-21-github-ssh-behind-proxy.html#from-git-ssh-to-git-https",
    "href": "posts/2020-10-21-github-ssh-behind-proxy.html#from-git-ssh-to-git-https",
    "title": "Use git with github (ssh) behind corporate proxy",
    "section": "from git ssh to git https",
    "text": "from git ssh to git https\n$ git remote set-url origin https://githib.com/castorfou/mit_600.2x.git\n$ git remote -v\norigin  https://github.com/castorfou/mit_600.2x.git (fetch)\norigin  https://github.com/castorfou/mit_600.2x.git (push)\nThis allows to fetch and pull updates\ngit fetch\ngit pull\nLastly to setup passwordless access to github"
  },
  {
    "objectID": "posts/2020-10-21-github-ssh-behind-proxy.html#github-token-to-access-passwordless-using-https",
    "href": "posts/2020-10-21-github-ssh-behind-proxy.html#github-token-to-access-passwordless-using-https",
    "title": "Use git with github (ssh) behind corporate proxy",
    "section": "Github token to access passwordless using https",
    "text": "Github token to access passwordless using https\nFrom https://clarusway.com/passwordless-usage-of-private-git-repositories/\nTo Generate token in github: - (profile &gt; Settings &gt; Developer settings &gt; Personal access tokens) - Generate new token - Select repo section\nIntegrate into git config: - copy token into .git/config remote url ( from url = https://github.com/castorfou/guillaume_blog.git to url = https://mytoken@github.com/castorfou/guillaume_blog.git)"
  },
  {
    "objectID": "posts/2022-07-21-install docker on WSL.html",
    "href": "posts/2022-07-21-install docker on WSL.html",
    "title": "install docker within WSL",
    "section": "",
    "text": "WSL 2 Docker inside WSL 2\ninstall ubuntu 22.04 on WSL"
  },
  {
    "objectID": "posts/2022-07-21-install docker on WSL.html#source-of-inspiration",
    "href": "posts/2022-07-21-install docker on WSL.html#source-of-inspiration",
    "title": "install docker within WSL",
    "section": "",
    "text": "WSL 2 Docker inside WSL 2\ninstall ubuntu 22.04 on WSL"
  },
  {
    "objectID": "posts/2022-07-21-install docker on WSL.html#pre-requisite-installation---ubuntu-docker",
    "href": "posts/2022-07-21-install docker on WSL.html#pre-requisite-installation---ubuntu-docker",
    "title": "install docker within WSL",
    "section": "Pre-requisite Installation - ubuntu-docker",
    "text": "Pre-requisite Installation - ubuntu-docker\n\nuninstall image (if needed)\n# wsl --unregister &lt;distroName&gt;\nwsl --unregister ubuntu-docker\n\n\nsetup installation directory\ncreate this structure by copying the existing one from ubuntu-22.04\nguillaume@LL11LPC0PQARQ:/mnt/d/wsl/Ubuntu-docker$ tree\n.\n└── download\n    ├── GWSL.Traditional.140.release.x64.exe\n    ├── ZscalerRootCA.crt\n    ├── jammy-server-cloudimg-amd64-wsl.rootfs.tar.gz\n    ├── setup_wsl_root.sh\n    └── setup_wsl_user.sh\n\n\ncreate ubuntu-docker image\nfrom Powershell\nwsl --import ubuntu-docker D:\\wsl\\ubuntu-docker\\instance D:\\wsl\\ubuntu-docker\\download\\jammy-server-cloudimg-amd64-wsl.rootfs.tar.gz\n\n#should appear in \nwsl --list --all -v\n\n\ndeclare ubuntu-docker in Windows Terminal\nWindows Terminal &gt; Settings &gt; Add a profile &gt; Duplicate a profile (from Ubuntu-22.04)\nName: ubuntu-docker\nCommand line: C:\\WINDOWS\\system32\\wsl.exe -d ubuntu-docker\nTab title: ubuntu docker\n\n\nsetup root configuration\nStart ubuntu-docker from Windows Terminal\ncp /mnt/d/wsl/Ubuntu-docker/download/setup_wsl_* .\nchmod +x setup_wsl_root.sh\n./setup_wsl_root.sh\nenter username and password\nFrom powershell, stop ubuntu-docker\nwsl -t ubuntu-docker\n\n\nsetup user configuration\nStart ubuntu-docker from Windows Terminal\nFollow instructions, don’t skip the integration of ssh key in gitlab\nguillaume@LL11LPC0PQARQ:~$ host google.fr\ngoogle.fr has address 142.250.75.227\ngoogle.fr has IPv6 address 2a00:1450:4007:811::2003\nHost google.fr not found: 3(NXDOMAIN)\nThat’s it for WSL setup, docker can now be installed"
  },
  {
    "objectID": "posts/2021-01-13-matplotlib-cheatsheet.html",
    "href": "posts/2021-01-13-matplotlib-cheatsheet.html",
    "title": "matplotlib cheatsheet",
    "section": "",
    "text": "matplotlib cheatsheet in pdf\npdf lecture in github\n\n\n\n\n# Introducing the pyplot interface\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nplt.show()\n\n# Adding data to axes\nax.plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-TAVG-NORMAL\"])\nplt.show()\n\n\n\n\n# Adding markers\nax.plot(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-PRCP-NORMAL\"],\nmarker=\"o\")\nplt.show()\n\n# Choosing markers\nax.plot(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-PRCP-NORMAL\"],\nmarker=\"v\")\nplt.show()\nmarkers\n# Setting the linestyle\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-TAVG-NORMAL\"],\nmarker=\"v\", linestyle=\"--\")\nplt.show()\nline style\n# Eliminating lines with linestyle\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-TAVG-NORMAL\"],\nmarker=\"v\", linestyle=\"None\")\nplt.show()\n\n# Choosing color\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-TAVG-NORMAL\"],\nmarker=\"v\", linestyle=\"--\", color=\"r\")\nplt.show()\n\n# Customizing the axes labels\nax.set_xlabel(\"Time (months)\")\nplt.show()\n\n# Setting the y axis label\nax.set_xlabel(\"Time (months)\")\nax.set_ylabel(\"Average temperature (Fahrenheit degrees)\")\nplt.show()\n\n# Adding a title\nax.set_title(\"Weather in Seattle\")\nplt.show()\n\n\n\n# Small multiples with plt.subplots\nfig, ax = plt.subplots(3, 2)\nplt.show()\n\n# Adding data to subplots\nax.shape\n(3, 2)\nax[0, 0].plot(seattle_weather[\"MONTH\"],seattle_weather[\"MLY-PRCP-NORMAL\"],color='b')\nplt.show()\n\n# Subplots with data\nfig, ax = plt.subplots(2, 1)\nax[0].plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-PRCP-NORMAL\"],color='b')\nax[0].plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-PRCP-25PCTL\"],linestyle='--', color='b')\nax[0].plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-PRCP-75PCTL\"],linestyle='--', color='b')\nax[1].plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-PRCP-NORMAL\"],color='r')\nax[1].plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-PRCP-25PCTL\"],linestyle='--', color='r')\nax[1].plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-PRCP-75PCTL\"],linestyle='--', color='r')\nax[0].set_ylabel(\"Precipitation (inches)\")\nax[1].set_ylabel(\"Precipitation (inches)\")\nax[1].set_xlabel(\"Time (months)\")\nplt.show()\n\n# Sharing the y-axis range\nfig, ax = plt.subplots(2, 1, sharey=True)\n\n\n\n\n\n\n\n# DateTimeIndex\nclimate_change.index\nDatetimeIndex(['1958-03-06', '1958-04-06', '1958-05-06', '1958-06-06',\n     dtype='datetime64[ns]', name='date', length=706, freq=None)\n               \n               \n# Plotting time-series data\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax.plot(climate_change.index, climate_change['co2'])\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)')\nplt.show()\n\n# Zooming in on a decade\nsixties = climate_change[\"1960-01-01\":\"1969-12-31\"]\nfig, ax = plt.subplots()\nax.plot(sixties.index, sixties['co2'])\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)')\nplt.show()\n\n# Zooming in on one year\nsixty_nine = climate_change[\"1969-01-01\":\"1969-12-31\"]\nfig, ax = plt.subplots()\nax.plot(sixty_nine.index, sixty_nine['co2'])\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)')\nplt.show()\n\n\n\n# Plotting two time-series together\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax.plot(climate_change.index, climate_change[\"co2\"])\nax.plot(climate_change.index, climate_change[\"relative_temp\"])\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm) / Relative temperature')\nplt.show()\n\n# Using twin axes\nfig, ax = plt.subplots()\nax.plot(climate_change.index, climate_change[\"co2\"])\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)')\nax2 = ax.twinx()\nax2.plot(climate_change.index, climate_change[\"relative_temp\"])\nax2.set_ylabel('Relative temperature (Celsius)')\nplt.show()\n\n# Separating variables by color\nfig, ax = plt.subplots()\nax.plot(climate_change.index, climate_change[\"co2\"], color='blue')\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)', color='blue')\nax2 = ax.twinx()\nax2.plot(climate_change.index, climate_change[\"relative_temp\"],\ncolor='red')\nax2.set_ylabel('Relative temperature (Celsius)', color='red')\nplt.show()\n\n# Coloring the ticks\nfig, ax = plt.subplots()\nax.plot(climate_change.index, climate_change[\"co2\"],\ncolor='blue')\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)', color='blue')\nax.tick_params('y', colors='blue')\nax2 = ax.twinx()\nax2.plot(climate_change.index,\nclimate_change[\"relative_temp\"],\ncolor='red')\nax2.set_ylabel('Relative temperature (Celsius)',\ncolor='red')\nax2.tick_params('y', colors='red')\nplt.show()\n\n# A function that plots time-series\ndef plot_timeseries(axes, x, y, color, xlabel, ylabel):\n    axes.plot(x, y, color=color)\n    axes.set_xlabel(xlabel)\n    axes.set_ylabel(ylabel, color=color)\n    axes.tick_params('y', colors=color)\n# Using our function\nfig, ax = plt.subplots()\nplot_timeseries(ax, climate_change.index, climate_change['co2'],'blue', 'Time', 'CO2 (ppm)')\nax2 = ax.twinx()\nplot_timeseries(ax, climate_change.index,climate_change['relative_temp'],'red', 'Time', 'Relative temperature (Celsius)')\nplt.show()\n\n\n\n# Annotation\nfig, ax = plt.subplots()\nplot_timeseries(ax, climate_change.index, climate_change['co2'],\n'blue', 'Time', 'CO2 (ppm)')\nax2 = ax.twinx()\nplot_timeseries(ax2, climate_change.index,\nclimate_change['relative_temp'],\n'red', 'Time', 'Relative temperature (Celsius)')\nax2.annotate(\"&gt;1 degree\",\nxy=[pd.TimeStamp(\"2015-10-06\"), 1])\nplt.show()\n\n# Positioning the text\nax2.annotate(\"&gt;1 degree\",\nxy=(pd.Timestamp('2015-10-06'), 1),\nxytext=(pd.Timestamp('2008-10-06'), -0.2))\n\n# Adding arrows to annotation\nax2.annotate(\"&gt;1 degree\",\nxy=(pd.Timestamp('2015-10-06'), 1),\nxytext=(pd.Timestamp('2008-10-06'), -0.2),\narrowprops={})\n\n# Customizing arrow properties\nax2.annotate(\"&gt;1 degree\",\nxy=(pd.Timestamp('2015-10-06'), 1),\nxytext=(pd.Timestamp('2008-10-06'), -0.2),\narrowprops={\"arrowstyle\":\"-&gt;\", \"color\":\"gray\"})\nCustomizing annotations\n\n\n\n\n\n\n\n# Olympic medals: visualizing the data\nmedals = pd.read_csv('medals_by_country_2016.csv', index_col=0)\nfig, ax = plt.subplots()\nax.bar(medals.index, medals[\"Gold\"])\nplt.show()\n\n# Interlude: rotate the tick labels\nfig, ax = plt.subplots()\nax.bar(medals.index, medals[\"Gold\"])\nax.set_xticklabels(medals.index, rotation=90)\nax.set_ylabel(\"Number of medals\")\nplt.show()\n\n# Olympic medals: visualizing the other medals : stacked bar chart\nfig, ax = plt.subplots\nax.bar(medals.index, medals[\"Gold\"])\nax.bar(medals.index, medals[\"Silver\"], bottom=medals[\"Gold\"])\nax.set_xticklabels(medals.index, rotation=90)\nax.set_ylabel(\"Number of medals\")\nplt.show()\n\n# Olympic medals: visualizing all three\nfig, ax = plt.subplots\nax.bar(medals.index, medals[\"Gold\"])\nax.bar(medals.index, medals[\"Silver\"], bottom=medals[\"Gold\"])\nax.bar(medals.index, medals[\"Bronze\"],\nbottom=medals[\"Gold\"] + medals[\"Silver\"])\nax.set_xticklabels(medals.index, rotation=90)\nax.set_ylabel(\"Number of medals\")\nplt.show()\n\n# Adding a legend\nfig, ax = plt.subplots\nax.bar(medals.index, medals[\"Gold\"], label=\"Gold\")\nax.bar(medals.index, medals[\"Silver\"], bottom=medals[\"Gold\"],\nlabel=\"Silver\")\nax.bar(medals.index, medals[\"Bronze\"],\nbottom=medals[\"Gold\"] + medals[\"Silver\"],\nlabel=\"Bronze\")\nax.set_xticklabels(medals.index, rotation=90)\nax.set_ylabel(\"Number of medals\")\nax.legend()\nplt.show()\n\n\n\n\n# Introducing histograms\nfig, ax = plt.subplots()\nax.hist(mens_rowing[\"Height\"])\nax.hist(mens_gymnastic[\"Height\"])\nax.set_xlabel(\"Height (cm)\")\nax.set_ylabel(\"# of observations\")\nplt.show()\n\n# Labels are needed\nax.hist(mens_rowing[\"Height\"], label=\"Rowing\")\nax.hist(mens_gymnastic[\"Height\"], label=\"Gymnastics\")\nax.set_xlabel(\"Height (cm)\")\nax.set_ylabel(\"# of observations\")\nax.legend()\nplt.show()\n\n# Customizing histograms: setting the number of bins\nax.hist(mens_rowing[\"Height\"], label=\"Rowing\", bins=5)\nax.hist(mens_gymnastic[\"Height\"], label=\"Gymnastics\", bins=5)\nax.set_xlabel(\"Height (cm)\")\nax.set_ylabel(\"# of observations\")\nax.legend()\nplt.show()\n\n# Customizing histograms: setting bin boundaries\nax.hist(mens_rowing[\"Height\"], label=\"Rowing\",\nbins=[150, 160, 170, 180, 190, 200, 210])\nax.hist(mens_gymnastic[\"Height\"], label=\"Gymnastics\",\nbins=[150, 160, 170, 180, 190, 200, 210])\nax.set_xlabel(\"Height (cm)\")\nax.set_ylabel(\"# of observations\")\nax.legend()\nplt.show()\n\n# Customizing histograms: transparency\nax.hist(mens_rowing[\"Height\"], label=\"Rowing\",\nbins=[150, 160, 170, 180, 190, 200, 210],\nhisttype=\"step\")\nax.hist(mens_gymnastic[\"Height\"], label=\"Gymnastics\",\nbins=[150, 160, 170, 180, 190, 200, 210],\nhisttype=\"step\")\nax.set_xlabel(\"Height (cm)\")\nax.set_ylabel(\"# of observations\")\nax.legend()\nplt.show()\n\n\n\n# Adding error bars to bar charts\nfig, ax = plt.subplots()\nax.bar(\"Rowing\",mens_rowing[\"Height\"].mean(),\nyerr=mens_rowing[\"Height\"].std())\nax.bar(\"Gymnastics\",mens_gymnastics[\"Height\"].mean(),\nyerr=mens_gymnastics[\"Height\"].std())\nax.set_ylabel(\"Height (cm)\")\nplt.show()\n\n# Adding error bars to plots\nfig, ax = plt.subplots()\nax.errorbar(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-TAVG-NORMAL\"],\nyerr=seattle_weather[\"MLY-TAVG-STDDEV\"])\n\nax.errorbar(austin_weather[\"MONTH\"],\naustin_weather[\"MLY-TAVG-NORMAL\"],\nyerr=austin_weather[\"MLY-TAVG-STDDEV\"])\n\nax.set_ylabel(\"Temperature (Fahrenheit)\")\nplt.show()\n\n# Adding boxplots\nfig, ax = plt.subplots()\nax.boxplot([mens_rowing[\"Height\"],\nmens_gymnastics[\"Height\"]])\nax.set_xticklabels([\"Rowing\", \"Gymnastics\"])\nax.set_ylabel(\"Height (cm)\")\nplt.show()\n\n\n\n\n# Introducing scatter plots\nfig, ax = plt.subplots()\nax.scatter(climate_change[\"co2\"], climate_change[\"relative_temp\"])\nax.set_xlabel(\"CO2 (ppm)\")\nax.set_ylabel(\"Relative temperature (Celsius)\")\nplt.show()\n\n# Customizing scatter plots\neighties = climate_change[\"1980-01-01\":\"1989-12-31\"]\nnineties = climate_change[\"1990-01-01\":\"1999-12-31\"]\nfig, ax = plt.subplots()\nax.scatter(eighties[\"co2\"], eighties[\"relative_temp\"],\ncolor=\"red\", label=\"eighties\")\nax.scatter(nineties[\"co2\"], nineties[\"relative_temp\"],\ncolor=\"blue\", label=\"nineties\")\nax.legend()\nax.set_xlabel(\"CO2 (ppm)\")\nax.set_ylabel(\"Relative temperature (Celsius)\")\nplt.show()\n\n# Encoding a third variable by color\nfig, ax = plt.subplots()\nax.scatter(climate_change[\"co2\"], climate_change[\"relative_temp\"],\nc=climate_change.index)\nax.set_xlabel(\"CO2 (ppm)\")\nax.set_ylabel(\"Relative temperature (Celsius)\")\nplt.show()\n\n\n\n\n\n\n\n# Choosing a style\nplt.style.use(\"ggplot\")\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-TAVG-NORMAL\"\nax.plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-TAVG-NORMAL\"])\nax.set_xlabel(\"Time (months)\")\nax.set_ylabel(\"Average temperature (Fahrenheit degrees)\")\nplt.show()\n                                                  \n# Back to the default\nplt.style.use(\"default\")                                                  \navailable styles\n# The \"bmh\" style\nplt.style.use(\"bmh\")\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-TAVG-NORMAL\"\nax.plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-TAVG-NORMAL\"])\nax.set_xlabel(\"Time (months)\")\nax.set_ylabel(\"Average temperature (Fahrenheit degrees)\")\nplt.show()\n                                                  \n# Seaborn styles\nplt.style.use(\"seaborn-colorblind\")\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-TAVG-NORMAL\"\nax.plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-TAVG-NORMAL\"])\nax.set_xlabel(\"Time (months)\")\nax.set_ylabel(\"Average temperature (Fahrenheit degrees)\")\nplt.show()                                                  \n\n\n\n\n# Saving the figure to file\nfig, ax = plt.subplots()\nax.bar(medals.index, medals[\"Gold\"])\nax.set_xticklabels(medals.index, rotation=90)\nax.set_ylabel(\"Number of medals\")\nfig.savefig(\"gold_medals.png\")\n\n# Different file formats\nfig.savefig(\"gold_medals.jpg\")\nfig.savefig(\"gold_medals.jpg\", quality=50)\nfig.savefig(\"gold_medals.svg\")\n\n# Resolution\nfig.savefig(\"gold_medals.png\", dpi=300)\n\n# Size\nfig.set_size_inches([5, 3])\n\n# Another aspect ratio\nfig.set_size_inches([3, 5])\n\n\n\n\n# Getting unique values of a column\nsports = summer_2016_medals[\"Sport\"].unique()\n\n# Bar-chart of heights for all sports\nfig, ax = plt.subplots()\nfor sport in sports:\nsport_df = summer_2016_medals[summer_2016_medals[\"Sport\"] == spor\nax.bar(sport, sport_df[\"Height\"].mean(),\nyerr=sport_df[\"Height\"].std())\nax.set_ylabel(\"Height (cm)\")\nax.set_xticklabels(sports, rotation=90)\nplt.show()"
  },
  {
    "objectID": "posts/2021-01-13-matplotlib-cheatsheet.html#introduction-to-matplotlib",
    "href": "posts/2021-01-13-matplotlib-cheatsheet.html#introduction-to-matplotlib",
    "title": "matplotlib cheatsheet",
    "section": "",
    "text": "# Introducing the pyplot interface\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nplt.show()\n\n# Adding data to axes\nax.plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-TAVG-NORMAL\"])\nplt.show()\n\n\n\n\n# Adding markers\nax.plot(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-PRCP-NORMAL\"],\nmarker=\"o\")\nplt.show()\n\n# Choosing markers\nax.plot(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-PRCP-NORMAL\"],\nmarker=\"v\")\nplt.show()\nmarkers\n# Setting the linestyle\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-TAVG-NORMAL\"],\nmarker=\"v\", linestyle=\"--\")\nplt.show()\nline style\n# Eliminating lines with linestyle\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-TAVG-NORMAL\"],\nmarker=\"v\", linestyle=\"None\")\nplt.show()\n\n# Choosing color\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-TAVG-NORMAL\"],\nmarker=\"v\", linestyle=\"--\", color=\"r\")\nplt.show()\n\n# Customizing the axes labels\nax.set_xlabel(\"Time (months)\")\nplt.show()\n\n# Setting the y axis label\nax.set_xlabel(\"Time (months)\")\nax.set_ylabel(\"Average temperature (Fahrenheit degrees)\")\nplt.show()\n\n# Adding a title\nax.set_title(\"Weather in Seattle\")\nplt.show()\n\n\n\n# Small multiples with plt.subplots\nfig, ax = plt.subplots(3, 2)\nplt.show()\n\n# Adding data to subplots\nax.shape\n(3, 2)\nax[0, 0].plot(seattle_weather[\"MONTH\"],seattle_weather[\"MLY-PRCP-NORMAL\"],color='b')\nplt.show()\n\n# Subplots with data\nfig, ax = plt.subplots(2, 1)\nax[0].plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-PRCP-NORMAL\"],color='b')\nax[0].plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-PRCP-25PCTL\"],linestyle='--', color='b')\nax[0].plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-PRCP-75PCTL\"],linestyle='--', color='b')\nax[1].plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-PRCP-NORMAL\"],color='r')\nax[1].plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-PRCP-25PCTL\"],linestyle='--', color='r')\nax[1].plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-PRCP-75PCTL\"],linestyle='--', color='r')\nax[0].set_ylabel(\"Precipitation (inches)\")\nax[1].set_ylabel(\"Precipitation (inches)\")\nax[1].set_xlabel(\"Time (months)\")\nplt.show()\n\n# Sharing the y-axis range\nfig, ax = plt.subplots(2, 1, sharey=True)"
  },
  {
    "objectID": "posts/2021-01-13-matplotlib-cheatsheet.html#plotting-time-series",
    "href": "posts/2021-01-13-matplotlib-cheatsheet.html#plotting-time-series",
    "title": "matplotlib cheatsheet",
    "section": "",
    "text": "# DateTimeIndex\nclimate_change.index\nDatetimeIndex(['1958-03-06', '1958-04-06', '1958-05-06', '1958-06-06',\n     dtype='datetime64[ns]', name='date', length=706, freq=None)\n               \n               \n# Plotting time-series data\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax.plot(climate_change.index, climate_change['co2'])\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)')\nplt.show()\n\n# Zooming in on a decade\nsixties = climate_change[\"1960-01-01\":\"1969-12-31\"]\nfig, ax = plt.subplots()\nax.plot(sixties.index, sixties['co2'])\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)')\nplt.show()\n\n# Zooming in on one year\nsixty_nine = climate_change[\"1969-01-01\":\"1969-12-31\"]\nfig, ax = plt.subplots()\nax.plot(sixty_nine.index, sixty_nine['co2'])\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)')\nplt.show()\n\n\n\n# Plotting two time-series together\nimport matplotlib.pyplot as plt\nfig, ax = plt.subplots()\nax.plot(climate_change.index, climate_change[\"co2\"])\nax.plot(climate_change.index, climate_change[\"relative_temp\"])\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm) / Relative temperature')\nplt.show()\n\n# Using twin axes\nfig, ax = plt.subplots()\nax.plot(climate_change.index, climate_change[\"co2\"])\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)')\nax2 = ax.twinx()\nax2.plot(climate_change.index, climate_change[\"relative_temp\"])\nax2.set_ylabel('Relative temperature (Celsius)')\nplt.show()\n\n# Separating variables by color\nfig, ax = plt.subplots()\nax.plot(climate_change.index, climate_change[\"co2\"], color='blue')\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)', color='blue')\nax2 = ax.twinx()\nax2.plot(climate_change.index, climate_change[\"relative_temp\"],\ncolor='red')\nax2.set_ylabel('Relative temperature (Celsius)', color='red')\nplt.show()\n\n# Coloring the ticks\nfig, ax = plt.subplots()\nax.plot(climate_change.index, climate_change[\"co2\"],\ncolor='blue')\nax.set_xlabel('Time')\nax.set_ylabel('CO2 (ppm)', color='blue')\nax.tick_params('y', colors='blue')\nax2 = ax.twinx()\nax2.plot(climate_change.index,\nclimate_change[\"relative_temp\"],\ncolor='red')\nax2.set_ylabel('Relative temperature (Celsius)',\ncolor='red')\nax2.tick_params('y', colors='red')\nplt.show()\n\n# A function that plots time-series\ndef plot_timeseries(axes, x, y, color, xlabel, ylabel):\n    axes.plot(x, y, color=color)\n    axes.set_xlabel(xlabel)\n    axes.set_ylabel(ylabel, color=color)\n    axes.tick_params('y', colors=color)\n# Using our function\nfig, ax = plt.subplots()\nplot_timeseries(ax, climate_change.index, climate_change['co2'],'blue', 'Time', 'CO2 (ppm)')\nax2 = ax.twinx()\nplot_timeseries(ax, climate_change.index,climate_change['relative_temp'],'red', 'Time', 'Relative temperature (Celsius)')\nplt.show()\n\n\n\n# Annotation\nfig, ax = plt.subplots()\nplot_timeseries(ax, climate_change.index, climate_change['co2'],\n'blue', 'Time', 'CO2 (ppm)')\nax2 = ax.twinx()\nplot_timeseries(ax2, climate_change.index,\nclimate_change['relative_temp'],\n'red', 'Time', 'Relative temperature (Celsius)')\nax2.annotate(\"&gt;1 degree\",\nxy=[pd.TimeStamp(\"2015-10-06\"), 1])\nplt.show()\n\n# Positioning the text\nax2.annotate(\"&gt;1 degree\",\nxy=(pd.Timestamp('2015-10-06'), 1),\nxytext=(pd.Timestamp('2008-10-06'), -0.2))\n\n# Adding arrows to annotation\nax2.annotate(\"&gt;1 degree\",\nxy=(pd.Timestamp('2015-10-06'), 1),\nxytext=(pd.Timestamp('2008-10-06'), -0.2),\narrowprops={})\n\n# Customizing arrow properties\nax2.annotate(\"&gt;1 degree\",\nxy=(pd.Timestamp('2015-10-06'), 1),\nxytext=(pd.Timestamp('2008-10-06'), -0.2),\narrowprops={\"arrowstyle\":\"-&gt;\", \"color\":\"gray\"})\nCustomizing annotations"
  },
  {
    "objectID": "posts/2021-01-13-matplotlib-cheatsheet.html#quantitative-comparisons-and-statistical-visualizations",
    "href": "posts/2021-01-13-matplotlib-cheatsheet.html#quantitative-comparisons-and-statistical-visualizations",
    "title": "matplotlib cheatsheet",
    "section": "",
    "text": "# Olympic medals: visualizing the data\nmedals = pd.read_csv('medals_by_country_2016.csv', index_col=0)\nfig, ax = plt.subplots()\nax.bar(medals.index, medals[\"Gold\"])\nplt.show()\n\n# Interlude: rotate the tick labels\nfig, ax = plt.subplots()\nax.bar(medals.index, medals[\"Gold\"])\nax.set_xticklabels(medals.index, rotation=90)\nax.set_ylabel(\"Number of medals\")\nplt.show()\n\n# Olympic medals: visualizing the other medals : stacked bar chart\nfig, ax = plt.subplots\nax.bar(medals.index, medals[\"Gold\"])\nax.bar(medals.index, medals[\"Silver\"], bottom=medals[\"Gold\"])\nax.set_xticklabels(medals.index, rotation=90)\nax.set_ylabel(\"Number of medals\")\nplt.show()\n\n# Olympic medals: visualizing all three\nfig, ax = plt.subplots\nax.bar(medals.index, medals[\"Gold\"])\nax.bar(medals.index, medals[\"Silver\"], bottom=medals[\"Gold\"])\nax.bar(medals.index, medals[\"Bronze\"],\nbottom=medals[\"Gold\"] + medals[\"Silver\"])\nax.set_xticklabels(medals.index, rotation=90)\nax.set_ylabel(\"Number of medals\")\nplt.show()\n\n# Adding a legend\nfig, ax = plt.subplots\nax.bar(medals.index, medals[\"Gold\"], label=\"Gold\")\nax.bar(medals.index, medals[\"Silver\"], bottom=medals[\"Gold\"],\nlabel=\"Silver\")\nax.bar(medals.index, medals[\"Bronze\"],\nbottom=medals[\"Gold\"] + medals[\"Silver\"],\nlabel=\"Bronze\")\nax.set_xticklabels(medals.index, rotation=90)\nax.set_ylabel(\"Number of medals\")\nax.legend()\nplt.show()\n\n\n\n\n# Introducing histograms\nfig, ax = plt.subplots()\nax.hist(mens_rowing[\"Height\"])\nax.hist(mens_gymnastic[\"Height\"])\nax.set_xlabel(\"Height (cm)\")\nax.set_ylabel(\"# of observations\")\nplt.show()\n\n# Labels are needed\nax.hist(mens_rowing[\"Height\"], label=\"Rowing\")\nax.hist(mens_gymnastic[\"Height\"], label=\"Gymnastics\")\nax.set_xlabel(\"Height (cm)\")\nax.set_ylabel(\"# of observations\")\nax.legend()\nplt.show()\n\n# Customizing histograms: setting the number of bins\nax.hist(mens_rowing[\"Height\"], label=\"Rowing\", bins=5)\nax.hist(mens_gymnastic[\"Height\"], label=\"Gymnastics\", bins=5)\nax.set_xlabel(\"Height (cm)\")\nax.set_ylabel(\"# of observations\")\nax.legend()\nplt.show()\n\n# Customizing histograms: setting bin boundaries\nax.hist(mens_rowing[\"Height\"], label=\"Rowing\",\nbins=[150, 160, 170, 180, 190, 200, 210])\nax.hist(mens_gymnastic[\"Height\"], label=\"Gymnastics\",\nbins=[150, 160, 170, 180, 190, 200, 210])\nax.set_xlabel(\"Height (cm)\")\nax.set_ylabel(\"# of observations\")\nax.legend()\nplt.show()\n\n# Customizing histograms: transparency\nax.hist(mens_rowing[\"Height\"], label=\"Rowing\",\nbins=[150, 160, 170, 180, 190, 200, 210],\nhisttype=\"step\")\nax.hist(mens_gymnastic[\"Height\"], label=\"Gymnastics\",\nbins=[150, 160, 170, 180, 190, 200, 210],\nhisttype=\"step\")\nax.set_xlabel(\"Height (cm)\")\nax.set_ylabel(\"# of observations\")\nax.legend()\nplt.show()\n\n\n\n# Adding error bars to bar charts\nfig, ax = plt.subplots()\nax.bar(\"Rowing\",mens_rowing[\"Height\"].mean(),\nyerr=mens_rowing[\"Height\"].std())\nax.bar(\"Gymnastics\",mens_gymnastics[\"Height\"].mean(),\nyerr=mens_gymnastics[\"Height\"].std())\nax.set_ylabel(\"Height (cm)\")\nplt.show()\n\n# Adding error bars to plots\nfig, ax = plt.subplots()\nax.errorbar(seattle_weather[\"MONTH\"],\nseattle_weather[\"MLY-TAVG-NORMAL\"],\nyerr=seattle_weather[\"MLY-TAVG-STDDEV\"])\n\nax.errorbar(austin_weather[\"MONTH\"],\naustin_weather[\"MLY-TAVG-NORMAL\"],\nyerr=austin_weather[\"MLY-TAVG-STDDEV\"])\n\nax.set_ylabel(\"Temperature (Fahrenheit)\")\nplt.show()\n\n# Adding boxplots\nfig, ax = plt.subplots()\nax.boxplot([mens_rowing[\"Height\"],\nmens_gymnastics[\"Height\"]])\nax.set_xticklabels([\"Rowing\", \"Gymnastics\"])\nax.set_ylabel(\"Height (cm)\")\nplt.show()\n\n\n\n\n# Introducing scatter plots\nfig, ax = plt.subplots()\nax.scatter(climate_change[\"co2\"], climate_change[\"relative_temp\"])\nax.set_xlabel(\"CO2 (ppm)\")\nax.set_ylabel(\"Relative temperature (Celsius)\")\nplt.show()\n\n# Customizing scatter plots\neighties = climate_change[\"1980-01-01\":\"1989-12-31\"]\nnineties = climate_change[\"1990-01-01\":\"1999-12-31\"]\nfig, ax = plt.subplots()\nax.scatter(eighties[\"co2\"], eighties[\"relative_temp\"],\ncolor=\"red\", label=\"eighties\")\nax.scatter(nineties[\"co2\"], nineties[\"relative_temp\"],\ncolor=\"blue\", label=\"nineties\")\nax.legend()\nax.set_xlabel(\"CO2 (ppm)\")\nax.set_ylabel(\"Relative temperature (Celsius)\")\nplt.show()\n\n# Encoding a third variable by color\nfig, ax = plt.subplots()\nax.scatter(climate_change[\"co2\"], climate_change[\"relative_temp\"],\nc=climate_change.index)\nax.set_xlabel(\"CO2 (ppm)\")\nax.set_ylabel(\"Relative temperature (Celsius)\")\nplt.show()"
  },
  {
    "objectID": "posts/2021-01-13-matplotlib-cheatsheet.html#sharing-visualizations-with-others",
    "href": "posts/2021-01-13-matplotlib-cheatsheet.html#sharing-visualizations-with-others",
    "title": "matplotlib cheatsheet",
    "section": "",
    "text": "# Choosing a style\nplt.style.use(\"ggplot\")\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-TAVG-NORMAL\"\nax.plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-TAVG-NORMAL\"])\nax.set_xlabel(\"Time (months)\")\nax.set_ylabel(\"Average temperature (Fahrenheit degrees)\")\nplt.show()\n                                                  \n# Back to the default\nplt.style.use(\"default\")                                                  \navailable styles\n# The \"bmh\" style\nplt.style.use(\"bmh\")\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-TAVG-NORMAL\"\nax.plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-TAVG-NORMAL\"])\nax.set_xlabel(\"Time (months)\")\nax.set_ylabel(\"Average temperature (Fahrenheit degrees)\")\nplt.show()\n                                                  \n# Seaborn styles\nplt.style.use(\"seaborn-colorblind\")\nfig, ax = plt.subplots()\nax.plot(seattle_weather[\"MONTH\"], seattle_weather[\"MLY-TAVG-NORMAL\"\nax.plot(austin_weather[\"MONTH\"], austin_weather[\"MLY-TAVG-NORMAL\"])\nax.set_xlabel(\"Time (months)\")\nax.set_ylabel(\"Average temperature (Fahrenheit degrees)\")\nplt.show()                                                  \n\n\n\n\n# Saving the figure to file\nfig, ax = plt.subplots()\nax.bar(medals.index, medals[\"Gold\"])\nax.set_xticklabels(medals.index, rotation=90)\nax.set_ylabel(\"Number of medals\")\nfig.savefig(\"gold_medals.png\")\n\n# Different file formats\nfig.savefig(\"gold_medals.jpg\")\nfig.savefig(\"gold_medals.jpg\", quality=50)\nfig.savefig(\"gold_medals.svg\")\n\n# Resolution\nfig.savefig(\"gold_medals.png\", dpi=300)\n\n# Size\nfig.set_size_inches([5, 3])\n\n# Another aspect ratio\nfig.set_size_inches([3, 5])\n\n\n\n\n# Getting unique values of a column\nsports = summer_2016_medals[\"Sport\"].unique()\n\n# Bar-chart of heights for all sports\nfig, ax = plt.subplots()\nfor sport in sports:\nsport_df = summer_2016_medals[summer_2016_medals[\"Sport\"] == spor\nax.bar(sport, sport_df[\"Height\"].mean(),\nyerr=sport_df[\"Height\"].std())\nax.set_ylabel(\"Height (cm)\")\nax.set_xticklabels(sports, rotation=90)\nplt.show()"
  },
  {
    "objectID": "posts/2022-01-01-logbook-January-22.html",
    "href": "posts/2022-01-01-logbook-January-22.html",
    "title": "Logbook for January 22",
    "section": "",
    "text": "Monday 1/3\nWill try to use Zotero for managing research papers. Can sync between PC. Seems helpful. My lib\nTuesday 1/4\nGit revert a file to a previous commit\ngit log 00\\ -\\ my_lib.ipynb\ngit checkout f97406b026bfdf529d2dc4de96224bdfbaa576a8 00\\ -\\ my_lib.ipynb"
  },
  {
    "objectID": "posts/2022-01-01-logbook-January-22.html#week-1---january-22",
    "href": "posts/2022-01-01-logbook-January-22.html#week-1---january-22",
    "title": "Logbook for January 22",
    "section": "",
    "text": "Monday 1/3\nWill try to use Zotero for managing research papers. Can sync between PC. Seems helpful. My lib\nTuesday 1/4\nGit revert a file to a previous commit\ngit log 00\\ -\\ my_lib.ipynb\ngit checkout f97406b026bfdf529d2dc4de96224bdfbaa576a8 00\\ -\\ my_lib.ipynb"
  },
  {
    "objectID": "posts/2022-01-01-logbook-January-22.html#week-2---january-22",
    "href": "posts/2022-01-01-logbook-January-22.html#week-2---january-22",
    "title": "Logbook for January 22",
    "section": "Week 2 - January 22",
    "text": "Week 2 - January 22\nMonday 1/17\nTo update fastai from an existing envt under windows\nconda update -n base -c defaults conda (from base)\nconda update fastai -c fastai -c pytorch -c conda-forge -c nvidia (from fastai)\nTo install mamba under WSL2\nconda install mamba -n base -c conda-forge (from base)\n\nthen\n\nmamba init\nTo use system CA certificate in WSL2\nexport REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\nTo install fastai in WSL2 using mamba\nmamba install -c fastchan fastai\nThursday 1/20\nStephane Mallat - collège de France - Information et complexité but unfortunately video is not yet available.\nRe-read of arXiv:2110.01889 Deep Neural Networks and Tabular Data: A Survey (here on zotero)"
  },
  {
    "objectID": "posts/2022-01-01-logbook-January-22.html#week-3---january-22",
    "href": "posts/2022-01-01-logbook-January-22.html#week-3---january-22",
    "title": "Logbook for January 22",
    "section": "Week 3 - January 22",
    "text": "Week 3 - January 22\nTuesday 1/26\nVideo of 1st lecture of Stephane Mallat 2022 is now available."
  },
  {
    "objectID": "posts/2020-09-26-matplotlib-multiple-subplots-and-animations.html",
    "href": "posts/2020-09-26-matplotlib-multiple-subplots-and-animations.html",
    "title": "Multiple subplots and animations with matplotlib",
    "section": "",
    "text": "Subplots\nWhat I want it to display multiple plots, with a given max rows. And to display my plots depending only on these parameters.\n\nfrom fastai.tabular.all import *\n\n%matplotlib inline\n\n# fastai v1 backward compatibility\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport numpy as np\n\n\ndef my_hidden_f(x):\n    return 4*x**3+2*x**2-12*x+5+10*torch.rand(x.shape)\n\nn=100\ntime = torch.ones(n,1) \ntime[:,0].uniform_(-3.14,3.14)\n\nspeed=my_hidden_f(time)\n\n\nplt.scatter(time[:,0], speed)\nplt.scatter(tensor(-1.5), my_hidden_f(tensor([-1.5])), color='red')\n\ndef f(t, params):\n    a,b,c,d = params\n    return a*(t**3) + (b*t**2) + c*t + d\n\ndef mse(preds, targets): return ((preds-targets)**2).mean()\n\ndef show_preds(preds, ax=None):\n    if ax is None: ax=plt.subplots()[1]\n    ax.scatter(time, speed)\n    ax.scatter(time, to_np(preds), color='red')\n    ax.set_ylim(-50,150)\n\nlr = 1e-4\n\ndef apply_step(params, prn=True):\n    preds = f(time, params)\n    loss = mse(preds, speed)\n    loss.backward()\n    params.data -= lr * params.grad.data\n    params.grad = None\n    if prn: print(loss.item())\n    return preds\n\n\n\n\n\n#load initial parameters\nparams = torch.randn(4).requires_grad_()\n#nbr of iterations\nmax_iter = 1000\n#nbr of curves visible\nnbr_graph = 4\n#max number of curves on one row\nmax_columns = 5\n#nbr of rows\nmax_rows = (nbr_graph-1) // max_columns + 1\n#nbr of iter per plot\ngraph_iteration = max_iter //(nbr_graph-1)\n\n_,axs = plt.subplots(nrows=max_rows,ncols=max_columns,figsize=(3*max_columns,3*max_rows))\n\ni=-1\nax_index= ((i+1) // graph_iteration ) // (max_columns),  ((i+1) // graph_iteration ) % (max_columns)\nif (max_rows ==1): ax_index= ((i+1) // graph_iteration ) % (max_columns)\n\nshow_preds(apply_step(params, prn=False), axs[ax_index])\naxs[ax_index].set_title('iter 0')\n\nfor i in range(max_iter): \n    preds=apply_step(params, prn=False)\n    if ((i+1) % graph_iteration == 0):         \n        ax_index= ((i+1) // graph_iteration ) // (max_columns),  ((i+1) // graph_iteration ) % (max_columns)\n        if (max_rows ==1): ax_index= ((i+1) // graph_iteration ) % (max_columns)\n        show_preds(preds, axs[ax_index])\n        axs[ax_index].set_title('iter '+str(i+1))\nplt.tight_layout()\n\n\n\n\n\n\nAnimation\nimport\n\n%matplotlib inline\n\n# fastai v1 backward compatibility\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport numpy as np\n\ndef tensor(*argv): return torch.tensor(argv)\n\n# TEST\nassert torch.all(tensor(1,2) == torch.tensor([1,2])), 'Backward compatibility with fastai v1'\n\nfunction and plot\n\nn=100\nx = torch.ones(n,1) \nx.uniform_(-3.14,3.14)\n\ndef my_function(x, a):\n    return ((torch.cat((x**3, x**2, x, torch.ones(n,1) ), 1))@a).reshape((n))\n\na=tensor(4., 2., -12., 5.)\ny = my_function(x, a)\n\na = tensor(-1.,-2., 6., -8)\ny_hat = my_function(x, a)\n\n\nplt.scatter(x[:,0], y)\nplt.scatter(x[:,0],y_hat);\n\ndef mse(y_hat, y): return ((y_hat-y)**2).mean()\n\n\n\n\ngradient descent\n\na = nn.Parameter(a); a\n\ndef update():\n    y_hat = my_function(x, a)\n    loss = mse(y, y_hat)\n    if t % 10 == 0: print(loss)\n    loss.backward()\n    with torch.no_grad():\n        a.sub_(lr * a.grad)\n        a.grad.zero_()\n\n        \nlr = 1e-3\nfor t in range(100): update()\n\ntensor(1967.0251, grad_fn=&lt;MeanBackward0&gt;)\ntensor(559.2718, grad_fn=&lt;MeanBackward0&gt;)\ntensor(365.7207, grad_fn=&lt;MeanBackward0&gt;)\ntensor(282.6393, grad_fn=&lt;MeanBackward0&gt;)\ntensor(245.4054, grad_fn=&lt;MeanBackward0&gt;)\ntensor(227.3450, grad_fn=&lt;MeanBackward0&gt;)\ntensor(217.3324, grad_fn=&lt;MeanBackward0&gt;)\ntensor(210.7267, grad_fn=&lt;MeanBackward0&gt;)\ntensor(205.5912, grad_fn=&lt;MeanBackward0&gt;)\ntensor(201.1171, grad_fn=&lt;MeanBackward0&gt;)\n\n\nanimation\n\nfrom matplotlib import animation, rc\nrc('animation', html='jshtml')\n\na = nn.Parameter(tensor(-1.,1))\n\na=tensor(4., 2., -12., 5.)\ny = my_function(x, a)\n\na = tensor(-1.,-2., 6., -8)\ny_hat = my_function(x, a)\na = nn.Parameter(a); a\n\nfig = plt.figure()\nplt.scatter(x[:,0], y, c='orange')\nline = plt.scatter(x[:,0], y_hat.detach())\nplt.close()\n\ndef animate(i):\n    line.set_offsets(np.c_[x[:,0], (my_function(x,a)).detach()])\n    update()\n\n    return line,\n\nanimation.FuncAnimation(fig, animate, np.arange(0, 300), interval=5)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/2022-01-18-wsl2 conda mamba cuda.html",
    "href": "posts/2022-01-18-wsl2 conda mamba cuda.html",
    "title": "setup wsl2 conda mamba and cuda",
    "section": "",
    "text": "most of it is explained in an internal blog entry.\nTo display windows version: winver.exe\nI use version 20H2 build 19042.1415\n\n\nIt is now as easy as to run wsl --install in powershell as admin.\nFull detail at MS WSL doc\nOther commands:\n# list all wsl distributions installed and their WSL version\nwsl --list --verbose\n\n# list all distributions available\nwsl --list --online\nVoici la liste des distributions valides qui peuvent être installées.\nInstaller à l’aide de « wsl --install -d &lt;Distribution&gt; ».\n\nNAME            FRIENDLY NAME\nUbuntu          Ubuntu\nDebian          Debian GNU/Linux\nkali-linux      Kali Linux Rolling\nopenSUSE-42     openSUSE Leap 42\nSLES-12         SUSE Linux Enterprise Server v12\nUbuntu-16.04    Ubuntu 16.04 LTS\nUbuntu-18.04    Ubuntu 18.04 LTS\nUbuntu-20.04    Ubuntu 20.04 LTS\n\n# install Linux distributions\nwsl --install -d &lt;Distribution Name&gt;\n\n# shutdown wsl: shutdown all \nwsl --shutdown \n\n# define default wsl distribution to use with wsl\nwsl -s &lt;DistributionName&gt;\n\n\n\nand here is a more advanced config to install in a non system drive (D: instead of C:)\n#from powershell\nNew-Item D:\\WSL\\Ubuntu-20.04 -ItemType Directory\nSet-Location D:\\WSL\\Ubuntu-20.04\n\n#list+link of distributions in https://docs.microsoft.com/en-us/windows/wsl/install-manual#downloading-distributions\nInvoke-WebRequest -Uri https://aka.ms/wslubuntu2004 -OutFile Ubuntu-20.04.appx -UseBasicParsing\n\nRename-Item .\\Ubuntu-20.04.appx Ubuntu-20.04.zip\nExpand-Archive .\\Ubuntu-20.04.zip -Verbose\n# and then run Ubuntu_2004.2021.825.0_x64.appx\nI don’t know yet where the WSL disk is located (is it a .vhdx file?)\nDisks are located at %USERPROFILE%\\AppData\\Local\\Packages\\[distro name]\n2 ditros used:\n\nwsl1 ubuntu 18.04: CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\nwsl2 ubuntu 20.04: CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\n\nSo disks are still in C:\n\nGuess I have to use move-wsl.\nSet-Location 'D:\\Program Files (x86)\\move-wsl\\'\n.\\move-wsl.ps1\n\nPS D:\\Program Files (x86)\\move-wsl&gt; .\\move-wsl.ps1\nGetting distros...\nSelect distro to move:\n1: Ubuntu-18.04\n2: Ubuntu\n2\nEnter WSL target directory:\nD:\\wsl\\Ubuntu-20.04\nMove Ubuntu to \"D:\\wsl\\Ubuntu-20.04\"? (Y|n): Y\nExporting VHDX to \"D:\\wsl\\Ubuntu-20.04\\Ubuntu.tar\" ...\nAnd after that, have to create file/etc/wsl.conf\nguillaume@LL11LPC0PQARQ:~$ cat /etc/wsl.conf\n[user]\ndefault=guillaume\n\n\n\n\n\nIt is nicely explained in the Michelin blog entry. DNS resolution is kind of broken (I think due to internal protections we use on our corporate PC)\nvpnkit provides a secured solution to make it work. And sakai135 has packaged it for wsl: wsl-vpnkit\nThe steps to install wsl-vpn kit are:\n\nCreate a working directory on your windows workspace and download this packaging of wsl-vpnkit inside.\nNow, open a powershell and go to the location of wsl-vpnkit.tar.gz, downloaded during the previous step\nOn your powershell terminal, launch:\n\n  #/!\\ in powserhsell\n  wsl --import wsl-vpnkit $env:USERPROFILE\\wsl-vpnkit wsl-vpnkit.tar.gz\n  wsl -d wsl-vpnkit\n\nYou can now exit your powershell\nFor the last step, to ensure all wsl reboot good communication, we will write in .profile file of your ubuntu user wsl-vpnkit initialization command:\n\n  echo 'wsl.exe -d wsl-vpnkit service wsl-vpnkit start' &gt;&gt; ~/.profile\n\nRelaunch your WSL terminal\n\n\n\n\ncreate a SSH key pair under your distribution\nssh-keygen -t rsa -b 4096 -C \"WSL2\"\nIntegrate into gitlab using gitlab doc. (copy id_rsa.pub into gitlab &gt; preferences &gt; SSH Keys)cat .s\n\n\n\nMichelin SI is behind an ssl proxy with his proper PKI for certificates delivering. That is why, your subsystem must add this pki in her recognized authorities.\nTo do this, we will clone a repository with the certificates in the subsystem and copy them to ca-certificates:\ngit clone git@gitlab.michelin.com:devops-foundation/devops_environment.git /tmp/devops_environment\nsudo cp /tmp/devops_environment/certs/* /usr/local/share/ca-certificates/\nsudo update-ca-certificates\nIf everything is ok, terminal notify you that certificates has been added.\nYou can now clean the temp working folder:\nrm -rf /tmp/devops_environment\nwe can have similar approach to update CA certifcates for Python. 1st step is to locate cacert.pem of your active python environment.\nimport certifi\ncertifi.where() \n&gt;&gt; '/home/guillaume/miniconda3/envs/fastai/lib/python3.9/site-packages/certifi/cacert.pem'\nTO BE FIXED\nAfter having run update-ca-certifcates, there is an updated ca file at /etc/ssl/certs/ca-certificates.crt. Let’s concatenate it to our cacert.pem.\ncp /etc/ssl/certs/ca-certificates.crt /tmp/ca-certificates.crt\nopenssl x509 -in /tmp/ca-certificates.crt -out /tmp/ca-certificates.pem -outform PEM\ncat /tmp/ca-certificates.pem | tee -a /home/guillaume/miniconda3/envs/fastai/lib/python3.9/site-packages/certifi/cacert.pem\n\n\n\nThe last step, to have a subsystem ready to use, is to have an apt with Michelin trusted sources configured. Ubuntu based package repositories can’t be used behind Michelin proxy.\nMichelin offers its own apt server with artifactory. To configure apt to use artifactory, launch these commands:\necho 'Acquire { http::User-Agent \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:13.37) Gecko/20100101 Firefox/31.33.7\"; };' | sudo tee /etc/apt/apt.conf.d/90globalprotectconf\nsudo sed -i 's@^\\(deb \\)http://archive.ubuntu.com/ubuntu/\\( focal\\(-updates\\)\\?.*\\)$@\\1https://artifactory.michelin.com/artifactory/ubuntu-archive-remote\\2\\n# &@' /etc/apt/sources.list\nsudo sed -i 's@^\\(deb \\)http://security.ubuntu.com/ubuntu/\\( focal\\(-updates\\)\\?.*\\)$@\\1https://artifactory.michelin.com/artifactory/ubuntu-security-remote\\2\\n# &@' /etc/apt/sources.list\n\n\n\nTo verify if everything is OK on your distribution:\n\nThis command must return google ip:\n\n  host google.fr\n\nThis command must return artifactory ip:\n\n  host artifactory.michelin.com\n\nYou are able to update your distribution without error:\n\n  sudo apt update\n  sudo apt upgrade -y"
  },
  {
    "objectID": "posts/2022-01-18-wsl2 conda mamba cuda.html#wsl2---installation-and-configuration",
    "href": "posts/2022-01-18-wsl2 conda mamba cuda.html#wsl2---installation-and-configuration",
    "title": "setup wsl2 conda mamba and cuda",
    "section": "",
    "text": "most of it is explained in an internal blog entry.\nTo display windows version: winver.exe\nI use version 20H2 build 19042.1415\n\n\nIt is now as easy as to run wsl --install in powershell as admin.\nFull detail at MS WSL doc\nOther commands:\n# list all wsl distributions installed and their WSL version\nwsl --list --verbose\n\n# list all distributions available\nwsl --list --online\nVoici la liste des distributions valides qui peuvent être installées.\nInstaller à l’aide de « wsl --install -d &lt;Distribution&gt; ».\n\nNAME            FRIENDLY NAME\nUbuntu          Ubuntu\nDebian          Debian GNU/Linux\nkali-linux      Kali Linux Rolling\nopenSUSE-42     openSUSE Leap 42\nSLES-12         SUSE Linux Enterprise Server v12\nUbuntu-16.04    Ubuntu 16.04 LTS\nUbuntu-18.04    Ubuntu 18.04 LTS\nUbuntu-20.04    Ubuntu 20.04 LTS\n\n# install Linux distributions\nwsl --install -d &lt;Distribution Name&gt;\n\n# shutdown wsl: shutdown all \nwsl --shutdown \n\n# define default wsl distribution to use with wsl\nwsl -s &lt;DistributionName&gt;\n\n\n\nand here is a more advanced config to install in a non system drive (D: instead of C:)\n#from powershell\nNew-Item D:\\WSL\\Ubuntu-20.04 -ItemType Directory\nSet-Location D:\\WSL\\Ubuntu-20.04\n\n#list+link of distributions in https://docs.microsoft.com/en-us/windows/wsl/install-manual#downloading-distributions\nInvoke-WebRequest -Uri https://aka.ms/wslubuntu2004 -OutFile Ubuntu-20.04.appx -UseBasicParsing\n\nRename-Item .\\Ubuntu-20.04.appx Ubuntu-20.04.zip\nExpand-Archive .\\Ubuntu-20.04.zip -Verbose\n# and then run Ubuntu_2004.2021.825.0_x64.appx\nI don’t know yet where the WSL disk is located (is it a .vhdx file?)\nDisks are located at %USERPROFILE%\\AppData\\Local\\Packages\\[distro name]\n2 ditros used:\n\nwsl1 ubuntu 18.04: CanonicalGroupLimited.Ubuntu18.04onWindows_79rhkp1fndgsc\nwsl2 ubuntu 20.04: CanonicalGroupLimited.UbuntuonWindows_79rhkp1fndgsc\n\nSo disks are still in C:\n\nGuess I have to use move-wsl.\nSet-Location 'D:\\Program Files (x86)\\move-wsl\\'\n.\\move-wsl.ps1\n\nPS D:\\Program Files (x86)\\move-wsl&gt; .\\move-wsl.ps1\nGetting distros...\nSelect distro to move:\n1: Ubuntu-18.04\n2: Ubuntu\n2\nEnter WSL target directory:\nD:\\wsl\\Ubuntu-20.04\nMove Ubuntu to \"D:\\wsl\\Ubuntu-20.04\"? (Y|n): Y\nExporting VHDX to \"D:\\wsl\\Ubuntu-20.04\\Ubuntu.tar\" ...\nAnd after that, have to create file/etc/wsl.conf\nguillaume@LL11LPC0PQARQ:~$ cat /etc/wsl.conf\n[user]\ndefault=guillaume\n\n\n\n\n\nIt is nicely explained in the Michelin blog entry. DNS resolution is kind of broken (I think due to internal protections we use on our corporate PC)\nvpnkit provides a secured solution to make it work. And sakai135 has packaged it for wsl: wsl-vpnkit\nThe steps to install wsl-vpn kit are:\n\nCreate a working directory on your windows workspace and download this packaging of wsl-vpnkit inside.\nNow, open a powershell and go to the location of wsl-vpnkit.tar.gz, downloaded during the previous step\nOn your powershell terminal, launch:\n\n  #/!\\ in powserhsell\n  wsl --import wsl-vpnkit $env:USERPROFILE\\wsl-vpnkit wsl-vpnkit.tar.gz\n  wsl -d wsl-vpnkit\n\nYou can now exit your powershell\nFor the last step, to ensure all wsl reboot good communication, we will write in .profile file of your ubuntu user wsl-vpnkit initialization command:\n\n  echo 'wsl.exe -d wsl-vpnkit service wsl-vpnkit start' &gt;&gt; ~/.profile\n\nRelaunch your WSL terminal\n\n\n\n\ncreate a SSH key pair under your distribution\nssh-keygen -t rsa -b 4096 -C \"WSL2\"\nIntegrate into gitlab using gitlab doc. (copy id_rsa.pub into gitlab &gt; preferences &gt; SSH Keys)cat .s\n\n\n\nMichelin SI is behind an ssl proxy with his proper PKI for certificates delivering. That is why, your subsystem must add this pki in her recognized authorities.\nTo do this, we will clone a repository with the certificates in the subsystem and copy them to ca-certificates:\ngit clone git@gitlab.michelin.com:devops-foundation/devops_environment.git /tmp/devops_environment\nsudo cp /tmp/devops_environment/certs/* /usr/local/share/ca-certificates/\nsudo update-ca-certificates\nIf everything is ok, terminal notify you that certificates has been added.\nYou can now clean the temp working folder:\nrm -rf /tmp/devops_environment\nwe can have similar approach to update CA certifcates for Python. 1st step is to locate cacert.pem of your active python environment.\nimport certifi\ncertifi.where() \n&gt;&gt; '/home/guillaume/miniconda3/envs/fastai/lib/python3.9/site-packages/certifi/cacert.pem'\nTO BE FIXED\nAfter having run update-ca-certifcates, there is an updated ca file at /etc/ssl/certs/ca-certificates.crt. Let’s concatenate it to our cacert.pem.\ncp /etc/ssl/certs/ca-certificates.crt /tmp/ca-certificates.crt\nopenssl x509 -in /tmp/ca-certificates.crt -out /tmp/ca-certificates.pem -outform PEM\ncat /tmp/ca-certificates.pem | tee -a /home/guillaume/miniconda3/envs/fastai/lib/python3.9/site-packages/certifi/cacert.pem\n\n\n\nThe last step, to have a subsystem ready to use, is to have an apt with Michelin trusted sources configured. Ubuntu based package repositories can’t be used behind Michelin proxy.\nMichelin offers its own apt server with artifactory. To configure apt to use artifactory, launch these commands:\necho 'Acquire { http::User-Agent \"Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:13.37) Gecko/20100101 Firefox/31.33.7\"; };' | sudo tee /etc/apt/apt.conf.d/90globalprotectconf\nsudo sed -i 's@^\\(deb \\)http://archive.ubuntu.com/ubuntu/\\( focal\\(-updates\\)\\?.*\\)$@\\1https://artifactory.michelin.com/artifactory/ubuntu-archive-remote\\2\\n# &@' /etc/apt/sources.list\nsudo sed -i 's@^\\(deb \\)http://security.ubuntu.com/ubuntu/\\( focal\\(-updates\\)\\?.*\\)$@\\1https://artifactory.michelin.com/artifactory/ubuntu-security-remote\\2\\n# &@' /etc/apt/sources.list\n\n\n\nTo verify if everything is OK on your distribution:\n\nThis command must return google ip:\n\n  host google.fr\n\nThis command must return artifactory ip:\n\n  host artifactory.michelin.com\n\nYou are able to update your distribution without error:\n\n  sudo apt update\n  sudo apt upgrade -y"
  },
  {
    "objectID": "posts/2022-01-18-wsl2 conda mamba cuda.html#conda-mamba---installation-and-configuration",
    "href": "posts/2022-01-18-wsl2 conda mamba cuda.html#conda-mamba---installation-and-configuration",
    "title": "setup wsl2 conda mamba and cuda",
    "section": "Conda Mamba - installation and configuration",
    "text": "Conda Mamba - installation and configuration\n\nconda installation\ntmpdir=$(mktemp -d)\ncd $tmpdir\nwget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nchmod +x Miniconda3-latest-Linux-x86_64.sh\n# answer yes to question Do you wish the installer to initialize Miniconda3 by running conda init?\nbash Miniconda3-latest-Linux-x86_64.sh -p $HOME/miniconda3\n\n&gt;&gt; ==&gt; For changes to take effect, close and re-open your current shell. &lt;==\nWith this configuration, conda will be activate at startup. If you’d prefer that conda’s base environment not be activated on startup, set the auto_activate_base parameter to false: conda config --set auto_activate_base false\n\n\nconda configuration\nAs we have in-house CA certificates, and conda uses its own CA certificates (in ~/miniconda3/ssl)\nWe have to change this behaviour and ask conda to use system CA certifcates.\nAt the end of .bash_rc, add export REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\n\n\nmamba installation\nconda install mamba -n base -c conda-forge\nmamba init\n\n\ninstallation jupyter notebook, nb_conda_kernels, jupyter lab\nmamba install nb_conda_kernels\nmamba install -c conda-forge jupyterlab jupyterlab-git\n\n\ncreate conda envt - fastai (v2.5.3) (optional)\nmamba create --name fastai\nmamba activate fastai\nmamba install -c fastai -c pytorch fastai\nmamba install ipykernel"
  },
  {
    "objectID": "posts/2022-01-18-wsl2 conda mamba cuda.html#jupyter",
    "href": "posts/2022-01-18-wsl2 conda mamba cuda.html#jupyter",
    "title": "setup wsl2 conda mamba and cuda",
    "section": "Jupyter",
    "text": "Jupyter\nStart jupyter (lab or notebook) from base environment, and switch to desired python environment.\n\nmodify jupyter config\n#create jupyter config file in ~.jupyter\njupyter notebook --generate-config\nAnd activate jupyter config file to change #c.NotebookApp.use_redirect_file = True to c.NotebookApp.use_redirect_file = False"
  },
  {
    "objectID": "posts/2023-08-01-logbook-August-23.html",
    "href": "posts/2023-08-01-logbook-August-23.html",
    "title": "Logbook for August 23",
    "section": "",
    "text": "holoviz and datashader, nbdev-mkdocs, git revert, wsl-vpnkit stopped to work"
  },
  {
    "objectID": "posts/2023-08-01-logbook-August-23.html#monday-0821",
    "href": "posts/2023-08-01-logbook-August-23.html#monday-0821",
    "title": "Logbook for August 23",
    "section": "Monday 08/21",
    "text": "Monday 08/21\ndatashader or how to use plotly/bokeh with millions of points\nBefore vacations I had some issues to have it run in a custom python environment.\nNow I have fixed it by: * installing pyviz_comms in my jupyter environment (e.g. conda install -n base_jupyter -c pyviz pyviz_comms) * adding these commands to my active environment\nconda install -c pyviz hvplot datashader\npip install -I pyarrow==11.0.0\npip install -Iv numpy==1.23.0\nAnd then I can just use it with:\nimport hvplot.pandas\ndf.hvplot.scatter(x='x', y='y', rasterize=True, cnorm='eq_hist', width=1200, height=600, c='sigma_1', dynspread=True)\nShould now create a blog entry to fully present that. Can start from the working example at gitlab &gt; dataprophet_TL &gt; nbs &gt; 7_datashader.ipynb"
  },
  {
    "objectID": "posts/2023-08-01-logbook-August-23.html#tuesday-0822",
    "href": "posts/2023-08-01-logbook-August-23.html#tuesday-0822",
    "title": "Logbook for August 23",
    "section": "Tuesday 08/22",
    "text": "Tuesday 08/22\nTrying nbdev-mkdocs which is providing a more modern version of doc website for nbdev using mkdocs.\nBut I have an issue when converting for janus-tools lib, as explained in issue #209\nShould start from scratch or bisect existing lib."
  },
  {
    "objectID": "posts/2023-08-01-logbook-August-23.html#thursday-0824",
    "href": "posts/2023-08-01-logbook-August-23.html#thursday-0824",
    "title": "Logbook for August 23",
    "section": "Thursday 08/24",
    "text": "Thursday 08/24\ngit or how to revert one file from a previous commit\nLet’s say I want to revert to a previous commit the file 3 - uq_conformal - dataset_S.ipynb\n1st to do is to list all known commits where this file is involved with git log –oneline\n❯ git log --oneline 3\\ -\\ uq_conformal\\ -\\ dataset_S.ipynb\n2888291 exploration espace latent\nf16fce7 training on dataset_S\nI would like to get back to the version in commit f16fce7\nThen to revert, it is just about using git checkout\ngit checkout f16fce7 -- 3\\ -\\ uq_conformal\\ -\\ dataset_S.ipynb\nand then to commit and push"
  },
  {
    "objectID": "posts/2023-08-01-logbook-August-23.html#friday-0825",
    "href": "posts/2023-08-01-logbook-August-23.html#friday-0825",
    "title": "Logbook for August 23",
    "section": "Friday 08/25",
    "text": "Friday 08/25\nLooks like no dns access today on my wsl.\n1st symptom was a timeout on a git fetch.\nThen host google.fr has a timeoiut as well.\nI then realized that wsl-vpnkit was stopped. Strange it is supposed to be launched automatically with my distro.\nStarting wsl-vpnkit manually (wsl -d wsl-vpnkit service wsl-vpnkit start) doesn’t help because at each DNS request, wsl-vpnkit is killed.\nLooking at the wsl-vpnkit logs with wsl.exe -d wsl-vpnkit --cd /app tail -f /var/log/wsl-vpnkit.log\ngives this\nip: RTNETLINK answers: File exists\nip: RTNETLINK answers: File exists\nrestored WSL 2 ip route\nwsl-gvproxy.exe exists at ./wsl-vpnkit/wsl-gvproxy.exe\nstarting gvproxy at ./wsl-vpnkit/wsl-gvproxy.exe...\nstarted gvproxy\nwaiting for dhcp...\ntime=\"2023-08-25T07:47:08Z\" level=fatal msg=\"cannot connect to host: fork/exec ./wsl-vpnkit/wsl-gvproxy.exe: exec format error\"\nsh: can't kill pid 51: No such process\nwsl-vm exited\nGoogling this error gives me cannot connect to host: fork/exec /app/wsl-gvproxy.exe: no such file or directory #217 on wsl-vpnkit github issues.\nAnd points to WSL2 (Preview) cannot run .exe files: exec format error: wsl.exe #8952 on WSL github issues.\nSuggestion is to run:\nsudo sh -c 'echo :WSLInterop:M::MZ::/init:PF &gt; /usr/lib/binfmt.d/WSLInterop.conf'\nsudo systemctl unmask systemd-binfmt.service\nsudo systemctl restart systemd-binfmt\nsudo systemctl mask systemd-binfmt.service\nAnd it works\nAdding this to WSL2 blog entry."
  },
  {
    "objectID": "posts/2021-03-25-contribute to a project with git.html",
    "href": "posts/2021-03-25-contribute to a project with git.html",
    "title": "Git - How To Contribute To A Project",
    "section": "",
    "text": "Based on http://qpleple.com/how-to-contribute-to-a-project-on-github/"
  },
  {
    "objectID": "posts/2021-03-25-contribute to a project with git.html#using-clustergit-as-an-example",
    "href": "posts/2021-03-25-contribute to a project with git.html#using-clustergit-as-an-example",
    "title": "Git - How To Contribute To A Project",
    "section": "Using clustergit as an example",
    "text": "Using clustergit as an example\nFork\nMake your own working copy of the project by forking it: go on the project page (https://github.com/mnagel/clustergit) and click “Fork”. You can access you copy at: https://github.com/castorfou/clustergit\nClone\nClone your fork git repository on your local computer:\ngit clone git@github.com:castorfou/clustergit.git\nBranch\ngit branch master-to-main\ngit checkout master-to-main\nThis is very important, create one branch per patch. And never submit a patch that has been done on the branch master or main!\nDevelop\nHere I want to reflect change from Oct/20 where default branch name in github is now main\nsed -i 's/master/main/g' clustergit\nCommit\ngit add -u\ngit commit -m \"default branch name 'main'\"\nPush to github\ngit push origin master-to-main\nCreate pull request\nGo on your fork page (https://github.com/castorfou/clustergit), then select master-to-main in the branch list and click “Pull Request”.\nSubmit patch\nCheck the diff, write a message explaining what you have done and why the repository owner should accept your pull request and submit."
  },
  {
    "objectID": "posts/2020-10-21-open-jupyter-from-http-link.html",
    "href": "posts/2020-10-21-open-jupyter-from-http-link.html",
    "title": "Open Jupyter Notebook with http launch instead of redirect file",
    "section": "",
    "text": "Where is the problem?\nDefault configuration when launching jupyter notebook is to create a redirect file.\nHere is the explanation from config file ~/.jupyter/jupyter_notebook_config.py.\n## Disable launching browser by redirect file\n#\n#  For versions of notebook &gt; 5.7.2, a security feature measure was added that\n#  prevented the authentication token used to launch the browser from being\n#  visible. This feature makes it difficult for other users on a multi-user\n#  system from running code in your Jupyter session as you.\n#\n#  However, some environments (like Windows Subsystem for Linux (WSL) and\n#  Chromebooks), launching a browser using a redirect file can lead the browser\n#  failing to load. This is because of the difference in file structures/paths\n#  between the runtime and the browser.\n#\n#  Disabling this setting to False will disable this behavior, allowing the\n#  browser to launch by using a URL and visible token (as before).\n#c.NotebookApp.use_redirect_file = True\nAnd when launching jupyter notebook from WSL\n(xgboost) guillaume@LL11LPC0PQARQ:~/git/d059-vld-ic$ jupyter notebook\n[I 13:09:57.346 NotebookApp] The port 8888 is already in use, trying another port.\n[I 13:09:57.370 NotebookApp] [jupyter_nbextensions_configurator] enabled 0.4.1\n[I 13:09:57.371 NotebookApp] Serving notebooks from local directory: /mnt/d/git/d059-vld-ic\n[I 13:09:57.372 NotebookApp] The Jupyter Notebook is running at:\n[I 13:09:57.373 NotebookApp] http://localhost:8889/?token=c3f77aea548937f5f563e0306d982d4332d26b0ed623e662\n[I 13:09:57.373 NotebookApp]  or http://127.0.0.1:8889/?token=c3f77aea548937f5f563e0306d982d4332d26b0ed623e662\n[I 13:09:57.374 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).\n[C 13:10:00.384 NotebookApp]\n\n    To access the notebook, open this file in a browser:\n        file:///home/guillaume/.local/share/jupyter/runtime/nbserver-828-open.html\n    Or copy and paste one of these URLs:\n        http://localhost:8889/?token=c3f77aea548937f5f563e0306d982d4332d26b0ed623e662\n     or http://127.0.0.1:8889/?token=c3f77aea548937f5f563e0306d982d4332d26b0ed623e662\n\n\n\nalt text\n\n\n\n\nSolution\nAs given in https://stackoverflow.com/questions/57679894/how-to-change-jupyter-launch-from-file-to-url,\nupdate jupyter config file to change #c.NotebookApp.use_redirect_file = True to c.NotebookApp.use_redirect_file = False\n\n\n\nalt text"
  },
  {
    "objectID": "posts/2020-10-07-gan-specialization-week3-mode_collapse-w_loss.html",
    "href": "posts/2020-10-07-gan-specialization-week3-mode_collapse-w_loss.html",
    "title": "GAN Specialization course 1 week 3 - mode collapse, vanishing gradient, wasserstein loss",
    "section": "",
    "text": "Mode collapse, Vanishing gradient\nVery good explanation about why it happens. Flat region when discriminator is learning faster (it has an easier job) than generator.\n\n\n\nalt text\n\n\n\n\nEarth mover’s distance. Wasserstein loss. 1-L continuous condition\n\n\n\nalt text"
  },
  {
    "objectID": "posts/2022-06-01-logbook-June-22.html",
    "href": "posts/2022-06-01-logbook-June-22.html",
    "title": "Logbook for June 22",
    "section": "",
    "text": "Wednesday 6/15\n\ncontinue deep rl class with unit 2, interesting notebook to learn about using optuna to tune hyperparameters\n\nFriday 6/17\n\nSylvain pointed me to a paper from X: Robust Reinforcement Learning with Distributional Risk-averse formulation now in zotero to use distribution information to strengthen RL epxloration. To be read and tested"
  },
  {
    "objectID": "posts/2022-06-01-logbook-June-22.html#week-24---june-22",
    "href": "posts/2022-06-01-logbook-June-22.html#week-24---june-22",
    "title": "Logbook for June 22",
    "section": "",
    "text": "Wednesday 6/15\n\ncontinue deep rl class with unit 2, interesting notebook to learn about using optuna to tune hyperparameters\n\nFriday 6/17\n\nSylvain pointed me to a paper from X: Robust Reinforcement Learning with Distributional Risk-averse formulation now in zotero to use distribution information to strengthen RL epxloration. To be read and tested"
  },
  {
    "objectID": "posts/2020-10-01-gan-pytorch-coursera.html",
    "href": "posts/2020-10-01-gan-pytorch-coursera.html",
    "title": "Generative Adversarial Networks (GANs) Specialization from Coursera",
    "section": "",
    "text": "Coursera\nThis specialization comes in 3 courses.\n\n\n\nalt text\n\n\nBuild Basic Generative Adversarial Networks\nBuild Better Generative Adversarial Networks\nApply Generative Adversarial Networks\n\n\nenv installation\nI am just getting the version from coursera to be sure I have the same behaviour.\n\nimport torch\n\n\nprint(torch.__version__)\n\n1.4.0\n\n\nSo I can now create a gan environment with appropriate lib versions.\nconda create -n gan python=3.7\nconda activate gan\nconda install -c pytorch pytorch=1.4.0\nconda install jupyter matplotlib\nconda install -c conda-forge tqdm\nconda install -c pytorch torchvision\n\n\ngit settings\necho \"# gan_specialization from coursera\" &gt;&gt; README.md\ngit init\ngit add README.md\ngit commit -m \"first commit\"\ngit branch -M master\ngit remote add origin git@github.com:castorfou/gan_specialization.git\ngit push -u origin master\nI am pushing notebooks to github\n\n\nIntro to PyTorch\nI have exported Intro to Pytorch notebook from coursera lab.\nTo run it on my machine.\n\n\nIntro to GAN using tensorflow\nVersions of python seems incompatible between each other. (3.7 for pytorch, 3.6 for tensorflow=1.10)\nI create a new python environment:\nconda create -n gan_tensorflow python=3.6\nconda activate gan_tensorflow\nconda install jupyter\nconda install -c conda-forge requests\npip install tensorflow-gpu==1.15"
  },
  {
    "objectID": "posts/2023-05-01-logbook-May-23.html",
    "href": "posts/2023-05-01-logbook-May-23.html",
    "title": "Logbook for May 23",
    "section": "",
    "text": "jupyterlab 4.0 is available"
  },
  {
    "objectID": "posts/2023-05-01-logbook-May-23.html#tuesday-0516",
    "href": "posts/2023-05-01-logbook-May-23.html#tuesday-0516",
    "title": "Logbook for May 23",
    "section": "Tuesday 05/16",
    "text": "Tuesday 05/16\n\njupyter 4.0 is out\nhttps://github.com/jupyterlab/jupyterlab/releases/tag/v4.0.0\nTo update\nconda activate base_jupyter\nmamba update -c conda-forge jupyterlab\nit is not yet in conda repos, and I will try later.\nIs there a way to be notified when a monitored package is updated?"
  },
  {
    "objectID": "posts/2021-03-01-logbook-March.html",
    "href": "posts/2021-03-01-logbook-March.html",
    "title": "Logbook for March 21",
    "section": "",
    "text": "Monday 3/1\nMIT 6S191 Deep Generative Modeling (lecture 4) - vaes and gans.\nMIT 6S191 De-biasing Facial Recognition Systems (lab 2): CNN, VAE, DB-VAE\nTuesday 3/2\nCollege de France Approximations non linéaires et réseaux de neurones (lecture 4)\nRL Course by David Silver lecture 1 - intro (22’/88’)\nFuture of Manufacturing@MIT - interesting landscape about Manufacturing and AI\nWednesday 3/3\nInterpretable Machine Learning by Christoph Molnar. LIME reading to understand context of local surrogate models. SHAP chapter using Janus data.\nDeep Reinforcement Learning by Thomas Simonini (Chapter 3 v1) on DQN with temporal limitation using LSTM, and experience replay. (replay buffer)\nThursday 3/4\nInterpretable Machine Learning by Christoph Molnar. PDP chapter using Janus data.\nFriday 3/5\nRL - Sutton book (p220-223) - full vs sample backups, trajectory sampling, heuristic search\nRL - Sutton book (p223+) - start of Approximate Solution Methods, why to use NN."
  },
  {
    "objectID": "posts/2021-03-01-logbook-March.html#week-9---mar-21",
    "href": "posts/2021-03-01-logbook-March.html#week-9---mar-21",
    "title": "Logbook for March 21",
    "section": "",
    "text": "Monday 3/1\nMIT 6S191 Deep Generative Modeling (lecture 4) - vaes and gans.\nMIT 6S191 De-biasing Facial Recognition Systems (lab 2): CNN, VAE, DB-VAE\nTuesday 3/2\nCollege de France Approximations non linéaires et réseaux de neurones (lecture 4)\nRL Course by David Silver lecture 1 - intro (22’/88’)\nFuture of Manufacturing@MIT - interesting landscape about Manufacturing and AI\nWednesday 3/3\nInterpretable Machine Learning by Christoph Molnar. LIME reading to understand context of local surrogate models. SHAP chapter using Janus data.\nDeep Reinforcement Learning by Thomas Simonini (Chapter 3 v1) on DQN with temporal limitation using LSTM, and experience replay. (replay buffer)\nThursday 3/4\nInterpretable Machine Learning by Christoph Molnar. PDP chapter using Janus data.\nFriday 3/5\nRL - Sutton book (p220-223) - full vs sample backups, trajectory sampling, heuristic search\nRL - Sutton book (p223+) - start of Approximate Solution Methods, why to use NN."
  },
  {
    "objectID": "posts/2021-03-01-logbook-March.html#week-10---mar-21",
    "href": "posts/2021-03-01-logbook-March.html#week-10---mar-21",
    "title": "Logbook for March 21",
    "section": "Week 10 - Mar 21",
    "text": "Week 10 - Mar 21\nMonday 3/8\nMIT 6S191 Deep Reinforcement Learning. Q-learning vs Policy Gradient.\nTuesday 3/9\nCollege de France Ondelettes et échantillonnage (lecture 5)\nRL Course by David Silver Introduction to Reinforcement Learning (lecture 1)\nInstallation of clustergit to detect local (=uncommited or unpushed) changes in repo\nWednesday 3/10\nDeep Reinforcement Learning by Thomas Simonini (Chapter 4 v1) on four strategies to improve DQN (fixed Q-targets, double DQN, dueling DQN (DDQN), Prioritized Experience Replay (PER))\nt-SNE using Janus data.\nRL Course by David Silver Markov Decision Processes (lecture 2)\nFriday 3/12\nRL - Sutton book (p287-352) - Applications and case studies, end of the book\nRL Course by David Silver Planning by Dynamic Programming (lecture 3)"
  },
  {
    "objectID": "posts/2021-03-01-logbook-March.html#week-11---mar-21",
    "href": "posts/2021-03-01-logbook-March.html#week-11---mar-21",
    "title": "Logbook for March 21",
    "section": "Week 11 - Mar 21",
    "text": "Week 11 - Mar 21\nMonday 3/15\nMIT 6S191 Limitations and New Frontiers.\nMIT 6S191 Pixels-to-Control Learning (lab 3): Cartpole and Pong\nRL Course by David Silver Model-Free Prediction (lecture 4)\nTuesday 3/16\nCollege de France Multi-résolutions (lecture 6)\nWednesday 3/17\nDeep Reinforcement Learning by Thomas Simonini (Chapter 5 v1) - Policy Gradient\nThursday 3/18\nDeep Reinforcement Learning by Thomas Simonini (Chapter 5 v1) - Policy Gradient notebooks\nRL Course by David Silver Model-Free Control (lecture 5)\nFriday 3/19\nDeep Reinforcement Learning by Thomas Simonini (Chapter 6 v1) - Advantage Actor Critic (A2C) and Asynchronous Advantage Actor Critic (A3C)\nCollege de France - l’apprentissage profond par Yann Lecunn 2016 - Pourquoi l’apprentissage profond ?"
  },
  {
    "objectID": "posts/2021-03-01-logbook-March.html#week-12---mar-21",
    "href": "posts/2021-03-01-logbook-March.html#week-12---mar-21",
    "title": "Logbook for March 21",
    "section": "Week 12 - Mar 21",
    "text": "Week 12 - Mar 21\nMonday 3/22\nMIT 6S191 Evidential Deep Learning and Uncertainty (lecture 7).\nDeep Reinforcement Learning by Thomas Simonini (v1 Part 5) - Advantage Actor Critic (A2C) - implementation and video\nTuesday 3/23\nCollege de France Bases orthonormales d’ondelettes (lecture 7)\nWednesday 3/24\nDeep Reinforcement Learning by Thomas Simonini (Chapter 7 v1) - Proximal Policy Optimization PPO\nStable baselines 3 - init and 1st tutorial\nThursday 3/25\nsetup headless raspberry pi to bridge wifi (tethering from phone) to ethernet (to wifi-router)\nStable baselines 3 - finalize init and go through documentation\nCreate a patch for a github project (by forking and pulling request)\nFriday 3/26\nStable baselines 3 - Documentation &gt; Examples\nRename my branches named master to main"
  },
  {
    "objectID": "posts/2021-03-01-logbook-March.html#week-13---mar-21",
    "href": "posts/2021-03-01-logbook-March.html#week-13---mar-21",
    "title": "Logbook for March 21",
    "section": "Week 13 - Mar 21",
    "text": "Week 13 - Mar 21\nMonday 3/29\nMIT 6S191 Bias and Fairness (lecture 8).\nWednesday 3/31\nCollege de France Parcimonie et compression d’images (lecture 8)"
  },
  {
    "objectID": "posts/2021-09-16-Fix-non-unique-cell-issue-in-Jupyter-Notebook.html",
    "href": "posts/2021-09-16-Fix-non-unique-cell-issue-in-Jupyter-Notebook.html",
    "title": "Fix non-unique cell issue in Jupyter Notebook",
    "section": "",
    "text": "subject is explained in https://github.com/jupyter/notebook/issues/6001\nimport nbformat as nbf\nfrom glob import glob\n\nimport uuid\ndef get_cell_id(id_length=8):\n    return uuid.uuid4().hex[:id_length]\n\n# your notebook name/keyword\nnb_name = '04 - data analysis from dataprophet - W34.ipynb'\nnotebooks = list(filter(lambda x: nb_name in x, glob(\"./*.ipynb\", recursive=True)))\n\n# iterate over notebooks\nfor ipath in sorted(notebooks):\n    # load notebook\n    ntbk = nbf.read(ipath, nbf.NO_CONVERT)\n    \n    cell_ids = []\n    for cell in ntbk.cells:\n        cell_ids.append(cell['id'])\n\n    # reset cell ids if there are duplicates\n    if not len(cell_ids) == len(set(cell_ids)): \n        for cell in ntbk.cells:\n            cell['id'] = get_cell_id()\n\n    nbf.write(ntbk, ipath)"
  },
  {
    "objectID": "posts/2020-10-09-gan-course2-week1-evaluations-on-gans.html",
    "href": "posts/2020-10-09-gan-course2-week1-evaluations-on-gans.html",
    "title": "GAN Specialization course 2 week 1 - evaluations on GANs",
    "section": "",
    "text": "Features extraction, inception v3, embeddings, FID (Fréchet Inception Distance), Sampling and Truncation, Precision and Recall\n\n\n\nalt text"
  },
  {
    "objectID": "posts/2023-01-17-chord-diagram.html",
    "href": "posts/2023-01-17-chord-diagram.html",
    "title": "Chord diagrams",
    "section": "",
    "text": "Generate quickly such visualizations\n\n\n\nimage.png\n\n\nFor a larger gallery, a great site Python Graph Gallery\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2023-01-17-chord-diagram.html#with-my-own-data",
    "href": "posts/2023-01-17-chord-diagram.html#with-my-own-data",
    "title": "Chord diagrams",
    "section": "with my own data",
    "text": "with my own data\n\nnodes_df = pd.read_excel('~/vbox/janus/temp/chord diagram.xlsx', sheet_name='nodes')\nhuman_links_df = pd.read_excel('~/vbox/janus/temp/chord diagram.xlsx', sheet_name='links', header=[1], index_col=1 )\nhuman_links_df.drop(columns=human_links_df.columns[0], axis=1,  inplace=True)\n\n\nnodes_df.head()\n\n\n\n\n\n\n\n\nname\ngroup\n\n\n\n\n0\nguillaume\n1\n\n\n1\nemilie\n1\n\n\n2\nsylvain\n1\n\n\n3\nteddy\n1\n\n\n4\ngilles\n1\n\n\n\n\n\n\n\n\nhuman_links_df.head()\n\n\n\n\n\n\n\n\nguillaume\nemilie\nsylvain\nteddy\ngilles\ngaurav\njerome\njupyter\nvscode\niolab\nwsl\nwindows\nazure ml\ndataiku\ngitlab\nartifactory\nstormshield disk\nnas d1\nazure blob storage\n\n\nname\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nguillaume\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n9.0\n1.0\n3.0\n7.0\n0.0\n1.0\n1.0\n8.0\n3.0\n5.0\n5.0\n0.0\n\n\nemilie\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n5.0\n5.0\n5.0\nNaN\n5.0\nNaN\n0.0\n5.0\nNaN\n5.0\n5.0\nNaN\n\n\nsylvain\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n2.0\n8.0\n2.0\n8.0\nNaN\nNaN\nNaN\n8.0\n3.0\n8.0\nNaN\n2.0\n\n\nteddy\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n5.0\n5.0\n10.0\nNaN\nNaN\nNaN\nNaN\n5.0\nNaN\nNaN\n10.0\nNaN\n\n\ngilles\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n10.0\nNaN\n10.0\nNaN\nNaN\nNaN\nNaN\n5.0\nNaN\nNaN\n10.0\nNaN\n\n\n\n\n\n\n\n\n# we have to transpose human_link to something simpler\nliste_nonnan = list(human_links_df[human_links_df.notnull()].stack().index)\nliste_refs = []\nfor (name1, name2) in liste_nonnan:\n    # print(f'{name1}, {name2}, {human_links_df.loc[name1,name2]}')\n    name1_id = nodes_df.index[nodes_df['name'] == name1].tolist()[0]\n    name2_id = nodes_df.index[nodes_df['name'] == name2].tolist()[0]\n    value = human_links_df.loc[name1,name2]\n    # print(f'{name1_id}, {name2_id}, {human_links_df.loc[name1,name2]}\\n')\n    if value &gt;0:\n        liste_refs.append([name1_id, name2_id, value])\nlinks_df = pd.DataFrame(liste_refs, columns=['source', 'target', 'value'])\n\n\nlinks_df.head()\n\n\n\n\n\n\n\n\nsource\ntarget\nvalue\n\n\n\n\n0\n0\n7\n9.0\n\n\n1\n0\n8\n1.0\n\n\n2\n0\n9\n3.0\n\n\n3\n0\n10\n7.0\n\n\n4\n0\n12\n1.0\n\n\n\n\n\n\n\n\n# data set\nnodes = hv.Dataset(nodes_df, 'index')\nlinks = links_df.copy()\n\n\n# chord diagram\n# chord = hv.Chord((links, nodes)).select(value=(5, None))\nchord = hv.Chord((links, nodes))\nchord.opts(\n    opts.Chord(cmap='Category20', edge_cmap='Category20', edge_color=dim('source').str(), \n               labels='name', node_color=dim('index').str()))"
  },
  {
    "objectID": "posts/2021-09-29-nbdev-notebook2script.html",
    "href": "posts/2021-09-29-nbdev-notebook2script.html",
    "title": "Generate python modules from jupyter notebooks",
    "section": "",
    "text": "I have been using this for more than a year and I have just realized I don’t have any blog entry about it?"
  },
  {
    "objectID": "posts/2021-09-29-nbdev-notebook2script.html#mark-cells-to-be-exported-in-your-notebook",
    "href": "posts/2021-09-29-nbdev-notebook2script.html#mark-cells-to-be-exported-in-your-notebook",
    "title": "Generate python modules from jupyter notebooks",
    "section": "Mark cells to be exported in your notebook",
    "text": "Mark cells to be exported in your notebook\nnotebook2scriptexpects a keyword at the top of each cell to be exported. This keyword is #export.\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’ ExecuteTime=‘{“end_time”:“2021-09-29T06:44:34.555874Z”,“start_time”:“2021-09-29T06:44:34.552776Z”}’ execution_count=1}\nvariable = 'This will be exported in a module'\n:::\n::: {.cell 0=‘e’ 1=‘x’ 2=‘p’ 3=‘o’ 4=‘r’ 5=‘t’ ExecuteTime=‘{“end_time”:“2021-09-29T06:44:54.039338Z”,“start_time”:“2021-09-29T06:44:54.036767Z”}’ execution_count=2}\nvariable2 = 'This one as well'\n:::\n\nvariable3 = 'Not this one'\n\nYou got the idea"
  },
  {
    "objectID": "posts/2021-09-29-nbdev-notebook2script.html#export-your-module-my_great_module",
    "href": "posts/2021-09-29-nbdev-notebook2script.html#export-your-module-my_great_module",
    "title": "Generate python modules from jupyter notebooks",
    "section": "Export your module my_great_module",
    "text": "Export your module my_great_module\n\n#generate py from ipynb\n#code from Jeremy Howard (fastai v2)\n#!python notebook2script.py \"00D059_init_and_import.ipynb\"\n!python notebook2script.py --fnameout=\"my_great_module.py\"  \"2021-09-29-nbdev-notebook2script.ipynb\"\n\nConverted 2021-09-29-nbdev-notebook2script.ipynb to exp/my_great_module.py"
  },
  {
    "objectID": "posts/2021-09-29-nbdev-notebook2script.html#exported-module",
    "href": "posts/2021-09-29-nbdev-notebook2script.html#exported-module",
    "title": "Generate python modules from jupyter notebooks",
    "section": "Exported module",
    "text": "Exported module\nIf subfolder exp doesn’t exist, it will be automatically created.\nAnd my_great_module.py is being created as well.\n\n\n\nexported_module.jpg\n\n\nHere is the content generated.\n\n!cat exp/my_great_module.py\n\n\n#################################################\n### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###\n#################################################\n# file to edit: 2021-09-29-nbdev-notebook2script.ipynb\n\n\nvariable = 'This will be exported in a module'\n\n\nvariable2 = 'This one as well'"
  },
  {
    "objectID": "posts/2022-10-01-logbook-October-22.html",
    "href": "posts/2022-10-01-logbook-October-22.html",
    "title": "Logbook for October 22",
    "section": "",
    "text": "Just playing with huggingface projects.\nWeekly someone from HF publishes news of the week\nLast 2 weeks, Thomas Simonini has sent updates on Transformers, Stable Diffusion. 09/27 10/03\nAnd just playing with these apps, I realize it has been developped using gradio. Should be nice to give a test. Could be usefull for this project: drag&drop badminton players spreadsheet, and return one with uptodate ranks"
  },
  {
    "objectID": "posts/2022-10-01-logbook-October-22.html#friday-107",
    "href": "posts/2022-10-01-logbook-October-22.html#friday-107",
    "title": "Logbook for October 22",
    "section": "",
    "text": "Just playing with huggingface projects.\nWeekly someone from HF publishes news of the week\nLast 2 weeks, Thomas Simonini has sent updates on Transformers, Stable Diffusion. 09/27 10/03\nAnd just playing with these apps, I realize it has been developped using gradio. Should be nice to give a test. Could be usefull for this project: drag&drop badminton players spreadsheet, and return one with uptodate ranks"
  },
  {
    "objectID": "posts/2022-10-01-logbook-October-22.html#wednesday-1012",
    "href": "posts/2022-10-01-logbook-October-22.html#wednesday-1012",
    "title": "Logbook for October 22",
    "section": "Wednesday 10/12",
    "text": "Wednesday 10/12\nI am interested since a while to skip execution of some cells in notebooks.\nI usually have to rerun (most parts of) a notebook when reopen it, \nin order to get access to previously defined variables and go on working.\n\nHowever, sometimes I'd like to skip some of the cells, which have no \ninfluence to subsequent cells (e.g., they might comprise a branch of \nanalysis that is finished) and could take very long time to run. \nThese cells can be scattered throughout the notebook, so that something \nlike \"Run All Below\" won't help much.\nI had used freeze extension a while ago when using exclusively jupyter notebook, and now I use jupyter lab and I have not found any alternative\nThere is a solution proposed here https://stackoverflow.com/questions/19309287/how-to-intermittently-skip-certain-cells-when-running-ipython-notebook that could be of interest:\nusing %%cache"
  },
  {
    "objectID": "posts/2022-10-01-logbook-October-22.html#saturday-1015",
    "href": "posts/2022-10-01-logbook-October-22.html#saturday-1015",
    "title": "Logbook for October 22",
    "section": "Saturday 10/15",
    "text": "Saturday 10/15\njust to create a bash script from Files app in ubuntu (explorer): https://itsfoss.com/add-new-document-option/\n\n\n\nimage.png\n\n\nI would like to create HD pictures to support my pitch of my newbiz idea.\nAnd korben has just tested promptomania to generate best prompt to generate diffusion pictures.\nI have installed a verssion on my linux using https://sd-webui.github.io/stable-diffusion-webui/docs/2.linux-installation.html\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-10-01-logbook-October-22.html#monday-1017",
    "href": "posts/2022-10-01-logbook-October-22.html#monday-1017",
    "title": "Logbook for October 22",
    "section": "Monday 10/17",
    "text": "Monday 10/17\nJust taken back blogging with nbdev to handle publication using gh actions to gh pages.\nAnd finally took time to start fastai courses with chapter 1 - Getting started."
  },
  {
    "objectID": "posts/2022-10-01-logbook-October-22.html#tuesday-1018",
    "href": "posts/2022-10-01-logbook-October-22.html#tuesday-1018",
    "title": "Logbook for October 22",
    "section": "Tuesday 10/18",
    "text": "Tuesday 10/18\nSearching why dark mode doesn’t toggle as expected, I land on this thread https://github.com/quarto-dev/quarto-cli/issues/822\nQuite interesting site where slides are published using quarto. https://pythoncoderunicorn.github.io/Quarto-RLadies/#/title-slide\nAn alternative to RISE?"
  },
  {
    "objectID": "posts/2022-10-01-logbook-October-22.html#thursday-1020",
    "href": "posts/2022-10-01-logbook-October-22.html#thursday-1020",
    "title": "Logbook for October 22",
    "section": "Thursday 10/20",
    "text": "Thursday 10/20\n\nportainer\nJust testing portainer for docker as explained in Run dataiku with docker\n\n\ndetect broken links in blog\nAnd have to figure out a way to detect broken links:\n\nusing google search console\n\nAs it takes a day to be processed I will test again tomorrow\n\n\nfavicon on blog\nCreation of a favicon for this blog.\n\n\ngoogle analytics on blog\nSetup google analytics, get G- Id, and update _quarto.yml accordingly as explained in quarto doc.\nAnalytics available here"
  },
  {
    "objectID": "posts/2022-10-01-logbook-October-22.html#friday-1021",
    "href": "posts/2022-10-01-logbook-October-22.html#friday-1021",
    "title": "Logbook for October 22",
    "section": "Friday 10/21",
    "text": "Friday 10/21\nFastai courses 2022 chapter 2 - Deployment completed\nFastai courses 2022 chapter 3 - Neural net foundations"
  },
  {
    "objectID": "posts/2021-01-21-aristotle-and-deep-learning.html",
    "href": "posts/2021-01-21-aristotle-and-deep-learning.html",
    "title": "Aristotle and Deep learning",
    "section": "",
    "text": "By reading some references in recent paper, I have started to read “artificial intelligence structures and strategies for complex problem solving” by George Luger.\n\nThis is a massive book from 2005 in its 6th edition. I don’t think it has been updated since that. And the author starts a writing of AI history.\nI have been intrigued by the use of the opening sentence from Aristotle in the Metaphysics: “All men by nature desire to know…”. I remembered that sentence (without knowing it was from Aristotle), and I jumped to The Metaphysics _ Aristotle’s wikipedia page (the French one). There is a nice presentation of The MetaPhysics and some extracts that I have found quite interesting. One of them following “All men by nature desire to know” is detailing what is art and science; and for art: one need to be able to recognize similar cases and be able to generalize to an (more) universal rule.\nI cannot not see a link with what is happening in what we do on a daily basis in AI and deep learning. I had been surprised by Jeremy Howard’s curriculum (if I am not wrong he has a major) in Philosophy, and I better understand why he is so good in what he does.\nShould have studied Philosophy and ancient Greek!\nWould love to know your thoughts about that. (and if anyone can ask Jeremy’s without directly @ him)\nHere is a more detailed analysis of Aristotle thought: (again from wikipedia, not my own ;))\nBy nature, all animals are sentient; but sensation is not yet sufficient to produce knowledge: indeed, remarks Aristotle, sensation engenders memory or not. But animals endowed with memory are the most intelligent and the best able to learn. However, man “lives on art and reasoning.” To learn, you have to feel, remember, but man has the capacity to draw experience from these simple images and from a multitude of experimental notions emerges a single judgment that is universal in all similar cases: it is what constitutes art: “Science and art arise for men through experience” 10. Art therefore presupposes: the ability to recognize similar cases and the ability to apply a universal rule to these cases.\n\nOf experience and art, which is more perfect? In practical life, experience seems superior to art, because it is knowledge of the particular, of the individual: sensations, the foundation of knowledge of the particular, are not science and do not teach us the why ( διότι). Art, for its part, knows the universal and goes beyond individual things, it is to art that knowledge and the faculty of understanding belong: men of art know the why and the cause. The wisest are wise not by practical skill, but by theory (λόγος) and knowledge of the causes. This explains the superiority of the architect over the maneuver.\n\nThe sign of this knowledge is that it can be taught; now men of art can teach. However, among the arts some relate to the necessities of life and others come from “leisure” which is knowledge sought for itself, as in mathematics. And through these appears the highest knowledge, wisdom, which has for its object the first causes and the first principles of what-is; therefore the theoretical sciences are superior to the practical sciences.\nFrom observations (rows of data) we can recognize similar cases (patterns or embeddings) and identify universal rules (models?)"
  },
  {
    "objectID": "posts/2020-10-20-mit-edx-introduction-computational-thinking-and-data-science.html",
    "href": "posts/2020-10-20-mit-edx-introduction-computational-thinking-and-data-science.html",
    "title": "edX MIT 6.00.2x Introduction to Computational Thinking and Data Science",
    "section": "",
    "text": "Last summer I have been following a 1st MIT course on python programming. Not that I would need this knowledge but as for Polytechnique courses, I like their way to explain knowledge foundations. Teachers from these schools tend to go back to deep roots, and provide clear and somtimes illuminating examples to help us understand concepts.\nAbout 6 years ago I have completed a Probability introduction from Ecole Polythechnique. That was great. I had always been hermeticly closed to probability and statistics. For a reason I don’t understand, it is not being teached in CPGE (which is a two-or-three-year intensive full-time course preparing top high school graduates for the entrance examination of French engineering and business schools, this is just after high school). It means last time I was exposed to probability was in high school, and probably in engineering school as well but on a light way.\nThat would be great to give back a look to these courses.\n\n\nUnfortunately I registered in September when only a couple of weeks were left to complete this 9-week course. And because I didn’t upgrade to a Verified Certificate, I lost access to materials and progress. It cut when my progress was about 38%.\nI like Eric Grimson’s style. He is calm and has his own way to explain some advanced subjects.\nNext session is planned on Jan 27, 2021. That would be a good idea to complete this course.\n\n\n\nFor this one I have registered on time. And I have purchased the Verified Certificate.\nHere is the full course program and dates:\n\n\n\nalt text\n\n\n1st lectures are interesting. As said before I like to be back to roots of problems. And on that matter I expect to get a full overview.\nLecture 4 should be released in the coming at the end of October. cannot wait to resume these sessions.\nAs a matter of comparaison with gan specialization from coursera+openAI, I like better the interactions with students offered by openAI. They use slack as a platform to support these interactions and I think it is a smart move."
  },
  {
    "objectID": "posts/2020-10-20-mit-edx-introduction-computational-thinking-and-data-science.html#mit-6.00.1x---introduction-to-computer-science-and-programming-using-python",
    "href": "posts/2020-10-20-mit-edx-introduction-computational-thinking-and-data-science.html#mit-6.00.1x---introduction-to-computer-science-and-programming-using-python",
    "title": "edX MIT 6.00.2x Introduction to Computational Thinking and Data Science",
    "section": "",
    "text": "Unfortunately I registered in September when only a couple of weeks were left to complete this 9-week course. And because I didn’t upgrade to a Verified Certificate, I lost access to materials and progress. It cut when my progress was about 38%.\nI like Eric Grimson’s style. He is calm and has his own way to explain some advanced subjects.\nNext session is planned on Jan 27, 2021. That would be a good idea to complete this course."
  },
  {
    "objectID": "posts/2020-10-20-mit-edx-introduction-computational-thinking-and-data-science.html#mit-6.00.2x---introduction-to-computational-thinking-and-data-science",
    "href": "posts/2020-10-20-mit-edx-introduction-computational-thinking-and-data-science.html#mit-6.00.2x---introduction-to-computational-thinking-and-data-science",
    "title": "edX MIT 6.00.2x Introduction to Computational Thinking and Data Science",
    "section": "",
    "text": "For this one I have registered on time. And I have purchased the Verified Certificate.\nHere is the full course program and dates:\n\n\n\nalt text\n\n\n1st lectures are interesting. As said before I like to be back to roots of problems. And on that matter I expect to get a full overview.\nLecture 4 should be released in the coming at the end of October. cannot wait to resume these sessions.\nAs a matter of comparaison with gan specialization from coursera+openAI, I like better the interactions with students offered by openAI. They use slack as a platform to support these interactions and I think it is a smart move."
  },
  {
    "objectID": "posts/2022-09-06-ssl-certificate_verify_failed.html",
    "href": "posts/2022-09-06-ssl-certificate_verify_failed.html",
    "title": "SSL: CERTIFICATE_VERIFY_FAILED",
    "section": "",
    "text": "Description of the problem\nFrom time to time when using network function, I have this kind of errors:\nTraceback (most recent call last):\n  File \"/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/urllib/request.py\", line 1346, in do_open\n    h.request(req.get_method(), req.selector, req.data, headers,\n  File \"/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/http/client.py\", line 1285, in request\n    self._send_request(method, url, body, headers, encode_chunked)\n  File \"/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/http/client.py\", line 1331, in _send_request\n    self.endheaders(body, encode_chunked=encode_chunked)\n  File \"/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/http/client.py\", line 1280, in endheaders\n    self._send_output(message_body, encode_chunked=encode_chunked)\n  File \"/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/http/client.py\", line 1040, in _send_output\n    self.send(msg)\n  File \"/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/http/client.py\", line 980, in send\n    self.connect()\n  File \"/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/http/client.py\", line 1454, in connect\n    self.sock = self._context.wrap_socket(self.sock,\n  File \"/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/ssl.py\", line 501, in wrap_socket\n    return self.sslsocket_class._create(\n  File \"/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/ssl.py\", line 1041, in _create\n    self.do_handshake()\n  File \"/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/ssl.py\", line 1310, in do_handshake\n    self._sslobj.do_handshake()\nssl.SSLCertVerificationError: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1129)\n\n\nContext\nMy company uses some ssl interceptor and it has to be considered as a cert autority.\n\n\nSolution\nfrom https://stackoverflow.com/questions/51390968/python-ssl-certificate-verify-error\nwhere certifcates are kept\n\nimport certifi\npem_path = certifi.where() \npem_path\n\n'/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/certifi/cacert.pem'\n\n\nget company certificates\n\ntmpdir = !mktemp -d\ntmpdir\n\n['/tmp/tmp.0V7L0xu2a5']\n\n\n\n!git clone git@gitlab.michelin.com:DEV/bib-certificates.git {tmpdir[0]}\n\nCloning into '/tmp/tmp.0V7L0xu2a5'...\nremote: Enumerating objects: 87, done.\nremote: Total 87 (delta 0), reused 0 (delta 0), pack-reused 87\nReceiving objects: 100% (87/87), 78.90 KiB | 1.55 MiB/s, done.\nResolving deltas: 100% (26/26), done.\n\n\n\n!ls -l {tmpdir[0]}/*trust-ca.pem\n\n-rw-r--r-- 1 guillaume guillaume 1606 Sep  6 19:11 /tmp/tmp.0V7L0xu2a5/cert_M_X5C_aze-cn-sslfwd-trust-ca.pem\n-rw-r--r-- 1 guillaume guillaume 1606 Sep  6 19:11 /tmp/tmp.0V7L0xu2a5/cert_M_X5C_rnh-ac-sslfwd-trust-ca.pem\n-rw-r--r-- 1 guillaume guillaume 1606 Sep  6 19:11 /tmp/tmp.0V7L0xu2a5/cert_M_X5C_rnh-eu-sslfwd-trust-ca.pem\n-rw-r--r-- 1 guillaume guillaume 1606 Sep  6 19:11 /tmp/tmp.0V7L0xu2a5/cert_M_X5C_rnh-na-sslfwd-trust-ca.pem\n-rw-r--r-- 1 guillaume guillaume 1602 Sep  6 19:11 /tmp/tmp.0V7L0xu2a5/cert_M_X5C_sase-mob-sslfwd-trust-ca.pem\n-rw-r--r-- 1 guillaume guillaume 1602 Sep  6 19:11 /tmp/tmp.0V7L0xu2a5/cert_M_X5C_sase-net-sslfwd-trust-ca.pem\n\n\n\nimport os\n\nfor filename in os.listdir(tmpdir[0]):\n    if filename.endswith(\"trust-ca.pem\"): \n         # print(os.path.join(directory, filename))\n        !cat {os.path.join(tmpdir[0], filename)} &gt;&gt; {pem_path}\n        continue\n    else:\n        continue\n\n\n\nValidate it works\n\nimport urllib.request\nwith urllib.request.urlopen('http://python.org/', cafile=certifi.where()) as response:\n   html = response.read()\n\n/tmp/ipykernel_2003/2808005746.py:2: DeprecationWarning: cafile, capath and cadefault are deprecated, use a custom context instead.\n  with urllib.request.urlopen('http://python.org/', cafile=certifi.where()) as response:\n\n\n\nhtml[:100]\n\nb'&lt;!doctype html&gt;\\n&lt;!--[if lt IE 7]&gt;   &lt;html class=\"no-js ie6 lt-ie7 lt-ie8 lt-ie9\"&gt;   &lt;![endif]--&gt;\\n&lt;!-'\n\n\nand from a command-line\nexport SSL_CERT_FILE='/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/certifi/cacert.pem'\nnbdev_new\n\n\nIntegration in WSL2\nI will modify SSL cert of my (base) environment.\nand add export SSL_CERT_FILE in .bashrc\nI have made the modification at install ubuntu 22.04 on WSL\n\n!cat ../files/setup_wsl_02_install_python_conda_part3.sh\n\necho \"configure SSL cert v2\"\n\nconda deactivate\npip install -U certifi\nexport SSL_CERT_FILE=`python -c 'import certifi;print(certifi.where())'`\n\nexport TMPDIR=`mktemp -d`\ngit clone git@gitlab.michelin.com:DEV/bib-certificates.git $TMPDIR\ncd $TMPDIR\ncat *trust-ca.pem &gt;&gt; $SSL_CERT_FILE\n\ntee -a ~/.bashrc &lt;&lt; EOF\nexport SSL_CERT_FILE=$SSL_CERT_FILE\nEOF\n\nif [ -e \"/.cfg\" ]; then\n        config='/usr/bin/git --git-dir=/.cfg/ --work-tree=/'\n        $config add ~/.bashrc\n        $config commit -m'export certificates for commandline'\n        $config push        \nfi\n\n\n\n\nTo be (re)executed after certifi update\nOf course each time certifi is being updated, we have to re-run this process.\nHere is a script that could be run each time we have the same problem:\n\n!cat /home/guillaume/_conda_env/update_SSL.sh\n\n#!/bin/bash\nconda deactivate\npip list|grep certifi\npip install -U certifi\npip list|grep certifi\nexport SSL_CERT_FILE=`python -c 'import certifi;print(certifi.where())'`\n\nexport TMPDIR=`mktemp -d`\ngit clone git@gitlab.michelin.com:DEV/bib-certificates.git $TMPDIR\ncd $TMPDIR\ncat *trust-ca.pem &gt;&gt; $SSL_CERT_FILE"
  },
  {
    "objectID": "posts/2020-10-07-conda-activate-from-bash-script.html",
    "href": "posts/2020-10-07-conda-activate-from-bash-script.html",
    "title": "Conda activate from bash scripts",
    "section": "",
    "text": "Can’t execute conda activate from bash script\nGood description of the problem in conda github.\nCalling conda activate from a bash script will raise some errors:\nCommandNotFoundError: Your shell has not been properly configured to use 'conda activate'.\nTo initialize your shell, run\n    $ conda init &lt;SHELL_NAME&gt;\n\nCurrently supported shells are:\n  - bash\n  - fish\n  - tcsh\n  - xonsh\n  - zsh\n  - powershell\n\nSee 'conda init --help' for more information and options.\n\n\nsource ~/your_conda/etc/profile.d/conda.sh\nIt is just a matter of sourcing the conda bash settings before calling conda activate.\nIn m case I have installed conda in ~/miniconda3, I just have to call source ~/miniconda3/etc/profile.d/conda.sh\n\n\nExample to run my blogging environment\n#!/bin/bash\nsource ~/miniconda3/etc/profile.d/conda.sh\ncd ~/git/guillaume/guillaume_blog/_notebooks\nconda activate fastai\njupyter notebook"
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html",
    "href": "posts/2022-09-12-nbdev2.html",
    "title": "nbdev2 - first steps",
    "section": "",
    "text": "fastai has just released nbdev2.\nThis is a complete rewrite with quarto. I like how they displayed features in that card"
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html#create-github-project",
    "href": "posts/2022-09-12-nbdev2.html#create-github-project",
    "title": "nbdev2 - first steps",
    "section": "create github project",
    "text": "create github project\n\ncreate a new project with github: dataset_tools. Give a description it will be reused by nbdev"
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html#integrate-nbdev-in-your-python-environment",
    "href": "posts/2022-09-12-nbdev2.html#integrate-nbdev-in-your-python-environment",
    "title": "nbdev2 - first steps",
    "section": "integrate nbdev in your python environment",
    "text": "integrate nbdev in your python environment\n\ncreate a local conda env dataset_tools with what is required to develop this library\n\n\n!cat /home/guillaume/_conda_env/dataset_tools.txt\n\nconda remove --name dataset_tools --all\nconda create --name dataset_tools python=3.9\nconda activate dataset_tools\nconda install ipykernel\npython -m ipykernel install --user --name=dataset_tools\npip install nbdev -U\npip install pandas\n\n\n\nimport sys\n!{sys.prefix}/bin/pip list|grep nbdev\n\nnbdev              2.2.10"
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html#clone-repo-and-turned-it-into-a-nbdev-repo",
    "href": "posts/2022-09-12-nbdev2.html#clone-repo-and-turned-it-into-a-nbdev-repo",
    "title": "nbdev2 - first steps",
    "section": "clone repo and turned it into a nbdev repo",
    "text": "clone repo and turned it into a nbdev repo\n\nclone repo dataset_tools and turn it into a nbdev repo\n\ngit clone git@github.com:castorfou/dataset_tools.git\nconda activate dataset_tools\ncd dataset_tools"
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html#nbdev_-commands-are-ready-to-be-used",
    "href": "posts/2022-09-12-nbdev2.html#nbdev_-commands-are-ready-to-be-used",
    "title": "nbdev2 - first steps",
    "section": "nbdev_ commands are ready to be used",
    "text": "nbdev_ commands are ready to be used\n\nnbdev can be used from here. For example nbdev_help to display all nbdev_ commands and what it does. And more detail can be got with -h: nbdev_new -h\n\n\n!{sys.prefix}/bin/nbdev_help\n\nnbdev_bump_version              Increment version in settings.ini by one\nnbdev_changelog                 Create a CHANGELOG.md file from closed and labeled GitHub issues\nnbdev_clean                     Clean all notebooks in `fname` to avoid merge conflicts\nnbdev_conda                     Create a `meta.yaml` file ready to be built into a package, and optionally build and upload it\nnbdev_create_config             Create a config file.\nnbdev_deploy                    Deploy docs to GitHub Pages\nnbdev_docs                      Create Quarto docs and README.md\nnbdev_export                    Export notebooks in `path` to Python modules\nnbdev_filter                    A notebook filter for Quarto\nnbdev_fix                       Create working notebook from conflicted notebook `nbname`\nnbdev_help                      Show help for all console scripts\nnbdev_install                   Install Quarto and the current library\nnbdev_install_hooks             Install Jupyter and git hooks to automatically clean, trust, and fix merge conflicts in notebooks\nnbdev_install_quarto            Install latest Quarto on macOS or Linux, prints instructions for Windows\nnbdev_merge                     Git merge driver for notebooks\nnbdev_migrate                   Convert all directives and callouts in `fname` from v1 to v2\nnbdev_new                       Create an nbdev project.\nnbdev_prepare                   Export, test, and clean notebooks, and render README if needed\nnbdev_preview                   Preview docs locally\nnbdev_pypi                      Create and upload Python package to PyPI\nnbdev_quarto                    Create Quarto docs and README.md\nnbdev_readme                    Render README.md from index.ipynb\nnbdev_release_both              Release both conda and PyPI packages\nnbdev_release_gh                Calls `nbdev_changelog`, lets you edit the result, then pushes to git and calls `nbdev_release_git`\nnbdev_release_git               Tag and create a release in GitHub for the current version\nnbdev_sidebar                   Create sidebar.yml\nnbdev_test                      Test in parallel notebooks matching `path`, passing along `flags`\nnbdev_trust                     Trust notebooks matching `fname`\nnbdev_update                    Propagate change in modules matching `fname` to notebooks that created them\n\n\n\nnbdev_new. It is creating the structure and files such as settings.ini.\nfrom base environment we can start jupyter notebook. It is advised to install nb_extensions (pip install jupyter_contrib_nbextensions), and activate TOC2. Open 00_core.ipynb with dataset_tools kernel. Rename 00_core.ipynb –&gt; 00_container.ipynb"
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html#and-prefix-in-notebooks-as-well",
    "href": "posts/2022-09-12-nbdev2.html#and-prefix-in-notebooks-as-well",
    "title": "nbdev2 - first steps",
    "section": "and #| prefix in notebooks as well",
    "text": "and #| prefix in notebooks as well\nJeremy explains then what are #| used by quarto and nbdev.\nAnd for example #| hide will allow to be executed but hide in your documentation.\nActually from a single notebook, you have 3 usages: * the notebook by itself - all cells are executed, whatever are the prefix #| that you display on cells * the python file - only the cells with #| export will be published in a python file referenced as #| default_exp &lt;name of python file&gt;. A new file is genreated when nbdev_export is called. * the documentation - all cells are used, except the one started with #| hide. Seems to be dynamically generated (when nbdev_preview is running?). #| export are handled specifically: if you have import, nothing is displayed. If you have code, definitions and docstrings are exported, and arguments as well.\nThere is an easy way to describe arguments of a function.\nJust make some indentation with comments such as in\n    def __init__(self, \n                 cle : str, # la clé du container\n                 dataset : pd.DataFrame = None, # le dataset\n                 colonnes_a_masquer : list = [], # les colonnes à masquer\n                 colonnes_a_conserver : list = [] # les colonnes qui ne seront pas transformées\n                ):\n\nshow_doc\nand we can directly see the effect of it by calling show_doc (show_doc(Container)). You can even call show_doc on code not written with nbdev, or not even written by you.\n\nfrom nbdev.showdoc import *\nimport pandas as pd\nshow_doc(pd.DataFrame)\n\n/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section See Also\n  else: warn(msg)\n/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/fastcore/docscrape.py:225: UserWarning: Unknown section Examples\n  else: warn(msg)\n\n\n\n\nDataFrame\n\n DataFrame (data=None, index:Axes|None=None, columns:Axes|None=None,\n            dtype:Dtype|None=None, copy:bool|None=None)\n\nTwo-dimensional, size-mutable, potentially heterogeneous tabular data.\nData structure also contains labeled axes (rows and columns). Arithmetic operations align on both row and column labels. Can be thought of as a dict-like container for Series objects. The primary pandas data structure.\n\n\n\n\n\n\n\n\n\n\nType\nDefault\nDetails\n\n\n\n\ndata\nNoneType\nNone\nDict can contain Series, arrays, constants, dataclass or list-like objects. Ifdata is a dict, column order follows insertion-order. If a dict contains Serieswhich have an index defined, it is aligned by its index... versionchanged:: 0.25.0 If data is a list of dicts, column order follows insertion-order.\n\n\nindex\nAxes | None\nNone\nIndex to use for resulting frame. Will default to RangeIndex ifno indexing information part of input data and no index provided.\n\n\ncolumns\nAxes | None\nNone\nColumn labels to use for resulting frame when data does not have them,defaulting to RangeIndex(0, 1, 2, …, n). If data contains column labels,will perform column selection instead.\n\n\ndtype\nDtype | None\nNone\nData type to force. Only a single dtype is allowed. If None, infer.\n\n\ncopy\nbool | None\nNone\nCopy data from inputs.For dict data, the default of None behaves like copy=True. For DataFrameor 2d ndarray input, the default of None behaves like copy=False... versionchanged:: 1.3.0\n\n\n\n\n\n\n\n\nunit testing\nThere are some basic testing functionalty available by importing fastcore. from fastcore.test import *\nWith test_eq very closed to assert and test_ne closed to assert not\n\nfrom fastcore.test import *\nshow_doc(test_eq)\nshow_doc(test_ne)\n\n\nsource\n\ntest_ne\n\n test_ne (a, b)\n\ntest that a!=b\n\n\n\nThis is convenient to integrate all the unit tests that way. When you will export by running Restart & Run All, if an error is met, export won’t be done.\nAnd one can run nbdev_test from the command line.\n\n\n@patch - define method out of its class\nJust by adding this import\nfrom fastcore.utils import *\none can use\n@patch\ndef new_method(self:myclass):\n    pass\n\n\nnbdev_export\nfrom command line, one can run nbdev_export\nor directly from jupyter, for example will be executing Restart & Run All\n#| hide\nimport nbdev; nbdev.nbdev_export()\nAnd we can install it to be used directly by running pip install -e .\nIt means that you can now import your project with\nfrom dataset_tools.container import *\nWhen it will be published (pypi or conda), it will be installable by calling\npip install dataset-tools\nor\nconda install -c fastai dataset-tools\nNB: see how _ has been turned into -, and for that to happen we have to update lib_name and lib_path in settings.ini by replacing _with -\nNB2: it is still confusing for me. It looks like modifying lib_path is not a good optiom.\n\n\nindex.ipynb\nHere it is a good idea to give overview about how to use it.\nBy importing your library and start using it.\nAnd it will be exported as the homepage of your lib.\nJust have to decide what should land in index and what should land in module page.\n\n\nnbdev_preview\nJust run it from command line\nnbdev_preview\nand it is accessible from http://localhost:3000.\nThis is a quarto webserver. The 1st time you launch it it will install quarto for you. On ubuntu this is a standard package so it will be updated regularly.\n\nfrom getpass import getpass\n!echo {getpass()} | sudo -S apt-cache show quarto\n\n········\n[sudo] password for guillaume: Package: quarto\nStatus: install ok installed\nPriority: optional\nSection: user/text\nInstalled-Size: 242759\nMaintainer: RStudio, PBC &lt;quarto@rstudio.org&gt;\nArchitecture: amd64\nVersion: 1.1.189\nDescription: Quarto is an academic, scientific, and technical publishing system built on Pandoc.\nDescription-md5: 516c872f9c3577457bbd01eac38f8130\nHomepage: https://github.com/quarto-dev/quarto-cli\n\n\n\n\n\nnbdev_test\nAs mentionned earlier, one can run nbdev_test to execute all tests in all notebooks.\nIf it fails, Hamel has shared his dev workflow. He runs Restart kernel & run All, and use %debug magic command to enter debug mode.\nYou then have access to all ipdb commands such as h for help, p var to print content of var, w for stacktraces\n\n%debug\n\n&gt; /tmp/ipykernel_2453/349085080.py(1)&lt;cell line: 1&gt;()\n----&gt; 1 show_doc(test_eq)\n\nipdb&gt; h\n\nDocumented commands (type help &lt;topic&gt;):\n========================================\nEOF    commands   enable    ll        pp       s                until \na      condition  exit      longlist  psource  skip_hidden      up    \nalias  cont       h         n         q        skip_predicates  w     \nargs   context    help      next      quit     source           whatis\nb      continue   ignore    p         r        step             where \nbreak  d          interact  pdef      restart  tbreak         \nbt     debug      j         pdoc      return   u              \nc      disable    jump      pfile     retval   unalias        \ncl     display    l         pinfo     run      undisplay      \nclear  down       list      pinfo2    rv       unt            \n\nMiscellaneous help topics:\n==========================\nexec  pdb\n\nipdb&gt; q\n\n\n\n\nGolden rule: don’t mix imports and code\nFor a reason it is asked not to mix cells with imports and code.\nI am not sure what is the core reason for that. Something due to show_doc or doc generation?\nDuring my tests, I have seen something complaining about it after running nbdev_export or nbdev_test but cannot reproduce that. Hmmm\n\n\nnbdev_clean\nJust to remove unnecessary metadata in ipynb files.\nWill open an issue, because it fails to run here\n(dataset_tools) guillaume@LK06LPF2LTSSL:~/git/dataset_tools$ nbdev_clean\n/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/nbdev/clean.py:110: UserWarning: Failed to clean notebook\n  warn(f'{warn_msg}')\n/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/nbdev/clean.py:111: UserWarning: clean_ids\n  warn(e)\n/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/nbdev/clean.py:111: UserWarning: clean_ids\n  warn(e)\n\n\npush to github\nNeed to activate github pages from your repo as explained in https://docs.github.com/en/pages/getting-started-with-github-pages/configuring-a-publishing-source-for-your-github-pages-site#publishing-from-a-branch\nSettings &gt; Pages &gt; Under “Build and deployment”, under “Branch”, use the None or Branch drop-down menu and select gh-pages as a publishing source.\n\n\n\nimage.png\n\n\nNot a bad thing to run all these stuff\nnbdev_clean\ngit diff\ngit status\ngit add -A\nnbdev_export\nnbdev_test\nnbdev_docs\ngit commit -am'init version'\ngit push\nNote that for a reason nbdev_clean is failing\n/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/nbdev/clean.py:110: UserWarning: Failed to clean notebook\n  warn(f'{warn_msg}')\n/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/nbdev/clean.py:111: UserWarning: clean_ids\n  warn(e)\n/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/nbdev/clean.py:111: UserWarning: clean_ids\n  warn(e)\nAnd Hamel suggests to add clean_ids = True in settings.ini\nnbdev_docsis pushing the content of index.ipynb to README.md\n\n\ndefine dep\nJust modify settings.inito add dependancies (here pandas)\n# end of settings.ini\n[..]\n### Optional ###\nrequirements = fastcore pandas\n# dev_requirements =\n# console_scripts =\nclean_ids = True\nEt voila!, doc is available at https://castorfou.github.io/dataset_tools/ and you can push that address to your repo settings\n\n\npublish to Pypi, conda, …\nThis is done by calling nbdev_pypior nbdev_conda. And it is modifying settings.ini to increment version number. (very much as nbdev_bump_version does)\nThere are other commands such as nbdev_release_xxx the seems to do quite the same for git."
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html#my-tests-with-our-internal-gitlab",
    "href": "posts/2022-09-12-nbdev2.html#my-tests-with-our-internal-gitlab",
    "title": "nbdev2 - first steps",
    "section": "my tests with our internal gitlab",
    "text": "my tests with our internal gitlab\n\ncreate project in gitlab\nProject name : nbdev_gitlab\nProject URL : https://gitlab.michelin.com janus nbdev_gitlab\nProject description : This is the smallest project to make nbdev working with gitlab\n\nCreate project\n\n\n\nclone it\nconda activate dataset_tools\ncd ~/git\ngit clone git@gitlab.michelin.com:janus/nbdev_gitlab.git\n\n\nnbdev_new\nexport SSL_CERT_FILE='/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/certifi/cacert.pem'\nnbdev_new\n/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/ghapi/core.py:99: UserWarning: Neither GITHUB_TOKEN nor GITHUB_JWT_TOKEN found: running as unauthenticated\n  else: warn('Neither GITHUB_TOKEN nor GITHUB_JWT_TOKEN found: running as unauthenticated')\nCould not access repo: janus/nbdev_gitlab to find your default branch - `main` assumed.\nEdit `settings.ini` if this is incorrect.\nIn the future, you can allow nbdev to see private repos by setting the environment variable GITHUB_TOKEN as described here:\nhttps://nbdev.fast.ai/cli.html#Using-nbdev_new-with-private-repos\nrepo = nbdev_gitlab # Automatically inferred from git\nuser = janus # Automatically inferred from git\nauthor = guillaume # Automatically inferred from git\nauthor_email = guillaume.ramelet@michelin.com # Automatically inferred from git\n# Please enter a value for description\ndescription = This is the smallest project to make nbdev working with gitlab\nsettings.ini created.\n/home/guillaume/miniconda/envs/dataset_tools/lib/python3.9/site-packages/ghapi/core.py:99: UserWarning: Neither GITHUB_TOKEN nor GITHUB_JWT_TOKEN found: running as unauthenticated\n  else: warn('Neither GITHUB_TOKEN nor GITHUB_JWT_TOKEN found: running as unauthenticated')\npandoc -o README.md\n  to: gfm+footnotes+tex_math_dollars-yaml_metadata_block\n  standalone: true\n  default-image-extension: png\n\nmetadata\n  description: This is the smallest project to make nbdev working with gitlab\n  title: nbdev_gitlab\n\nOutput created: _docs/README.md\n\n!ls -l ~/git/nbdev_gitlab\n\ntotal 36\n-rwxrwxrwx 1 guillaume guillaume   978 Sep  5 18:31 00_core.ipynb\n-rwxrwxrwx 1 guillaume guillaume 11337 Sep  5 18:31 LICENSE\n-rwxrwxrwx 1 guillaume guillaume   111 Sep  5 18:31 MANIFEST.in\n-rwxrwxrwx 1 guillaume guillaume   309 Sep 13 14:02 README.md\ndrwxrwxrwx 1 guillaume guillaume  4096 Sep 13 14:02 _docs\n-rwxrwxrwx 1 guillaume guillaume   728 Sep 13 14:02 _quarto.yml\n-rwxrwxrwx 1 guillaume guillaume  1561 Sep 13 14:02 index.ipynb\ndrwxrwxrwx 1 guillaume guillaume  4096 Sep 13 14:02 nbdev_gitlab\n-rwxrwxrwx 1 guillaume guillaume   945 Sep 13 14:02 settings.ini\n-rwxrwxrwx 1 guillaume guillaume  2541 Sep  5 18:31 setup.py\n-rwxrwxrwx 1 guillaume guillaume   600 Sep  5 18:31 styles.css\n\n\n\n\nchange in settings.ini\n- set company_name = acme\n\n- set doc_path = public\n- set branch = main instead of master\n- doc_host = https://%(user)s.pages.gitlab.%(company_name)s.com/\n- git_url = https://gitlab.%(company_name)s.com/%(user)s/%(repo)s\n- doc_baseurl = /%(repo)s\n\n\nchange in _quarto.yml\nnothing to be done with nbdev &gt; v2.3.3\n\n\ncreate .gitlab-ci.yml –&gt; build/publish documentation, push to artifactory\nWith gitlab you have a nice editor to edit pipelines (CI lint)\nOne way to debug is to insert sleep xx and then click debug.\nYou then have access to your docker image.\ndefault:\n  image: 'docker.artifactory.michelin.com/michelin/hub/ubuntu20.04:bib-1.1'\n  tags:\n    - k8s\n  interruptible: true\n  retry:\n    max: 2\n    when:\n      - runner_system_failure\n      - stuck_or_timeout_failure\n\n# Functions that should be executed before the build script is run\nbefore_script:\n  - apt -y install wget\n  - wget \"https://github.com/quarto-dev/quarto-cli/releases/download/v1.1.189/quarto-1.1.189-linux-amd64.deb\"\n  - dpkg -i quarto-1.1.189-linux-amd64.deb\n  - apt -y install python3-pip\n  - wget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/castorfou/guillaume_blog/master/files/setup_wsl_08_pip.sh | bash\n  - pip3 install nbdev\n  - nbdev_install\n\nstages:\n  - test\n  - build_doc\n  - build\n  - deploy_artifactory\n\ntests:\n  stage: test\n  script:\n    - nbdev_test\n\npages:\n  stage: build_doc\n  script:\n    - nbdev_docs\n  artifacts:\n    paths:\n      # The folder that contains the files to be exposed at the Page URL\n      - public\n  rules:\n    # This ensures that only pushes to the default branch will trigger\n    # a pages deploy\n    - if: $CI_COMMIT_REF_NAME == $CI_DEFAULT_BRANCH\n\nwheel:\n  stage: build\n  script:\n    - mkdir -p public\n    - echo \"Build wheel with python version `python3 --version`:\"\n    - pip install -U setuptools wheel pydnx_packaging\n    - pip install -e .\n    - python3 setup.py bdist_wheel\n    - mkdir -p packages && mv dist/* packages/\n  artifacts:\n    when: always\n    paths:\n      - packages/\n\npublish:\n  stage: deploy_artifactory\n  dependencies:\n    - wheel\n  only:\n    - tags\n  script:\n    # create credential config file\n    - &gt;\n      if [ -f '.pypirc' ]; then\n        echo \"Information: .pypirc file is not mandatory anymore.\" && cp .pypirc ~/\n      else\n        echo \"[distutils]\n        index-servers = local\n        [local]\n        repository: https://artifactory.michelin.com/api/pypi/pypi\n        username: fm00884\n        password: &lt;don't even think about it&gt;\" &gt; ~/.pypirc\n      fi\n    - pip install -U twine\n    - pip index versions nbdev_gitlab || true\n    - echo 'If the \"twine upload\" command below failed with a 403 status code, please check that the version is not already uploaded on artifactory (see versions of nbdev_git above).'\n    - twine upload --verbose -r local packages/*\n\n\ncommit to gitlab\nnbdev_prepare\nrm -rf index_files\nnbdev_docs #optionnal if nbdev_preview was used\nnbdev_proc_nbs\ngit diff\ngit status\ngit add -A\ngit commit -am'&lt;proper comment&gt;'\ngit push\n\n\nsetup online-documentation badge\n\nFrom Settings &gt; General &gt; Badges\ncreate a new entry doc\nLink: https://janus.si-pages.michelin.com/nbdev_gitlab/\nBadge image URL: https://img.shields.io/badge/-online_documentation-grey.svg\n\n\n[manual way] create a new version, tag, publication to artifactory\nTo summarize, here is the publishing process\nnbdev_bump_version\ngit add -A\ngit commit -am'&lt;my tag changelog&gt;'\ngit tag -a 0.0.3 -m \"&lt;my tag changelog&gt;\"\ngit push origin 0.0.3 \nAnd it will be published at: artifactory janus-tools package\nto automatically reuse tag name from settings.ini, just use (script way) create a new version, tag, publication to artifactory\nnbdev_bump_version increases version number (in settings.ini and ini.py)\n$ nbdev_bump_version\nOld version: 0.0.2\nNew version: 0.0.3\nwhich is modifying 2 files:\n$ git diff\ndiff --git a/nbdev_gitlab/__init__.py b/nbdev_gitlab/__init__.py\n-__version__ = \"0.0.2\"\n+__version__ = \"0.0.3\"\ndiff --git a/settings.ini b/settings.ini\n-version = 0.0.2\n+version = 0.0.3\n\n\n[script way] create a new version, tag, publication to artifactory\njust call push_tag.sh, it will increase version (calling nbdev_bump_version), and create/push tag with this version and last git commit\n\n!cat ../files/push_tag.sh\n\n#!/bin/bash\nnbdev_bump_version\nLAST_GIT_COMMENT=`git log -1 --pretty=%B`\nVERSION_TO_TAG=`grep \"version \" settings.ini | cut -d '=' -f 2`\n\necho \"Tag: $VERSION_TO_TAG - Comment: $LAST_GIT_COMMENT\"\n\ngit add -A\ngit commit -am\"$LAST_GIT_COMMENT\"\ngit tag -a $VERSION_TO_TAG -m \"$LAST_GIT_COMMENT\"\ngit push origin $VERSION_TO_TAG"
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html#hide",
    "href": "posts/2022-09-12-nbdev2.html#hide",
    "title": "nbdev2 - first steps",
    "section": "#| hide",
    "text": "#| hide\nnot exported, not displayed in doc, executed in jupyter\nSome examples:\n\nimports\nimports that I need for development that I don’t need in my lib\nhere it will be used later in internal tests (and will be executed with nbdev_test)\n#| hide\n#not exported, not displayed in doc, executed in jupyter\n# I need this to develop but not to be found in my lib (actuelly my lib should not depend on nbdev)\nfrom nbdev.showdoc import *\nimport tempfile\nfrom sklearn.datasets import load_diabetes\n\n\ntests\nsome internal tests that I don’t wand in doc\n#| hide\nwith tempfile.TemporaryDirectory(dir=root_data) as tmpdirname:\n    temp_mixpath = MixPath(tmpdirname.split(os.sep)[-1])\n    print(temp_mixpath, temp_mixpath.OBF_DIRECTORY)\nor\n#| hide\ntest_eq(ml25625,MixPath('25625'))\n\n\ntoc\nsome markdown that will appear in jupyter’s TOC\nbut not in doc because I have some export after that\n#| hide\n\n### DatasetObf.get_dataset_initial_filtré\n\n\nexport module\nat the end of notebook\nhere to have an entry in TOC\n#| hide\n# Export module\nand here to export notebook code when restart kernel and run all\n#| hide\nimport nbdev; nbdev.nbdev_export()"
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html#exporti---used-in-combination-of-patch-and-show_doc",
    "href": "posts/2022-09-12-nbdev2.html#exporti---used-in-combination-of-patch-and-show_doc",
    "title": "nbdev2 - first steps",
    "section": "#| exporti - used in combination of @patch and show_doc",
    "text": "#| exporti - used in combination of @patch and show_doc\nexporti will export code but not doc - I use show_doc below\nwithout exporti I would have 2 entries in doc\nI prefer it like that to have a toc entry in jupyter\nAnd only with methods from a class. (otherwise it won’t be exposed)\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html#fixed-nbdev_clean-fails",
    "href": "posts/2022-09-12-nbdev2.html#fixed-nbdev_clean-fails",
    "title": "nbdev2 - first steps",
    "section": "[fixed] nbdev_clean fails",
    "text": "[fixed] nbdev_clean fails\nhttps://forums.fast.ai/t/nbdev-clean-fails-cryptically/98784/13\nSolution: update fastcore to version &gt; 1.2.5"
  },
  {
    "objectID": "posts/2022-09-12-nbdev2.html#fixed-nbdev_prepare-typeerror-exception-when-parsing-pycaret-import",
    "href": "posts/2022-09-12-nbdev2.html#fixed-nbdev_prepare-typeerror-exception-when-parsing-pycaret-import",
    "title": "nbdev2 - first steps",
    "section": "[fixed] nbdev_prepare TypeError exception when parsing pycaret import",
    "text": "[fixed] nbdev_prepare TypeError exception when parsing pycaret import\nas explained in https://github.com/fastai/nbdev/issues/1150\nSeem has fixed it. Culprit was in execnb. It will be integrated in release 0.1.5. Meanwhile I can fix it by running pip install git+https://github.com/fastai/execnb.git\n(for example in .gitlab-ci.yml)"
  },
  {
    "objectID": "posts/2022-06-15-deep-rl-class-with-huggingface.html",
    "href": "posts/2022-06-15-deep-rl-class-with-huggingface.html",
    "title": "Deep RL class - huggingface",
    "section": "",
    "text": "Didn’t mention that but I have started The Hugging Face Deep Reinforcement Learning Class by Thomas Simonini.\nThomas is now part of HuggingFace.\n1st step is to fork the repo, and for mine it is here.\nAnd clone it locally: git clone git@github.com:castorfou/deep-rl-class.git ou git clone https://github.com/castorfou/deep-rl-class.git\nI followed the 1st unit in May/11.\nthere is a community on discord at https://discord.gg/aYka4Yhff9, with a lounge about RL.\n\nUnit 1 - Introduction to Deep Reinforcement Learning\n\n📖 It starts with some general introduction to deep RL and then a quizz.\n\n\n👩‍💻 1st practice uses this lunar lander environment, and you train a PPO agent to get the highest score,\n\nand this runs on colab : https://github.com/huggingface/deep-rl-class/blob/main/unit1/unit1.ipynb (just by clicking on )\nthere is a leaderboard running under huggingface (one can publish models to huggingface) https://huggingface.co/spaces/chrisjay/Deep-Reinforcement-Learning-Leaderboard . Just need an huggingface account for that (used my Michelin account)\n\nA guide has been recently added explaining how to tune hyperparameters using optuna. 👉 https://github.com/huggingface/deep-rl-class/blob/main/unit1/unit1_optuna_guide.ipynb. Should do it!\nTo start unit2. Introduction to Q-Learning\n\nfirst update from fork just by clicking\nand update your local repo (git fetch git pull)\n\n\n\n\nUnit 2 - Introduction to Q-Learning\n\n📖 part 1 - we learned about the value-based methods and the difference between Monte Carlo and Temporal Difference Learning. Then a quizz (easy one)\n\n\n📖 part 2 - and then Q-learning which is an off-policy value-based method that uses a TD approach to train its action-value function. Then a quizz (less easier)\n\n\n👩‍💻 hands-on. 1st algo (FrozenLake) is published in Guillaume63/q-FrozenLake-v1-4x4-noSlippery. 2nd algo (Taxi) is published in Guillaume63/q-Taxi-v3. Leaderboard is here\n\n\n\nUnit 3 - Deep Q-Learning with Atari Games\n\n📖 The Deep Q-Learning chapter 👾 👉 https://huggingface.co/blog/deep-rl-dqn\n\n\n👩‍💻 Start the hands-on here 👉 https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit3/unit3.ipynb\nfrom discord, a video (30’) by Antonin Raffin about Automatic Hyperparameter Optimization @ ICRA 22 - Tools for Robotic RL 6/8. Never thought about it that way, it can help to speed training phase.\nfrom discord as well a video to build a doom ai model (3 hours!)\nand from discord a lecture from Pieter Abbeel explaining Q-value to DQN and why we have this double network at L2 Deep Q-Learning (Foundations of Deep RL Series. This is part of a larger lecture available at Foundations of Deep RL – 6-lecture series by Pieter Abbeel\nAnd then a video explaining Deep RL at the Edge of the Statistical Precipice. This was from a paper at Neurips.\n\n\n\nUnit 4 - An Introduction to Unity ML-Agents with Hugging Face 🤗\n\n📖 tutorial 👉 https://link.medium.com/KOpvPdyz4qb\nThomas starts with evolutions on RL domain, citing Decision Transformers as one of the last hot topic. And then introduces Unity and how it can now be used with RL agents.\n\n\n\nunity ML-Agents toolkit\n\n\nInteresting idea to introduce curiosity and to make it real as an intrinsic reward.\n\nNote: It guided me to gentle introductions to cross-entropy for machine learning and information entropy.\n\nLow Probability Event (surprising): More information. High entropy.\nHigher Probability Event (unsurprising): Less information. Low entropy.\nSkewed Probability Distribution (unsurprising): Low entropy.\nBalanced Probability Distribution (surprising): High entropy.\n\n$$ Information:\n\\h(x)=-(P(x)) $$\n\\[\nEntropy:\n\\\\H(X) = – \\sum_{x \\in X} P(x)  \\log(P(x))\n\\]\n\\[\nCross-Entropy:\\\\H(P, Q) = – \\sum_{x \\in X} P(x)  \\log(Q(x))\n\\]\nCross-Entropy and KL divergence are similar but not exactly the same. Specifically, the KL divergence measures a very similar quantity to cross-entropy. It measures the average number of extra bits required to represent a message with Q instead of P, not the total number of bits.\n\\[\nKL\\ Divergence\\ (relative\\ entropy):\n\\\\KL(P||Q)=– \\sum_{x \\in X} P(x)  \\frac{\\log(Q(x))}{\\log(P(x))}\n\\\\H(P, Q) = H(P) + KL(P || Q)\n\\]\n\n\n\n👩‍💻 Here are the steps for the training:\n\nclone repo and install environment\n\n# from ~/git/guillaume\ngit clone https://github.com/huggingface/ml-agents/\n# bug with python 3.9 - https://github.com/Unity-Technologies/ml-agents/issues/5689\nconda create  --name ml-agents python=3.8\nconda activate ml-agents\n# Go inside the repository and install the package \ncd ml-agents \npip install -e ./ml-agents-envs \npip install -e ./ml-agents\n\ndownload the Environment Executable (pyramids from google drive)\n\nUnzip it and place it inside the MLAgents cloned repo in a new folder called trained-envs-executables/linux\n\nmodify nbr of steps to 1000000 in config/ppo/PyramidsRND.yaml\ntrain\n\nmlagents-learn config/ppo/PyramidsRND.yaml --env=training-envs-executables/linux/Pyramids/Pyramids --run-id=\"First Training\" --no-graphics\n\nmonitor training\n\ntensorboard --logdir results --port 6006\n(auto reload is off by default this day, click settings and check Reload data) (because I have installed v2.3.0 and not 2.4.0, there is no autofit domain to data and it is annoying)\n\npush to 🤗 Hub\n\nCreate a new token (https://huggingface.co/settings/tokens) with write role\nCopy the token, Run this and past the token huggingface-cli login\nPush to Hub\nmlagents-push-to-hf --run-id='First Training' --local-dir='results/First Training' --repo-id='Guillaume63/MLAgents-Pyramids' --commit-message='Trained pyramids agent upload'\nand now I can play it from https://huggingface.co/Guillaume63/MLAgents-Pyramids and watch your Agent play…\n\n\n\nUnit 5 - Policy Gradient with PyTorch\n\n1️⃣ 📖 Read Policy Gradient with PyTorch Chapter.\nAdvantage and disadvantage of policy gradient vs DQN.\nReinforce algorithm (Monte Carlo policy gradient): it uses an estimated return from an entire episode to update the policy parameters.\nThe output of it is a probability distribution of actions. And we try to maximize J(θ) which is this estimated return. (details of Policy Gradient theorem in this video from Pieter Abbeel)\nWe will update weights using this gradient: \\[\n\\theta \\gets  \\theta + \\alpha\\nabla_\\theta J(\\theta)\n\\] \n\n\\(\\nabla_\\theta\\log\\pi_\\theta(a_t \\| s_t)\\) is the direction of steepest increase of the (log) probability of selecting action at from state \\(s_t\\). =&gt; This tells use how we should change the weights of policy if we want to increase/decrease the log probability of selecting action at state \\(s_t\\).\n\\(R(\\tau)\\) is the scoring function:\n\nIf the return is high, it will push up the probabilities of the (state, action) combinations.\nElse, if the return is low, it will push down the probabilities of the (state, action) combinations.\n\n\n\n\n2️⃣ 👩‍💻 Then dive on the hands-on where you’ll code your first Deep Reinforcement Learning algorithm from scratch: Reinforce.\n👉 https://colab.research.google.com/github/huggingface/deep-rl-class/blob/main/unit5/unit5.ipynb\n1st model is Cartpole. After training on 10’000 episodes, perfect score of 500 +- 0. Thomas pointed me to a video (3h) from Aniti where Antonin Raffin gives some tips and tricks. And points to many papers such as Deep Reinforcement Learning that Matters (in zotero)\n2nd model is Pixelcopter. High level of variance in perf. Recommended by Thomas to tune hyper parameters (optuna?).\n3rd model is Pong."
  },
  {
    "objectID": "posts/2020-09-28-upgrade-ubuntu-18.04-to-20.04.html",
    "href": "posts/2020-09-28-upgrade-ubuntu-18.04-to-20.04.html",
    "title": "Upgrade ubuntu LTS 18.04 to 20.04",
    "section": "",
    "text": "Standard upgrade process\nAs a LTS user, I want to keep using these long term support version.\n\n!cat /etc/issue\n\nUbuntu 18.04.5 LTS \\n \\l\n\n\n\nA good way to do it is by using do-release-upgrade tool. Full explanation at: 18.04 to 20.04.\nsudo do-release-upgrade\nChecking for a new Ubuntu release\nThere is no development version of an LTS available.\nTo upgrade to the latest non-LTS develoment release \nset Prompt=normal in /etc/update-manager/release-upgrades.\n\n\nWaiting for blockers to be fixed\nThere is a last blocker before releasing Ubuntu 20.04.1 LTS.\n{% include alert.html text=“Expected around 1st of October 2020.” %}\n\n\n(2020-09-28) blockers are fixed, upgrade in progress\nUnfortunately the upgrade process went uneventful. Nothing broke, nothing to learn ;)\nIt took minutes to do the upgrade.\n\n\n\nalt text\n\n\nUbuntu releases-code names"
  },
  {
    "objectID": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html",
    "href": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html",
    "title": "Introduction to Reinforcement Learning with David Silver",
    "section": "",
    "text": "This classic 10 part course, taught by Reinforcement Learning (RL) pioneer David Silver, was recorded in 2015 and remains a popular resource for anyone wanting to understand the fundamentals of RL.\nWebsite with 10 lectures: videos and slides\nMy repo with slides"
  },
  {
    "objectID": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-1-introduction-to-reinforcement-learning",
    "href": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-1-introduction-to-reinforcement-learning",
    "title": "Introduction to Reinforcement Learning with David Silver",
    "section": "3/9/21 - Lecture 1: Introduction to Reinforcement Learning",
    "text": "3/9/21 - Lecture 1: Introduction to Reinforcement Learning\nThis introduction is essentially about giving examples of RL to have a good intuition about this field and to provide definitions or context:\n\nDefinitions: rewards, actions, agent, environment, state (and history)\nMajor components: policy, value function, model\nCategorizing RL agents (taxonomy): value based, policy based, actor critic, model free, model based\nLearning and planning\nPrediction and control\n\nAnd David gives 2 references:\n\nwell known Introduction to Reinforcement Learning, Sutton and Barto, 1998\nAlgorithms for Reinforcement Learning, Szepesvari. Available online.\n\nPolicy \\[\\pi\\](s): essentially a map from state to action. Can be deterministic \\[\\pi\\](s) or stochastic \\[\\pi\\](a|s).\nValue function v\\(\\pi\\)(s): is a prediction of expected future reward.\nModel: it is not the environment itself but useful to predict what the environment will do next. 2 types of models: transitions model and rewards model. Transition model predicts the next state (e.g. based on dynamics). Reward model predicts the next immediate reward.\nA lot of algorithms are model-free and doesn’t require these models. It is a fundamental distinctions in RL.\n\nAnd then David explains 2 fundamental different problems with Learning vs Planning.\nWith Learning, environment is unknown, agent interacts directly with the environment and improves its policy.\nWith Planning, a model of environment is known, and agent “plays” with this model and improves its policy.\nThese 2 problems may be linked where you start to learn from the environment and apply planning then.\n2 examples based on atari games.\nAnother topic is exploration vs exploitation then prediction and control."
  },
  {
    "objectID": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-2-markov-decision-processes",
    "href": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-2-markov-decision-processes",
    "title": "Introduction to Reinforcement Learning with David Silver",
    "section": "3/10/21 - Lecture 2: Markov Decision Processes",
    "text": "3/10/21 - Lecture 2: Markov Decision Processes\nMarkov decision processes formally describe an environment for reinforcement learning.\nMarkov property: the future is independent of the past given the present.\nMarkov Process (or Markov Chain) is the tuple (S, P)\n\nWe can take sample episodes from this chain. (e.g. C1 FB FB C1 C2 C3 Pub C1 FB FB FB C1 C2 C3 Pub C2 Sleep)\nWe can formalize the transition matrix from s to s’.\nWhen you add reward you get Markov reward process (S, P, R, \\[\\gamma\\])\nReward here is a function to map for each state the immediate reward.\n\\[\\gamma\\] is the discounted factor, \\[\\epsilon\\] [0,1]. David explains why we could need such discount.\nReturn Gt is the total discounted reward at time-step t for a given sample.\n\nValue function v(s) is really what we care about, it is the long-term value of state s.\n\nBellman Equation for MRPs\nThe value function can be decomposed into two parts: - immediate reward Rt+1 - discounted value of next state \\[\\gamma\\].v (St+1)\n\nWe use that to calculate value function with \\[\\gamma\\] \\(\\neq\\) 0.\nAnd calculating value function can be seen as the resolution of this linear equation:\n\nAnd now we introduce actions and it gives Markov Decision Process\n\nAnd we introduce policy\n\nThen we can define the state-value function v\\(\\pi\\)(s,a) for a given policy \\[\\pi\\]\n\nand action-value function q\\(\\pi\\)(s,a) for a given policy \\[\\pi\\]\n\nAnd impact on Bellman Equation ends like that:\n\nv is giving us how good it is to be in a state. q is giving us how good is it to take an action.\nAnd then we have the Bellman equation expressed with v and q.\nWe don’t care much about a given v\\(\\pi\\), we want to get the best policy. And ultimately to get q* which is the optimal action value function.\n\nThe optimal value function specifies the best possible performance in the MDP. A MDP is “solved” when we know the optimal value function q*.\nWhat we really care about is optimal policy \\[\\pi\\]*. There is a partial ordering about policies. And a theorem saying that for any MDP, there exists at least one optimal policy.\nSo the optimal value function calculation is similar to what we did earlier when we averaged the value of the next state but now we take the max instead of average.\nSo no we can write the Bellman Optimality Equation. Unfortunately this is non-linear.\nThere are many approaches such as iterative ones.\n\nValue Iteration\nPolicy Iteration\nQ-learning\nSarsa"
  },
  {
    "objectID": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-3-planning-by-dynamic-programming",
    "href": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-3-planning-by-dynamic-programming",
    "title": "Introduction to Reinforcement Learning with David Silver",
    "section": "3/12/21 - Lecture 3: Planning by Dynamic Programming",
    "text": "3/12/21 - Lecture 3: Planning by Dynamic Programming\nWill discuss from the agent side: how to solve these MDP problems.\nDavid starts with general ideas on dynamic programming. (programming in a sense of policy)\nValue function is an important idea for RL because it sotres valuable information that you can later reuse (it embeds solutions). And Bellman equation gives the recursive decomposition.\nPlanning by Dynamic Programming\nWe assume full knowledge of the MDP. Dynamic programming is used for planning in an MDP. With 2 usages:\n\nprediction: given MDP and policy \\[\\pi\\], we predict the value of this policy v\\(\\pi\\).\ncontrol: given MDP, we get optimal value function v* and optimal policy \\(\\pi\\)*.\n\nAnd by full MDP it would mean for an atari game to have access to internal code to calculate everything.\nWe need the 2 aspects to solve MDP: prediction to value policy, and control to get the best one.\nPolicy Evaluation\nProblem: evaluate a given policy π Solution: iterative application of Bellman expectation backup\n(Bellman expectation is used in prediction, Bellman optimality is used in control)\nDavid takes an example with a small grid-world and calculates iteratively (k=0, 1, 2, …) v(s) for a uniform random policy (north, south, east, west with prob 0.25) (left column). And then we follow policy greedily using v function. (right column)\nPolicy Iteration\nIn small grid-world example, just by evaluating the policy and act greedily were sufficient to get the optimal policy. This is not generally the case. In general, need more iterations of evaluation (iterative policy evaluation) / improvement (greedy policy). But this process of policy iteration always converges to π∗\nDavid uses Jack’s Car Rental where it needs 4 steps to get the optimal policy. And explains why acting greedy improves the policy. And if improvement stops, Bellman optimality equation is satisfied, we have our optimal policy.\nSome question then about convergence of v\\(\\pi\\) . Why not update policy at each step of evaluation -&gt; this is value iteration.\nValue Iteration\nProblem: find optimal policy π Solution: iterative application of Bellman optimality backup\nExtensions to dynamic programming\nDP uses full-width backups. It is effective for medium-sized problems. Curse of dimensionality for large problems. Even one backup can be too expensive.\nOne solution is to sample backups.\nAdvantages: Model-free: no advance knowledge of MDP required Breaks the curse of dimensionality through sampling Cost of backup is constant, independent of n = |S|"
  },
  {
    "objectID": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-4-model-free-prediction",
    "href": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-4-model-free-prediction",
    "title": "Introduction to Reinforcement Learning with David Silver",
    "section": "3/15/21 - Lecture 4: Model-Free Prediction",
    "text": "3/15/21 - Lecture 4: Model-Free Prediction\nModel-Free: no-one gives us the MDP. And we still want to solve it.\n\nMonte-Carlo learning: basically methods which goes all the way to the end of trajectory and estimates value by looking at sample returns.\nTemporal-Difference learning: goes one step ahead and estimates after one step\nTD(\\[\\lambda\\]): unify both approaches\n\nWe give up the assumption giving how the environment works (which is highly unrealistic for interesting problems). We break it down in 2 pieces (as with previous lecture with planning):\n\npolicy evaluation case (this lecture) - how much reward we get from that policy (in model-free envt)\ncontrol (next lecture) - find the optimum value function and then optimum policy\n\nMonte-Carlo Reinforcement Learning\nWe go all the way through the episodes and we take sample returns. So the estimated value function can be the average of all returns. You have to terminate to perform this mean.\nIt means we use the empirical mean return in place of expected return. (by law of large numbers, this average returns will converge to value function as the number of episodes for that state tends to infinity)\nTemporal-Difference Reinforcement Learning\nTD learns from incomplete episodes, by bootstrapping\nDavid takes an example from Sutton about predicting time to commute home, comparing MC and TD.\nTD target (Rt+1+\\[\\gamma\\]Vt+1) is biased estimate of v\\(\\pi\\)(St), but has lower variance than the return Gt.\nDavid compares perf of MC, TD(0), … using Random Walk example and different values of \\[\\alpha\\]."
  },
  {
    "objectID": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-5-model-free-control",
    "href": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-5-model-free-control",
    "title": "Introduction to Reinforcement Learning with David Silver",
    "section": "3/18/21 - Lecture 5: Model-Free Control",
    "text": "3/18/21 - Lecture 5: Model-Free Control\nDistinction between on-policy (learning by doing the job) and off-policy (following someone else behavior)\non-policy\nIn Monte-Carlo approach, we have 2 issues. First is that we don’t have access to model so we should use Q(s, a) instead of v(s). Second is lack of exploration so we should use \\[\\epsilon\\]-greedy policy.\nWith GLIE (Greedy in the Limit with Infinite Exploration), we can update Q after each episodes.\nWe will now use TD:\nNatural idea: use TD instead of MC in our control loop\n\nApply TD to Q(S, A)\nUse \\[\\epsilon\\]-greedy policy improvement\nUpdate every time-step\n\nThis is SARSA update. Every single time-step we update our diagram.\nA generalisation is n-step Sarsa. n=1 is standard Sarsa. n=\\[\\infty\\] is MC.\nTo get the best of both worlds, we consider Sarsa(\\[\\lambda\\]). We have a forward version\n\nAnd a backward version which allows online experience. Thanks to eligibility traces.\noff-policy\nWhy is this important?\n\nLearn from observing humans or other agents\nRe-use experience generated from old policies π 1 , π 2 , …, π t−1\nLearn about optimal policy while following exploratory policy\nLearn about multiple policies while following one policy\n\nWe can apply it in importance sampling for off-policy. With Monte-Carlo it is however useless due to high variance. It is imperative to to TD.\nWe can apply that to Q-learning. We can use greedy slection on target policy \\[\\pi\\] and \\[\\epsilon\\] greedy on behaviour policy \\[\\mu\\]."
  },
  {
    "objectID": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-6-value-function-approximation",
    "href": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-6-value-function-approximation",
    "title": "Introduction to Reinforcement Learning with David Silver",
    "section": "4/27/21 - Lecture 6: Value Function Approximation",
    "text": "4/27/21 - Lecture 6: Value Function Approximation\nHow to scale up value function approach.\nValue Function Approximation\nSo far we have represented value function by a lookup table Every state s has an entry V (s) Or every state-action pair s, a has an entry Q(s, a)\nSolution for large MDPs: Estimate value function with function approximation v̂ (s, w) ≈ v π (s) or q̂(s, a, w) ≈ q π (s, a) Generalise from seen states to unseen states Update parameter w using MC or TD learning\nThere are many function approximators, e.g.\n\nLinear combinations of features\nNeural network\nDecision tree\nNearest neighbour\nFourier / wavelet bases\n\nWe focus on differentiable function approximators."
  },
  {
    "objectID": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-7-policy-gradient-methods",
    "href": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-7-policy-gradient-methods",
    "title": "Introduction to Reinforcement Learning with David Silver",
    "section": "5/4/21 - Lecture 7: Policy Gradient Methods",
    "text": "5/4/21 - Lecture 7: Policy Gradient Methods\n3 methods:\n\nfinite difference\nMC policy gradient\nActor-Critic Policy Gradient\n\nadvantages of policy based RL vs value based RL:\n\nconvergence (w/o oscillation that one can see in value based)\neffective in continuous action spaces (in some cases taking the max (of q value) can be quite expensive)\npolicy based RL can learn stochastic policies which can be beneficial in some cases (e.g. rock scissor paper) (usually where you don’t fall into MDP with perfect states representation but we get partially observed environments)\n\nSome examples of policy: softmax policy and gaussian policy.\nOne-step MDP: terminating after 1 time-step. No sequence. In that case we have \\[\nJ(\\theta)=\\mathbb{E}_{\\pi_\\theta}[r]=\\sum_{s \\in \\mathcal{S}}d(s)\\sum_{a \\in \\mathcal{A}}\\pi_\\theta(s, a)\\mathcal{R}_{s,a}\n\\\\\nand\\\\\n\\nabla_\\theta J(\\theta) = \\sum_{s \\in \\mathcal{S}}d(s)\\sum_{a \\in \\mathcal{A}}\\pi_\\theta(s, a)\\nabla_\\theta \\log\\pi_\\theta(s, a)\\mathcal{R}_{s,a}\n\\\\\n\\nabla_\\theta J(\\theta) = \\mathbb{E}_{\\pi_\\theta}[\\nabla_\\theta \\log\\pi_\\theta(s, a)r]\n\\] Generalization is to replace instantaneous reward r with long-term value \\(Q_\\pi(s,a)\\)\n1st algorithm is Monte-Carlo policy gradient (REINFORCE) - tend to be slow, very high variance\nWhere we sample \\(Q_\\pi(s,a)\\) in \\(v_t\\) and regularly update \\(\\theta\\).\nReducing variance using a critic.\nWe use a critic to estimate the action-value function, \\(Q_w (s, a) ≈ Q_{π_θ} (s, a)\\) Actor-critic algorithms maintain two sets of parameters:\n\nCritic Updates action-value function parameters w\nActor Updates policy parameters θ, in direction suggested by critic\n\nActor-critic algorithms follow an approximate policy gradient \\[\n\\nabla_\\theta J(\\theta) \\approx \\mathbb{E}_{\\pi_\\theta}[\\nabla_\\theta \\log\\pi_\\theta(s, a)Q_w(s, a)]\n\\\\\n\\Delta\\theta=\\alpha\\nabla_\\theta\\log\\pi_\\theta(s, a)Q_w(s, a)\n\\] Critic will use a policy evaluation (several options seen so far: monte-carlo policy evaluation, TD, TD(\\(\\lambda\\)))"
  },
  {
    "objectID": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-8-integrating-learning-and-planning",
    "href": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-8-integrating-learning-and-planning",
    "title": "Introduction to Reinforcement Learning with David Silver",
    "section": "6/21/21 - Lecture 8: Integrating Learning and Planning",
    "text": "6/21/21 - Lecture 8: Integrating Learning and Planning\n3 parts in this lecture:\n\nmodel based reinforcement learning\nintegrated architecture\nsimulation-based search\n\nLearn by model. What we mean by the model is 2 parts: understand transitions (how one state will transition to another state) and reward. If the agent has this understanding, then one can plan with that.\nModel-Free RL\n\nNo model\nLearn value function (and/or policy) from experience\n\nModel-Based RL\n\nLearn a model from experience\nPlan value function (and/or policy) from model\n\nModel-Based RL (using Sample-Based Planning)\n\nLearn a model from real experience\nPlan value function (and/or policy) from simulated experience\n\nDyna-Q is a way to combine real experience with simulation.\nSimulation-Based Search\n\nForward search paradigm using sample-based planning\nSimulate episodes of experience from now with the model\nApply model-free RL to simulated episodes\n\nSimulate episodes of experience from now with the model\n\\[\n\\Big\\{ S_t^k, A_t^k, R_{t+1}^k, ..., S_T^k \\Big\\}_{k=1}^K \\sim \\mathcal{M}_v\n\\]\nApply model-free RL to simulated episodes\n\nMonte-Carlo control → Monte-Carlo search\nSarsa → TD search"
  },
  {
    "objectID": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-9-exploration-and-exploitation",
    "href": "posts/2021-03-09-Introduction to Reinforcement Learning with David Silver.html#lecture-9-exploration-and-exploitation",
    "title": "Introduction to Reinforcement Learning with David Silver",
    "section": "7/1/21 - Lecture 9: Exploration and exploitation",
    "text": "7/1/21 - Lecture 9: Exploration and exploitation\nDavid starts with a multi-armed bandit case. We can think about it as a one-step MDP.\nBut in that case we don’t have states anymore.\nDefinition of regret as the total opportunity loss (how far we are from the best value). And maximizing cumulative reward is the same as minimizing total regret.\nGreedy and \\(\\epsilon\\)-greedy have linear total regret.\nOptimism in face of uncertainty: don’t play the one with best mean value but play the one with best potential (characterized with the highest tail) = select action maximising Upper Confidence Bound (UCB)\n\\(\\epsilon\\)-greedy is behaving right when properly tuned or can be a disaster otherwise. UCB is comparable to properly tuned \\(\\epsilon\\)-greedy.\nthesis from a French guy about thompson sampling in optimisation control problems: Exploration-Exploitation with Thompson Sampling in Linear"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html",
    "title": "WSL2 from Windows Store",
    "section": "",
    "text": "From devblogs: The Windows Subsystem for Linux in the Microsoft Store is now generally available on Windows 10 and 11\n\n\nThere are 100s of bug fixes and improvements that you can read through on our release notes page to see all the improvements that we’ve put into the Store version of WSL. In this blog post I’ll highlight some of the significant changes that you might see as a user upgrading to the Store version for the first time.\n\nYou can opt in for systemd support\nWindows 10 users can now use Linux GUI apps! This was previously only available to Windows 11 users\nwsl --install now includes:\n\nDirect installation from the Microsoft Store by default\n--no-launch option to not launch the distro after installing\n--web-download option which will download the distro through our GitHub releases page rather than through the Microsoft Store\n\nwsl --mount now includes:\n\n--vhd option to make mounting VHD files easier\n--name option to make naming the mountpoint easier\n\nwsl --import and wsl --export now include:\n\n--vhd option to import or export to a VHD directly\n\nAdded wsl --import-in-place to take an existing .vhdx file and register it as a distro\nAdded wsl --version to print your version information more easily\nwsl --update now includes:\n\nOpening the Microsoft Store page by default\n--web-download option to allow updates from our GitHub release page\n\nBetter error printing\nAll of WSLg and the WSL kernel are packaged into the same WSL package, meaning no more extra MSI installs!"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#whats-new-in-the-store-version-of-wsl",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#whats-new-in-the-store-version-of-wsl",
    "title": "WSL2 from Windows Store",
    "section": "",
    "text": "There are 100s of bug fixes and improvements that you can read through on our release notes page to see all the improvements that we’ve put into the Store version of WSL. In this blog post I’ll highlight some of the significant changes that you might see as a user upgrading to the Store version for the first time.\n\nYou can opt in for systemd support\nWindows 10 users can now use Linux GUI apps! This was previously only available to Windows 11 users\nwsl --install now includes:\n\nDirect installation from the Microsoft Store by default\n--no-launch option to not launch the distro after installing\n--web-download option which will download the distro through our GitHub releases page rather than through the Microsoft Store\n\nwsl --mount now includes:\n\n--vhd option to make mounting VHD files easier\n--name option to make naming the mountpoint easier\n\nwsl --import and wsl --export now include:\n\n--vhd option to import or export to a VHD directly\n\nAdded wsl --import-in-place to take an existing .vhdx file and register it as a distro\nAdded wsl --version to print your version information more easily\nwsl --update now includes:\n\nOpening the Microsoft Store page by default\n--web-download option to allow updates from our GitHub release page\n\nBetter error printing\nAll of WSLg and the WSL kernel are packaged into the same WSL package, meaning no more extra MSI installs!"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#systemd",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#systemd",
    "title": "WSL2 from Windows Store",
    "section": "systemd",
    "text": "systemd\nfollowing this article: systemd support\nModify /etc/wsl.conf with\n[boot]\nsystemd=true\nAnd restart wsl image (wsl -t ubuntu-22.04)\nTest that it works by running\nsystemctl list-unit-files --type=service\n\n\n\nimage.png\n\n\nI can now use systemctl to manage services such as\nsudo systemctl restart autofs.service"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#snapd",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#snapd",
    "title": "WSL2 from Windows Store",
    "section": "snapd",
    "text": "snapd\nUpgrade snap\nsudo apt-get -y upgrade snapd\nCheck it is running\n$ snap list\nName    Version        Rev    Tracking       Publisher   Notes\ncore20  20220318       1405   latest/stable  canonical✓  base\nlxd     5.0.0-b0287c1  22923  5.0/stable/…   canonical✓  -\nsnapd   2.55.3         15534  latest/stable  canonical✓  snapd"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#firefox",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#firefox",
    "title": "WSL2 from Windows Store",
    "section": "firefox",
    "text": "firefox\nAnd install firefox\nsudo snap install firefox\n# due to a bug when opening settings\n# https://answers.launchpad.net/ubuntu/+question/701403https://answers.launchpad.net/ubuntu/+question/701403\nsudo apt install xdg-desktop-portal-gtksudo apt install xdg-desktop-portal-gtk\n\n\n\nimage.png\n\n\nTo allow external websites, import this certificate /usr/local/share/ca-certificates/cert_M_X5C_sase-mob-sslfwd-trust-ca.crt in the certificate manager\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#nautilus",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#nautilus",
    "title": "WSL2 from Windows Store",
    "section": "nautilus",
    "text": "nautilus\nAnd install nautilus\nsudo apt install nautilus nautilus-extension-gnome-terminal\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#gimp",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#gimp",
    "title": "WSL2 from Windows Store",
    "section": "gimp",
    "text": "gimp\nAnd install gimp\nsudo apt install gimp"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#zettlr-markdown-editor",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#zettlr-markdown-editor",
    "title": "WSL2 from Windows Store",
    "section": "Zettlr (markdown editor)",
    "text": "Zettlr (markdown editor)\nNow that typora is not open sourced anymore, switch to Zettlr\nwget https://github.com/Zettlr/Zettlr/releases/download/v2.3.0/Zettlr-2.3.0-amd64.deb\nsudo apt-get install libxss1\nsudo dpkg -i Zettlr-2.3.0-amd64.deb\nZettlr  --disable-hardware-acceleration"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#snap-store",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#snap-store",
    "title": "WSL2 from Windows Store",
    "section": "snap-store",
    "text": "snap-store\nI can install like for other softwares\nsudo snap install snap-store\n# to fix \"Unable to download updates, you do not have permission to install software\"\nsudo apt install --reinstall policykit-1-gnome\nsudo apt install --reinstall gnome-software\n# to fix \"Unable to install &lt;e.g. notepadqq&gt;: authentication was required\"\nsudo snap remove snap-store\nrm -rf ~/snap/snap-store\nsudo snap install snap-store\nsnap run snap-store\nbut it failed at installing anything\n\n\n\nimage.png\n\n\n\ninvestigations\n\nOrg.freedesktop.fwupd: Timeout was reached\n\n\n\nimage.png\n\n\nThis is the trace when starting snap-store\n12:54:21:0924 Gs  plugin fwupd took 25.0 seconds to do setup\n12:54:47:0573 Gs  can't reliably fixup error code 20 in domain g-dbus-error-quark\n12:54:47:0574 Gs  can't reliably fixup error code 20 in domain g-dbus-error-quark\n12:54:47:0574 Gs  not handling error failed for action refresh: Error calling StartServiceByName for org.freedesktop.fwupd: Failed to activate service 'org.freedesktop.fwupd': timed out (service_start_timeout=25000ms)\n12:54:47:0574 Gs  not handling error failed for action get-updates-historical: Error calling StartServiceByName for org.freedesktop.fwupd: Failed to activate service 'org.freedesktop.fwupd': timed out (service_start_timeout=25000ms)\n12:54:47:0622 Gs  not handling error no-security for action refresh: Failed to obtain authentication.\n12:54:47:0671 Gs  adding wildcard app */*/*/org.gnome.Builder.desktop/* to plugin cache\n12:54:47:0671 Gs  adding wildcard app */*/*/org.gnome.Calculator.desktop/* to plugin cache\n12:54:47:0671 Gs  adding wildcard app */*/*/org.gnome.clocks.desktop/* to plugin cache\n12:54:47:0671 Gs  adding wildcard app */*/*/org.gnome.Dictionary.desktop/* to plugin cache\n12:54:47:0671 Gs  adding wildcard app */*/*/org.gnome.Documents.desktop/* to plugin cache\n12:54:47:0671 Gs  adding wildcard app */*/*/org.gnome.Evince/* to plugin cache\n12:54:47:0671 Gs  adding wildcard app */*/*/org.gnome.gedit.desktop/* to plugin cache\n12:54:47:0671 Gs  adding wildcard app */*/*/org.gnome.Maps.desktop/* to plugin cache\n12:54:47:0671 Gs  adding wildcard app */*/*/org.gnome.Weather/* to plugin cache\n12:54:47:0677 Gs  Only 0 apps for recent list, hiding\n12:55:13:0039 Gs  can't reliably fixup error code 20 in domain g-dbus-error-quark\nsudo systemctl status fwupd.service\n○ fwupd.service - Firmware update daemon\n     Loaded: loaded (/lib/systemd/system/fwupd.service; static)\n     Active: inactive (dead)\n       Docs: https://fwupd.org/\n\nDec 20 09:05:50 L001LPF3RKAR5 systemd[1]: Condition check resulted in Firmware update daemon being skipped.\nDec 20 09:06:16 L001LPF3RKAR5 systemd[1]: Condition check resulted in Firmware update daemon being skipped.\nDec 20 09:06:44 L001LPF3RKAR5 systemd[1]: Condition check resulted in Firmware update daemon being skipped.\nDec 20 12:11:54 L001LPF3RKAR5 systemd[1]: Condition check resulted in Firmware update daemon being skipped.\nDec 20 12:12:20 L001LPF3RKAR5 systemd[1]: Condition check resulted in Firmware update daemon being skipped.\nDec 20 12:12:45 L001LPF3RKAR5 systemd[1]: Condition check resulted in Firmware update daemon being skipped.\nDec 20 13:53:56 L001LPF3RKAR5 systemd[1]: Condition check resulted in Firmware update daemon being skipped.\nDec 20 13:54:22 L001LPF3RKAR5 systemd[1]: Condition check resulted in Firmware update daemon being skipped.\nDec 20 13:54:48 L001LPF3RKAR5 systemd[1]: Condition check resulted in Firmware update daemon being skipped.\nDec 20 14:00:02 L001LPF3RKAR5 systemd[1]: Condition check resulted in Firmware update daemon being skipped."
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#dropbox",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#dropbox",
    "title": "WSL2 from Windows Store",
    "section": "dropbox",
    "text": "dropbox\nThis one is the official one but it fails\nsudo apt install nautilus-dropbox\ndropbox start -i\nanother one\nrm -rf ~/.dropbox-dist ~/.dropbox\nwget -q -O ~/dropbox https://www.dropbox.com/download?dl=packages/dropbox.py\nchmod a+x ~/dropbox\nDISPLAY='' dropbox start -i\nbut still no luck\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#desktop",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#desktop",
    "title": "WSL2 from Windows Store",
    "section": "Desktop",
    "text": "Desktop\nWoulld like to test https://askubuntu.com/questions/1442663/cannot-start-gnome-session-after-enabling-systemd-on-latest-wsl2:\nThere 2 ways: - configure and access from XRDP - direct configuration\nWill try on a fresh new image"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#rc.local",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#rc.local",
    "title": "WSL2 from Windows Store",
    "section": "rc.local",
    "text": "rc.local\nIt would allow services to be created and run at boot time: https://www.cyberciti.biz/faq/how-to-enable-rc-local-shell-script-on-systemd-while-booting-linux-system/\nnot tested yet."
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#fixed-error-createprocessparsecommon",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#fixed-error-createprocessparsecommon",
    "title": "WSL2 from Windows Store",
    "section": "[FIXED] ERROR: CreateProcessParseCommon",
    "text": "[FIXED] ERROR: CreateProcessParseCommon\nWhen starting image after wsl update, I have the following error:\n&lt;3&gt;WSL (8) ERROR: CreateProcessParseCommon:782: Failed to translate \\\\wsl.localhost\\ubuntu-22.04\\home\\guillaume\nI am not the only one, I have posted in this issue from WSL github repo.\nA solution given in the thread is to update the way to call vpnkit (in .profile)\nwsl.exe -d wsl-vpnkit --cd /app service wsl-vpnkit status &gt;/dev/null || wsl.exe -d wsl-vpnkit --cd /app service wsl-vpnkit start"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#cannot-install-from-snap-store",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#cannot-install-from-snap-store",
    "title": "WSL2 from Windows Store",
    "section": "Cannot install from snap-store",
    "text": "Cannot install from snap-store\n\n\n\nimage.png\n\n\n14:12:09:0637 Gs  not handling error no-security for action refresh: Failed to obtain authentication.\n14:12:09:0638 Gs  not handling error not-supported for action get-updates-historical: The name org.freedesktop.fwupd was not provided by any .service files"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#wsl-some-icons-in-taskbar-for-linux-applications-are-defaulting-to-tux",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#wsl-some-icons-in-taskbar-for-linux-applications-are-defaulting-to-tux",
    "title": "WSL2 from Windows Store",
    "section": "WSL some icons in taskbar for linux applications are defaulting to Tux",
    "text": "WSL some icons in taskbar for linux applications are defaulting to Tux\nhttps://github.com/microsoft/wslg/issues/944\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#fixed-starting-gui-apps-takes-longer-with-new-version",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#fixed-starting-gui-apps-takes-longer-with-new-version",
    "title": "WSL2 from Windows Store",
    "section": "[FIXED] Starting GUI apps takes longer with new version",
    "text": "[FIXED] Starting GUI apps takes longer with new version\nhttps://github.com/microsoft/wslg/issues/1030"
  },
  {
    "objectID": "posts/2022-12-19-wsl2-from-windows-store.html#launching-sublime-text-is-crashing-wsl",
    "href": "posts/2022-12-19-wsl2-from-windows-store.html#launching-sublime-text-is-crashing-wsl",
    "title": "WSL2 from Windows Store",
    "section": "Launching sublime-text is crashing WSL",
    "text": "Launching sublime-text is crashing WSL\nhttps://github.com/microsoft/wslg/issues/1051\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2021-04-09-wsl2 cuda conda.html",
    "href": "posts/2021-04-09-wsl2 cuda conda.html",
    "title": "setup wsl2 with cuda and conda",
    "section": "",
    "text": "workaround explained in this blog entry\nwsl -d Ubuntu-20.04 sudo ~/Applications/wsl-vpnkit/wsl-vpnkit-main/wsl-vpnkit"
  },
  {
    "objectID": "posts/2021-04-09-wsl2 cuda conda.html#wsl2-and-network-proxychains",
    "href": "posts/2021-04-09-wsl2 cuda conda.html#wsl2-and-network-proxychains",
    "title": "setup wsl2 with cuda and conda",
    "section": "",
    "text": "workaround explained in this blog entry\nwsl -d Ubuntu-20.04 sudo ~/Applications/wsl-vpnkit/wsl-vpnkit-main/wsl-vpnkit"
  },
  {
    "objectID": "posts/2021-04-09-wsl2 cuda conda.html#cuda",
    "href": "posts/2021-04-09-wsl2 cuda conda.html#cuda",
    "title": "setup wsl2 with cuda and conda",
    "section": "cuda",
    "text": "cuda\nhttps://docs.nvidia.com/cuda/wsl-user-guide/index.html#installing-nvidia-drivers\ninstall nvidia cuda specific driver for WSL: https://developer.nvidia.com/cuda/wsl on windows. (version 470.14_quadro_win10-dch_64bit_international in my case)\nproxychains wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-ubuntu2004.pin\nsudo mv cuda-ubuntu2004.pin /etc/apt/preferences.d/cuda-repository-pin-600\nsudo apt-key adv --fetch-keys https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/7fa2af80.pub\nsudo proxychains add-apt-repository \"deb https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/ /\"\nsudo proxychains apt-get update\nsudo proxychains apt-get -y install cuda-toolkit-11-2\nhttps://christianjmills.com/Using-PyTorch-with-CUDA-on-WSL2/\nnew version using WSL-ubuntu as distro\nhttps://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&target_distro=WSLUbuntu&target_version=20&target_type=deblocal\nproxychains wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin\nsudo mv cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600\nproxychains wget https://developer.download.nvidia.com/compute/cuda/11.2.2/local_installers/cuda-repo-wsl-ubuntu-11-2-local_11.2.2-1_amd64.deb\nsudo dpkg -i cuda-repo-wsl-ubuntu-11-2-local_11.2.2-1_amd64.deb\nsudo apt-key add /var/cuda-repo-wsl-ubuntu-11-2-local/7fa2af80.pub\nsudo proxychains apt-get update\nsudo proxychains apt-get -y install cuda\ntest cuda\nconda activate pytorch\nipython\nimport torch\ntorch.cuda.is_available()"
  },
  {
    "objectID": "posts/2021-04-09-wsl2 cuda conda.html#conda",
    "href": "posts/2021-04-09-wsl2 cuda conda.html#conda",
    "title": "setup wsl2 with cuda and conda",
    "section": "conda",
    "text": "conda\nfrom https://docs.conda.io/en/latest/miniconda.html\ndownload https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\nand install with ./Miniconda3-latest-Linux-x86_64.sh -p $HOME/miniconda3"
  },
  {
    "objectID": "posts/2021-04-09-wsl2 cuda conda.html#pycaret",
    "href": "posts/2021-04-09-wsl2 cuda conda.html#pycaret",
    "title": "setup wsl2 with cuda and conda",
    "section": "pycaret",
    "text": "pycaret\nconda create --name pycaret python=3.7\nconda activate pycaret\n\nproxychains pip install pycaret shap\nproxychains conda install -c conda-forge  nb_conda jupyter_contrib_nbextensions fire pyfiglet openpyxl\njupyter contrib nbextensions install --user\nproxychains conda upgrade nbconvert"
  },
  {
    "objectID": "posts/2021-04-09-wsl2 cuda conda.html#pytorch",
    "href": "posts/2021-04-09-wsl2 cuda conda.html#pytorch",
    "title": "setup wsl2 with cuda and conda",
    "section": "pytorch",
    "text": "pytorch\nproxychains conda create -n pytorch python=3.8\nproxychains conda activate pytorch\nproxychains conda install -c pytorch pytorch=1.7.1 torchvision\nproxychains conda install jupyter\nproxychains conda install -c conda-forge jupyter_contrib_nbextensions"
  },
  {
    "objectID": "posts/2021-06-07-reinforcement-learning-specialization-coursera-course3.html",
    "href": "posts/2021-06-07-reinforcement-learning-specialization-coursera-course3.html",
    "title": "Reinforcement Learning Specialization - Coursera - course 3 - Prediction and Control with Function Approximation",
    "section": "",
    "text": "Coursera website: course 3 - Prediction and Control with Function Approximation of Reinforcement Learning Specialization\nmy notes on course 1 - Fundamentals of Reinforcement Learning, course 2 - Sample-based Learning Methods, course 4 - A Complete Reinforcement Learning System (Capstone)\nspecialization roadmap - course 3 - Prediction and Control with Function Approximation (syllabus)\ncourse 3 - In Course 3, we leave the relative comfort of small finite MDPs and investigate RL with function approximation. Here we will see that the main concepts from Courses 1 and 2 transferred to problems with larger infinite state spaces. We will cover feature construction, neural network learning, policy gradient methods, and other particularities of the function approximation setting.\nWeek 1 - On-policy Prediction with Approximation\nWeek 2 - Constructing Features for Prediction\nWeek 3 - Control with Approximation\nWeek 4 - Policy Gradient"
  },
  {
    "objectID": "posts/2021-06-07-reinforcement-learning-specialization-coursera-course3.html#course-3---week-1---on-policy-prediction-with-approximation",
    "href": "posts/2021-06-07-reinforcement-learning-specialization-coursera-course3.html#course-3---week-1---on-policy-prediction-with-approximation",
    "title": "Reinforcement Learning Specialization - Coursera - course 3 - Prediction and Control with Function Approximation",
    "section": "Course 3 - Week 1 - On-policy Prediction with Approximation",
    "text": "Course 3 - Week 1 - On-policy Prediction with Approximation\n\nModule 1 Learning Objectives\nLesson 1: Estimating Value Functions as Supervised Learning\n\nUnderstand how we can use parameterized functions to approximate value functions\nExplain the meaning of linear value function approximation\nRecognize that the tabular case is a special case of linear value function approximation.\nUnderstand that there are many ways to parameterize an approximate value function\nUnderstand what is meant by generalization and discrimination\nUnderstand how generalization can be beneficial\nExplain why we want both generalization and discrimination from our function approximation\nUnderstand how value estimation can be framed as a supervised learning problem\nRecognize not all function approximation methods are well suited for reinforcement learning\n\nLesson 2: The Objective for On-policy Prediction\n\nUnderstand the mean-squared value error objective for policy evaluation\nExplain the role of the state distribution in the objective\nUnderstand the idea behind gradient descent and stochastic gradient descent\nOutline the gradient Monte Carlo algorithm for value estimation\nUnderstand how state aggregation can be used to approximate the value function\nApply Gradient Monte-Carlo with state aggregation\n\nLesson 3: The Objective for TD\n\nUnderstand the TD-update for function approximation\nHighlight the advantages of TD compared to Monte-Carlo\nOutline the Semi-gradient TD(0) algorithm for value estimation\nUnderstand that TD converges to a biased value estimate\nUnderstand that TD converges much faster than Gradient Monte Carlo\n\nLesson 4: Linear TD\n\nDerive the TD-update with linear function approximation\nUnderstand that tabular TD(0) is a special case of linear semi-gradient TD(0)\nHighlight the advantages of linear value function approximation over nonlinear\nUnderstand the fixed point of linear TD learning\nDescribe a theoretical guarantee on the mean squared value error at the TD fixed point\n\n\n\nLesson 1: Estimating Value Functions as Supervised Learning\nReading Chapter 9.1-9.4 (pp. 197-209) in the Reinforcement Learning textbook\n\nIn many of the tasks to which we would like to apply reinforcement learning the state space is combinatorial and enormous; the number of possible camera images, for example, is much larger than the number of atoms in the universe.\nIn many of our target tasks, almost every state encountered will never have been seen before. To make sensible decisions in such states it is necessary to generalize from previous encounters with different states that are in some sense similar to the current one. In other words, the key issue is that of generalization. How can experience with a limited subset of the state space be usefully generalized to produce a good approximation over a much larger subset?\nFortunately, generalization from examples has already been extensively studied, and we do not need to invent totally new methods for use in reinforcement learning. To some extent we need only combine reinforcement learning methods with existing generalization methods. The kind of generalization we require is often called function approximation because it takes examples from a desired function (e.g., a value function) and attempts to generalize from them to construct an approximation of the entire function. Function approximation is an instance of supervised learning, the primary topic studied in machine learning, artificial neural networks, pattern recognition, and statistical curve fitting.\n\nVideo Moving to Parameterized Functions by Adam\nBy the end of this video, you’ll be able to understand how we can use parameterized functions to approximate values, explain linear value function approximation, recognize that the tabular case is a special case of linear value function approximation, and understand that there are many ways to parameterize an approximate value function.\nVideo Generalization and Discrimination by Martha\nBy the end of this video, you will be able to understand what is meant by generalization and discrimination, understand how generalization can be beneficial, and explain why we want both generalization and discrimination from our function approximation.\nVideo Framing Value Estimation as Supervised Learning by Martha\nBy the end of this video, you will be able to understand how value estimation can be framed as a supervised learning problem, and recognize that not all function approximation methods are well suited for reinforcement learning.\n\n\nLesson 2: The Objective for On-policy Prediction\nVideo The Value Error Objective by Adam\nBy the end of this video you will be able to understand the Mean Squared Value Error objective for policy evaluation and explain the role of the state distribution in the objective.\n\\[\n\\overline{VE}=\\displaystyle\\sum_{s}\\mu(s)[v_\\pi(s)-\\hat{v}(s,w)]^2\n\\] This is the Mean Squared Value Error Objective where \\(\\mu\\) reflects how much we care about each state (a probability distribution)\nVideo Introducing Gradient Descent by Martha\nBy the end of this video, you will be able to understand the idea of gradient descent, and understand that gradient descent converges to stationary points.\nVideo Gradient Monte for Policy Evaluation by Martha\nBy the end of this video, you will be able to understand how to use gradient descent and stochastic gradient descent to minimize value error and outline the Gradient Monte Carlo algorithm for value estimation.\n\nVideo State Aggregation with Monte Carlo by Adam\nBy the end of this video, you will be able to understand how state aggregation can be used to approximate the value function and apply gradient Monte Carlo with state aggregation.\n\n\nLesson 3: The Objective for TD\nVideo Semi-Gradient TD for Policy Evaluation by Adam\nBy the end of this video you will be able to understand the TD update for function approximation, and outline the semi-gradient TD(0) algorithm for value estimation.\n\nVideo Comparing TD and Monte Carlo with State Aggregation by Adam\nBy the end of this video, you’ll be able to understand that TD converges to a bias value estimate and understand that TD can learn faster than Gradient Monte Carlo.\nVideo Doina Precup: Building Knowledge for AI Agents with Reinforcement Learning\n\n\nLesson 4: Linear TD\nVideo The Linear TD Update by Martha\nBy the end of this video, you’ll be able to derive the TD update with linear function approximation, understand that tabular TD(0) as a special case of linear semi gradient TD(0), and understand why we care about linear TD as a special case.\nVideo The True Objective for TD by Martha\nBy the end of this video, you will be able to understand the fixed point of linear TD and describe a theoretical guarantee on the mean squared value error at the TD fixed point.\nVideo Week 1 Summary by Adam\n\n\nAssignment\nTD with State Aggregation\nnotebooks in github"
  },
  {
    "objectID": "posts/2021-06-07-reinforcement-learning-specialization-coursera-course3.html#course-3---week-2---constructing-features-for-prediction",
    "href": "posts/2021-06-07-reinforcement-learning-specialization-coursera-course3.html#course-3---week-2---constructing-features-for-prediction",
    "title": "Reinforcement Learning Specialization - Coursera - course 3 - Prediction and Control with Function Approximation",
    "section": "Course 3 - Week 2 - Constructing Features for Prediction",
    "text": "Course 3 - Week 2 - Constructing Features for Prediction\n\nModule 2 Learning Objectives\nLesson 1: Feature Construction for Linear Methods\n\nDescribe the difference between coarse coding and tabular representations\nExplain the trade-off when designing representations between discrimination and generalization\nUnderstand how different coarse coding schemes affect the functions that can be represented\nExplain how tile coding is a (computationally?) convenient case of coarse coding\nDescribe how designing the tilings affects the resultant representation\nUnderstand that tile coding is a computationally efficient implementation of coarse coding\n\nLesson 2: Neural Networks\n\nDefine a neural network\nDefine activation functions\nDefine a feedforward architecture\nUnderstand how neural networks are doing feature construction\nUnderstand how neural networks are a non-linear function of state\nUnderstand how deep networks are a composition of layers\nUnderstand the tradeoff between learning capacity and challenges presented by deeper networks\n\nLesson 3: Training Neural Networks\n\nCompute the gradient of a single hidden layer neural network\nUnderstand how to compute the gradient for arbitrarily deep networks\nUnderstand the importance of initialization for neural networks\nDescribe strategies for initializing neural networks\nDescribe optimization techniques for training neural networks\n\n\n\nLesson 1: Feature Construction for Linear Methods\nReading Chapter 9.4-9.5.0 (pp. 204-210), 9.5.3-9.5.4 (pp. 215-222) and 9.7 (pp. 223-228) in the Reinforcement Learning textbook\nVideo Coarse Coding by Adam\nBy the end of this video, you’ll be able to describe coarse coding and describe how it relates to state aggregation.\n\nVideo Generalization Properties of Coarse Coding by Martha\nBy the end of this video, you’ll be able to describe how coarse coding parameters affect generalization and discrimination, and understand how that affects learning speed and accuracy.\nVideo Tile Coding by Adam\nBy the end of this video, you’ll be able to explain how tile coding achieves both generalization and discrimination, and understand the benefits and limitations of tile coding.\nVideo Using Tile Coding in TD by Adam\nBy the end of this video, you’ll be able to explain how to use tile coding with TD learning and identify important properties of tile code representations.\n\n\nLesson 2: Neural Networks\nVideo What is a Neural Network? by Martha\nBy the end of this video, you’ll be able to define a neural network, define an activation function and understand how a neural network is a parameterized function.\nVideo Non-linear Approximation with Neural Networks by Martha\nBy the end of this video, you will understand how neural networks do feature construction, and understand how neural networks are a non-linear function of state.\nVideo Deep Neural Networks by Adam\nBy the end of this video, you will understand how deep neural networks are composed of many layers and understand that depth can facilitate learning features through composition and abstraction.\n\n\nLesson 3: Training Neural Networks\nVideo Gradient Descent for Training Neural Networks by Martha\nBy the end of this video, you’ll be able to derive the gradient of a neural network and implement gradient descent on a neural network.\nVideo Optimization Strategies for NNs by Martha\nBy the end of this video, you will be able to understand the importance of initialization for neural networks and describe optimization techniques for training neural networks.\nVideo David Silver on Deep Learning + RL = AI?\nVideo Week 2 Review by Adam\n\n\nAssignment\nSemi-gradient TD with a Neural Network\nnotebooks in github"
  },
  {
    "objectID": "posts/2021-06-07-reinforcement-learning-specialization-coursera-course3.html#course-3---week-3---control-with-approximation",
    "href": "posts/2021-06-07-reinforcement-learning-specialization-coursera-course3.html#course-3---week-3---control-with-approximation",
    "title": "Reinforcement Learning Specialization - Coursera - course 3 - Prediction and Control with Function Approximation",
    "section": "Course 3 - Week 3 - Control with Approximation",
    "text": "Course 3 - Week 3 - Control with Approximation\n\nModule 3 Learning Objectives\nLesson 1: Episodic Sarsa with Function Approximation\n\nExplain the update for Episodic Sarsa with function approximation\nIntroduce the feature choices, including passing actions to features or stacking state features\nVisualize value function and learning curves\nDiscuss how this extends to Q-learning easily, since it is a subset of Expected Sarsa\n\nLesson 2: Exploration under Function Approximation\n\nUnderstanding optimistically initializing your value function as a form of exploration\n\nLesson 3: Average Reward\n\nDescribe the average reward setting\nExplain when average reward optimal policies are different from discounted solutions\nUnderstand how differential value functions are different from discounted value functions\n\n\n\nLesson 1: Episodic Sarsa with Function Approximation\nReading Chapter 10 (pp. 243-246) and 10.3 (pp. 249-252) in the Reinforcement Learning textbook\nVideo Episodic Sarsa with Function Approximation by Adam\nBy the end of this video, you’ll be able to understand how to construct action-dependent features for approximate action values and explain how to use Sarsa in episodic tasks with function approximation.\n\nVideo Episodic Sarsa in Mountain Car by Adam\nBy the end of this video, you will gain experience analyzing the performance of an approximate TD control method.\nVideo Expected Sarsa with Function Approximation by Adam\nBy the end of this video, you’ll be able to explain the update for expected Sarsa with function approximation, and explain the update for Q-learning with function approximation.\n\n\n\nLesson 2: Exploration under Function Approximation\nVideo Exploration under Function Approximation by Martha\nBy the end of this video, you’ll be able to describe how optimistic initial values and \\(\\epsilon\\)-greedy can be used with function approximation.\n\n\nLesson 3: Average Reward\nVideo Average Reward: A New Way of Formulating Control Problems by Martha\nBy the end of this video, you’ll be able to describe the average reward setting, explain when average reward optimal policies are different from policies obtained under discounting and understand differential value functions.\nSatinder Singh on Intrinsic Rewards\nVideo Week 3 Review by Martha\n\n\nAssignment\nFunction Approximation and Control\nnotebooks in github"
  },
  {
    "objectID": "posts/2021-06-07-reinforcement-learning-specialization-coursera-course3.html#course-3---week-4---policy-gradient",
    "href": "posts/2021-06-07-reinforcement-learning-specialization-coursera-course3.html#course-3---week-4---policy-gradient",
    "title": "Reinforcement Learning Specialization - Coursera - course 3 - Prediction and Control with Function Approximation",
    "section": "Course 3 - Week 4 - Policy Gradient",
    "text": "Course 3 - Week 4 - Policy Gradient\n\nModule 4 Learning Objectives\nLesson 1: Learning Parameterized Policies\n\nUnderstand how to define policies as parameterized functions\nDefine one class of parameterized policies based on the softmax function\nUnderstand the advantages of using parameterized policies over action-value based methods\n\nLesson 2: Policy Gradient for Continuing Tasks\n\nDescribe the objective for policy gradient algorithms\nDescribe the results of the policy gradient theorem\nUnderstand the importance of the policy gradient theorem\n\nLesson 3: Actor-Critic for Continuing Tasks\n\nDerive a sample-based estimate for the gradient of the average reward objective\nDescribe the actor-critic algorithm for control with function approximation, for continuing tasks\n\nLesson 4: Policy Parameterizations\n\nDerive the actor-critic update for a softmax policy with linear action preferences\nImplement this algorithm\nDesign concrete function approximators for an average reward actor-critic algorithm\nAnalyze the performance of an average reward agent\nDerive the actor-critic update for a gaussian policy\nApply average reward actor-critic with a gaussian policy to a particular task with continuous actions\n\n\n\nLesson 1: Learning Parameterized Policies\nReading Chapter 13 (pp. 321-336) in the Reinforcement Learning textbook\nVideo Learning Policies Directly by Adam\nBy the end of this video, you’ll be able to understand how to define policies as parameterized functions and define one class of parametrized policies based on the softmax function.\nVideo Advantages of Policy Parameterization by Adam\nBy the end of this video, you’ll be able to understand some of the advantages of using parameterized policies.\n\n\nLesson 2: Policy Gradient for Continuing Tasks\nVideo The Objective for Learning Policies by Martha\nBy the end of this video, you’ll be able to describe the objective for policy gradient algorithms.\n\nVideo The Policy Gradient Theorem by Martha\nBy the end of this video, you will be able to describe the result of the policy gradient theorem and understand the importance of the policy gradient theorem.\n\n\n\nLesson 3: Actor-Critic for Continuing Tasks\nVideo Estimating the Policy Gradient by Martha\nBy the end of this video, you will be able to derive a sample-based estimate for the gradient of the average reward objective.\n\nVideo Actor-Critic Algorithm by Adam\nBy the end of this video, you’ll be able to describe the actor-critic algorithm for control with function approximation for continuing tasks.\n\n\n\nLesson 4: Policy Parameterizations\nVideo Actor-Critic with Softmax Policies by Adam\nBy the end of this video you’ll be able to derive the actor critic update for a Softmax policy with linear action preferences and implement this algorithm.\nVideo Demonstration with Actor-Critic by Adam\nBy the end of this video, you’ll be able to design a function approximator for an average reward actor-critic algorithm and analyze the performance of an average reward agent.\nVideo Gaussian Policies for Continuous Actions by Martha\nBy the end of this video, you’ll be able to derive the actor-critic update for a Gaussian policy and apply average reward actor-critic with a Gaussian policy to task with continuous actions.\nVideo Week 4 Summary by Martha\n\n\n\nAssignment\nAverage Reward Softmax Actor-Critic using Tile-coding\nnotebooks in github"
  },
  {
    "objectID": "posts/2021-02-26-logbook-Februrary.html",
    "href": "posts/2021-02-26-logbook-Februrary.html",
    "title": "Logbook for February 21",
    "section": "",
    "text": "This is a test. I will try to keep words on a monthly (this page), weekly (per heading), daily basis. Just some short entries with possibly some links to more detailed materials."
  },
  {
    "objectID": "posts/2021-02-26-logbook-Februrary.html#week-8---feb-21",
    "href": "posts/2021-02-26-logbook-Februrary.html#week-8---feb-21",
    "title": "Logbook for February 21",
    "section": "Week 8 - Feb 21",
    "text": "Week 8 - Feb 21\nMonday 2/22\nTo develop knowledge about RL, here is my learning process on a weekly basis.\nMonday MIT 6S191\nTuesday College de France\nWednesday Deep Reinforcement Learning by Thomas Simonini\nFriday RL readings: papers, books, …\nFriday 2/26\nblog fastpages - setup automated upgrade (instructions from _fastpages_docs) v2.1.42\nblog fastpages - display image preview (update of _config.yml)\nRL - understood differences between Q-learning and Sarsa algorithms in end of step2 part2\nRL - Sutton book (p200-220) - eligibility traces, and start of planning vs learning"
  },
  {
    "objectID": "posts/2021-07-01-logbook-July.html",
    "href": "posts/2021-07-01-logbook-July.html",
    "title": "Logbook for July 21",
    "section": "",
    "text": "Thursday 7/1\nPaper reviewed on arxiv about revisiting Deep Learning Models for Tabular Data. arXiv:2106.11959v1 (FT-Transformer, ResNet, MLP) architectures can compete with GBDT models. Examples are not detailed in paper but code seems available at https://github.com/yandex-research/rtdl (rtdl (Revisiting Tabular Deep Learning) based on PyTorch)\nRL Course by David Silver Exploration and Exploitation (lecture 9)"
  },
  {
    "objectID": "posts/2021-07-01-logbook-July.html#week-26---july-21",
    "href": "posts/2021-07-01-logbook-July.html#week-26---july-21",
    "title": "Logbook for July 21",
    "section": "",
    "text": "Thursday 7/1\nPaper reviewed on arxiv about revisiting Deep Learning Models for Tabular Data. arXiv:2106.11959v1 (FT-Transformer, ResNet, MLP) architectures can compete with GBDT models. Examples are not detailed in paper but code seems available at https://github.com/yandex-research/rtdl (rtdl (Revisiting Tabular Deep Learning) based on PyTorch)\nRL Course by David Silver Exploration and Exploitation (lecture 9)"
  },
  {
    "objectID": "posts/2021-07-01-logbook-July.html#week-27---july-21",
    "href": "posts/2021-07-01-logbook-July.html#week-27---july-21",
    "title": "Logbook for July 21",
    "section": "Week 27 - July 21",
    "text": "Week 27 - July 21\nWednesday 7/7\nStart of Deep Neural Networks with PyTorch on Coursera by IBM.\nFriday 7/9\nDeep Neural Networks with PyTorch - week 2 - linear regression"
  },
  {
    "objectID": "posts/2021-07-01-logbook-July.html#week-28---july-21",
    "href": "posts/2021-07-01-logbook-July.html#week-28---july-21",
    "title": "Logbook for July 21",
    "section": "Week 28 - July 21",
    "text": "Week 28 - July 21\nMonday 7/12\nDeep Neural Networks with PyTorch - week 3 - multiple input output linear regression, logistic regression for classification\nDeep Neural Networks with PyTorch - week 4 - softmax regression\nThursday 7/15\nDeep Neural Networks with PyTorch - week 4 - shallow neural networks\nDeep Neural Networks with PyTorch - week 5 - deep neural networks\nFriday 7/16\nDeep Learning with PyTorch book\n\n\n\nimg\n\n\nPyTorch Ecosystem day 2021:\n\nlightning to remove boilerplate code - to be tested!\ntorchstudio to visualize dataset and models\npytorch-ignite from my colleague Sylvain - high-level library to help training evaluating NN\npytorchts to play with timeseries\nmultitask RL environments and baselines for RL\nrlstructures python library for RL research\nmbrl-lib to write model-based RL algorithms\npystiche framework for style transfer\n\nDeep Neural Networks with PyTorch - week 6 - convolutional neural networks - even if I don’t need it"
  },
  {
    "objectID": "posts/2021-07-01-logbook-July.html#week-30---july-21",
    "href": "posts/2021-07-01-logbook-July.html#week-30---july-21",
    "title": "Logbook for July 21",
    "section": "Week 30 - July 21",
    "text": "Week 30 - July 21\nMonday 7/26\nDeep Neural Networks with PyTorch - week 7 - fashion mnist\nReading of some papers:\n\nDeep Reinforcement Learning Approaches for Process Control by Steven Spielberg Pon Kumar - thesis, UBC 2017\nA Deep Learning Architecture for Predictive Control by Steven Spielberg Pon Kumar - ScienceDirect 2018\nDeep Reinforcement Learning for Process Control: A Primer for Beginners by Steven Spielberg et al. 2004\nReinforcement Learning for Statistical Process Control in Manufacturing - by Zsolt János Viharos 2020"
  },
  {
    "objectID": "posts/2021-07-29-git-clean-large-files.html",
    "href": "posts/2021-07-29-git-clean-large-files.html",
    "title": "git clean repo with bfg",
    "section": "",
    "text": "bfg website"
  },
  {
    "objectID": "posts/2021-07-29-git-clean-large-files.html#bfg-installation-from-scratch",
    "href": "posts/2021-07-29-git-clean-large-files.html#bfg-installation-from-scratch",
    "title": "git clean repo with bfg",
    "section": "bfg installation from scratch",
    "text": "bfg installation from scratch\ninstall java8\nsudo apt install openjdk-8-jre-headless\njava -version\n&gt;&gt; openjdk version \"1.8.0_312\"\n&gt;&gt; OpenJDK Runtime Environment (build 1.8.0_312-8u312-b07-0ubuntu1~20.04-b07)\n&gt;&gt; OpenJDK 64-Bit Server VM (build 25.312-b07, mixed mode)\ndownload bfg.jar\ncd ~\nmkdir -p Applications/bfg\ncd Applications/bfg\n# link from https://rtyley.github.io/bfg-repo-cleaner/\nwget https://repo1.maven.org/maven2/com/madgag/bfg/1.14.0/bfg-1.14.0.jar\nand add an alias to .bashrc\n$ grep -n -s bfg .*\n.bashrc:95:alias bfg='java -jar ~/Applications/bfg/bfg-1.14.0.jar'\n$ source .bashrc"
  },
  {
    "objectID": "posts/2021-07-29-git-clean-large-files.html#general-usage",
    "href": "posts/2021-07-29-git-clean-large-files.html#general-usage",
    "title": "git clean repo with bfg",
    "section": "General usage",
    "text": "General usage\nWe will fix ~/git/d059-vld-ic"
  },
  {
    "objectID": "posts/2021-07-29-git-clean-large-files.html#remove-big-files",
    "href": "posts/2021-07-29-git-clean-large-files.html#remove-big-files",
    "title": "git clean repo with bfg",
    "section": "Remove big files",
    "text": "Remove big files\nno need to create a clone, we can directly work on our repo\nbfg --strip-blobs-bigger-than 100M ~/git/d059-vld-ic\ncd ~/git/d059-vld-ic\ngit reflog expire --expire=now --all && git gc --prune=now --aggressive\nNote: if you get a message Warning : no large blobs matching criteria found in packfiles - does the repo need to be packed?, you have to launch git gc"
  },
  {
    "objectID": "posts/2021-07-29-git-clean-large-files.html#remove-big-files-from-protected-commits",
    "href": "posts/2021-07-29-git-clean-large-files.html#remove-big-files-from-protected-commits",
    "title": "git clean repo with bfg",
    "section": "Remove big files from protected commits",
    "text": "Remove big files from protected commits\nProtected commits\n-----------------\n\nThese are your protected commits, and so their contents will NOT be altered:\n\n * commit d914f24e (protected by 'HEAD')\nIn that case it is even easier, no need of bfg:\ngit rm --cached &lt;my large file&gt;\ngit commit --amend -C HEAD"
  },
  {
    "objectID": "posts/2021-07-29-git-clean-large-files.html#remove-forbidden-files-such-as-.mp3-.tar.gz",
    "href": "posts/2021-07-29-git-clean-large-files.html#remove-forbidden-files-such-as-.mp3-.tar.gz",
    "title": "git clean repo with bfg",
    "section": "Remove forbidden files such as .mp3, .tar.gz",
    "text": "Remove forbidden files such as .mp3, .tar.gz\nneed to create a clone, we can directly work on our repo\n$ cd ~/Applications/bfg\njava -jar bfg-1.13.0.jar --delete-files '*.mp3' --no-blob-protection ~/git/data-scientist-skills\njava -jar bfg-1.13.0.jar --delete-files '*.tar.gz' --no-blob-protection ~/git/data-scientist-skills\n\ngit reflog expire --expire=now --all && git gc --prune=now --aggressive"
  },
  {
    "objectID": "posts/2021-07-29-git-clean-large-files.html#improve-.gitignore",
    "href": "posts/2021-07-29-git-clean-large-files.html#improve-.gitignore",
    "title": "git clean repo with bfg",
    "section": "Improve .gitignore",
    "text": "Improve .gitignore\nsee git ignore large files"
  },
  {
    "objectID": "posts/2023-10-05-update-jupyterlab-v4.html",
    "href": "posts/2023-10-05-update-jupyterlab-v4.html",
    "title": "Update jupyter lab to v4",
    "section": "",
    "text": "As mentionned in logbook May-23, jupyter lab v4 is now available."
  },
  {
    "objectID": "posts/2023-10-05-update-jupyterlab-v4.html#tqdm",
    "href": "posts/2023-10-05-update-jupyterlab-v4.html#tqdm",
    "title": "Update jupyter lab to v4",
    "section": "tqdm",
    "text": "tqdm\n\nfrom tqdm.notebook import trange, tqdm\nfrom time import sleep\n\nfor i in trange(3, desc='1st loop'):\n    for j in tqdm(range(100), desc='2nd loop'):\n        sleep(0.01)"
  },
  {
    "objectID": "posts/2023-10-05-update-jupyterlab-v4.html#ipywidgets",
    "href": "posts/2023-10-05-update-jupyterlab-v4.html#ipywidgets",
    "title": "Update jupyter lab to v4",
    "section": "ipywidgets",
    "text": "ipywidgets\n\nimport ipywidgets\nipywidgets.__version__\n\n'8.1.1'\n\n\n\nipywidgets.widgets.Button(description=\"Hello World!\")"
  },
  {
    "objectID": "posts/2021-01-26-reinforcement-learning-readings.html",
    "href": "posts/2021-01-26-reinforcement-learning-readings.html",
    "title": "Reinforcement learning readings",
    "section": "",
    "text": "from https://www.youtube.com/watch?v=Obek04C8L5E&feature=youtu.be\nat 26’ idea that you can tackle over-optimism models by using ensemble models. See paper at 2018 Model-Ensemble Trust-Region Policy Optimization"
  },
  {
    "objectID": "posts/2021-01-26-reinforcement-learning-readings.html#reinforcement-learning-for-real-world-robotics",
    "href": "posts/2021-01-26-reinforcement-learning-readings.html#reinforcement-learning-for-real-world-robotics",
    "title": "Reinforcement learning readings",
    "section": "",
    "text": "from https://www.youtube.com/watch?v=Obek04C8L5E&feature=youtu.be\nat 26’ idea that you can tackle over-optimism models by using ensemble models. See paper at 2018 Model-Ensemble Trust-Region Policy Optimization"
  },
  {
    "objectID": "posts/2021-01-26-reinforcement-learning-readings.html#reinforcement-learning-algorithms-an-intuitive-overview",
    "href": "posts/2021-01-26-reinforcement-learning-readings.html#reinforcement-learning-algorithms-an-intuitive-overview",
    "title": "Reinforcement learning readings",
    "section": "1/26/21 - Reinforcement Learning algorithms — an intuitive overview",
    "text": "1/26/21 - Reinforcement Learning algorithms — an intuitive overview\nfrom https://medium.com/@SmartLabAI/reinforcement-learning-algorithms-an-intuitive-overview-904e2dff5bbc\n\ngive an overview of various RL models. Model-based vs model-free.\nAnd papers and codes."
  },
  {
    "objectID": "posts/2021-01-26-reinforcement-learning-readings.html#reinforcement-learning-partie-1-introduction-in-french",
    "href": "posts/2021-01-26-reinforcement-learning-readings.html#reinforcement-learning-partie-1-introduction-in-french",
    "title": "Reinforcement learning readings",
    "section": "1/26/21 - Reinforcement learning, partie 1 : introduction (in French)",
    "text": "1/26/21 - Reinforcement learning, partie 1 : introduction (in French)\nThere is a reference to an introduction paper: from Sutton, Richard S., and Andrew G. Barto « Reinforcement learning : an introduction. » (2011). (I have an updated version from 2015)\nThere is a reference to a blog article [2] Steeve Huang. “Introduction to Various Reinforcement Learning Algorithms. Part I” (Q-Learning, SARSA, DQN, DDPG)”. (2018)\nAnd the paper for OpenAI Gym [3] Greg Brockman, Vicki Cheung, Ludwig Pettersson, Jonas Schneider, John Schulman, Jie Tang, Wojciech Zaremba. “OpenAI Gym”. (2016)"
  },
  {
    "objectID": "posts/2021-01-26-reinforcement-learning-readings.html#reinforcement-learning-an-introduction---i-tabular-solution-methods",
    "href": "posts/2021-01-26-reinforcement-learning-readings.html#reinforcement-learning-an-introduction---i-tabular-solution-methods",
    "title": "Reinforcement learning readings",
    "section": "1/27/21 - Reinforcement learning : an introduction - I tabular solution methods",
    "text": "1/27/21 - Reinforcement learning : an introduction - I tabular solution methods\nas a ref. from Reinforcement learning, partie 1 : introduction (in French)\nI like this summary about RL\n\nReinforcement learning is a computational approach to understanding and automating goal-directed learning and decision-making. It is distinguished from other computational approaches by its emphasis on learning by an agent from direct interaction with its environment, without relying on exemplary supervision or complete models of the environment. In our opinion, reinforcement learning is the first field to seriously address the computational issues that arise when learning from interaction with an environment in order to achieve long-term goals. Reinforcement learning uses a formal framework defining the interaction between a learning agent and its environment in terms of states, actions, and rewards. This framework is intended to be a simple way of representing essential features of the artificial intelligence problem. These features include a sense of cause and effect, a sense of uncertainty and nondeterminism, and the existence of explicit goals.\n\nThere is some history about RL. Bellman equation and dynamic programming are at the beginning of RL.\nI read about HJB equation from Huyên PHAM (from a French Math magazine). It is funny to see why dynamic programming has been named that way, and how to deal with management.\n\nThe class of methods for solving optimal control problems by solving this equation came to be known as dynamic programming (Bellman, 1957a). Bellman (1957b) also introduced the discrete stochastic version of the optimal control problem known as Markovian decision processes (MDPs), and Ronald Howard (1960) devised the policy iteration method for MDPs. All of these are essential elements underlying the theory and algorithms of modern reinforcement learning.\n\nAll the vocabulary around RL is coming from dynamic programming and MDP.\nMarkov decision process - Wikipedia\n\n\n\nInteresting to read that the famous cart pole experiment (learning to balance a pole hinged to a movable cart) came from Michie and Chambers in 1968, 53 years ago! (and derived from tic-tac-toe experiment)\nI don’t understand the subtlety behind the move from “learning with a teacher” to “learning with a critic” following the modified Least-Mean-Square (LMS) algorithm; Widrow and Hoff (1973)\nAnd some explanations about temporal-difference. I have just understood that a convergence effort happened (in 1989) by Chris Watkin who brought together temporal-difference and optimal control by developing Q-learning.\nAfter this introduction, here is the content:\n1st part is about finite markov decision processes—and its main ideas including Bellman equations and value functions.\n2nd part is about describing three fundamental classes of methods for solving finite Markov decision problems: dynamic programming, Monte Carlo methods, and temporal-difference learning. Each class of methods has its strengths and weaknesses. Dynamic programming methods are well developed mathematically, but require a complete and accurate model of the environment. Monte Carlo methods don’t require a model and are conceptually simple, but are not suited for step-by-step incremental computation. Finally, temporal-difference methods require no model and are fully incremental, but are more complex to analyze.\n3rd part is about combining these methods to offer a complete and unified solution to the tabular reinforcement learning problem.\nWe can think of terms agent, environment, and action as engineers’ terms controller, controlled system (or plant), and control signal.\n\n\n\nThe agent–environment interaction in reinforcement learning.\n\n\nExplanation about agent vs environment. Often not the same as physical boundaries of a robot: this boundary represents the limit of the agent’s absolute control, not of its knowledge. Many different agents can be operated at once.\nThe agent’s goal is to maximize the total mount of reward it receives.\nI should re-read the full chapter3 because a lot of concepts coming from MDP is exposed, and their links to RL. At the end I should be able to answer most of end-of-chapter exercises. Have clearer view about how to define what are my agents/environment in my case; how to define actions (low-level definition (e.g. V in level1 electrical grid vs high level decision)); everything related to q* and Q-learning.\n\ndynamic programming (DP) (chap4 - 103-126)\nWhat is key here is to have an exact way to describe your environment. Which is not always feasible. And we need computer power to go through all states, compute value function. There is a balance between policy evaluation and policy improvement but this is not crystal clear to me. And I don’t understand asynchronous DP. I haven’t developed enough intuitions behind DP, and I am unable to answer exercises. I understand though that reinforcement learning can solve some problems by approximating part of it (evaluation, environment, …)\n\n\nmonte carlo (MC) methods (chap5 - 127-156)\nfirst-visit vs every-visit methods. First-visit has been widely studied. Blackjack example. Explanation of Monte Carlo ES (exploratory starts); and how to avoid this unlikely assumption thanks to on-policy or off-policy methods (on-policy estimate the value of a policy while using it for control. In off-policy methods these two functions are separated (behavior and target)).\nOne issue with MC methods is to ensure sufficient exploration. One approach is to start with a random state-action pair, could work with simulated episodes but unlikely to learn from real experience.\nMC methods do not bootstrap (i.e. they don’t update their value estimates based on other value estimates) (TODO learn more about bootstrapping)\n\n\ntemporal-difference (TD) learning (chap6 - 157-180)\nTD learning is a combination of Monte Carlo ideas and dynamic programming (DP) ideas. Like DP, TD methods update estimates based in part on other learned estimates, without waiting for a final outcome (they bootstrap, or said differently they learn a guess from a guess).\nIf you consider optimization as a 2 phases approach: prediction problem (ie policy evaluation) and control problem (ie optimal policy), DP, TD, MC differences are at the prediction problem. On control problem they use variations of generalized policy iteration (GPI).\nTD methods combine the sampling of Monte Carlo with the bootstrapping of DP.\nExample based on Driving Home. In TD you update prediction at each step, not waiting for the final return as in MC.\n\n\neligibility traces (chap7 - 181-208)\nTD(\\[\\lambda\\]) is a way to integrate MC and TD.\nIf one wants to use TD methods because of their other advantages, but the task is at least partially non-Markov, then the use of an eligibility trace method is indicated. Eligibility traces are the first line of defense against both long-delayed rewards and non-Markov tasks.\nI am not sure to understand the effect of bootstrap.\n\n\nPlanning and Learning with Tabular Methods (chap8 - 209-220-236)\nplanning = require a model (dynamic programming, heuristic search)\nlearning = can be used without a model (MC, TD)\nThe difference is that whereas planning uses simulated experience generated by a model, learning methods use real experience generated by the environment."
  },
  {
    "objectID": "posts/2021-01-26-reinforcement-learning-readings.html#from-a-deep-reinforcement-learning-based-multi-criteria-decision-support-system-for-optimizing-textile-chemical-process",
    "href": "posts/2021-01-26-reinforcement-learning-readings.html#from-a-deep-reinforcement-learning-based-multi-criteria-decision-support-system-for-optimizing-textile-chemical-process",
    "title": "Reinforcement learning readings",
    "section": "2/18/21 - from A Deep Reinforcement Learning Based Multi-Criteria Decision Support System for Optimizing Textile Chemical Process",
    "text": "2/18/21 - from A Deep Reinforcement Learning Based Multi-Criteria Decision Support System for Optimizing Textile Chemical Process\nThis is a more practical paper and should help to figure out what could be our own implementation.\nOverall MDP (markov decision process) structure is quite interesting with 3 blocks:\n\nRF (random forest) models (one per objective)\nAHP (analytic hierarchy process) which is a MCDM (Multiple criteria decision-making) method\nDQN which is the reinforcement learning part to approximate the Q function\n\n\nthere are interesting references.\n[2] K. Suzuki, ARTIFICIAL NEURAL NETWORKS - INDUSTRIAL AND CONTROL ENGINEERING APPLICATIONS. 2011.\n\nIt is nearly impossible to upgrade the textile chemical manufacturing processes directly by only following the cases from other industries without considering the detailed characteristics of this sector and specific investigations in the applicable advanced technologies. To this end, the construction of accurate models for simulating manufacturing processes using intelligent techniques is rather necessary[2]\n\n[4]A. Ghosh, P. Mal, and A. Majumdar, Advanced Optimization and Decision-Making Techniques in Textile Manufacturing.2019.\n\n[..] Therefore, production decision-makers cannot effectively control the processes in order to obtain desired product functionalities [4]\n\n[53] T.L. Saaty, “What is the analytic hierarchy process?” Mathematical models for decision support, Springer, 1988, pp.109 121.\n\nThe AHP is a MCDM method introduced by Saaty [53]\n\n[54]R. S. Sutton and A. G. Barto, Introduction to reinforcement learning, vol. 135. MIT press Cambridge, 1998.\n\nThe Markov property indicates that the state transitions are only dependent on the current state and current action is taken, but independent to all prior states and actions[54].\n\n[66] Z. Chourabi, F.Khedher, A. Babay and M. Cheikhrouhou, “Multi-criteria decision making in workforce choice using AHP, WSM and WPM”, J.Text.Inst., 2018\n\nHowever, it is worth remarking that certain features of this framework may hinder the massive promotion and application of it. The AHP has been successfully implemented in MCDM problems [41], [66]"
  },
  {
    "objectID": "posts/2021-01-26-reinforcement-learning-readings.html#the-complete-reinforcement-learning-dictionary",
    "href": "posts/2021-01-26-reinforcement-learning-readings.html#the-complete-reinforcement-learning-dictionary",
    "title": "Reinforcement learning readings",
    "section": "2/18/21 - The Complete Reinforcement Learning Dictionary",
    "text": "2/18/21 - The Complete Reinforcement Learning Dictionary\nrecommandations:\n\n\nIf you’re looking for a quick, 10-minutes crash course into RL with code examples, checkout my Qrash Course series: Introduction to RL and Q-Learning and Policy Gradients and Actor-Critics.\nI you’re into something deeper, and would like to learn and code several different RL algorithms and gain more intuition, I can recommend this series by Thomas Simonini and this series by Arthur Juliani.\nIf you’re ready to master RL, I will direct you to the “bible” of Reinforcement Learning — “Reinforcement Learning, an introduction” by Richard Sutton and Andrew Barto. The second edition (from 2018) is available for free (legally) as a PDF file."
  },
  {
    "objectID": "posts/2021-01-26-reinforcement-learning-readings.html#reinforcement-learning-an-introduction---ii-approximate-solution-methods",
    "href": "posts/2021-01-26-reinforcement-learning-readings.html#reinforcement-learning-an-introduction---ii-approximate-solution-methods",
    "title": "Reinforcement learning readings",
    "section": "3/5/21 - Reinforcement learning : an introduction - II Approximate Solution Methods",
    "text": "3/5/21 - Reinforcement learning : an introduction - II Approximate Solution Methods\nThis is the 2nd part of the book.\nOn-policy Approximation of Action Values\nAs mentioned in introduction of part II, what is developed in part I (our estimates of value functions are represented as a table with one entry for each state or for each state–action pair) is instructive, but of course it is limited to tasks with small numbers of states and actions.\nHow can experience with a limited subset of the state space be usefully generalized to produce a good approximation over a much larger subset?\nThis is a generalization issue (or function approximation) one could consider as an instance of supervised learning, where we use the s-&gt;v of each backup as a training example, and then interpret the approximate function produced as an estimated value function.\nBertsekas and Tsitsiklis (1996) present the state of the art in function approximation in reinforcement learning.\nPolicy approximation\nActor-Critic: The policy structure is known as the actor, because it is used to select actions, and the estimated value function is known as the critic, because it criticizes the actions made by the actor.\n(3/12/21) end of book. Chapter 14 - Applications and case studies.\nI like this statement:\n\nApplications of reinforcement learning are still far from routine and typically require as much art as science. Making applications easier and more straightforward is one of the goals of current research in reinforcement learning.\n\nTD backgammon (1995). It uses a neural net (1 hidden layer, from 40 to 80 units) to approximate the predicted probability of winning v(s) for a given state. In later version, some domain features were used but still using self-play TD learning method. (I don’t know specifics for these domain features). And last versions give an interest to opponent reactions (possible dice rolls and moves)\nSamuel’s Checkers Player (~1960). (Checkers c’est le jeu de dames). It is based on minimax procedure to find the best move from current position. 1st learning used was rote learning (storing position(s value). 2nd learning used alpha-beta (linked to minimax procedure) and hierarchical lookup tables instead of linear function approximation.\nAcrobot (1993). Use of Sarsa(\\[\\lambda\\]). Interesting to see that an exploration step can spoil a whole sequence of good actions. This is why greedy policy is used (\\[\\epsilon\\]=0).\nElevator dispatching (1996). With a reward being the negative of the sum of the squared waiting times of all waiting passengers. (squared to push the system to avoid big waiting times). We use an extension of Q-learning to semi-Markov decision problems. For function approximation, a nonlinear neural network trained by back-propagation was used to represent the action-value function.\nDynamic Channel Allocation (1997). The channel assignment problem can be formulated as a semi-Markov decision process much as the elevator dispatching problem was in the previous section.\nJob-Shop Scheduling (1996). Zhang and Dietterich’s job-shop scheduling system is the first successful instance of which we are aware in which reinforcement learning was applied in plan-space, that is, in which states are complete plans (job-shop schedules in this case), and actions are plan modifications. This is a more abstract application of reinforcement learning than we are used to thinking about.\nChapter 15 - Prospects\n\nThis is a map to distinguish where to use different techniques. And considerations of a 3rd dimension regarding function approximation, or on/off-policy.\nAnd then opening to non markov case such as the theory of partially observable MDPs (POMDPs). (StarCraft!)\nReferences\n25 pages of references! Woawww."
  },
  {
    "objectID": "posts/2023-01-23-latex_reference.html",
    "href": "posts/2023-01-23-latex_reference.html",
    "title": "Latex in markdown reference",
    "section": "",
    "text": "Reference\nhttps://en.wikibooks.org/wiki/LaTeX/Mathematics\n\n\nExamples\nWe can integrate markdown between $ $ or $$ $$\nSingle $ will be inline\nDouble $$ will be centered into a new line\n\n\n\n\n\n\n\nLaTeX\nMarkdow\n\n\n\n\n\\(\\widehat{q}\\)\n\\widehat{q}\n\n\n\\(|x-x_M|\\)\n|x-x_M|\n\n\n\\(f_M(x)\\)\nf_M(x)\n\n\n\\(\\displaystyle\\sum_{m}\\)\n\\displaystyle\\sum_{m}\n\n\n\\(\\langle{x,w_m}\\rangle\\)\n\\langle{x,w_m}\\rangle\n\n\n\\(\\| v_m \\|\\)\n\\| v_m \\|\n\n\n\\(\\cos\\)\n\\cos\n\n\n\\(\\mathbb{Z}^d\\)\n\\mathbb{Z}$^d\n\n\n\\(\\infty\\)\n\\infty\n\n\n\\(f \\in L^2\\)\nf \\in L^2\n\n\n$$\n\\implies\n\n\n\\(\\lim\\limits_{M \\to \\infty}\\)\n\\lim\\limits_{M \\to \\infty}\n\n\n\\(P(A|B) = \\frac{P(B|A)*P(A)}{P(B)}\\)\nP(A|B) = \\frac{P(B|A)*P(A)}{P(B)}\n\n\n\\(\\begin{align} \\\\ Q_t(a) &= \\frac{\\text{sum of rewards when } \\mathit{a} \\text{ taken prior to }\\mathit{t}}{\\text{number of times } \\mathit{a} \\text{ taken prior to }\\mathit{t}} \\\\ & = \\frac{\\displaystyle\\sum_{i=1}^{t-1} R_i.\\mathcal{1}_{A_i=a}}{\\displaystyle\\sum_{i=1}^{t-1} \\mathcal{1}_{A_i=a}} \\end{align}\\)\n\\begin{align} \\\\  Q_t(a) &= \\frac{\\text{sum of rewards when } \\mathit{a} \\text{ taken prior to }\\mathit{t}}{\\text{number of times } \\mathit{a} \\text{ taken prior to }\\mathit{t}} \\\\  & = \\frac{\\displaystyle\\sum_{i=1}^{t-1} R_i.\\mathcal{1}_{A_i=a}}{\\displaystyle\\sum_{i=1}^{t-1} \\mathcal{1}_{A_i=a}}  \\end{align}\n\n\n\\(A_t=\\underset{a}{\\mathrm{argmax}}{\\text{ }Q_t(a)}\\)\nA_t=\\underset{a}{\\mathrm{argmax}}{\\text{ }Q_t(a)}\n\n\n\\(p(s',r|s,a) \\doteq Pr\\{S_t=s', R_t=r|S_{t-1}=s, A_{t-1}=a\\}\\)\np(s',r|s,a) \\doteq Pr\\{S_t=s', R_t=r|S_{t-1}=s, A_{t-1}=a\\}\n\n\n\\(q_\\pi(s,a) \\doteq \\mathbb{E}[R_{t+1}+\\gamma.G_{t+1}|S_t=s, A_t=a]\\)\nq_\\pi(s,a) \\doteq \\mathbb{E}[R_{t+1}+\\gamma.G_{t+1}|S_t=s, A_t=a]\n\n\n\\(v_*(s)\\doteq \\max\\limits_{\\pi} v_\\pi(s), \\forall s \\in S\\)\nv_*(s)\\doteq \\max\\limits_{\\pi} v_\\pi(s), \\forall s \\in S\n\n\n\\(q_\\pi(s,a) \\doteq \\mathbb{E}[R_{t+1}+\\gamma.G_{t+1}|S_t=s, A_t=a]\\)\nq_\\pi(s,a) \\doteq \\mathbb{E}[R_{t+1}+\\gamma.G_{t+1}|S_t=s, A_t=a]\n\n\n\\(l(w,b)=\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}(y_n-(x_nw+b))^2\\)\nl(w,b)=\\frac{1}{N}\\displaystyle\\sum_{n=1}^{N}(y_n-(x_nw+b))^2\n\n\n\\(\\nabla l(w,b) = \\begin{bmatrix}\\frac{\\partial l(w,b)}{\\partial w_1}\\\\ \\vdots \\\\\\frac{\\partial l(w,b)}{\\partial w_d}\\end{bmatrix}\\)\n\\nabla l(w,b) = \\begin{bmatrix}\\frac{\\partial l(w,b)}{\\partial w_1}\\\\ \\vdots \\\\\\frac{\\partial l(w,b)}{\\partial w_d}\\end{bmatrix}\n\n\n\\(\\\\ H(X) = – \\sum_{x \\in X} P(x) * \\log(P(x))\\)\n\\\\ H(X) = – \\sum_{x \\in X} P(x) * \\log(P(x))\n\n\n\\(X \\sim \\mathcal{N}(\\mu,\\,\\sigma^{2})\\)\nX \\sim \\mathcal{N}(\\mu,\\,\\sigma^{2})\n\n\n\\(\\sqrt[n]{1+x+x^2+x^3+\\dots+x^n}\\)\n\\sqrt[n]{1+x+x^2+x^3+\\dots+x^n}"
  },
  {
    "objectID": "posts/2021-06-30-documentation-python.html",
    "href": "posts/2021-06-30-documentation-python.html",
    "title": "Autogenerate documentation from custom python classes",
    "section": "",
    "text": "!conda env list\n\n# conda environments:\n#\nbase                     /home/explore/miniconda3\naniti                    /home/explore/miniconda3/envs/aniti\naudioclass               /home/explore/miniconda3/envs/audioclass\ncoursera_rl              /home/explore/miniconda3/envs/coursera_rl\nd059                  *  /home/explore/miniconda3/envs/d059\ndatacamp                 /home/explore/miniconda3/envs/datacamp\ndeeplearning_specialization     /home/explore/miniconda3/envs/deeplearning_specialization\ndeeplearning_specialization_keras     /home/explore/miniconda3/envs/deeplearning_specialization_keras\ndeeplearning_specialization_tf1     /home/explore/miniconda3/envs/deeplearning_specialization_tf1\ndrl_handson              /home/explore/miniconda3/envs/drl_handson\ndrl_simonini             /home/explore/miniconda3/envs/drl_simonini\nfastai                   /home/explore/miniconda3/envs/fastai\nfastaudio                /home/explore/miniconda3/envs/fastaudio\ngan                      /home/explore/miniconda3/envs/gan\ngan_tensorflow           /home/explore/miniconda3/envs/gan_tensorflow\nmacos                    /home/explore/miniconda3/envs/macos\nminecraft                /home/explore/miniconda3/envs/minecraft\nmit_6002x                /home/explore/miniconda3/envs/mit_6002x\nmit_6S191                /home/explore/miniconda3/envs/mit_6S191\npycaret                  /home/explore/miniconda3/envs/pycaret\npytorch                  /home/explore/miniconda3/envs/pytorch\nscikit-learn-course      /home/explore/miniconda3/envs/scikit-learn-course\nshap                     /home/explore/miniconda3/envs/shap\nsqueezebox               /home/explore/miniconda3/envs/squeezebox\nstablebaselines3         /home/explore/miniconda3/envs/stablebaselines3\nzoe                      /home/explore/miniconda3/envs/zoe\n\n\n\n\nimport sys\n!conda install --yes --prefix {sys.prefix} pdoc3\n\nCollecting package metadata (current_repodata.json): done\nSolving environment: / \nThe environment is inconsistent, please check the package plan carefully\nThe following packages are causing the inconsistency:\n\n  - defaults/linux-64::matplotlib==3.3.2=0\n  - defaults/linux-64::matplotlib-base==3.3.2=py38h817c723_0\n  - defaults/linux-64::spacy==2.3.2=py38hfd86e86_0\n  - pytorch/linux-64::torchvision==0.8.1=py38_cu110\n  - defaults/linux-64::numpy==1.19.2=py38h54aff64_0\n  - defaults/linux-64::thinc==7.4.1=py38hfd86e86_0\n  - defaults/linux-64::cython-blis==0.4.1=py38h7b6447c_1\n  - fastai/noarch::fastprogress==1.0.0=pyh39e3cac_0\n  - fastai/noarch::fastai==2.1.4=py_0\n  - defaults/linux-64::mkl_random==1.1.1=py38h0573a6f_0\n  - pytorch/linux-64::pytorch==1.7.0=py3.8_cuda11.0.221_cudnn8.0.3_0\n  - defaults/linux-64::pandas==1.1.3=py38he6710b0_0\n  - fastai/noarch::fastscript==1.0.0=0\n  - defaults/linux-64::scipy==1.5.2=py38h0b6359f_0\n  - defaults/linux-64::mkl_fft==1.2.0=py38h23d657b_0\n  - fastai/noarch::fastbook==0.0.14=py_0\n  - defaults/linux-64::scikit-learn==0.23.2=py38h0573a6f_0\ndone\n\n## Package Plan ##\n\n  environment location: /home/explore/miniconda3/envs/d059\n\n  added / updated specs:\n    - pdoc3\n\n\nThe following NEW packages will be INSTALLED:\n\n  mako               pkgs/main/noarch::mako-1.1.4-pyhd3eb1b0_0\n  markdown           pkgs/main/linux-64::markdown-3.3.4-py38h06a4308_0\n  pdoc3              pkgs/main/noarch::pdoc3-0.9.2-pyhd3eb1b0_0\n\nThe following packages will be UPDATED:\n\n  ca-certificates                              2020.10.14-0 --&gt; 2021.5.25-h06a4308_1\n  certifi            pkgs/main/noarch::certifi-2020.6.20-p~ --&gt; pkgs/main/linux-64::certifi-2021.5.30-py38h06a4308_0\n  mkl_fft                              1.2.0-py38h23d657b_0 --&gt; 1.3.0-py38h54f3939_0\n  openssl                                 1.1.1h-h7b6447c_0 --&gt; 1.1.1k-h27cfd23_0\n  scipy                                1.5.2-py38h0b6359f_0 --&gt; 1.6.2-py38h91f5cce_0\n\n\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done"
  },
  {
    "objectID": "posts/2021-06-30-documentation-python.html#force-refresh-of-doc",
    "href": "posts/2021-06-30-documentation-python.html#force-refresh-of-doc",
    "title": "Autogenerate documentation from custom python classes",
    "section": "force refresh of doc",
    "text": "force refresh of doc\nin case of existing html file\npdoc --html --output-dir exp/html --force exp/my_classe.py"
  },
  {
    "objectID": "posts/2020-10-06-gan-specialization-course1-week1-intro_to_gan.html",
    "href": "posts/2020-10-06-gan-specialization-course1-week1-intro_to_gan.html",
    "title": "GAN Specialization course 1 week 1 - intro to GAN",
    "section": "",
    "text": "My notes\n\n\n\nalt text\n\n\n\n\n\nalt text"
  },
  {
    "objectID": "posts/2022-07-01-logbook-July-22.html",
    "href": "posts/2022-07-01-logbook-July-22.html",
    "title": "Logbook for July 22",
    "section": "",
    "text": "Friday 7/1\n\ncontinue deep rl class with unit 4, unity ml agents within huggingface. And there is a link to a page explaining decision transformers. Seems quite powerful and could be useful for me."
  },
  {
    "objectID": "posts/2022-07-01-logbook-July-22.html#week-26---july-22",
    "href": "posts/2022-07-01-logbook-July-22.html#week-26---july-22",
    "title": "Logbook for July 22",
    "section": "",
    "text": "Friday 7/1\n\ncontinue deep rl class with unit 4, unity ml agents within huggingface. And there is a link to a page explaining decision transformers. Seems quite powerful and could be useful for me."
  },
  {
    "objectID": "posts/2022-07-01-logbook-July-22.html#week-27---july-22",
    "href": "posts/2022-07-01-logbook-July-22.html#week-27---july-22",
    "title": "Logbook for July 22",
    "section": "Week 27 - July 22",
    "text": "Week 27 - July 22\nWednesday 7/6\n\ncontinue deep rl class with unit 5, Policy Gradient with PyTorch"
  },
  {
    "objectID": "posts/2022-07-01-logbook-July-22.html#week-29---july-22",
    "href": "posts/2022-07-01-logbook-July-22.html#week-29---july-22",
    "title": "Logbook for July 22",
    "section": "Week 29 - July 22",
    "text": "Week 29 - July 22\nThursday 7/21\n\nI would like to host kaggle-like competitions. I have found EvalAI which could be an option. I could push a competition for my data manufacturing colleagues and for other areas in my company. There is a comparison with other kind of platforms (both closed and open sourced)\ninstalling rancher desktop to test EvalAI I don’t have administrator rights anymore, so I have moved to installing docker in WSL.\n\nFriday 7/22\n\nbased on my docker in WSL installation, I tried to follow EvalAI instructions. It fails at docker-compose build phase. I have opened a ticket."
  },
  {
    "objectID": "posts/2022-07-01-logbook-July-22.html#week-30---july-22",
    "href": "posts/2022-07-01-logbook-July-22.html#week-30---july-22",
    "title": "Logbook for July 22",
    "section": "Week 30 - July 22",
    "text": "Week 30 - July 22\nMonday 7/25\nAs a matter of test, installation of EvalAI on my linux machine (no issue with corporate FW) using docker.\nWhen starting, this error: ERROR: for db Cannot start service db: [...] listen tcp 0.0.0.0:5432: bind: address already in use. Just kill the running postgres process as explained in Evalai - Common Errors during installation\nTuesday 7/26\nAs a matter of test, installation of EvalAI on my wsl machine using virtualenv (no docker) to try a gitlab connectivity instead of github. Tried on ubuntu-22.04. And tried on ubuntu-18.04 without success.\nWednesday 7/27\nNot giving up 😓. Will try this: build docker image from linux, save it. Moved it to my wsl image. Restore it. Pray. How to copy a Docker image from one server to another without pushing it to a repository first?\n\nfrom linux: sudo docker save -o /tmp/evalai_nodejs.tar evalai_nodejs\nfrom wsl:\n\nsudo mkdir /mnt/e\nsudo mount -t drvfs E: /mnt/e\n# pv to copy with a progress bar\npv /mnt/e/janus/evalai_nodejs.tar &gt; ~/tmp/evalai_nodejs.tar\nsudo docker load -i evalai_nodejs.tar\ncd ~/evalai\ndocker-compose up\nbut I don’t know how to go further as explained in this evalai issue\nOk this works with the following images:\nevalai_django.tar  \nevalai_nodejs.tar  \nevalai_nodejs_v2.tar  \nevalai_worker.tar\nFriday7/29\nNow that I can start Evalai on my corporate machine, how to setup it with gitlab."
  },
  {
    "objectID": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html",
    "href": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html",
    "title": "ANITI’s first Reinforcement Learning Virtual School",
    "section": "",
    "text": "https://rlvs.aniti.fr/\nSchedule is"
  },
  {
    "objectID": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#rlvs-schedule",
    "href": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#rlvs-schedule",
    "title": "ANITI’s first Reinforcement Learning Virtual School",
    "section": "RLVS schedule",
    "text": "RLVS schedule\nThis condensed schedule does not include class breaks and social events. Times are Central European Summer Time (UTC+2).\n\n\n\nSchedule\n\n\n\n\n\n\n\nMarch 25th\n9:00-9:10\nOpening remarks\nS. Gerchinovitz\n\n\n\n9:10-9:30\nRLVS Overview\nE. Rachelson\n\n\n\n9:30-13:00\nRL fundamentals\nE. Rachelson\n\n\n\n14:00-16:00\nIntroduction to Deep Learning\nD. Wilson\n\n\n\n16:30-17:30\nReward Processing Biases in Humans and RL Agents\nI. Rish\n\n\n\n17:45-18:45\nIntroduction to Hierarchical Reinforcement Learning\nD. Precup\n\n\nMarch 26th\n10:00-12:00\nStochastic bandits\nT. Lattimore\n\n\n\n14:00-16:00\nMonte Carlo Tree Search\nT. Lattimore\n\n\n\n16:30-17:30\nMulti-armed bandits in clinical trials\nD. A. Berry\n\n\nApril 1st\n9:00-15:00\nDeep Q-Networks and its variants\nB. Piot, C. Tallec\n\n\n\n15:15-16:15\nRegularized MDPs\nM. Geist\n\n\n\n16:30-17:30\nRegret bounds of model-based reinforcement learning\nM. Wang\n\n\nApril 2nd\n9:00-12:30\nPolicy Gradients and Actor Critic methods\nO. Sigaud\n\n\n\n14:00-15:00\nPitfalls in Policy Gradient methods\nO. Sigaud\n\n\n\n15:30-17:30\nExploration in Deep RL\nM. Pirotta\n\n\nApril 8th\n9:00-11:00\nEvolutionary Reinforcement Learning\nD. Wilson, J.-B. Mouret\n\n\n\n11:30-12:30\nEvolving Agents that Learn More Like Animals\nS. Risi\n\n\n\n14:00-16:00\nMicro-data Policy Search\nK. Chatzilygeroudis, J.-B. Mouret\n\n\n\n16:30-17:30\nEfficient Motor Skills Learning in Robotics\nD. Lee\n\n\nApril 9th\n9:00-13:00\nRL tips and tricks\nA. Raffin\n\n\n\n14:30-15:30\nSymbolic representations and reinforcement learning\nM. Garnelo\n\n\n\n15:45-16:45\nLeveraging model-learning for extreme generalization\nL. P. Kaelbling\n\n\n\n17:00-18:00\nRLVS wrap-up\nE. Rachelson"
  },
  {
    "objectID": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#deep-q-networks-and-its-variants",
    "href": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#deep-q-networks-and-its-variants",
    "title": "ANITI’s first Reinforcement Learning Virtual School",
    "section": "(4/1/21) - Deep Q-Networks and its variants",
    "text": "(4/1/21) - Deep Q-Networks and its variants\nSpeaker is Bilal Piot.\nDeep Q network as a solution for a practicable control theory.\nIntroduction of ALE (Atari Learning Environment)\nDQN is (almost) end-to-end: from raw observations to actions. Bilal explains the preprocessing part (from 160x210x3 to 84x84 + stacking 4 frames + downsampling to 15 Hz)\nValue Iteration (VI) algorithm: Recurrent algorithm to get Q. \\(Q_{k+1}=T^*Q\\)\nBut it is not practical in a real-world case. What we can do is use interactions with real world. And estimate \\(Q^*\\) using a regression.\nWould be interesting to have slides. I like the link between regression notations and VI notation.\nFrom neural Fitted-\\(Q\\) to DQN. Main difference is data collection (in DQN you have updated interactions and it allows exploration, and size of architecture)\nWith DQN we have acting part and learning part. Acting is the data collection. (using \\(\\epsilon\\)-greedy policy)\nhands-on based on DQN tutorial notebook.\nhad to export LD_LIBRARY_PATH=/home/explore/miniconda3/envs/aniti/lib/\nNice introduction to JAX and haiku. Haiku is similar modules in pytorch and can turn NN into pure version. Which is useful for Jax.\noverview of the literature"
  },
  {
    "objectID": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#from-policy-gradients-to-actor-critic-methods",
    "href": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#from-policy-gradients-to-actor-critic-methods",
    "title": "ANITI’s first Reinforcement Learning Virtual School",
    "section": "(4/2/21) - From Policy Gradients to Actor Critic methods",
    "text": "(4/2/21) - From Policy Gradients to Actor Critic methods\nOlivier Sigaud is the speaker.\nHe has pre-recorded his lecture in videos. I have missed the start so I will have to watch them later.\nPolicy Gradient in pratice\nDon’t become an alchemist ;)\nAs stochastic policies, squashed gaussian is interesting because it allows continuous variable + bounds.\nExploration in Deep RL"
  },
  {
    "objectID": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#evolutionary-reinforcement-learning",
    "href": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#evolutionary-reinforcement-learning",
    "title": "ANITI’s first Reinforcement Learning Virtual School",
    "section": "(4/8/21) - Evolutionary Reinforcement Learning",
    "text": "(4/8/21) - Evolutionary Reinforcement Learning\npdf version of the slides are available here\nthen Evolving Agents that Learn More Like Animals\nThis morning was more about what we can do when we have infinite calculation power and data.\nAfternoon will be the opposite."
  },
  {
    "objectID": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#micro-data-policy-search",
    "href": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#micro-data-policy-search",
    "title": "ANITI’s first Reinforcement Learning Virtual School",
    "section": "(4/8/21) - Micro-data Policy Search",
    "text": "(4/8/21) - Micro-data Policy Search\nMost policy search algorithms require thousands of training episodes to find an effective policy, which is often infeasible when experiments takes time or are expensive (for instance, with physical robot or with an aerodynamics simulator). This class focuses on the extreme other end of the spectrum: how can an algorithm adapt a policy with only a handful of trials (a dozen) and a few minutes? By analogy with the word “big-data”, we refer to this challenge as “micro-data reinforcement learning”. We will describe two main strategies: (1) leverage prior knowledge on the policy structure (e.g., dynamic movement primitives), on the policy parameters (e.g., demonstrations), or on the dynamics (e.g., simulators), and (2) create data-driven surrogate models of the expected reward (e.g., Bayesian optimization) or the dynamical model (e.g., model-based policy search), so that the policy optimizer queries the model instead of the real system. Most of the examples will be about robotic systems, but the principle apply to any other expensive setup.\nall material: https://rl-vs.github.io/rlvs2021/micro-data.html"
  },
  {
    "objectID": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#rl-in-practice-tips-and-tricks-and-practical-session-with-stable-baselines3",
    "href": "posts/2021-04-01-Aniti - RLVS - seminaire RL.html#rl-in-practice-tips-and-tricks-and-practical-session-with-stable-baselines3",
    "title": "ANITI’s first Reinforcement Learning Virtual School",
    "section": "(4/9/21) - RL in Practice: Tips and Tricks and Practical Session With Stable-Baselines3",
    "text": "(4/9/21) - RL in Practice: Tips and Tricks and Practical Session With Stable-Baselines3\n​ Abstract: The aim of the session is to help you do reinforcement learning experiments. The first part covers general advice about RL, tips and tricks and details three examples where RL was applied on real robots. The second part will be a practical session using the Stable-Baselines3 library.\nPre-requisites: Python programming, RL basics, (recommended: Google account for the practical session in order to use Google Colab).\nAdditional material: Website: https://github.com/DLR-RM/stable-baselines3 Doc: https://stable-baselines3.readthedocs.io/en/master/\nOutline: Part I: RL Tips and Tricks / The Challenges of Applying RL to Real Robots\n\nIntroduction (3 minutes)\nRL Tips and tricks (45 minutes)\n\nGeneral Nuts and Bolts of RL experimentation (10 minutes)\nRL in practice on a custom task (custom environment) (30 minutes)\nQuestions? (5 minutes)\n\nThe Challenges of Applying RL to Real Robots (45 minutes)\n\nLearning to control an elastic robot - DLR David Neck Example (15 minutes)\nLearning to drive in minutes and learning to race in hours - Virtual and real racing car (15 minutes)\nLearning to walk with an elastic quadruped robot - DLR bert example (10 minutes)\nQuestions? (5 minutes+)\n\n\nPart II: Practical Session with Stable-Baselines3\n\nStable-Baselines3 Overview (20 minutes)\nQuestions? (5 minutes)\nPractical Session - Code along (1h+)\n\naction space\nWhen using continuous space, you need to normalize! (normalized action space -1, -1)\nthere is a checker for that in stable baselines 3.\nreward\nstart with reward shaping.\ntermination condition\nearly stopping makes learning faster (and safer for robots)\n\nfor hyperparameter tuning, Antonin recommends Optuna.\nabout the Henderson paper: Deep Reinforcement Learning that Matters\n\nand then the controller will use latent representation / current speed + history as observation space.\nLearning to drive takes then 10 min, and to race 2 hours.\n\nhandson\nslides: https://araffin.github.io/slides/rlvs-sb3-handson/\nnotebook: https://github.com/araffin/rl-handson-rlvs21\nRL zoo: https://github.com/DLR-RM/rl-baselines3-zoo\ndocumentation for SB3 usefull for completing exercises: https://stable-baselines3.readthedocs.io/en/master/\nhttps://excalidraw.com/"
  },
  {
    "objectID": "posts/2021-01-14-java-installation-on-ubuntu-20.04.html",
    "href": "posts/2021-01-14-java-installation-on-ubuntu-20.04.html",
    "title": "Java installation on Ubuntu 20.04",
    "section": "",
    "text": "Following these instructions: https://www.digitalocean.com/community/tutorials/how-to-install-java-with-apt-on-ubuntu-20-04-fr.\n\nCurrent configuration\n\n!java --version\n\nopenjdk 11.0.9.1 2020-11-04\nOpenJDK Runtime Environment (build 11.0.9.1+1-Ubuntu-0ubuntu1.20.04)\nOpenJDK 64-Bit Server VM (build 11.0.9.1+1-Ubuntu-0ubuntu1.20.04, mixed mode, sharing)\n\n\n\n\nDownload Oracle JDK 11\nFrom https://launchpad.net/~linuxuprising/+archive/ubuntu/java/+packages, I can identify the focal version:\noracle-java11-installer-local - 11.0.9-1~linuxuprising0    (changes file)  logix2  2020-10-22  Published   Focal   Java\nI download the given version from Oracle website: https://www.oracle.com/java/technologies/javase-jdk11-downloads.html. Java SE Development Kit 11.0.9 Linux x64 Compressed Archive\nAnd yes you have to login with an oracle account to download it.\n\n\nInstallation via linuxuprising/java\nsudo add-apt-repository ppa:linuxuprising/java\nsudo apt update\nsudo mkdir -p /var/cache/oracle-jdk11-installer-local/\nsudo cp ~/Downloads/jdk-11.0.9_linux-x64_bin.tar.gz /var/cache/oracle-jdk11-installer-local/\nsudo apt install oracle-java11-installer-local\nAfter accepting the license agreement, installation is running\n\n\nCheck\n$ sudo update-alternatives --config java\nThere are 2 choices for the alternative java (providing /usr/bin/java).\n\n  Selection    Path                                         Priority   Status\n------------------------------------------------------------\n  0            /usr/lib/jvm/java-11-openjdk-amd64/bin/java   1111      auto mode\n  1            /usr/lib/jvm/java-11-openjdk-amd64/bin/java   1111      manual mode\n* 2            /usr/lib/jvm/java-11-oracle/bin/java          1091      manual mode\n\n\nEnvironment variable\nEnter /usr/lib/jvm/java-11-oracle as your JAVA_HOME variable in /etc/environment\n$ cat /etc/environment\nPATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\"\nJAVA_HOME=\"/usr/lib/jvm/java-11-oracle\"\n$ source /etc/environment\n$ echo $JAVA_HOME\n/usr/lib/jvm/java-11-oracle"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html",
    "title": "Blog - migrate to quarto",
    "section": "",
    "text": "Hamel just announced that fastpages will be discontinued as nbdev+quarto is now a valid option to provide a blogging platform. He has written a migration guide for that.\nThis is my walkthrough."
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#install-quarto",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#install-quarto",
    "title": "Blog - migrate to quarto",
    "section": "install quarto",
    "text": "install quarto\n$ sudo apt install quarto\n[sudo] password for guillaume:\nReading package lists... Done\nBuilding dependency tree... Done\nReading state information... Done\nquarto is already the newest version (1.1.189).\n0 upgraded, 0 newly installed, 0 to remove and 0 not upgraded.\nwill have to see what will happen on platforms where I don’t have admin rights.\nHere Quarto is already present because I use it for nbdev2."
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#create-repo-blog",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#create-repo-blog",
    "title": "Blog - migrate to quarto",
    "section": "create repo blog",
    "text": "create repo blog\nI create blog repo on github.\nAnd I can now get it locally: git clone https://github.com/castorfou/blog.git (I am from office, only https is accepted)"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#create-a-quarto-blog",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#create-a-quarto-blog",
    "title": "Blog - migrate to quarto",
    "section": "create a quarto blog",
    "text": "create a quarto blog\ncd ~/git/blog\nquarto create-project --type website:blog .\nquarto install extension quarto-ext/video\nIssue here with quarto install when running from a corporate pc\n$ quarto install extension quarto-ext/video\nSending fatal alert BadCertificate\nERROR: TypeError: error sending request for url (https://github.com/quarto-ext/video/archive/refs/heads/main.tar.gz): error trying to connect: invalid peer certificate contents: invalid peer certificate: UnknownIssuer\nI have opened an issue at https://github.com/quarto-ext/video/issues/27"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#copy-former-blog-content---notebooks-and-markdown-files",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#copy-former-blog-content---notebooks-and-markdown-files",
    "title": "Blog - migrate to quarto",
    "section": "copy former blog content - notebooks and markdown files",
    "text": "copy former blog content - notebooks and markdown files\nYour new repo will have a posts/ directory.\nThis is where you will copy all of your notebook and markdown posts from fastpages.\ncp -r ../guillaume_blog/_notebooks/* posts/\ncp -r ../guillaume_blog/_posts/* posts/\nI have to fix some stuff here,\nsome markdown posts have empty description which is not allowed by the migration process.\nTo fix that I will run sed -i -- 's/^description:[[:space:]*]$/description:\\ \\\"\\\"/' ~/git/blog/posts/*.md\nGlobally to identify culprit, I executed this:\nchemin=`pwd`\nfor FILE in ../guillaume_blog/_posts/*; \\\ndo echo $FILE; \\\ncp \"$FILE\" posts/; \\\nsed -i -- 's/^description:[[:space:]*]$/description:\\ \\\"\\\"/' $chemin/posts/*.md; \\\nnbdev_migrate --path posts; \\\nrm -f posts/* 2&gt; /dev/null; \\\ndone;\nbut now that I know the migration issues, I can just execute:\n# handle empty description in markdown files\nchemin=`pwd`\nsed -i -- 's/^description:[[:space:]*]$/description:\\ \\\"\\\"/' $chemin/posts/*.md\n# code should not be here\nrm posts/notebook2script.py \nrm -rf posts/exp\nWhat was wrong with 2021-02-10-college-de-france-representations-parcimonieuses.md was accents in title. Removing é with e fixed it."
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#copy-former-blog-content---images",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#copy-former-blog-content---images",
    "title": "Blog - migrate to quarto",
    "section": "copy former blog content - images",
    "text": "copy former blog content - images\nmkdir images\ncp -r ../guillaume_blog/images/* images\ncp -r ../guillaume_blog/images/copied_from_nb/* images"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#migrate-posts-to-quarto",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#migrate-posts-to-quarto",
    "title": "Blog - migrate to quarto",
    "section": "migrate posts to quarto",
    "text": "migrate posts to quarto\nconda activate dataset_tools #this is an env with nbdev installed\n#install last version of nbdev\npip install -U nbdev\nnbdev_migrate --path posts"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#update-some-files",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#update-some-files",
    "title": "Blog - migrate to quarto",
    "section": "update some files",
    "text": "update some files\n\n.gitignore: we suggest adding _site/ as well as dot files .*\nabout.qmd: I reuse my former _pages/about.md\nprofile.jpg: and use my profile picture\n\n\n!cat ../.gitignore\n\n/.quarto/\n.*\n!.gitignore\n!.github"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#preview",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#preview",
    "title": "Blog - migrate to quarto",
    "section": "preview",
    "text": "preview\nquarto preview\nHere we can fix many thinks, and auto update rendered pages is just excellent!\n\nmove images from posts to posts/images (have to restart quarto preview after that)\ndelete the 2 examples (welcome and post-with-code)\n\nWill have to browse through all the site to see if all is properly rendered. &gt; fix for broken links or Jekyll shortcodes (things with {% … %}) that need to be converted to Quarto. Search the the Quarto documentation if you need help locating specific Quarto features."
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#keep-git-repo-in-sync",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#keep-git-repo-in-sync",
    "title": "Blog - migrate to quarto",
    "section": "keep git repo in sync",
    "text": "keep git repo in sync\nNOW=`date '+%F_%H:%M'`;\ngit add .\ngit commit -m \"$NOW\"\ngit push"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#publication-to-gh-pages-using-gh-actions",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#publication-to-gh-pages-using-gh-actions",
    "title": "Blog - migrate to quarto",
    "section": "publication to gh-pages using gh-actions",
    "text": "publication to gh-pages using gh-actions\nThere are 2 ways to publish. A straightforword one by calling quarto publish. And a more advanced one with github actions.\nUsing my corporate PC, quarto publish fails so I will give github actions a try.\n\nquarto publish\nquarto publish gh-pages\n:heavy_check_mark: This is ok when publishing with home PC.\n:x: But fails when publishing with corporate PC.see below quarto publishing issue behind firewall\nshared it with community at discord: https://discord.com/channels/689892369998676007/1020178609605984267/1020631703653462038\n\n\ngithub actions\nas explained in https://quarto.org/docs/publishing/github-pages.html#github-action\n1st step is to decide where code is executed: * local execution and rendering * local execution with CI rendering * CI execution and rendering\nI think I will go for local execution and rendering.\n\nfreezing computations\nTo be added to _quarto.yml\nexecute:\n  freeze: auto\nAnd then quarto render\n\n\npublish actions\nAdd a publish.yml GitHub Action to your project by creating this YAML file and saving it to .github/workflows/publish.yml:\non:\n  workflow_dispatch:\n  push:\n    branches: main\n\nname: Quarto Publish\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: write\n    steps:\n      - name: Check out repository\n        uses: actions/checkout@v2\n\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n\n      - name: Render and Publish\n        uses: quarto-dev/quarto-actions/publish@v2\n        with:\n          target: gh-pages\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\nWe can now remove the publish command from publish.sh\nAnd remove _site/ from .gitignore"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#open-external-links-in-new-tabs",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#open-external-links-in-new-tabs",
    "title": "Blog - migrate to quarto",
    "section": "open external links in new tabs",
    "text": "open external links in new tabs\nthanks to https://quarto.org/docs/reference/formats/html.html#links\n\n!cat ../_quarto.yml |grep -A 2 external\n\n    link-external-icon: true\n    link-external-newwindow: true\n    link-external-filter: ^(?:http:|https:)\\/\\/castorfou\\.github\\.io\\/"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#setup-favicon.ico",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#setup-favicon.ico",
    "title": "Blog - migrate to quarto",
    "section": "setup favicon.ico",
    "text": "setup favicon.ico\nCreation of a favicon for this blog. Using gimp\nAnd quarto doc for favicon\n\n!cat ../_quarto.yml |grep -B 2 favico\n\nwebsite:\n  title: \"Guillaume's blog\"\n  favicon: favicon_small.png\n\n\nAnd favicon_small.png is just at root.\n\n!find ../  -name 'favicon_small.png'\n\n../favicon_small.png\n../_site/favicon_small.png"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#setup-rss-feed",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#setup-rss-feed",
    "title": "Blog - migrate to quarto",
    "section": "setup RSS feed",
    "text": "setup RSS feed\nDiscussing with my colleague Jerome, he was interested to get RSS feed from my blog.\nI was kind of reluctant because it is not really a blog, it is more a wiki-log. I constantly update articles, sometimes months after the 1st publication.\nAnyway, here is how I did to activate RSS feed: just add the option feed: true in index.qmd\n\n!cat ../index.qmd | grep --color=always -z 'feed: true'\n\n---\ntitle: \"blog\"\nlisting:\n  contents: posts\n  sort: \"date desc\"\n  type: default\n  categories: true\n  sort-ui: false\n  filter-ui: true\n  feed: true\npage-layout: full\ntitle-block-banner: false\n---\n\n\n\n\n\nAnd here is the result in Feedly\n\n\n\n\nto be improved\n\nno icon in feedly for this feed (I would like it to use my favicon)\nwhen publishing an update on article, create new entry in rss feed"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#tbd-detect-broken-links",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#tbd-detect-broken-links",
    "title": "Blog - migrate to quarto",
    "section": "(tbd) detect broken links",
    "text": "(tbd) detect broken links\nGuillaume’s blog - Logbook for October 22\n\nAnd have to figure out a way to detect broken links:\n\nusing google search console\n\nAs it takes a day to be processed I will test again tomorrow"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#change-theme-and-allow-lightdark-mode",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#change-theme-and-allow-lightdark-mode",
    "title": "Blog - migrate to quarto",
    "section": "change theme and allow light/dark mode",
    "text": "change theme and allow light/dark mode\n\n!cat ../_quarto.yml | grep -A2 theme\n\n    theme: \n      light: journal\n      dark: darkly\n\n\nAnd to have a light banner in the landing page\n\n!cat ../index.qmd | grep banner\n\ntitle-block-banner: false"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#tbd-fix-latex-expressions",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#tbd-fix-latex-expressions",
    "title": "Blog - migrate to quarto",
    "section": "(tbd) fix latex expressions",
    "text": "(tbd) fix latex expressions"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#tbd-google-analytics-on-blog",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#tbd-google-analytics-on-blog",
    "title": "Blog - migrate to quarto",
    "section": "(tbd) google analytics on blog",
    "text": "(tbd) google analytics on blog\nGuillaume’s blog - Logbook for October 22\n\nSetup google analytics, get G- Id, and update _quarto.yml accordingly as explained in quarto doc.\nAnalytics available here"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#tbd-allow-comments",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#tbd-allow-comments",
    "title": "Blog - migrate to quarto",
    "section": "(tbd) allow comments",
    "text": "(tbd) allow comments"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#workaround-quarto-publishing-issue-behind-firewall",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#workaround-quarto-publishing-issue-behind-firewall",
    "title": "Blog - migrate to quarto",
    "section": "[workaround] quarto publishing issue behind firewall",
    "text": "[workaround] quarto publishing issue behind firewall\nIdentical to error happening when installing quarto extension\nhttps://github.com/quarto-ext/video/issues/27\n$ quarto publish\n? Publish update to: › https://castorfou.github.io/blog/ (GitHub Pages)\nFrom https://github.com/castorfou/blog\n * branch            gh-pages   -&gt; FETCH_HEAD\n \norigin  https://github.com/castorfou/blog.git (fetch)\norigin  https://github.com/castorfou/blog.git (push)\nTo https://github.com/castorfou/blog.git\n + 0a3710d...1aeaf23 HEAD -&gt; gh-pages (forced update)\nfatal: 'fadc274b' is not a working tree\n\nNOTE: GitHub Pages sites use caching so you might need to click the refresh\nbutton within your web browser to see changes after deployment.\n\n(\\) Deploying gh-pages branch to website (this may take a few minutes)Sending fatal alert BadCertificate\n[✓] Deploying gh-pages branch to website (this may take a few minutes)\nERROR: TypeError: error sending request for url (https://castorfou.github.io/blog/.nojekyll): error trying to connect: invalid peer certificate contents: invalid peer certificate: UnknownIssuer\nFor context, I use quarto as a replacement of fastai/fastpages and followed a migration guide from Hamel Hussain asking for this installation.\nAnd I’m in a corporate environment with transparent proxies and self signed certificates. My system has updated CERT in /usr/local/share/ca-certificates/, and SSL_CERT_FILE environment variable pointing to updated corporate pem.\n$ quarto install extension quarto-ext/lightbox\nSending fatal alert BadCertificate\nERROR: TypeError: error sending request for url (https://github.com/quarto-ext/lightbox/archive/refs/heads/main.tar.gz): error trying to connect: invalid peer certificate contents: invalid peer certificate: UnknownIssuer\nIt fails with the same message. When I run quarto publish I have the same issue.\nOne option is to use github actions as explained in publication to gh-pages using gh-actions."
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#workaround-inline-images-are-not-properly-rendered",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#workaround-inline-images-are-not-properly-rendered",
    "title": "Blog - migrate to quarto",
    "section": "[workaround] inline images are not properly rendered",
    "text": "[workaround] inline images are not properly rendered\nanalysis made at inline images from jupyter with quarto\nshort answer: use jupyter lab to blog"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#albert-rapp-as-an-example",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#albert-rapp-as-an-example",
    "title": "Blog - migrate to quarto",
    "section": "Albert Rapp as an example",
    "text": "Albert Rapp as an example\nhttps://albert-rapp.de/posts/13_quarto_blog_writing_guide/13_quarto_blog_writing_guide.html"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#workaround-links-are-not-rendered-as-links",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#workaround-links-are-not-rendered-as-links",
    "title": "Blog - migrate to quarto",
    "section": "[workaround] links are not rendered as links",
    "text": "[workaround] links are not rendered as links\nin jupyter, just typing url turns it into a link. Not with quarto: https://castorfou.github.io/blog/\nanyway to do it ?\nhttps://github.com/quarto-dev/quarto-cli/discussions/2609\n\nsuggestions\nFirst one is to surround url with pointy braces ‘&lt;&gt;’\nDoes it work: https://pandoc.org/MANUAL.html#links-1\nAnd better one (?) would be to run pandoc with autolink_bare_uris\nJust modifying _quarto.yml in ( format &gt; html &gt; from ) option\n\n\n\nimage.png\n\n\n\n!cat ../_quarto.yml | grep -B5 autolink\n\n  html:\n    theme: \n      light: journal\n      dark: darkly\n    css: styles.css\n    from: markdown+autolink_bare_uris"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#quarto-updated-to-version-1.2.269",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#quarto-updated-to-version-1.2.269",
    "title": "Blog - migrate to quarto",
    "section": "quarto updated to version 1.2.269",
    "text": "quarto updated to version 1.2.269\n~/temp$ wget https://github.com/quarto-dev/quarto-cli/releases/download/v1.2.269/quarto-1.2.269-linux-amd64.deb\n~/temp$ sudo apt install ./quarto-1.2.269-linux-amd64.deb \n~/temp$ quarto -V\n1.2.269\nI don’t know what is the changelog. Looks like we don’t need to install video extension anymore. (quarto install extension quarto-ext/video)\n~/git/blog$ quarto remove extension quarto-ext/video\nI have started a thread in fastai forum. There are updates with widget states and inline images. Update worth running!"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#move-to-quarto-1.3",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#move-to-quarto-1.3",
    "title": "Blog - migrate to quarto",
    "section": "move to quarto > 1.3",
    "text": "move to quarto &gt; 1.3\nwith quarto 1.3, we have acces to code annotation which is a fancy feature https://quarto.org/docs/prerelease/1.3/code-annotation.html#overview\nand to use it in my blog, I have to switch to quarto pre-release version.\nThis happens in blog/publish.yml\n      - name: Set up Quarto\n        uses: quarto-dev/quarto-actions/setup@v2\n        with:\n          version: 'pre-release'"
  },
  {
    "objectID": "posts/2022-09-16-migrate blog from nbdev to quarto.html#bug-error-file-name-too-long-os-error-36-when-rendering-with-v1.3.242",
    "href": "posts/2022-09-16-migrate blog from nbdev to quarto.html#bug-error-file-name-too-long-os-error-36-when-rendering-with-v1.3.242",
    "title": "Blog - migrate to quarto",
    "section": "[bug] ERROR: File name too long (os error 36), when rendering with v1.3.242",
    "text": "[bug] ERROR: File name too long (os error 36), when rendering with v1.3.242\nMar-03 23\nJust opened this https://github.com/quarto-dev/quarto-cli/issues/4613\nand to fix it I moved back to stable quarto version (removed pre-release version from publish.yml)\nit uses quarto 1.2.335"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html",
    "title": "Live coding sessions from fastai",
    "section": "",
    "text": "From time to time, Jeremy organizes live coding session.\nThey are recorded (~1h each) and he takes one subject, and tackle it. They seem to be for beginners. But I am quite sure I can get some tips that I will write down on this page.\n18 sessions so far (jan-23):\nLive-coding (aka walk-thrus) ✅ - Part 1 2022 - fast.ai Course Forums"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#start-from-a-fresh-user-in-wsl",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#start-from-a-fresh-user-in-wsl",
    "title": "Live coding sessions from fastai",
    "section": "start from a fresh user in WSL",
    "text": "start from a fresh user in WSL\nI try things with a complete fresh new user fastai in WSL\nsudo adduser --gecos \"\" fastai\nsudo usermod -aG sudo,adm fastai\nsu - fastai\n\n!id fastai\n\nuid=1001(fastai) gid=1001(fastai) groups=1001(fastai),4(adm),27(sudo)\n\n\nif needed, completey delete user and home directory\nsudo userdel -rfRZ fastai\n\nand setup things for this new user\n\nX apps\nTo launch X apps\npushd ~\ntee -a .bashrc &lt;&lt; EOF\nexport DISPLAY=\":0\"\nEOF\npopd\nAlias terminal explorer (nautilus)\npushd ~\ntee -a .bash_aliases &lt;&lt; EOF\nalias terminal='dbus-launch gnome-terminal &'\nalias explorer='dbus-launch nautilus &'\nEOF\npopd\nTake it into account\npushd ~\nsource .bashrc\npopd\nUpdate Ctrl-C Ctrl-V keybindings in gnome-terminal\n\n\n\nimage.png\n\n\n\n\nSSL, CA, SSH setups\nTo avoid “unsafe legacy renegotiation disabled” (linked to my corporate network architecture)\nand “SSL peer certificate or SSH remote key was not OK”\npushd ~\ntee -a .bashrc &lt;&lt; EOF\nexport OPENSSL_CONF=/etc/ssl/openssl.cnf\nexport REQUESTS_CA_BUNDLE=/etc/ssl/certs/ca-certificates.crt\nEOF\nsource .bashrc\npopd\nTo connect to gitlab\nNot the smartest way to do it but I copy ssh keys from my main user\nsudo bash -c \"cp ~guillaume/.ssh/id_rsa* ~fastai/.ssh/\"\nsudo bash -c \"chown fastai:fastai ~fastai/.ssh/*\""
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#install-python-distribution---mambaforge-the-manual-way",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#install-python-distribution---mambaforge-the-manual-way",
    "title": "Live coding sessions from fastai",
    "section": "install python distribution - mambaforge | the manual way",
    "text": "install python distribution - mambaforge | the manual way\nThis is from https://github.com/conda-forge/miniforge#mambaforge\nMambaforge is miniforge but with mamba already setup.\npushd ~/downloads\nbash Mambaforge-Linux-x86_64.sh\npopd\nAnd to this question &gt; Do you wish the installer to initialize Mambaforge by running conda init? [yes|no]\nWe answer Yes, and then\n\n==&gt; For changes to take effect, close and re-open your current shell. &lt;==\n\nJeremy hates to not automate things you could have to do several times.\nTo do it we revert everything done here manually (including conda-init in .bashrc)"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#about-python-version",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#about-python-version",
    "title": "Live coding sessions from fastai",
    "section": "about python version",
    "text": "about python version\nby searching for python eol, you fall into https://endoflife.date/python\n\n\n\nimage.png\n\n\nand recommandation from Jeremy is to take penultimate one. It looks like ot is what is followed by mambaforge"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#install-python-distribution---mambaforge-the-automated-way",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#install-python-distribution---mambaforge-the-automated-way",
    "title": "Live coding sessions from fastai",
    "section": "install python distribution - mambaforge | the automated way",
    "text": "install python distribution - mambaforge | the automated way\nIt is at https://github.com/fastai/fastsetup\nIt is Jeremy’s repo that contains anything he uses to setup a new computer\nThere is a thing called setup-conda.sh\nwget --no-check-certificate --content-disposition -O - https://raw.githubusercontent.com/fastai/fastsetup/master/setup-conda.sh | bash\nand run mamba init to allow mamba activate"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#and-then-activate-self-certificates-into-ca",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#and-then-activate-self-certificates-into-ca",
    "title": "Live coding sessions from fastai",
    "section": "and then activate self-certificates into CA",
    "text": "and then activate self-certificates into CA\nSetup pip, instal certifi and update CA\npushd ~\n# setup pip\nmkdir -p ~/.config/pip\ntee ~/.config/pip/pip.conf &lt;&lt; EOF\n[global]\ntimeout = 1000\nindex-url = https://pypi.org/simple/\ntrusted-host = download.pytorch.org\n               pypi.python.org\n               files.pythonhosted.org\n               pypi.org\n               artifactory.michelin.com\nextra-index-url= https://artifactory.michelin.com/api/pypi/pypi/simple\nEOF\n# install certifi\npip install -U certifi\nexport SSL_CERT_FILE=`python -c 'import certifi;print(certifi.where())'`\n# update CA\nexport TMPDIR=`mktemp -d`\ngit clone git@gitlab.michelin.com:DEV/bib-certificates.git $TMPDIR\ncd $TMPDIR\ncat *trust-ca.pem &gt;&gt; $SSL_CERT_FILE\ncd\n# export SSL_CERT_FILE\ntee -a ~/.bashrc &lt;&lt; EOF\nexport SSL_CERT_FILE=`python -c 'import certifi;print(certifi.where())'`\nexport REQUESTS_CA_BUNDLE=`python -c 'import certifi;print(certifi.where())'`\nEOF\nsource ~/.bashrc\npopd"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#install-packages-in-base",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#install-packages-in-base",
    "title": "Live coding sessions from fastai",
    "section": "install packages in base",
    "text": "install packages in base\n\nipython\nmamba install ipython\nHere Jeremy mentionned that Wes McKinney, author of “Python for Data Analysis” does much much things in ipython.\nAnd this is worthy to be read\n\n\n\nimage.png\n\n\n\n\npytorch\nLet’s install pytorch (searching pytorch install) https://pytorch.org/get-started/locally/\n\n\n\nimage.png\n\n\nmamba install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\nfrom ipython we can test\nIn [2]: torch.cuda.get_device_name()\nOut[2]: 'NVIDIA GeForce RTX 3080 Laptop GPU'\n\n\njupyter\nLet’s install jupyter (searching jupyter lab install) https://jupyterlab.readthedocs.io/en/stable/getting_started/installation.html\nBecause we use mamba, conda-forge channel is the default so\nmamba install jupyterlab\nAnd we can test by running it jupyter lab\nBecause I have firefox installed in WSL, I don’t have the same issue Jeremy mentionned. And because I have another instance of jupyter running under my main user (where I blog this), it opens on port 8889\n\n\n\nimage.png\n\n\n\n\nipywidgets\nmamba install ipywidgets"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#end-of-session---wrap-up",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#end-of-session---wrap-up",
    "title": "Live coding sessions from fastai",
    "section": "End of session - wrap-up",
    "text": "End of session - wrap-up\nThis was the base environnement setup after installing mambaforge\nconda_env/base.txt\npip install -U certifi\nexport SSL_CERT_FILE=`python -c 'import certifi;print(certifi.where())'`\n# update CA\nexport TMPDIR=`mktemp -d`\ngit clone git@gitlab.michelin.com:DEV/bib-certificates.git $TMPDIR\npushd $TMPDIR\ncat *trust-ca.pem &gt;&gt; $SSL_CERT_FILE\npopd\n\nmamba install ipython\n\nmamba install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\n\nmamba install jupyterlab ipywidgets\nStarting from this fresh install, let’s retest stable diffusion and my issues on WSL:\nmamba create --name fastai_diffusers --clone base\nmamba activate fastai_diffusers\npip install -Uq diffusers transformers fastcore\nmamba install matplotlib\ncd ~/nbs\ngit clone https://github.com/fastai/diffusion-nbs.git\njupyter lab\nand open/run stable_diffusion.ipynb\nbut this is not better (still on cuda 1.7, this is maybe why)\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#tmux",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#tmux",
    "title": "Live coding sessions from fastai",
    "section": "tmux",
    "text": "tmux\nThis is a little bit as screen\ninstallation\nsudo snap install tmux --classic\nusage\njust run tmux to start a new window.\nFrom here you have special commands, starting with binding key (default is Ctrl-b)\nStart a new pan (vertical split): C-b %\nStart a new pan (horizontal split): C-b \"\nClose a pan: C-d\nNavigate through pans: C-b arrow keys\nZoom-in zoom-out: C-b z\nDetach window: C-b d\nNavigate in scrillback buffer: C-b [ then arrow keys, pg-up, pg-down\nRe-attach window: tmux a\n\n\n\nimage.png"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#jupyter-shortcuts",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#jupyter-shortcuts",
    "title": "Live coding sessions from fastai",
    "section": "jupyter shortcuts",
    "text": "jupyter shortcuts\nin command mode\n1 - for titles # (if in code, it auto switches to markdown)\n2 - for titles ##\n3 - for titles ###\ny to switch to code cells (much used to m for markdown)"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#install-fastai",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#install-fastai",
    "title": "Live coding sessions from fastai",
    "section": "install fastai",
    "text": "install fastai\nfrom https://docs.fast.ai/\nmamba install -c fastchan fastai"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#run-fastbook-notebooks",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#run-fastbook-notebooks",
    "title": "Live coding sessions from fastai",
    "section": "run fastbook notebooks",
    "text": "run fastbook notebooks\nAnd to run notebooks from fastbook, we have to install fastbook and sentencepiece as well\n\nuntar_data issues\npath = untar_data(URLs.MNIST_SAMPLE) fails with &gt; [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:997)\nnot exactly why because my certifi/certs are updated with my corporate CA\nAnd if I workaround with this preceeding\nimport ssl\nssl._create_default_https_context = ssl._create_unverified_context\nI have another error which is MICHELIN GROUP - Internet Access blocked&lt;/h1&gt;&lt;br&gt;Access denied. You are attempting to access the Internet using an obsolete version of Chrome.\nLooking in fastai code, I see something like https://github.com/fastai/fastai2/blob/master/fastai2/data/external.py#L162 s.headers.update({'User-Agent': 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:71.0) Gecko/20100101 Firefox/71.0'})\nIs it that user-agent is old and considered as dangerous by security agent in my company?"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#end-of-session---wrap-up-1",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#end-of-session---wrap-up-1",
    "title": "Live coding sessions from fastai",
    "section": "End of session - wrap-up",
    "text": "End of session - wrap-up\nShould defintely solve the issue with untar_data\nAnd at the end of this session, my base environment has been built this way\npip install -U certifi\nexport SSL_CERT_FILE=`python -c 'import certifi;print(certifi.where())'`\n# update CA\nexport TMPDIR=`mktemp -d`\ngit clone git@gitlab.michelin.com:DEV/bib-certificates.git $TMPDIR\ncd $TMPDIR\ncat *trust-ca.pem &gt;&gt; $SSL_CERT_FILE\ncd\n\nmamba install ipython\n\nmamba install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia\n\nmamba install jupyterlab ipywidgets\n\nmamba install -c fastchan fastai fastbook sentencepiece"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#paperspace-gradient-notebooks",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#paperspace-gradient-notebooks",
    "title": "Live coding sessions from fastai",
    "section": "paperspace gradient notebooks",
    "text": "paperspace gradient notebooks\nI use github to sign-up on paperspace. And create a project, then a notebook (actually a server?)\nhttps://console.paperspace.com/teox6gpp0/projects/pa3mp7r16wz/notebooks"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#graphical-debugger-in-jupyter-lab",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#graphical-debugger-in-jupyter-lab",
    "title": "Live coding sessions from fastai",
    "section": "graphical debugger in jupyter lab",
    "text": "graphical debugger in jupyter lab\n\n\n\nimage.png\n\n\none can see the limit of from xxx import *, you will have the full variables in this window."
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#classic-non-graphical-debugger",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#classic-non-graphical-debugger",
    "title": "Live coding sessions from fastai",
    "section": "classic, non-graphical debugger",
    "text": "classic, non-graphical debugger\nJust by adding %%debug\nand for a reason it works better when you navigate into a function\n\n\n\nimage.png\n\n\nAnd have access to classic ipdb options\nhfor help\nc for continue\nn for next\np for print\nsfor step into\nqfor quit\nor a second way:\n\nfrom pdb import set_trace\n\ndef f():\n    for i in range(3):\n        set_trace()\n        print(i)\n\n\nf()\n\n&gt; /tmp/ipykernel_1682/972468431.py(6)f()\n      2 \n      3 def f():\n      4     for i in range(3):\n      5         set_trace()\n----&gt; 6         print(i)\n\n0\n\n\nipdb&gt;  p i\nipdb&gt;  q"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#persistent-storage-in-paperspace",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#persistent-storage-in-paperspace",
    "title": "Live coding sessions from fastai",
    "section": "persistent storage in paperspace",
    "text": "persistent storage in paperspace\n/storage is following you on all your servers.\nTo keep a consistent environment each time you start a paperspace server, Jeremy is following this process:\n\ninstall additional lib with pip --user. e.g. pip install -U fastcore --user. It will install libs in ~/.local\nmove .local to /storage: mv ~/.local /storage\nsymbolic link back from /storage/.local to ~/.local: ln -s /storage/.local ~/\n\nThis has to be done once.\nAnd because paperspace has this nifty thing to call /storage/.bash.local at the start of a session, you can automate things here.\n\n\n\nimage.png\n\n\nActually it may be smarter to include this into /storage/pre-run.sh and not /storage/.bash.local. First one is run once at the start of your server. The last one is run each time you open a terminal"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#sys.path",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#sys.path",
    "title": "Live coding sessions from fastai",
    "section": "sys.path",
    "text": "sys.path\nJeremy gets some issue because site-packages was not part of sys.path…\n\nimport sys\n\nsys.path\n\n['/mnt/c/Users/f279814/git/blog/posts',\n '/home/guillaume/miniconda/envs/fastai/lib/python310.zip',\n '/home/guillaume/miniconda/envs/fastai/lib/python3.10',\n '/home/guillaume/miniconda/envs/fastai/lib/python3.10/lib-dynload',\n '',\n '/home/guillaume/miniconda/envs/fastai/lib/python3.10/site-packages']"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#optimised-config-for-paperspace",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#optimised-config-for-paperspace",
    "title": "Live coding sessions from fastai",
    "section": "optimised config for paperspace",
    "text": "optimised config for paperspace\nEssentially Jeremy has been improving his paperspace configuration\nbased on paperspace special configuration where\n\n/storage is linked to your account (and maybe to your organization account) and will follow you under all your servers (notebooks in paperspace), and\n/notebooks is linked to your server (notebook) and will follow you for this server, whatever is the machine you decide to attach to it.\n\nJeremy setups .local, .ssh, and then move that to /storage, create symlinks.\nI am less interested by that one, watched at x2 speed…"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#vim",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#vim",
    "title": "Live coding sessions from fastai",
    "section": "vim",
    "text": "vim\noverview on vim. Nothing new here, except for learning resources\n\nhttps://www.openvim.com/ that I didn’t know, and\nvimtutor as well\nhttps://vim-adventures.com/ which is a kind of game\n\n\n\n\nimage.png\n\n\nJeremy’s vim config file is at https://github.com/fastai/dotfiles/blob/master/.vimrc"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#ctags",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#ctags",
    "title": "Live coding sessions from fastai",
    "section": "ctags",
    "text": "ctags\nusing a clone of fastai to illustrate, and Jeremy used an option to clone without the full depth which is much much quicker\ngit clone https://github.com/fastai/fastai.git --depth 1\n1st thing is to install universal-ctags:\n\none option is to use snap: sudo snap install universal-ctags. It is what I used but Jeremy doesn’t lik snap (why?)\n2nd one is mamba: mamba install universal-ctags\n\nAnd now we can\ncd ~/git/fastai/fastai\nctags -R .\n#we can look into tags file with all symbols being used in this repo\nless tags\n\n#jump to a tag ArrayMask\nvim -t ArrayMask\n\n#open a file\nvim layers.py\n#enter tag to jump to (tj: tag jump)\n#enter just the 1st letters and press enter, it will suggest matching cases\n#e.g. Array\n:tj Array\n# or from code itself, if cursor is on a word, to get to its tag\nCtrl-]\n#e.g. cursor on Module, Ctrl-]\nclass View(Module):\n# will jump to torch_core.py\nclass Module(nn.Module, metaclass=PrePostInitMeta):\n# to get back to previous tag\nCtrl-t\nWe can create a ctags config file to ignore locations such as .pynb_checkpoints…\n# we can use stag (split tag)\n:stag DataL &lt;enter&gt;\n# it will split the screen in 2 parts"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#paperspace-and-ctags-and-other-stuff",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#paperspace-and-ctags-and-other-stuff",
    "title": "Live coding sessions from fastai",
    "section": "paperspace and ctags and other stuff",
    "text": "paperspace and ctags and other stuff\nOne option is to install in a specific directory using mamba\nmamba -p ~/conda install universal-ctags, and to move ~/conda to /storage, and link symlinks within /storage/.bash.local"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#use-paperspace-with-fastbook",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#use-paperspace-with-fastbook",
    "title": "Live coding sessions from fastai",
    "section": "use paperspace with fastbook",
    "text": "use paperspace with fastbook\nSteps to setup paperspace:\n\nupload ssh keys for github to paperspace /storage/cfg/.ssh (be sure to copy a key declared to github (yes double check that) and chmod 600 your private key)\ngit clone https://github.com/fastai/paperspace-setup.git in /notebooks\ncd paperspace-setup\n./setup.sh\nShutdown your machine and start up a new one\n\nFork fastbook\n\nsource ~/.bashrc # don’t know why it is not done automatically\ngit clone git@github.com:castorfou/fastbook.git in /notebooks\n\nAnd now we can run notebooks from /fastbook/clean e.g. 01_intro.ipynb\n\n\n\nimage.png\n\n\nJeremy dives into what happens here:\n\nfrom xxx import *: and link to all.py\nto break down cells into splitted cells (with one command per cell) using key shortcut: Ctrl-Shift -"
  },
  {
    "objectID": "posts/2023-01-25-fastai-live-coding-sessions.html#kaggle-competition",
    "href": "posts/2023-01-25-fastai-live-coding-sessions.html#kaggle-competition",
    "title": "Live coding sessions from fastai",
    "section": "kaggle competition",
    "text": "kaggle competition\nIt starts with an overview of different types of Kaggle competitions (kudos, knowledge, …, money) and going through a competition as suggested by Radek.\nTo follow I will switch to my fastai user, install kaggle into base environment. (pip install kaggle)\nGet kaggle json from kaggle website. Account &gt; API &gt; Create New API Token\nYou get\n\nEnsure kaggle.json is in the location ~/.kaggle/kaggle.json to use the API.\n\nSo download, copy (using upload in jupyter lab), move in right location, change owner and chmod 600\nAnd I can download paddy dataset with\ncd ~/nbs/kaggle/paddy\nkaggle competitions download -c paddy-disease-classification\nUnzip and then look at directory structure, number of files\nfind . -type d -print0 | \nwhile read -d '' -r dir; do     \n    files=(\"$dir\"/*);     \n    printf \"%5d files in directory %s\\n\" \"${#files[@]}\" \"$dir\"; \ndone\n\n    5 files in directory .\n 3469 files in directory ./test_images\n   10 files in directory ./train_images\n  380 files in directory ./train_images/bacterial_leaf_streak\n 1088 files in directory ./train_images/tungro\n  965 files in directory ./train_images/brown_spot\n 1442 files in directory ./train_images/dead_heart\n 1594 files in directory ./train_images/hispa\n 1764 files in directory ./train_images/normal\n  620 files in directory ./train_images/downy_mildew\n  337 files in directory ./train_images/bacterial_panicle_blight\n 1738 files in directory ./train_images/blast\n  479 files in directory ./train_images/bacterial_leaf_blight\nAnd then we can start to work on it.\n\nfrom fastai.vision.all import *\n\nPath.BASE_PATH = path = Path.home()/'git'/'kaggle'/'paddy'\n\npath.ls()\n\n(#5) [Path('paddy-disease-classification.zip'),Path('sample_submission.csv'),Path('test_images'),Path('train.csv'),Path('train_images')]\n\n\nPath is neat. Define this BASE_PATH to simplify ls() output.\nHad to insert\nimport ssl\nssl._create_default_https_context = ssl._create_unverified_context\nto be able to download resnet34\nFor a reason, surely the same issue as I got with diffusion model, my kernel dies when training\n\n\n\nimage.png\n\n\nAnd Jeremy shares some tip about nvidia-smi. He suggests to use nvidia-smi dmon instead of watch nvidia-smi (and monitor sm column and see if io allow it to be high enough)\nRunning it in vscode, I have more information\n\n\n\nimage.png\n\n\nCould not load library libcudnn_cnn_infer.so.8. Error: libcuda.so: cannot open shared object file: No such file or directory\nAnd to fix it, quite easy\nadd this to .bashrc\n\nexport LD_LIBRARY_PATH=/usr/lib/wsl/lib"
  },
  {
    "objectID": "posts/2020-10-01-fingerprint-authentication-sudoers.html",
    "href": "posts/2020-10-01-fingerprint-authentication-sudoers.html",
    "title": "Use fingerprint to authenticate on Ubuntu, and passwordless on some apps",
    "section": "",
    "text": "Fingerprint authentication\n\n\n\nalt text\n\n\nJust by activating Fingerprint login, quite surprisingly it has been working directly.\n\n\nPasswordless commands\nBecause I have changed my password for a quite complex one, I am interested to launch some sudo commands without prompt of password.\nHow to run sudo commands without password\nUse visudo to update /etc/sudoers. I understand there is some syntax check to avoid mistake when editing this file. You don’t want to be left with a defective sudo system.\nI have just added this line. explore is my username. I can add additional commands after a comma (e.g. /bin/systemctl restart httpd.service, /bin/kill)\nexplore ALL = NOPASSWD: /usr/bin/apt"
  },
  {
    "objectID": "posts/2021-06-01-logbook-June.html",
    "href": "posts/2021-06-01-logbook-June.html",
    "title": "Logbook for June 21",
    "section": "",
    "text": "Tuesday 6/1\nMachine learning in python with scikit-learn end of module 3. Hyperparameter tuning\nReinforcement Learning Specialization - C2W3 - Temporal Difference for Control - start\nWednesday 6/2\nSHAP: An introduction to explainable AI with Shapley values, Be careful when interpreting predictive models in search of causal insights\nMachine learning in python with scikit-learn module 4. Linear models\nThursday 6/3\nTalk (30’) from Michael Bronstein on Geometric Deep Learning - permutations invariant is a domain research I could use\nMachine learning in python with scikit-learn end of module 4. Linear models\nFriday 6/4\nReinforcement Learning Specialization - C2W4 - Planning, Learning and Acting\nEnd of course 2 of Reinforcement Learning Specialization"
  },
  {
    "objectID": "posts/2021-06-01-logbook-June.html#week-22---june-21",
    "href": "posts/2021-06-01-logbook-June.html#week-22---june-21",
    "title": "Logbook for June 21",
    "section": "",
    "text": "Tuesday 6/1\nMachine learning in python with scikit-learn end of module 3. Hyperparameter tuning\nReinforcement Learning Specialization - C2W3 - Temporal Difference for Control - start\nWednesday 6/2\nSHAP: An introduction to explainable AI with Shapley values, Be careful when interpreting predictive models in search of causal insights\nMachine learning in python with scikit-learn module 4. Linear models\nThursday 6/3\nTalk (30’) from Michael Bronstein on Geometric Deep Learning - permutations invariant is a domain research I could use\nMachine learning in python with scikit-learn end of module 4. Linear models\nFriday 6/4\nReinforcement Learning Specialization - C2W4 - Planning, Learning and Acting\nEnd of course 2 of Reinforcement Learning Specialization"
  },
  {
    "objectID": "posts/2021-06-01-logbook-June.html#week-23---june-21",
    "href": "posts/2021-06-01-logbook-June.html#week-23---june-21",
    "title": "Logbook for June 21",
    "section": "Week 23 - June 21",
    "text": "Week 23 - June 21\nMonday 6/7\nReinforcement Learning Specialization - C3W1 - On-policy Prediction with Approximation\nThursday 6/10\nReinforcement Learning Specialization - C3W2 - Constructing Features for Prediction\nFriday 6/11\nMachine learning in python with scikit-learn module 5. Decision tree models\nReinforcement Learning Specialization - C3W3 - Control with Approximation"
  },
  {
    "objectID": "posts/2021-06-01-logbook-June.html#week-24---june-21",
    "href": "posts/2021-06-01-logbook-June.html#week-24---june-21",
    "title": "Logbook for June 21",
    "section": "Week 24 - June 21",
    "text": "Week 24 - June 21\nMonday 6/14\nReinforcement Learning Specialization - C3W4 - Policy Gradient\nReinforcement Learning Specialization - C4W1 - start of course 4. A Complete Reinforcement Learning System (Capstone) - week 1 to week 4\nWednesday 6/16\nReinforcement Learning Specialization - C4W4 - Milestone 3: Identify Key Performance Parameters, C4W5 - Milestone 4: Implement your agent\nThursday 6/17\nReinforcement Learning Specialization - end of C4W5 - Milestone 4: Implement your agent\nFriday 6/18\nReinforcement Learning Specialization - C4W6 - Milestone 5: Submit your Parameter Study!\nEnd of Specialization"
  },
  {
    "objectID": "posts/2021-06-01-logbook-June.html#week-25---june-21",
    "href": "posts/2021-06-01-logbook-June.html#week-25---june-21",
    "title": "Logbook for June 21",
    "section": "Week 25 - June 21",
    "text": "Week 25 - June 21\nMonday 6/21\nMachine learning in python with scikit-learn module 6. Ensemble of models\nRL Course by David Silver Integrating learning and planning (lecture 8)\nThursday 6/24\nMachine learning in python with scikit-learn module 7. Evaluating model performance -End of this course"
  },
  {
    "objectID": "posts/2021-06-01-logbook-June.html#week-26---june-21",
    "href": "posts/2021-06-01-logbook-June.html#week-26---june-21",
    "title": "Logbook for June 21",
    "section": "Week 26 - June 21",
    "text": "Week 26 - June 21\nMonday 6/28\nAI Tech watchfulness in Manufacturing using Arxiv Sanity Presever\nPaper reviewed on arxiv about local post-hoc explanations for predictive process monitoring in manufacturing. arXiv:2009.10513v2. SHAP, ICE and why this approach makes sense in manufacturing domains.\nWednesday 6/30\nSurvey Paper reviewed on Journal of Manufacturing Systems about Deep learning for smart manufacturing: Methods and applications. j.jmsy.2018.01.003. Review use of deep learning algorithms: CNN, RBM, auto encoders, RNN and applications for smart manufacturing: quality inspection, fault assessment, defect prognosis (RUL). Unfortunately prescriptive usage are missing. Points to multiple references origins of these algorithms and applications. Great survey paper!"
  },
  {
    "objectID": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html",
    "href": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html",
    "title": "Learning: College de France - Representations parcimonieuses",
    "section": "",
    "text": "Un exposé en 8 cours au collège de France de Stéphane Mallat sur les représentations parcimonieuses - 2021.\nCela donne envie d’aller voir ses autres cours:\nA peu près 16 vidéos de 1h30 par cours. Et des notes de cours en pdf."
  },
  {
    "objectID": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#le-triangle-régularité-approximation-parcimonie-lecture-1",
    "href": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#le-triangle-régularité-approximation-parcimonie-lecture-1",
    "title": "Learning: College de France - Representations parcimonieuses",
    "section": "2/15/21 - Le triangle « Régularité, Approximation, Parcimonie » (lecture 1)",
    "text": "2/15/21 - Le triangle « Régularité, Approximation, Parcimonie » (lecture 1)\nC’est l’introduction du cours. J’apprécie les références historiques et philosphiques partant du rasoir d’Ockam. C’est le principe d’économie ou de parcimonie: le beau, le vrai viendrait du simple.\nLa 1ere fois que j’entends une référence précise sur l’opposition entre biais (erreur sur modèle) et variance (erreur sur données ou mesures)\nEt une invitation à consulter une méthodologie d’analyse de données par Pierre Courtiol en utilisant Kaggle. L’idée d’une approche simple linéaire pour bien comprendre quelles étapes successives à emprunter pour améliorer son approche. Me semble assez orthogonal à ce que peut proposer Jeremy Howard: commencer tôt, overfitting n’est pas un probleme, pas de early stopping, etc."
  },
  {
    "objectID": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#approximations-linéaires-et-analyse-de-fourier-lecture-2",
    "href": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#approximations-linéaires-et-analyse-de-fourier-lecture-2",
    "title": "Learning: College de France - Representations parcimonieuses",
    "section": "2/10/21 - Approximations linéaires et analyse de Fourier (lecture 2)",
    "text": "2/10/21 - Approximations linéaires et analyse de Fourier (lecture 2)\nJ’ai commencé par ce cours conseillé par Rémi mon pote enseignant chercheur en math. C’est un peu le grand écart avec des méthodes d’enseignement anglo-saxonnes mais ça fait du bien. C’est finalement plus proche de ce que j’ai connu dans ma formation initiale.\nS.Mallat présente les équivalences (sous certaines conditions) entre\n\nRégularité\nApproximation en basse dimension\net représentation parcimonieuse\n\ndans le cadre des approximations linéaires. Il parle des 2 mondes: traitement du signal et analyse de la donnée. Je suis moins intéressé par le 1er monde, mais j’apprécie la piqure de rappel. Je ne me rappelais pas du tout l’importance de l’analyse de Fourier et la construction des bases de L[0,1] par exemple.\nEt il revient sur les singularités, beaucoup d’informations sont portées par les singularités (par exemple les frontières dans une image)\nJe crois bien que je vais me faire toute la session, et sans doute les autres années."
  },
  {
    "objectID": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#grande-dimension-et-composantes-principales-lecture-3",
    "href": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#grande-dimension-et-composantes-principales-lecture-3",
    "title": "Learning: College de France - Representations parcimonieuses",
    "section": "2/23/21 - Grande dimension et composantes principales (lecture 3)",
    "text": "2/23/21 - Grande dimension et composantes principales (lecture 3)\nDans ce cadre linéaire grande dimension, quelle meilleure base - approche PCA et base Karhunen-Loeve.\nQuid quand on passe en non linéaire.\nRéseau neurone à 1 couche cachée, théoreme de representation universel.\nRetour sur les bases de L²[0,1] qui sont les bases de Fourier en variables complexes.\nPour un passage en dimension q, on remplace n par (n1, …, nq) et la multiplication n*u par le produit scalaire &lt;n, u&gt;.\nEn travaillant sur les équivalences du triangle, il montre pourquoi on est très limité en approximation lineaire quand la dimension augmente.\nEn approximation lineaire, il suffit de prendre les 1ers vecteurs (se limiter à une dimension q) (en base de fourier par exemple) pour avoir une assez bonne approximation. Dans des signaux plus perturbés (avec des singularités) on perd plus d’énergie: il faudrait échantilloner plus fin dans ces zones de singularités et si on dispose d’une base orthonormée il s’agirait non plus de prendre les q 1ers vecteurs mais de prendre ceux d’intéret."
  },
  {
    "objectID": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#approximations-non-linéaires-et-réseaux-de-neurones-lecture-4",
    "href": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#approximations-non-linéaires-et-réseaux-de-neurones-lecture-4",
    "title": "Learning: College de France - Representations parcimonieuses",
    "section": "3/2/21 - Approximations non linéaires et réseaux de neurones (lecture 4)",
    "text": "3/2/21 - Approximations non linéaires et réseaux de neurones (lecture 4)\nLe triangle (approximation basse dimensions, représentation parcimonieuse, régularité) d’un point de vue non linéaire.\nIci plutôt qu’approximer un signal en prenant les M 1ers coefficients de Fourier (basses dimensions), on va prendre M coefficients mais dépendamment de x. C’est ici qu’on introduit la non-linéarité. L’erreur est alors la queue de distribution des coefficients ordonnés. On veut que l’énergie des plus petits coefficients soit négligeable.\nPas facile d’obtenir cet ordre, on cherche une façon de limiter les coefficients non ordonnés nous donnant une représentation parcimonieuse. En utilisant la nome l\\(\\alpha\\) avec \\[\\alpha\\] petit (inférieur à 2 et proche de 0), on introduit cette décroissance mais cette fois-ci sur les coefficients non ordonnés.\nIntéressant d’avoir des normes convexes, et dans ce cas on ne peut prendre que \\[\\alpha\\]=1. C’est pour ça qu’on voit apparaître partout les normes l1 dans les algorithmes d’apprentissage (norme convexe garantissant une forme de sparsité).\nOn passe aux réseaux de neurones à 1 couche cachée. Et on va basculer dans les notations de x(u) à f(x)., avec x \\[\\epsilon\\] [0, 1]d.\n\nIci on projette f dans l’espace engendré par ces vecteurs { \\[\\rho\\](x.wm+bm) }n&lt;=M.\nOn peut facilement calculer l’erreur quadratique comme l’intégrale sur les x \\[\\epsilon\\] [0, 1]d de la norme l² ( f(x)-ftilde(x) ) et il y a un belle démonstration qui est le théorème d’approximation universelle (démontrée entre 1988 et 1992) qui montre que l’erreur tend vers 0 quand M tend vers l’infini.\nLa démonstration avec \\[\\rho\\] = eia revient à une décomposition d’en Fourier. Et pour d’autres non régularité comme reLu ou sigmoid, il s’agit d’un changement de base.\nEt là on arrive à la malédiction de la dimensionnalité car quand d est grand (disons 1M), les coefficients baissent à une faible vitesse. Que faut-il faire pour battre cette malédiction?\nBaron en 1993 introduit une hypothèse de regularité qui permet de borner l’erreur par un terme qui ne dépend pas de la dimension. C’est donc gagné sauf que l’hypothèse de régularité n’est généralement pas valide dans les cas qui nous intéressent.\nStéphane Mallat, de façon brillante mais est-ce étonnant, explique pourquoi l’approche des mathématiciens est une impasse et pourquoi ce qu’on cherche à faire se ramène à un problème bayésien. Car les problèmes qui nous intéressent (par exemple la classification d’objets, ne va solliciter qu’un minuscule espace (même si de grande dimension) parmi toutes les images possibles). On va donc chercher à caractériser x pour chaque y (classe). (revoir vidéo entre 49’ et 1h03)\nL’enjeu est de caractériser le support qui est beaucoup plus concentré que [0,1]d.\nDonc on va retravailler sur les approximations non linéaires de x, le signal lui-même (et non plus f), et d’essayer de comprendre pourquoi on peut faire beaucoup mieux que la transformée de Fourier et quelle genre de bases vont nous permettre de faire bcp mieux. Une des applications va être la compression, qui va nous amener à étudier la théorie de l’information et la théorie de l’information c’est exactement la théorie probabiliste qui explique ces phénomènes de concentration et les mesure avec l’entropie.\nIntroduction des bases d’ondelettes qui vont permettre de représenter les singularités locales. Les ondelettes sont à la fois localisées (paramètre v) et dilatées (paramètre s). Il faudra à partir de ces ondelettes construire des bases orthogonales pour arriver à des approximations basses dimensions (et garder les grands coefficients)\nOn introduit la notion de régularité locale exprimée avec lipchitz \\[\\alpha\\]. Avec \\[\\alpha\\] &lt;1 pour exprimer les singularités."
  },
  {
    "objectID": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#ondelettes-et-échantillonnage-lecture-5",
    "href": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#ondelettes-et-échantillonnage-lecture-5",
    "title": "Learning: College de France - Representations parcimonieuses",
    "section": "3/9/21 - Ondelettes et échantillonnage (lecture 5)",
    "text": "3/9/21 - Ondelettes et échantillonnage (lecture 5)\nOn était resté sur une représentation de signaux qui ne présentent pas de régularité uniforme mais qui présentent des singularités que nous voulons capter, ces singularités étant porteuses d’informations importantes (par exemple les contours dans une image). Ces singularités n’étant pas très nombreuses, on peut toujours parler de régularité locale.\nOn va donc utiliser des ondelettes pour décomposer ces signaux, d’où la notion de représentation parcimonieuse, exprimée sur la base d’ondelettes orthonormales. Et enfin en en sélectionnant un petit nombre nous revenons sur nos approximations en basse dimension.\nLe produit scalaire du signal x(u) par l’ondelette \\[\\psi\\]v,s revient à un produit de convolution de x par l’ondelette conjuguée. Ca veut dire que sur les points de singularités les produits scalaires vont être maximisés.\nStéphane Mallat passe un long moment pour nous amener à la construction de ces bases d’ondelettes orthonormales. Il part des bases de Haar puis de Shannon et arrive à une construction plus récente par Yves Meyer en 1986."
  },
  {
    "objectID": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#multi-résolutions-lecture-6",
    "href": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#multi-résolutions-lecture-6",
    "title": "Learning: College de France - Representations parcimonieuses",
    "section": "3/16/21 - Multi-résolutions (lecture 6)",
    "text": "3/16/21 - Multi-résolutions (lecture 6)\nOn a vu la dernière fois qu’on pouvait construire une base d’ondelette le long des indices de dilatations en 2j.\nOn va voir maintenant qu’on peut translater les ondelettes par des facteurs 2j.n.\nDonc quand j est grand, les échelles sont de plus en plus grande. Et j petit va amener un échantillonnage de plus en plus fin.\n\\[\n\\left\\{ \\Psi_{(j,n)}(u)=\\frac{1}{\\sqrt{2^j}}\\Psi \\left( \\frac{u-2^jn}{2^j} \\right) \\right\\}_{(j, n) \\epsilon \\Z^2}\n\\]\nsont-elles des bases orthonormales. Ensuite on appliquerait les techniques d’approximations consistant à éliminer les petits coefficients.\nLes multi-résolutions sont des espaces linéaires sur lesquels nous allons projeter ces signaux. On va chercher à réduire les dimensions (par ex d’une image) en projetant sur ces espaces emboîtés. Et conserver le maximum d’information.\nUn produit scalaire avec une fonction translatée peut toujours s’écrire comme un produit de convolution (Stéphane Mallat répète souvent cette propriété)\nStéphane Mallat fait ensuite le lien avec les algorithmes en bancs de filtre (cascades de filtrage + échantillonnage).\nDans ces opérations il y a sans arrêt des passages du continu au discret. Par exemple si je prends un signal et que je le projette sur ces espaces je me retrouve avec les coordonnées, qui sont les produits scalaires avec mes \\[\\phi\\]j,n (car base orthogonale), ce qui revient à filtrer et sous échantillonner."
  },
  {
    "objectID": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#bases-orthonormales-dondelettes-lecture-7",
    "href": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#bases-orthonormales-dondelettes-lecture-7",
    "title": "Learning: College de France - Representations parcimonieuses",
    "section": "3/23/21 - Bases orthonormales d’ondelettes (lecture 7)",
    "text": "3/23/21 - Bases orthonormales d’ondelettes (lecture 7)\nOn repart sur notre triangle. Depuis 2 cours on est sur l’approximation basse dimension.\nStéphane Mallat applique le théorème sur des cas particuliers de la base de Haar, puis de la base de Shannon. Et revient sur la construction d’une base orthonormales avec des ondelettes “optimales”.\n\nQuand on prend le produit scalaire de notre signal f avec les ondelettes, on obtient des résultats presque nuls lorsque le signal est régulier. Et plus on a de moments nuls avec nos ondelettes, plus la régularité est ignorée (l’approximation par projection sur un espace vectorielle des monômes à l’ordre n).\nOn va cascader les projections aj (et les détails dj), et ça va revenir à cascader les filtres (les coefficients et les ondelettes).\nPour cela on calcule les valeurs des aj et dj en fonction de aj-1. On montre que cela s’obtient en filtrant (respectivement avec les \\[\\overline{h}\\] et \\[\\overline{g}\\]) puis en sous-échantillonnant. En cascadant on obtient une série de filtrages, sous-échantillonnages, filtrages, sous-échantillonnages, , etc.\nLes filtrages sont des convolutions. Si h a un support compact, ça va réduire le temps de calcul.(le nombre d’éléments non nuls correspond à la taille du filtre). Le nombre d’opérations pour passer de aL à aL-1, dL-1 est N*2m (où N: nombre de coefficients de aL et m est le nombre de moments nuls)\nLe nombre d’opérations est linéaire, et la constante correspond à la taille des filtres.\nOn peut inverser cet algorithmes (car base o.n.) et la structure emboîtée va nous donner algorithme de reconstruction. On va sur-échantillonner (augmenter d’un facteur 2 en intercalant des 0) et appliquer les filtres g et h, et sommer pour obtenir le résultat.\nDonc en gardant la base fréquence aJ et tous les détails {dj}, on reconstitue aL. (les signaux sur des grilles de plus en plus fines)\nStéphane Mallat finit sur des exemples en 2 dimensions. En 2 dimensions on aura 3 ondelettes à chaque échelle (1 avec les hautes fréquences dans une direction, 1 avec les hautes fréquences dans l’autre direction, et la dernière avec haute fréquence sur les 2 directions (les coins))."
  },
  {
    "objectID": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#parcimonie-et-compression-dimages-lecture-8",
    "href": "posts/2021-02-10-college-de-france-representations-parcimonieuses.html#parcimonie-et-compression-dimages-lecture-8",
    "title": "Learning: College de France - Representations parcimonieuses",
    "section": "3/30/21 - Parcimonie et compression d’images (lecture 8)",
    "text": "3/30/21 - Parcimonie et compression d’images (lecture 8)\nStéphane Mallat propose un survol de tout le cours pour montrer la logique dans laquelle on a évolué.\nEn reprenant le triangle Régularité - Approximation en basse dimension (au cœur du traitement de donnée) - Représentation parcimonieuse. Les équivalences entre régularité et la construction de représentations parcimonieuses permettent de construire des approximations en basse dimension.\nMais on peut les interpréter différemment :\n\nd’un point de vue linéaire : on peut construire des approximations linéaires qui vont correspondre à des formes de régularité et certains types de représentations parcimonieuses (en particulier dans la base de Fourrier quand on a des invariants par translation)\nen prenant un point de vue non linéaire : qui consiste non pas à faire des projections dans des espaces linéaires mais plutôt des projections dans des unions d’espaces linéaires obtenus en sélectionnant de façon libre dans une base orthogonale les plans les plus représentatifs.\n\nIl reprend en détail ce qu’on a vu en repartant de la théorie développée par Fourier (1822 ça ne date pas d’hier). Et reprend les réseaux de neurones à 1 couche cachée.\n\\[\nf_M(x)=\\displaystyle\\sum_{m}w(m)\\rho(\\langle{x,w_m}\\rangle+b_m)\n\\]\nL’entrée est x en dimension d, dans la première couche on calcule des produits scalaires avec les vecteurs \\(v_m\\) qui sont les colonnes d’un opérateur linéaire \\(W_1\\) et ces M produits scalaires vont être regroupés avec un relu (ou toute autre non-régularité) et un biais, et dans la dernière couche on fait une combinaison linéaire pour construire l’approximation. M est le nombre d’éléments dans la couche cachée, peut-on bien approximer f(x) à partir de cette construction ?\nCes réseaux, en prenant comme non-régularité un cosinus, nous font retomber sur des séries de Fourier.\n\\[\nf_M(x)=\\displaystyle\\sum_{\\| v_m \\|&lt;R}w(m) \\cos (\\langle{x,w_m}\\rangle+b_m)\n\\]\nFaire une décomposition avec un réseau de neurone à 1 couche cachée est très similaire à décomposer la fonction dans une base de Fourier. Prendre un relu consisterait à faire un changement de base entre le relu et le cosinus.\nSi on veut approximer une fonction uniformément régulière, il va falloir garder les basses fréquences. Mais \\(x\\) n’est pas en dimension 1 mais en dimension \\(d\\). Les fréquences qu’il va falloir prendre ici sont dans \\(\\Z^d\\), il va falloir garder toutes les fréquences dans une boule de rayon plus petit que \\(R\\). Mais quand on est en dimension \\(q\\), le nombre d’éléments dans une boule plus petit que \\(R\\) va croître comme \\(R^q\\). Donc il va falloir garder énormément d’éléments.\nOn a la possibilité d’approximer n’importe quelle fonction dans \\(L^2\\) avec une erreur qui va décroître vers 0 quand le nombre de termes \\(M\\) tend vers \\(\\infty\\) parce qu’on a une base orthogonale et donc n’importe quelle fonction peut être représentée à partir de la base\n\\[\nf \\in L^2 \\implies \\lim\\limits_{M \\to \\infty}\\| f-f_M \\|=0\n\\]\nC’est le théorème d’approximation universelle.\nPar contre si on a une régularité on peut préciser la vitesse de décroissance de l’erreur et en particulier si ma fonction est \\(\\alpha\\) dérivée dans un espace de Sobolev de degré \\(\\alpha\\), l’erreur va décroître d’autant plus vite que la régularité est grande, parce que les coefficients de Fourier vont décroître, et la vitesse de décroissance dépend de \\(\\alpha/d\\).\n\\[\nf \\in H^\\alpha \\implies \\|f-f_M\\| = o(M^{-\\alpha/d})\n\\]\nC’est la malédiction de la dimensionnalité.\nUne autre approche consiste à reprendre ce cercle d’un point de vue non-linéaire. Au lieu de toujours prendre les mêmes coefficients pour approximer les fonctions qui m’intéressent, je vais adapter les coefficients à la fonction. C’est l’esprit des approximations non-linéaires.\nSi je considère les vecteurs de Fourier, et ses coefficients ont une norme \\(L^p\\) qui converge, pour un \\(p&lt;2\\). Alors on a vu que les coefficients vont décroître à une vitesse qui dépend de \\(p\\). Ca veut dire qu’il y a quelques grands coefficients et beaucoup de petits. Si on choisit les grands coefficients alors on va avoir une erreur qui décroît comme \\(-2/(p+1)\\), l’erreur décroît lorsque \\(M\\) augmente, indépendamment de la dimension.\n\\[\nSparse \\quad Fourier \\quad coefficients: Barron \\quad p&lt;2\n\\\\\n\\displaystyle\\sum_{v \\in \\Z^d} |\\langle{f(x), F_v(x)}\\rangle|^p &lt; \\infty \\implies \\|f-f_M\\|=o(M^{-2/p+1})\n\\]\nno curse. Mais résultat tautologique. Pourquoi cette fonction serait approximable avec quelques coefficients de Fourier. Ça n’explique en rien pourquoi on peut améliorer fortement ce résultat en augmentant le nombre de couche. C’est simple mais ça n’explique pas les performances des réseaux de neurones profonds.\nD’où l’approche par ondelettes.\nEt la nécessité de construire des bases orthogonales d’ondelettes à décroissance rapide. Travaux de Yves Meyer. (en essayant de démontrer que ça n’était pas possible il a réussi à en construire ;)) Et S.Mallat a amélioré cette approche en se basant sur des approches de multi résolutions avec des espaces imbriqués.\nOn peut construire ces ondelettes en cascadant des filtres à différentes échelles (passe bas et passe bande à différentes échelles).\nI.Daubechies a montré qu’on peut construire des ondelettes à support compact.\nY.Meyer a montré ce que ça donnait en dimension 2 (et c’est généralisable en dimension q) avec 3 ondelettes."
  },
  {
    "objectID": "posts/2021-09-01-logbook-September.html",
    "href": "posts/2021-09-01-logbook-September.html",
    "title": "Logbook for September 21",
    "section": "",
    "text": "Thursday 9/2\nPaper reviewed on arxiv about Continuous Control With Deep Reinforcement Learning. (Lillicrap et. al - 2015) arXiv:1509.02971. This is about DDPG. Initial paper comes from David Silver: Deterministic policy gradient algorithms in ICML 2014, but is not easy to read. Here is a review from towardsdatascience, in which the Deep Deterministic Policy Gradients (DDPG) is presented, and is written for people who wish to understand the DDPG algorithm."
  },
  {
    "objectID": "posts/2021-09-01-logbook-September.html#week-35---september-21",
    "href": "posts/2021-09-01-logbook-September.html#week-35---september-21",
    "title": "Logbook for September 21",
    "section": "",
    "text": "Thursday 9/2\nPaper reviewed on arxiv about Continuous Control With Deep Reinforcement Learning. (Lillicrap et. al - 2015) arXiv:1509.02971. This is about DDPG. Initial paper comes from David Silver: Deterministic policy gradient algorithms in ICML 2014, but is not easy to read. Here is a review from towardsdatascience, in which the Deep Deterministic Policy Gradients (DDPG) is presented, and is written for people who wish to understand the DDPG algorithm."
  },
  {
    "objectID": "posts/2021-09-01-logbook-September.html#week-36---september-21",
    "href": "posts/2021-09-01-logbook-September.html#week-36---september-21",
    "title": "Logbook for September 21",
    "section": "Week 36 - September 21",
    "text": "Week 36 - September 21\nMonday 9/6\nInstall of barrier to share keyboard/mouse between linux and windows. Nice combinaison with KVM usb switch.\nMove wsl to another drive with move-wsl\nWednesday 9/8\nCreation of custom gym environment and optimization using DQN, then DDPG with stable baselines 3. Takes around 50,000 steps to optimize a ultra simple grid problem… No success with DDPG, something missing?\nThursday 9/9\nStill playing with gym and stable baselines 3. A2C, PPO and SAC are working but DDPG and TD3 are not (and I don’t know why)"
  },
  {
    "objectID": "posts/2021-09-01-logbook-September.html#week-38---september-21",
    "href": "posts/2021-09-01-logbook-September.html#week-38---september-21",
    "title": "Logbook for September 21",
    "section": "Week 38 - September 21",
    "text": "Week 38 - September 21\nMonday 9/20\nBack to Aniti RL virtual school. Looking for material to be used to explain RL to my colleagues, and how to properly describe the experience I am running with gym.\nCertainly will start lectures from deepming: 2021 DeepMind x UCL RL Lecture Series\nThursday 9/23\nStart plotly course from datacamp using my datacamp learning process. I need basic interactivity and 3d plots to illustrate reward functions."
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "",
    "text": "From http://introtodeeplearning.com/\nI keep all content (lectures, notebooks) in github\nThis is done with google contribution, and therefore all examples are in tensorflow. I will try to adapt notebooks in PyTorch."
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#intro-to-deep-learning---lecture-1",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#intro-to-deep-learning---lecture-1",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "2/5/21 - Intro to Deep Learning - lecture 1",
    "text": "2/5/21 - Intro to Deep Learning - lecture 1\nLecturer: Alexander Amini\nIntro is just jaw-dropping!\n2020 intro was top.\n2021 intro is just awesome.\nIt is a standard overview of simple deep learning concepts: Perceptron, multi-perceptron, dense layers, loss, gradient-descent, backprop, SGD, regularization, dropout, early stoppping"
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#deep-sequence-modeling---lecture-2",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#deep-sequence-modeling---lecture-2",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "2/15/21 - Deep Sequence Modeling - lecture 2",
    "text": "2/15/21 - Deep Sequence Modeling - lecture 2\nNew lecturer: Ava Soleimany\nNice introduction to sequence modeling with Many-to-One, One-to-Many, Many-to-Many.\nRNN and implementation in TensorFlow. And NLP examples: next word problem. (and NLP concepts such as Vocabulary, Indexing, Embedding)\nAnd what we need for sequence modeling:\n\nhandle variable-length sequences\ntrack long-term dependencies\nmaintain information about order\nshare parameters across the sequence\n\nBackpropagation through time and problem of exploding/vanishing gradients.\nAgainst exploding: gradient clipping. Against vanishing: 3 ways explained - activation functions, weight init, network arch.\nGated cell: to control what information is passed through. Ex: LSTM Long Short Term Memory. They support something closed to Forget Store Update Output. Ava explains graphically which part of LSTM cells is providing which function.\nAnd then examples: Music generation (to generate 4th movement of last symphony from Schubert!), sentiment classification, machine translation (with Attention mechanisms which provide learnable memory access to solve Not long memory), trajectory prediction, environmental modeling."
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#intro-to-tensorflow-music-generation---software-lab-1",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#intro-to-tensorflow-music-generation---software-lab-1",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "2/16/21 - Intro to TensorFlow; Music Generation - software lab 1",
    "text": "2/16/21 - Intro to TensorFlow; Music Generation - software lab 1\nAs an exercise I have completed labs in TensorFlow and adapted them in PyTorch.\nWith LSTM, I ran into this error: UnknownError: Fail to find the dnn implementation. [Op:CudnnRNN]\nWhich is solved by calling tf.config.experimental.set_memory_growth.\nimport tensorflow as tf \ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n  try:\n    # Currently, memory growth needs to be the same across GPUs\n    for gpu in gpus:\n      tf.config.experimental.set_memory_growth(gpu, True)\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n  except RuntimeError as e:\n    # Memory growth must be set before GPUs have been initialized\n    print(e)\nMusic lab is nice to play with. I am not sure I would be able to convert to PyTorch. It would require time!"
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#deep-computer-vision---lecture-3",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#deep-computer-vision---lecture-3",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "2/22/21 - Deep Computer Vision - lecture 3",
    "text": "2/22/21 - Deep Computer Vision - lecture 3\nI have never been a big fan of computer vision.\nI like the idea developed by Alexander Amini about hierarchy of features. (low level: edges, spots; mid level: eyes, noses)\nAnd how he explains limitation of FC layers for visual detection, and introduction of spatial structure (feature extraction with convolutions)\nSome nice examples of hand-engineered convolution filters for different needs: sharpen, edge detect, strong edge detect.\nThen classic explanations of CNN with convolution, max pooling.\nI like the way classification problems are broken down between feature learning (convolution+relu, pooling, repeated several times) and classification (flatten, FC, softmax) which is a task learning part.\nThe second part (task learning part) can be anything: classification, object detection, segmentation, probabilistic control, …\n\nNice explanation of R-CNN to learn region proposals.\nIntroduction to Software lab2: de-biaising facial recognition systems."
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#deep-generative-modeling---lecture-4",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#deep-generative-modeling---lecture-4",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "3/1/21 - Deep Generative Modeling - lecture 4",
    "text": "3/1/21 - Deep Generative Modeling - lecture 4\nFrom pattern discovered from data (underlying structure of the data), generate examples following these patterns.\nAutoencoder: foundational generative model which builds up latent variable representation by self-encoding the input. To train such network, we create a decoder to go from latent variable to generated output, and then compare input to generated output.\n\nVariational autoencoder (vae): with vae we try to encode inputs as distributions defined by mean \\[\\mu\\] and variance \\[\\sigma\\]. And we want to achieve continuity and completeness:\n\ncontinuity: points that are close in latent space –&gt; similar content after decoding\ncompleteness: sampling from latent space –&gt; ‘meaningful’ content after decoding\n\nRegularization is pushing to get these properties.\n\nAnd the learning process is about minimizing reconstruction loss + a regularization term:\n\nAva is then explaining the smart trick to allow backpropagation to happen. Indeed by introducing stochastic term in the sampling layer, we are breaking the backpropagation logic.\nWe are moving z from a normal distribution to \\[\\mu\\]+\\[\\sigma\\].\\[\\epsilon\\] where \\[\\epsilon\\] follow a normal distribution of mean 0, std 1.\nExplanation then of space disentanglement via \\[\\beta\\]-VAEs. It allows latent variables to be independent.\n\nAnd then some introduction about **GANs* (Generative Adversarial Network) which are a way to make a generative model by having 2 neural networks (generator and discriminator) compete with each other.\nAnd share some recent advances on GAN such as StyleGAN(2), conditional GAN, CycleGAN. CycleGAN is famous for turning horses in zebras, but it can be used to transform speech as well (used in the synthesis of Obama’s voice)"
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#de-biasing-facial-recognition-systems---software-lab-2",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#de-biasing-facial-recognition-systems---software-lab-2",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "3/1/21 - De-biasing Facial Recognition Systems - Software Lab 2",
    "text": "3/1/21 - De-biasing Facial Recognition Systems - Software Lab 2\nPart 1 MNIST\nstarts with FC layers. With some overfitting but a good accuracy of 96%.\nthen move to a CNN architecture. I ran into gpu issues. Accuracy is now 99%.\nI didn’t manage to make the last part working. (using tape.gradient)\nPart 2 Debiasing\nFit a CNN model to classify faces based on celebA dataset. And see the bias effect by predicting on Fitzpatrick scale skin type classification system.\nUse VAE to learn latent structure.\n\n\n\nThe concept of a VAE\n\n\nTo then debias using DB-VAE model.\n\n\n\nDB-VAE\n\n\nThere is a lack of progressive unit tests to validate each step. Cannot go to the end.\nWould be interested to see how to apply to non computer vision problems."
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#deep-reinforcement-learning---lecture-5",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#deep-reinforcement-learning---lecture-5",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "3/8/21 - Deep Reinforcement Learning - lecture 5",
    "text": "3/8/21 - Deep Reinforcement Learning - lecture 5\nQ-function captures the expected total future reward an agent in state s can receive by executing a certain action a.\nDistinction between Value Learning (learn Q function) and Policy Learning (find directly \\[\\pi\\](s)).\n\nValue Learning or DQN\n\n\nThe key thing is about handling of continuous actions.\nLet’s see how to do it with policy learning:\nPolicy learning or Policy Gradient (PG)\n\n\nAlexanders ends the lecture by discussing about Deepmind progress:\n\nalphaGo - 2016: with a pretrain in supervised mode then standard DRL\nalphaGo Zero - 2017: standard DRL without pretraining\nalphaZero - 2018: standard DRL without pretraining and applied to several games (Go, Chess, Shogi)\nMuZero - 2020: learns the rules of the game by itself, create unknown dynamics"
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#limitations-and-new-frontiers---lecture-6",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#limitations-and-new-frontiers---lecture-6",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "3/15/21 - Limitations and New Frontiers - lecture 6",
    "text": "3/15/21 - Limitations and New Frontiers - lecture 6\nUniversal Approximation Theorem: A feedforward network with a single layer is sufficient to approximate, to an arbitrary precision, any continuous function.\nAva emphasizes importance of training data (e.g. for generalization) and mentions a paper called “Understanding Deep Neural Networks Requires Rethinking Generalization”.\nSome fail examples with dogs colorization (BW -&gt; colors) creating pink zone under the mouth.\nAnd another one with Tesla autopilot. It motivates working on uncertainty in Deep Learning.\n\nwe need uncertainty metrics to assess the noise inherent to the data: aleatoric uncertainty\nwe need uncertainty metrics to assess the network’s confidence in its predictions: epistemic uncertainty\n\nAva cites an example of a real 3D printed turtle designed to fool a classifier from turtle to rifle.\nNew frontier: Encoding Structure into Deep Learning.\nCNN is a nice way to extract features from an image. But not all kind of data can express features in an euclidean way. Graphs is used as a structure for representing data in a lot of cases.\nIt drives us to Graph Convolutional Networks (GCNs). The graph convolutional operator is going to associate weights with each of the edges and apply the weights across the graph and then the kernel is going to be moved to the next node in the graph extracting information about its local connectivity. That local information is going to be aggregated and the NN is going to then learn a function that encodes that local information into a higher level representation.\nNew frontier: Automated Machine Learning & AI.\nUsing a neural architecture search algorithm. At each step the model samples a brand new network. For each layer, defines number of fileters, filet height, width, stride height, width, nbr of fileters, etc. Update RNN controller based on the accuracy of the child network after training.\nFrom autoML to autoAI: an automated complete pipeline for designing and deploying ML and AI models."
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#pixels-to-control-learning---software-lab-3",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#pixels-to-control-learning---software-lab-3",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "3/15/21 - Pixels-to-Control Learning - Software Lab 3",
    "text": "3/15/21 - Pixels-to-Control Learning - Software Lab 3\nThis is about reinforcement learning.\n\n\n\nalt text\n\n\nWe install (apt) xvfb and python-opengl.\nAnd will learn with cartpole and pong.\nStill this issue\n\nUnknownError: Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above. [[node sequential_8/conv2d_4/Conv2D (defined at :19) ]] [Op:__inference_distributed_function_2442603]\n\nSolved by running\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        # Currently, memory growth needs to be the same across GPUs\n        for gpu in gpus:\n            tf.config.experimental.set_memory_growth(gpu, True)\n        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n    except RuntimeError as e:\n        # Memory growth must be set before GPUs have been initialized\n        print(e)\nI couldn’t go through the training of Pong agent due to GPU limitation?\n2021-03-15 10:54:19.479775: W tensorflow/core/framework/op_kernel.cc:1655] OP_REQUIRES failed at conv_grad_input_ops.cc:1254 : Resource exhausted: OOM when allocating tensor with shape[3944,48,10,10] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfcbash"
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#evidential-deep-learning-and-uncertainty---lecture-7",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#evidential-deep-learning-and-uncertainty---lecture-7",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "3/22/21 - Evidential Deep Learning and Uncertainty - lecture 7",
    "text": "3/22/21 - Evidential Deep Learning and Uncertainty - lecture 7"
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#bias-and-fairness---lecture-8",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#bias-and-fairness---lecture-8",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "3/29/21 - Bias and Fairness - lecture 8",
    "text": "3/29/21 - Bias and Fairness - lecture 8\nThis starts as a standard lecture about bias.\nI like emphasis about bias that could stand in all stages of AI life cycle:\n\ndata (obviously)\nmodel\ntraining and deployment\nevaluation\ninterpretation\n\nGood explanation about biases due to class imbalance. It develops my intuition about it.\nBalanced batches can be the answer.\nExample weighting is another option using inverse frequency as a weight.\n\nAdversarial learning to mitiage Bias.\nApplication in NLP to complete analogies. He is to she, as doctor is to ?\nSame thing with Learned Latent Structure. (can be used to create fair and representative dataset)"
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#learning-for-information-extraction---lecture-9.",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#learning-for-information-extraction---lecture-9.",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "4/15/21 - Learning for Information Extraction - lecture 9.",
    "text": "4/15/21 - Learning for Information Extraction - lecture 9.\nDeep CPCFG for Information Extraction\nLecturer: Nigel Duffy and Freddy Chua, Ernst & Young AI Labs\nFocus is about document intelligence (extract info from business documents)\ne.g. extract information from semi-structured documents such as tax forms (souvenirs ;))"
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#taming-dataset-bias---lecture-10",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#taming-dataset-bias---lecture-10",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "4/27/21 - Taming Dataset Bias - lecture 10",
    "text": "4/27/21 - Taming Dataset Bias - lecture 10\nvideo\ndataset bias and training shift\n(from one city to another (summer vs winter), from simulated to real control, from one culture to another)\nCan fix with more data …(can be very expensive if we want to address all combinations) or use unlabeled data ?\n\nAdversarial approach to fool a domain discriminator. (domain discriminator trained to distinguished source and target domains)\nAnother approach is pixel alignment."
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#towards-ai-for-3d-content-creation---lecture-11",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#towards-ai-for-3d-content-creation---lecture-11",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "4/30/21 - Towards AI for 3D Content Creation - lecture 11",
    "text": "4/30/21 - Towards AI for 3D Content Creation - lecture 11\nvideo\n\nSanja Fidler; Professor U. of Toronto and Head of AI at NVIDIA"
  },
  {
    "objectID": "posts/2021-02-05-learning-MIT-6.S191-2021.html#ai-in-healthcare---lecture-12",
    "href": "posts/2021-02-05-learning-MIT-6.S191-2021.html#ai-in-healthcare---lecture-12",
    "title": "Learning: MIT 6.S191 Introduction to Deep Learning - 2021",
    "section": "4/30/21 - AI in Healthcare - lecture 12",
    "text": "4/30/21 - AI in Healthcare - lecture 12\nvideo\n\nKatherine Chou; Director of Research and Innovations, Google"
  },
  {
    "objectID": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html",
    "href": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html",
    "title": "Practicing: Deep Reinforcement Learning Course by Thomas Simonini",
    "section": "",
    "text": "A course by Thomas Simonini\nSyllabus (from 2018)\nCourse introduction (from 2020)\nEverything available in github\nI appreciate the effort to update examples, and some 2018 implementations became obsolete. Historical Atari VC2600 games are now Starcraft 2 or minecraft, and news series on building AI for video games in Unity and Unreal Engine.."
  },
  {
    "objectID": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-1---an-introduction-to-deep-reinforcement-learning",
    "href": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-1---an-introduction-to-deep-reinforcement-learning",
    "title": "Practicing: Deep Reinforcement Learning Course by Thomas Simonini",
    "section": "(2/19/21) - Chapter 1 - An Introduction to Deep Reinforcement Learning?",
    "text": "(2/19/21) - Chapter 1 - An Introduction to Deep Reinforcement Learning?\nPrevious version from 2018: What is Deep Reinforcement Learning? is quite interesting. With 3 parts:\n\nWhat Reinforcement Learning is, and how rewards are the central idea\nThe three approaches of Reinforcement Learning\nWhat the “Deep” in Deep Reinforcement Learning means\n\n\nRewards, long-term future reward, discount rate.\n\nEpisodic (starting and ending point) vs Continuous (e.g. stock trading) tasks.\nWay of learning: Monte Carlo (MC: rewards collected at the end of an episode) vs Temporal Difference (TD: estimate rewards at each step)\n\nExploration/Exploitation trade off. Will see later different ways to handle that trade-off.\n\n\nThree approaches to Reinforcement Learning\nThese are value-based, policy-based, and model-based.\n\nValue Based\nIn value-based RL, the goal is to optimize the value function V(s).\nThe value function is a function that tells us the maximum expected future reward the agent will get at each state.\n\n\n\nPolicy Based\nIn policy-based RL, we want to directly optimize the policy function π(s) without using a value function.\nThe policy is what defines the agent behavior at a given time.\nWe have two types of policy:\n\nDeterministic: a policy at a given state will always return the same action.\nStochastic: output a distribution probability over actions.\n\n\n\n\nModel Based\nIn model-based RL, we model the environment. This means we create a model of the behavior of the environment. Not addressed in this course.\n\n\n\nDeep Reinforcement Learning\nIn Q-learning, we keep a table of actions to take for each state (based on reward). This can be huge.\nDeep Learning allows to approximate this Q function.\n\nUpdated version from 2020 (and video version)\nThis is a good starting point, well explained.\nReinforcement Learning is just a computational approach of learning from action.\nA formal definition\n\nReinforcement learning is a framework for solving control tasks (also called decision problems) by building agents that learn from the environment by interacting with it through trial and error and receiving rewards (positive or negative) as unique feedback.\n\nSome explanations about observations (partial description) vs states (fully observed envt). Only differs in implementation, all theoretical background stays the same.\nAction space where we can distinguish discrete (e.g. fire, up) actions from continuous (e.g. turn 23deg) ones.\nReward part is the same as the one from 2018. With cheese, mouse, maze example.\nEpisodic and continuous tasks part is the same as the one from 2018.\nExploration/Exploitation trade-off is explained the same way + an additional example taken from berkley - CS 294-112 - Deep Reinforcement Learning course. I want to learn more about this course!\nAbout solving RL problems, it is now presented as 2 main approaches:\n\npolicy-based methods\nvalue-based methods\n\n\nAnd bedore to explain that, nice presentation of what is a policy \\(\\pi\\). Solving RL problem is to find that optimal policy: directly with policy-based method, indirectly (through value function) with value-based method.\nThere is an explanation about different types of policy: deterministic and stochastic.\nAnd that we use deep neural networks to estimate the action to take (policy based) or to estimate the value of a state (value based). Thomas suggests to go further with deep learning with MIT 6.S191, which is the one (version 2021) I follow these days."
  },
  {
    "objectID": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-2---part-1---q-learning-lets-create-an-autonomous-taxi",
    "href": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-2---part-1---q-learning-lets-create-an-autonomous-taxi",
    "title": "Practicing: Deep Reinforcement Learning Course by Thomas Simonini",
    "section": "(2/19/21) - Chapter 2 - part 1 - Q-Learning, let’s create an autonomous Taxi",
    "text": "(2/19/21) - Chapter 2 - part 1 - Q-Learning, let’s create an autonomous Taxi\nAnd in video (I like to read + watch the video at the same time)\nHere in Step 2 we focus on a value-based method: Q-learning. And what is seen in part 1 and 2:\n\n\nValue-based method\nRemember what we mean in value-based method\n\nyou don’t train your policy, you define a simple function such as greedy function to select the best association State-Action, so the best action.\n\n\nBellman equation\neach value as the sum of the expected return, which is a long process. This is equivalent to the sum of immediate reward + the discounted value of the state that follows.\n\n\n\nMonte Carlo vs Temporal Difference\nAnd then an explanation about 2 types of method to learn a policy or a value-function:\n\nMonte Carlo: learning at the end of the episode. With Monte Carlo, we update the value function from a complete episode and so we use the actual accurate discounted return of this episode.\nTD learning: learning at each step. With TD learning, we update the value function from a step, so we replace Gt that we don’t have with an estimated return called TD target. (chich is the immediate reward + the discounted value of the next state)\n\n\nIt was not clear to me that these methods could be used for policy-based approach. It is now!"
  },
  {
    "objectID": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-2---part-2---q-learning-lets-create-an-autonomous-taxi",
    "href": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-2---part-2---q-learning-lets-create-an-autonomous-taxi",
    "title": "Practicing: Deep Reinforcement Learning Course by Thomas Simonini",
    "section": "(2/24/21) - Chapter 2 - part 2 - Q-Learning, let’s create an autonomous Taxi",
    "text": "(2/24/21) - Chapter 2 - part 2 - Q-Learning, let’s create an autonomous Taxi\nBut the video is not yet available.\nWhat is Q-Learning?\nQ-Learning is an off-policy value-based method that uses a TD approach to train its action-value function:\n\n“Off-policy”: we’ll talk about that at the end of this chapter.\n“Value-based method”: it means that it finds its optimal policy indirectly by training a value-function or action-value function that will tell us what’s the value of each state or each state-action pair.\n“Uses a TD approach”: updates its action-value function at each step.\n\nQ stands for quality (quality of action). After training we’ll get the optimal Q-function.\nWhen choosing an action, we have to balance between exploration and exploitation with \\[\\epsilon\\] - greedy:\n\nBut at beginning Q table is not trained yet so we have to increase exploitation. It is done with some decreasing \\[\\epsilon\\].\n\nThe Q-learning algorithm is a 4-step process:\n\nstep1: Q-Table init\nstep2: Choose action (\\[\\epsilon\\] - greedy strategy)\nstep3: Perform action At and get Rt+1 and St+1\nstep4: Update Q(St, At)\n\n\n\n\nUpdate Q(St, At)\n\n\nWhy it is called off-policy? Because we don’t have the same logic to select action (\\[\\epsilon\\] - greedy) and update Q (greedy).\nWith On-policy: we use the same policy for acting and updating. Sarsa is such an algorithm.\n\nNice and simple manual example with mouse, cheese in a maze. We run Q-learning and make all calculation by hands.\n\n \n\nimplement with numpy+gym this algorithm should be a nice exercise.\n\nThere is an exercise to implement a taxi, within this notebook at colab google. Taxi V3 is an env from opengym."
  },
  {
    "objectID": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#back-to-2018---chapter-3---deep-q-learning-with-doom",
    "href": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#back-to-2018---chapter-3---deep-q-learning-with-doom",
    "title": "Practicing: Deep Reinforcement Learning Course by Thomas Simonini",
    "section": "(3/3/21) - back to 2018 - Chapter 3 - Deep Q-learning with Doom",
    "text": "(3/3/21) - back to 2018 - Chapter 3 - Deep Q-learning with Doom\nArticle, Notebook, Video\nWe’ll create an agent that learns to play Doom. Doom is a big environment with a gigantic state space (millions of different states). Creating and updating a Q-table for that environment would not be efficient at all.\nThe best idea in this case is to create a neural network that will approximate, given a state, the different Q-values for each action.\n\n\nAddresses pb of temporal limitation: get multiple frames to have sense of motion.\nVideo is nice because it goes from start and follows closely all steps.\nI wil try to implement in my own by creating an environment and running under a clone of Deep_reinforcement_learning_Course Thomas’s repo\nHere at Deep Q learning with Doom.ipynb\nI had to switch to tensorflow-gpu 1.13. Manage some cuda memory issue. But then was able to run it.\nHowever as Thomas says, I should do it step by step on my own."
  },
  {
    "objectID": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-4-improvements-in-deep-q-learning-v1",
    "href": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-4-improvements-in-deep-q-learning-v1",
    "title": "Practicing: Deep Reinforcement Learning Course by Thomas Simonini",
    "section": "(3/10/21) - Chapter 4: Improvements in Deep Q Learning V1",
    "text": "(3/10/21) - Chapter 4: Improvements in Deep Q Learning V1\nArticle, Notebook, Video\nfour strategies that improve — dramatically — the training and the results of our DQN agents:\n\nfixed Q-targets\ndouble DQNs\ndueling DQN (aka DDQN)\nPrioritized Experience Replay (aka PER)\n\nfixed Q-targets to avoid chasing a moving target\n\nUsing a separate network with a fixed parameter (let’s call it w-) for estimating the TD target.\nAt every \\[\\Tau\\] step, we copy the parameters from our DQN network to update the target network.\n\n\nImprovements in Deep Q Learning: Dueling Double DQN, Prioritized Experience Replay, and fixed…\nImplementation\nImplementing fixed q-targets is pretty straightforward:\n\nFirst, we create two networks (DQNetwork, TargetNetwork)\nThen, we create a function that will take our DQNetwork parameters and copy them to our TargetNetwork\nFinally, during the training, we calculate the TD target using our target network. We update the target network with the DQNetwork every \\[\\Tau\\] step (\\[\\Tau\\] is an hyper-parameter that we define).\n\ndouble DQNs to handle overestimating of Q-values (at the beginning of training, taking the maximum q value (which is noisy) as the best action to take can lead to false positives)\nwe move from this TD target logic\n\nto the use of 2 networks\n\nuse our DQN network to select what is the best action to take for the next state (the action with the highest Q value).\nuse our target network to calculate the target Q value of taking that action at the next state.\n\n\nImplementation\n\nDueling DQN (aka DDQN)\nbased on this paper Dueling Network Architectures for Deep Reinforcement Learning.\nWith DDQN, we want to separate the estimator of these two elements, using two new streams:\n\none that estimates the state value V(s)\none that estimates the advantage for each action A(s,a)\n\n\nand this can be combined with Prioritized experience replay.\nThis is nicely explained in this article. DDQN explanation is clearer than Thomas’.\nThe key here is to deal efficiently with experiences. When treating all samples the same, we are not using the fact that we can learn more from some transitions than from others. Prioritized Experience Replay (PER) is one strategy that tries to leverage this fact by changing the sampling distribution.\nI guess there are several options to manage this prioritization (we would prefer transitions that do not fit well to our current estimate of Q function). And a key aspect is the performance of this selection. One implementation is SumTree.\nI have to see full implementation in the notebook to fully understand the logic.\nAbout the video\nThomas has insisted about the importance to master these architecture (DQN then DDQN, etc) before going further with state of the art architectures (Policy Gradient, PPO…)\nApproach in videos is now different. In previous videos it was about explaining articles. Now it is more turned to implementation details based on notebooks.\nThomas has given a reference to Arthur Juliani who is a senior ML engineer at Unity. I would like to browse though this reference and see what can be done.\nShould follow video and run/update notebook in //."
  },
  {
    "objectID": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-5-policy-gradients-v1",
    "href": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-5-policy-gradients-v1",
    "title": "Practicing: Deep Reinforcement Learning Course by Thomas Simonini",
    "section": "(3/17/21) - Chapter 5: Policy Gradients V1",
    "text": "(3/17/21) - Chapter 5: Policy Gradients V1\nArticle, Notebook, Video\nIn policy-based methods, instead of learning a value function that tells us what is the expected sum of rewards given a state and an action, we learn directly the policy function that maps state to action (select actions without using a value function).\n3 main advantages to use Policy Gradients vs Q learning:\n\nconvergence - have better convergence properties\neffective in high dimension, or with continuous actions\nstochastic policy - no need for exploration,/exploitation tradeoff\n\nBut can be longer to train.\nPolicy search\nWe can dfine our policy as the probability distribution of actions (for a given state)\n\nAnd how good is this policy? Measured with J(\\[\\theta\\])\n\nWe must find \\[\\theta\\] to maximize J(\\[\\theta\\]). How?\n2 steps:\n\nMeasure the quality of a π (policy) with a policy score function J(θ)\nUse policy gradient ascent to find the best parameter θ that improves our π.\n\nthe Policy Score function J(θ)\n3 ways (maybe more)\nCalculate the mean of the return from the first time step (G1). This is the cumulative discounted reward for the entire episode.\n\nIn a continuous environment, we can use the average value, because we can’t rely on a specific start state. Each state value is now weighted (because some happen more than others) by the probability of the occurrence of the respected state.\n\nThird, we can use the average reward per time step. The idea here is that we want to get the most reward per time step.\n\nPolicy gradient ascent\nbecause we want to maximize our Policy score function\n\nThe solution will be to use the Policy Gradient Theorem. This provides an analytic expression for the gradient ∇ of J(θ) (performance) with respect to policy θ that does not involve the differentiation of the state distribution. (using likelihood ratio trick)\n\nIt gives\n\nR(\\[\\tau\\]) is like a scalar value score.\nImplementation\nAs with the previous section, this is good to watch the video at the same time.\nAnd now this is the implementation in\ndoom deathmatch notebook\n\nas with Pong, we stack frames to understand dynamic with deque.\nEven with GPU growth setup, I run an error after the 1st epoch.\n==========================================\nEpoch:  1 / 5000\n\nNumber of training episodes: 15\nTotal reward: 7.0\nMean Reward of that batch 0.4666666666666667\nAverage Reward of all training: 0.4666666666666667\nMax reward for a batch so far: 7.0\nResourceExhaustedError: OOM when allocating tensor with shape[5030,32,24,39] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n     [[{{node PGNetwork/train/gradients/PGNetwork/conv2/conv2/Conv2D_grad/Conv2DBackpropInput}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\nI have to reduce batch size (to 1000) to make it work.\nAnd I can monitor gpu memory consumption with watch nvidia-smi\n\nor we can use gpustat -i 2\n[0] Quadro RTX 4000 | 59’C, 34 %, 39 W | 7819 / 7982 MB | explore(6729M) gdm(162M) explore(388M) explore(282M) explore(86M) explore(89M) explore(3M)"
  },
  {
    "objectID": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-6-advantage-actor-critic-a2c-and-asynchronous-advantage-actor-critic-a3c-v1",
    "href": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-6-advantage-actor-critic-a2c-and-asynchronous-advantage-actor-critic-a3c-v1",
    "title": "Practicing: Deep Reinforcement Learning Course by Thomas Simonini",
    "section": "(3/19/21) - Chapter 6: Advantage Actor Critic (A2C) and Asynchronous Advantage Actor Critic (A3C) V1",
    "text": "(3/19/21) - Chapter 6: Advantage Actor Critic (A2C) and Asynchronous Advantage Actor Critic (A3C) V1\nArticle, Notebook, Video\n“hybrid method”: Actor Critic. We’ll using two neural networks:\n\nan Actor that controls how our agent behaves (policy-based)\na Critic that measures how good the action taken is (value-based)\n\n\nActor is using a policy function \\[\n\\pi(s, a, \\theta)\n\\] Critic is using a value function\n\\[\n\\widehat{q}(s,a,w)\n\\] Which means 2 sets of weights to be optimized separately \\[\\theta\\] and w.\n\nWe can use advantage function to stabilize learning:\n\n\nTwo different strategies: Asynchronous or Synchronous\nWe have two different strategies to implement an Actor Critic agent:\n\nA2C (aka Advantage Actor Critic)\nA3C (aka Asynchronous Advantage Actor Critic)\n\nHere we focus on A2C.\n(3/22/21) - Implementation and video\nIt is a little bit confusing. I won’t run it. I would have liked a more pregressive approach and to understand all steps Thomas did to get to that final implementation."
  },
  {
    "objectID": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-7-proximal-policy-optimization-ppo-v1",
    "href": "posts/2021-02-19-Deep Reinforcement Learning Course by Thomas Simonini.html#chapter-7-proximal-policy-optimization-ppo-v1",
    "title": "Practicing: Deep Reinforcement Learning Course by Thomas Simonini",
    "section": "(3/24/21) - Chapter 7: Proximal Policy Optimization PPO V1",
    "text": "(3/24/21) - Chapter 7: Proximal Policy Optimization PPO V1\nArticle, Notebook\nThe central idea of Proximal Policy Optimization is to avoid having too large policy update. (we use a ratio that will tells us the difference between our new and old policy and clip this ratio from 0.8 to 1.2)\nClipped Surrogate Objective Function\n\nWe will penalize changes that lead to a ratio that will away from 1 (in the paper ratio can only vary from 0.8 to 1.2). By doing that we’ll ensure that not having too large policy update because the new policy can’t be too different from the older one.\n2 implementations are known TRPO (Trust Region Policy Optimization) and PPO clip. TRPO being complex and costly, we focus on PPO:\n\nAnd the final loss will be:\n\nNow the implementation\nBy looking at the implementation, I ran into Stable baselines3.\nThis is a major update of Stable Baselines based on pytorch. It seems interesting!\nI like this comment from Stable Baselines3 in the v1.0 blog post:\n\nMotivation\nDeep reinforcement learning (RL) research has grown rapidly in recent years, yet results are often difficult to reproduce. A major challenge is that small implementation details can have a substantial effect on performance – often greater than the difference between algorithms. It is particularly important that implementations used as experimental baselines are reliable; otherwise, novel algorithms compared to weak baselines lead to inflated estimates of performance improvements.\nTo help with this problem, we present Stable-Baselines3 (SB3), an open-source framework implementing seven commonly used model-free deep RL algorithms, relying on the OpenAI Gym interface.\n\nI will create a new blog entry about Stable Baselines3.\nas for previous notebook, I need to purchase Sonic2-3 to make it worked. Not for now maybe later."
  },
  {
    "objectID": "posts/2021-01-13-installing-python-packages-from-jupyter.html",
    "href": "posts/2021-01-13-installing-python-packages-from-jupyter.html",
    "title": "How To Install Packages from the Jupyter Notebook",
    "section": "",
    "text": "This is directly from https://jakevdp.github.io/blog/2017/12/05/installing-python-packages-from-jupyter/.\nHere are my own experimentations following this article detailed explanations."
  },
  {
    "objectID": "posts/2021-01-13-installing-python-packages-from-jupyter.html#how-your-operating-system-locates-executables",
    "href": "posts/2021-01-13-installing-python-packages-from-jupyter.html#how-your-operating-system-locates-executables",
    "title": "How To Install Packages from the Jupyter Notebook",
    "section": "How your operating system locates executables",
    "text": "How your operating system locates executables\n\n!echo $PATH\n\n/home/explore/gems/bin:/home/explore/miniconda3/envs/pytorch/bin:/home/explore/miniconda3/condabin:/home/explore/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n\n\n\n!type python\n\npython is /home/explore/miniconda3/envs/pytorch/bin/python\n\n\nYou can optionally add the -a tag to see all available versions of the command in your current shell environment; for example:\n\n!type -a python\n\npython is /home/explore/miniconda3/envs/pytorch/bin/python\npython is /usr/bin/python\n\n\n\n!type -a conda\n\nconda is /home/explore/miniconda3/condabin/conda"
  },
  {
    "objectID": "posts/2021-01-13-installing-python-packages-from-jupyter.html#how-python-locates-packages",
    "href": "posts/2021-01-13-installing-python-packages-from-jupyter.html#how-python-locates-packages",
    "title": "How To Install Packages from the Jupyter Notebook",
    "section": "How Python locates packages",
    "text": "How Python locates packages\n\nimport sys\nsys.path\n\n['/home/explore/git/guillaume/blog/_notebooks',\n '/home/explore/miniconda3/envs/pytorch/lib/python38.zip',\n '/home/explore/miniconda3/envs/pytorch/lib/python3.8',\n '/home/explore/miniconda3/envs/pytorch/lib/python3.8/lib-dynload',\n '',\n '/home/explore/miniconda3/envs/pytorch/lib/python3.8/site-packages',\n '/home/explore/miniconda3/envs/pytorch/lib/python3.8/site-packages/IPython/extensions',\n '/home/explore/.ipython']\n\n\nBy default, the first place Python looks for a module is an empty path, meaning the current working directory. If the module is not found there, it goes down the list of locations until the module is found. You can find out which location has been used using the __path__ attribute of an imported module:\n\nimport numpy\nnumpy.__path__\n\n['/home/explore/miniconda3/envs/pytorch/lib/python3.8/site-packages/numpy']\n\n\nby printing the sys.path variables for each of the available python executables in my path, using Jupyter’s delightful ability to mix Python and bash commands in a single code block:\n\npaths = !type -a python\nfor path in set(paths):\n    path = path.split()[-1]\n    print(path)\n    !{path} -c \"import sys; print(sys.path)\"\n    print()\n\n/usr/bin/python\n['', '/usr/lib/python2.7', '/usr/lib/python2.7/plat-x86_64-linux-gnu', '/usr/lib/python2.7/lib-tk', '/usr/lib/python2.7/lib-old', '/usr/lib/python2.7/lib-dynload', '/home/explore/.local/lib/python2.7/site-packages', '/usr/local/lib/python2.7/dist-packages', '/usr/local/lib/python2.7/dist-packages/PyCapture2-0.0.0-py2.7-linux-x86_64.egg', '/usr/lib/python2.7/dist-packages']\n\n/home/explore/miniconda3/envs/pytorch/bin/python\n['', '/home/explore/miniconda3/envs/pytorch/lib/python38.zip', '/home/explore/miniconda3/envs/pytorch/lib/python3.8', '/home/explore/miniconda3/envs/pytorch/lib/python3.8/lib-dynload', '/home/explore/miniconda3/envs/pytorch/lib/python3.8/site-packages']\n\n\n\npip install will install in the Python in the same path:\n\n!type pip\n\npip is /home/explore/miniconda3/envs/pytorch/bin/pip\n\n\nconda install will install in the active conda envt\n\n!conda env list\n\n# conda environments:\n#\nbase                     /home/explore/miniconda3\nd059                     /home/explore/miniconda3/envs/d059\ndatacamp                 /home/explore/miniconda3/envs/datacamp\ndeeplearning_specialization     /home/explore/miniconda3/envs/deeplearning_specialization\ndeeplearning_specialization_keras     /home/explore/miniconda3/envs/deeplearning_specialization_keras\ndeeplearning_specialization_tf1     /home/explore/miniconda3/envs/deeplearning_specialization_tf1\ndrl_handson              /home/explore/miniconda3/envs/drl_handson\nfastai                   /home/explore/miniconda3/envs/fastai\ngan                      /home/explore/miniconda3/envs/gan\ngan_tensorflow           /home/explore/miniconda3/envs/gan_tensorflow\nmit_6002x                /home/explore/miniconda3/envs/mit_6002x\npytorch               *  /home/explore/miniconda3/envs/pytorch\nsqueezebox               /home/explore/miniconda3/envs/squeezebox\n\n\n\nThe reason both pip and conda default to the conda pytorch environment is that this is the Python environment I used to launch the notebook."
  },
  {
    "objectID": "posts/2021-01-13-installing-python-packages-from-jupyter.html#how-jupyter-executes-code-jupyter-kernels",
    "href": "posts/2021-01-13-installing-python-packages-from-jupyter.html#how-jupyter-executes-code-jupyter-kernels",
    "title": "How To Install Packages from the Jupyter Notebook",
    "section": "How Jupyter executes code: Jupyter Kernels",
    "text": "How Jupyter executes code: Jupyter Kernels\n\n!jupyter kernelspec list\n\nAvailable kernels:\n  python2    /home/explore/.local/share/jupyter/kernels/python2\n  python3    /home/explore/miniconda3/envs/pytorch/share/jupyter/kernels/python3\n\n\n\n!cat /home/explore/miniconda3/envs/pytorch/share/jupyter/kernels/python3/kernel.json\n\n{\n \"argv\": [\n  \"/home/explore/miniconda3/envs/pytorch/bin/python\",\n  \"-m\",\n  \"ipykernel_launcher\",\n  \"-f\",\n  \"{connection_file}\"\n ],\n \"display_name\": \"Python 3\",\n \"language\": \"python\"\n}\n\n\nIf you’d like to create a new kernel, you can do so using the jupyter ipykernel command; for example, I created the above kernels for my primary conda environments using the following as a template:\n$ source activate myenv\n$ python -m ipykernel install --user --name myenv --display-name \"Python (myenv)\""
  },
  {
    "objectID": "posts/2022-02-01-logbook-February-22.html",
    "href": "posts/2022-02-01-logbook-February-22.html",
    "title": "Logbook for February 22",
    "section": "",
    "text": "Thursday 2/3\nStephane Mallat - collège de France - Information et complexité video n°2: Estimation par maximum de vraisemblance"
  },
  {
    "objectID": "posts/2022-02-01-logbook-February-22.html#week-5---february-22",
    "href": "posts/2022-02-01-logbook-February-22.html#week-5---february-22",
    "title": "Logbook for February 22",
    "section": "",
    "text": "Thursday 2/3\nStephane Mallat - collège de France - Information et complexité video n°2: Estimation par maximum de vraisemblance"
  },
  {
    "objectID": "posts/2022-02-01-logbook-February-22.html#week-8---february-22",
    "href": "posts/2022-02-01-logbook-February-22.html#week-8---february-22",
    "title": "Logbook for February 22",
    "section": "Week 8 - February 22",
    "text": "Week 8 - February 22\nMonday 2/21\nStephane Mallat - collège de France - Information et complexité video n°3: Optimisation et modèles exponentiels\nTuesday 2/22\nAntonin Raffin (Stable Baselines 3 author) explains how to better evaluate RL agents using Rliable. Would like to test that."
  },
  {
    "objectID": "posts/2022-04-07-keep dotfiles in git.html",
    "href": "posts/2022-04-07-keep dotfiles in git.html",
    "title": "keep dotfiles in git",
    "section": "",
    "text": "as pointed by Jeremy Howard."
  },
  {
    "objectID": "posts/2022-04-07-keep dotfiles in git.html#source-of-inspiration",
    "href": "posts/2022-04-07-keep dotfiles in git.html#source-of-inspiration",
    "title": "keep dotfiles in git",
    "section": "",
    "text": "as pointed by Jeremy Howard."
  },
  {
    "objectID": "posts/2022-04-07-keep dotfiles in git.html#how-to-setup-it",
    "href": "posts/2022-04-07-keep dotfiles in git.html#how-to-setup-it",
    "title": "keep dotfiles in git",
    "section": "How to setup it",
    "text": "How to setup it\n\nprerequisites\nI consider I already have a git repo with my dotfiles from other machines.\nRepo: git@&lt;your_gitlab_address&gt;:&lt;your_id&gt;/dotfiles.git\nI keep one separate branch per machine. Current branches: master (empty), and WSL2.\nI am going to add a machine called iolab.\n\n\nfrom iolab - .cfg in $HOME\ngit init --bare $HOME/.cfg\nalias config='/usr/bin/git --git-dir=$HOME/.cfg/ --work-tree=$HOME'\nconfig config --local status.showUntrackedFiles no\necho \"alias config='/usr/bin/git --git-dir=$HOME/.cfg/ --work-tree=$HOME'\" &gt;&gt; $HOME/.bash_aliases\n\n\nfrom iolab - .cfg in /\nsudo mkdir /.cfg\nsudo chown uid:gid /.cfg\ngit init --bare /.cfg\nalias config='/usr/bin/git --git-dir=/.cfg/ --work-tree=/'\nconfig config --local status.showUntrackedFiles no\necho \"alias config='/usr/bin/git --git-dir=/.cfg/ --work-tree=/'\" &gt;&gt; $HOME/.bash_aliases\nAnd we can now run config status\n(base) [ 09:53:56 ][ id: ~ ]$ config status\n# On branch master\n#\n# Initial commit\n#\nnothing to commit (create/copy files and use \"git add\" to track)\nbut now we would like to create a new branch, and push all this to our central repo.\nFirst we have to set this central repo.\nconfig remote add origin git@&lt;your_gitlab_address&gt;:&lt;your_id&gt;/dotfiles.git\nconfig fetch\nBefore creating our branch, we have to commit something (to really create our local branch master)\nconfig add .bashrc\nconfig commit -m 'init with .bashrc'\nAnd then only we can create our branch iolab\nconfig branch iolab\nconfig checkout iolab\nconfig push --set-upstream origin iolab\nwe are now ready to use it"
  },
  {
    "objectID": "posts/2022-04-07-keep dotfiles in git.html#how-to-use-it",
    "href": "posts/2022-04-07-keep dotfiles in git.html#how-to-use-it",
    "title": "keep dotfiles in git",
    "section": "How to use it",
    "text": "How to use it\nconfig add .bash_aliases\nconfig commit -m'bash aliases'\nconfig push"
  },
  {
    "objectID": "posts/2022-04-07-keep dotfiles in git.html#how-to-setup-2-remote-repo",
    "href": "posts/2022-04-07-keep dotfiles in git.html#how-to-setup-2-remote-repo",
    "title": "keep dotfiles in git",
    "section": "How to setup 2 remote repo",
    "text": "How to setup 2 remote repo\nThere is a nice explanation abut how to work with multiple repos in https://jigarius.com/blog/multiple-git-remote-repositories.\nTo follow that, I will configure my dotfile repo from WSL2 to push to 2 remotes, one on gitlab (internal) and one on github.\nFor the moment it is only connected to gitlab.\n$ config remote -v\norigin  git@gitlab.michelin.com:janus/dotfiles.git (fetch)\norigin  git@gitlab.michelin.com:janus/dotfiles.git (push)\nMy github repo is at: https://github.com/castorfou/dotfiles.git (I use https, because of my local firewall)\n$ config remote set-url --add --push origin git@gitlab.michelin.com:janus/dotfiles.git\n$ config remote set-url --add --push origin https://github.com/castorfou/dotfiles.git\n$ config push origin GR_WSL2\nI have to get a token from github to access in https\nTo generate a token:\n\nLog into GitHub\nClick on your name / Avatar in the upper right corner and select Settings\nOn the left, click Developer settings\nSelect Personal access tokens and click Generate new token\nGive the token a description/name and select the scope of the token\n\nI selected repo only to facilitate pull, push, clone, and commit actions\nClick the link Read more about OAuth scopes for details about the permission sets\n\nClick Generate token\nCopy the token – this is your new password!\n\nLastly, to ensure the local computer remembers the token, we can enable caching of the credentials. This configures the computer to remember the complex token so that we dont have too.\ngit config --global credential.helper cache"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html",
    "href": "posts/2023-01-02-logbook-January-23.html",
    "title": "Logbook for January 23",
    "section": "",
    "text": "I have left on-going tests last week of 22.\nTrying to start a X-session on ubuntu 22.04 within this new version of WSL.\nDone it on a sandbox distro at Run gnome-session in Ubuntu LTS\nNow gnome-shell can be started from distro ubuntu-x11 by calling gnomeshell.sh\n\n\n\n\n\n\njupyter lab\nsetup my base_jupyter env jupyter lab in WSL\nNow jupyter lab starts automatically with distro ubuntu-22.04\nand can be restarted with sudo systemctl restart jupyterlab\nzotero\ncan install and use it including sync (otherwise no interest)\n\n\n\n\nget back to fastai lesson 8\nopened a ticket in wsl github : WSL some icons in taskbar for linux applications are defaulting to Tux (triaged to wslg)\n\n\n\nWorking with collab filtering (to fill NaN), inspired by fastai Lesson 8 - Practical Deep Learning for Coders 2022\nseems it takes 6x times longer to use collab_learner instead of directly embeddings\nI need to understand why. I know why, it was just a mistake in calling collab_learner(dls, n_factors, y_range=y_range) (forgot y_range=)"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#monday-0102",
    "href": "posts/2023-01-02-logbook-January-23.html#monday-0102",
    "title": "Logbook for January 23",
    "section": "",
    "text": "I have left on-going tests last week of 22.\nTrying to start a X-session on ubuntu 22.04 within this new version of WSL.\nDone it on a sandbox distro at Run gnome-session in Ubuntu LTS\nNow gnome-shell can be started from distro ubuntu-x11 by calling gnomeshell.sh"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#tuesday-0103",
    "href": "posts/2023-01-02-logbook-January-23.html#tuesday-0103",
    "title": "Logbook for January 23",
    "section": "",
    "text": "jupyter lab\nsetup my base_jupyter env jupyter lab in WSL\nNow jupyter lab starts automatically with distro ubuntu-22.04\nand can be restarted with sudo systemctl restart jupyterlab\nzotero\ncan install and use it including sync (otherwise no interest)"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#wednesday-0104",
    "href": "posts/2023-01-02-logbook-January-23.html#wednesday-0104",
    "title": "Logbook for January 23",
    "section": "",
    "text": "get back to fastai lesson 8\nopened a ticket in wsl github : WSL some icons in taskbar for linux applications are defaulting to Tux (triaged to wslg)"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#friday-0106",
    "href": "posts/2023-01-02-logbook-January-23.html#friday-0106",
    "title": "Logbook for January 23",
    "section": "",
    "text": "Working with collab filtering (to fill NaN), inspired by fastai Lesson 8 - Practical Deep Learning for Coders 2022\nseems it takes 6x times longer to use collab_learner instead of directly embeddings\nI need to understand why. I know why, it was just a mistake in calling collab_learner(dls, n_factors, y_range=y_range) (forgot y_range=)"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#tuesday-0109",
    "href": "posts/2023-01-02-logbook-January-23.html#tuesday-0109",
    "title": "Logbook for January 23",
    "section": "Tuesday 01/09",
    "text": "Tuesday 01/09\nI have continued my experimentations with collaborative filtering and embedding matrices. With nice results. I have played with parameters (y_range) and hyper parameters (wd). Will have to share with colleagues to get their feedback.\nI have started to use collab_learner with NN. But I have to better understand what is behind.\nContinue to listen to this lesson 8 (1:06). It is back to computer vision with convolution. I have less interest for these matters but I still like the way Jeremy uses Excel to illustrate all these concepts. Jeremy: the AI excel master."
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#thursday-0111",
    "href": "posts/2023-01-02-logbook-January-23.html#thursday-0111",
    "title": "Logbook for January 23",
    "section": "Thursday 01/11",
    "text": "Thursday 01/11\nThis is the end of Lesson 8 - Practical Deep Learning for Coders 2022\nAnd a perfect time to start Lesson 9 - Deep learning foundations to stable diffusion"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#monday-0116",
    "href": "posts/2023-01-02-logbook-January-23.html#monday-0116",
    "title": "Logbook for January 23",
    "section": "Monday 01/16",
    "text": "Monday 01/16\nStephane Mallat will give his 2023 course at College de France in the following weeks.\n\n\n\nimage.png\n\n\nI guess it will be a great time as always."
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#tuesday-0117",
    "href": "posts/2023-01-02-logbook-January-23.html#tuesday-0117",
    "title": "Logbook for January 23",
    "section": "Tuesday 01/17",
    "text": "Tuesday 01/17\n\nCtrl-C in gnome-terminal\nIn Windows Terminal (and it seems OSX as well), Ctrl-C has 2 behaviours - if some text is highlighted, then it means COPY - if nothing is selected, then it is INTERRUPT\nAnd I like this behaviour.\nUnfortunately it is not the case with gnome terminal. But what I did was to update shortcut options to map Copy with Ctrl-C.\n\n\n\nimage.png\n\n\nAnd automatically it remaps INTERRUPT with Ctrl-Shift-C.\nNot as good as Windows Terminal but good enough for now."
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#wednesday-0118",
    "href": "posts/2023-01-02-logbook-January-23.html#wednesday-0118",
    "title": "Logbook for January 23",
    "section": "Wednesday 01/18",
    "text": "Wednesday 01/18\n\nIssue on WSLg - detached window cannot be used\nJust opened an issue at Detached windows cannot be used (e.g. in gimp)\nI had opened another one in WSLg WSL some icons in taskbar for linux applications are defaulting to Tux (when set_app_id doesn’t match with .desktop file)"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#thursday-0119",
    "href": "posts/2023-01-02-logbook-January-23.html#thursday-0119",
    "title": "Logbook for January 23",
    "section": "Thursday 01/19",
    "text": "Thursday 01/19\n2 tips I have just used in RSS feed for my blog\nTo highlight some text from a file from jupyter\nuse | grep --color=always -z 'feed: true'\n\n!cat ../index.qmd | grep --color=always -z 'feed: true'\n\n---\ntitle: \"blog\"\nlisting:\n  contents: posts\n  sort: \"date desc\"\n  type: default\n  categories: true\n  sort-ui: false\n  filter-ui: true\n  feed: true\npage-layout: full\ntitle-block-banner: false\n---\n\n\n\n\n\nTo insert rescaled image into jupyter\nJust copy paste the image in a markdown cell:\n![image.png](attachment:24349bd1-4c85-4c51-833c-808bb8c82a38.png)\nvalidate cell to save this image file\nand turn this into html code\n&lt;div&gt;\n   &lt;img src=\"attachment:24349bd1-4c85-4c51-833c-808bb8c82a38.png\" width=\"200\"&gt;\n&lt;/div&gt;\n\n\n\ndiscord app in wsl\nfor a reason (maybe due to [snap] CA Certificates from /usr/local/share/ca-certificates are not used),\ndiscord snap cannot (ERR_CERT_AUTHORITY_INVALID) fetch data, complete its installation and cannot be used"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#monday-0123",
    "href": "posts/2023-01-02-logbook-January-23.html#monday-0123",
    "title": "Logbook for January 23",
    "section": "Monday 01/23",
    "text": "Monday 01/23\n\nIssue on WSLg - icons missing\nGot an answer from https://github.com/microsoft/wslg/issues/944#issuecomment-1399107496\n\nfor sublime-text, you can rename /var/lib/snapd/desktop/applications/sublime-text_subl.desktop to /var/lib/snapd/desktop/applications/sublime_text.desktop. Since the application reports “sublime_text” as their app_id, just rename its .desktop file to same as it’s app_id, thanks!\n\nNot exactly what I do: steps for sublime text in WSL"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#tuesday-0124",
    "href": "posts/2023-01-02-logbook-January-23.html#tuesday-0124",
    "title": "Logbook for January 23",
    "section": "Tuesday 01/24",
    "text": "Tuesday 01/24\nI would like to follow live coding sessions from Jeremy Howard.\n1st one at https://forums.fast.ai/t/live-coding-1/96649\nThose are entry level, but I am sure to learn thinks from it. And maybe detect why I have kernel dying when running stable diffusion inference from my WSL."
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#wednesday-0125",
    "href": "posts/2023-01-02-logbook-January-23.html#wednesday-0125",
    "title": "Logbook for January 23",
    "section": "Wednesday 01/25",
    "text": "Wednesday 01/25\nJust started watching Live coding sessions from fastai"
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#friday-0126",
    "href": "posts/2023-01-02-logbook-January-23.html#friday-0126",
    "title": "Logbook for January 23",
    "section": "Friday 01/26",
    "text": "Friday 01/26\nJust watched video #1 of Stephane Mallat 2023."
  },
  {
    "objectID": "posts/2023-01-02-logbook-January-23.html#monday-0130",
    "href": "posts/2023-01-02-logbook-January-23.html#monday-0130",
    "title": "Logbook for January 23",
    "section": "Monday 01/30",
    "text": "Monday 01/30\nJust watched Live coding session #3 from fastai"
  },
  {
    "objectID": "posts/2020-09-11-git-commit-without-password.html",
    "href": "posts/2020-09-11-git-commit-without-password.html",
    "title": "Git push to github without password",
    "section": "",
    "text": "By default everytime I push to github, I have a prompt asking for password.\nWould be great if I could leverage ssh keys to authenticate."
  },
  {
    "objectID": "posts/2020-09-11-git-commit-without-password.html#update-remote-from-https-to-ssh",
    "href": "posts/2020-09-11-git-commit-without-password.html#update-remote-from-https-to-ssh",
    "title": "Git push to github without password",
    "section": "Update remote from https to ssh",
    "text": "Update remote from https to ssh\nFrom https://stackoverflow.com/questions/14762034/push-to-github-without-a-password-using-ssh-key,\nFor example, a GitHub project like Git will have an HTTPS URL:\n\nhttps://github.com/&lt;Username&gt;/&lt;Project&gt;.git\nAnd the SSH one:\n\ngit@github.com:&lt;Username&gt;/&lt;Project&gt;.git\nYou can do:\n\ngit remote set-url origin git@github.com:&lt;Username&gt;/&lt;Project&gt;.git\nto change the URL.\nIn my case I have\n(xgboost) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog$ git remote -v\norigin  https://github.com/castorfou/guillaume_blog.git (fetch)\norigin  https://github.com/castorfou/guillaume_blog.git (push)\nI have just to modify:\ngit remote set-url origin git@github.com:castorfou/guillaume_blog.git"
  },
  {
    "objectID": "posts/2020-09-11-git-commit-without-password.html#results",
    "href": "posts/2020-09-11-git-commit-without-password.html#results",
    "title": "Git push to github without password",
    "section": "Results",
    "text": "Results\nIt looks like working:\n(xgboost) guillaume@LL11LPC0PQARQ:~/git/guillaume_blog$ git push\nCounting objects: 4, done.\nDelta compression using up to 8 threads.\nCompressing objects: 100% (4/4), done.\nWriting objects: 100% (4/4), 1.59 KiB | 812.00 KiB/s, done.\nTotal 4 (delta 2), reused 0 (delta 0)\nremote: Resolving deltas: 100% (2/2), completed with 2 local objects.\nTo github.com:castorfou/guillaume_blog.git\n   4013108..ae78b99  master -&gt; master"
  },
  {
    "objectID": "posts/2020-09-11-git-commit-without-password.html#drawback-doesnt-work-behing-a-firewall",
    "href": "posts/2020-09-11-git-commit-without-password.html#drawback-doesnt-work-behing-a-firewall",
    "title": "Git push to github without password",
    "section": "Drawback: doesn’t work behing a firewall",
    "text": "Drawback: doesn’t work behing a firewall\n{% include alert.html text=“To find a solution to use a proxy” %}\nHere are 2 ways to be tested: https://stackoverflow.com/questions/1728934/accessing-a-git-repository-via-ssh-behind-a-firewall https://stackoverflow.com/questions/18604719/how-to-configure-git-to-clone-repo-from-github-behind-a-proxy-server?noredirect=1&lq=1"
  },
  {
    "objectID": "posts/2020-12-13-from-cron-to-anacron.html",
    "href": "posts/2020-12-13-from-cron-to-anacron.html",
    "title": "From cron to anacron",
    "section": "",
    "text": "I run generate_plots.sh daily at 9:30 AM. However what happens if my PC is off at that time, will have to wait another uptime at 9:30 AM.\nSolution is to move from cron to anacron.\nFrom https://www.putorius.net/cron-vs-anacron.html:\n\n\n\nalt text"
  },
  {
    "objectID": "posts/2020-12-13-from-cron-to-anacron.html#anacron-folders",
    "href": "posts/2020-12-13-from-cron-to-anacron.html#anacron-folders",
    "title": "From cron to anacron",
    "section": ".anacron folders",
    "text": ".anacron folders\nCreate a .anacron folder in your home directory and in it two subfolders, etc and spool\n\n!mkdir -p ~/.anacron/{etc,spool}"
  },
  {
    "objectID": "posts/2020-12-13-from-cron-to-anacron.html#anacrontab",
    "href": "posts/2020-12-13-from-cron-to-anacron.html#anacrontab",
    "title": "From cron to anacron",
    "section": "anacrontab",
    "text": "anacrontab\nCreate a new file ~/.anacron/etc/anacrontab with the following content:\n# ~/.anacron/etc/anacrontab: configuration file for anacron\n\n# See anacron(8) and anacrontab(5) for details.\n\nSHELL=/bin/bash\nPATH=/usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin:/home/explore/miniconda3/bin:/home/explore/miniconda3/condabin:/home/explore/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n\n# period  delay  job-identifier  command\n1         10     squeezebox         ~/git/guillaume/squeezebox/generate_plots.sh"
  },
  {
    "objectID": "posts/2020-12-13-from-cron-to-anacron.html#start-anacron",
    "href": "posts/2020-12-13-from-cron-to-anacron.html#start-anacron",
    "title": "From cron to anacron",
    "section": "start anacron",
    "text": "start anacron\nAdd the following line to your crontab using crontab -e:\n@hourly /usr/sbin/anacron -s -t $HOME/.anacron/etc/anacrontab -S $HOME/.anacron/spool\nAnd remove squeezebox entry from crontab.\n\n!crontab -l\n\n# NVIDIA SDK Manager updater\n# NVIDIA SDK Manager updater\n0 12 */7 * * /bin/bash /home/explore/.nvsdkm/.updater/updater.sh\n#30 9 * * * ~/git/guillaume/squeezebox/generate_plots.sh\n@hourly /usr/sbin/anacron -s -t $HOME/.anacron/etc/anacrontab -S $HOME/.anacron/spool"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "This is more a journal where I am adding entries about my (baby steps) learnings. It is likely to be centered around python, git, data-science, … I have been strongly inspired by Rachel Thomas explaining why I should blog. Specially when starting such a journey to turn a datascientist.\nMy intent would be to regularly add entries to this blog. Ideally at least once a week. Maybe only short ones, the point being to stick on this frequent activity. If it takes days to write posts I am pretty sure I won’t do it. Those entries are personnal thoughts and not those of my employer Michelin."
  },
  {
    "objectID": "about.html#this-blog",
    "href": "about.html#this-blog",
    "title": "About",
    "section": "",
    "text": "This is more a journal where I am adding entries about my (baby steps) learnings. It is likely to be centered around python, git, data-science, … I have been strongly inspired by Rachel Thomas explaining why I should blog. Specially when starting such a journey to turn a datascientist.\nMy intent would be to regularly add entries to this blog. Ideally at least once a week. Maybe only short ones, the point being to stick on this frequent activity. If it takes days to write posts I am pretty sure I won’t do it. Those entries are personnal thoughts and not those of my employer Michelin."
  },
  {
    "objectID": "about.html#me",
    "href": "about.html#me",
    "title": "About",
    "section": "Me",
    "text": "Me\nI am Guillaume Ramelet. I am 46 (in 2022). Father of 3. And have been working for a French tire company for 15+ years. I am French and as you can read English is not my mother tongue (but using English is a good exercise, isn’t it)"
  }
]