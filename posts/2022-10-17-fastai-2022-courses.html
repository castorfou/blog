<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.269">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2022-10-17">
<meta name="description" content="fastai courses 2022">

<title>Guillaume’s blog - Practical Deep Learning for Coders</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon_small.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-12YC1FPHWN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-12YC1FPHWN', { 'anonymize_ip': true});
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script>
<script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>


<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="Guillaume’s blog - Practical Deep Learning for Coders">
<meta name="twitter:description" content="fastai courses 2022">
<meta name="twitter:image" content="https://castorfou.github.io/images/icons/fastai.png">
<meta name="twitter:image-height" content="234">
<meta name="twitter:image-width" content="576">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Guillaume’s blog</span>
    </a>
  </div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/castorfou"><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/GuillaumeRamel1"><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
              <div class="quarto-toggle-container">
                  <a href="" class="quarto-color-scheme-toggle nav-link" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
              </div>
              <div id="quarto-search" class="" title="Search"></div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Practical Deep Learning for Coders</h1>
                  <div>
        <div class="description">
          fastai courses 2022
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">fastai</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">October 17, 2022</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#source-of-inspiration" id="toc-source-of-inspiration" class="nav-link active" data-scroll-target="#source-of-inspiration">Source of inspiration</a></li>
  <li><a href="#setup-local-conda-environment-for-fastai" id="toc-setup-local-conda-environment-for-fastai" class="nav-link" data-scroll-target="#setup-local-conda-environment-for-fastai">Setup local conda environment for fastai</a>
  <ul class="collapse">
  <li><a href="#conda-environment" id="toc-conda-environment" class="nav-link" data-scroll-target="#conda-environment">conda environment</a></li>
  <li><a href="#setup-kaggle" id="toc-setup-kaggle" class="nav-link" data-scroll-target="#setup-kaggle">setup kaggle</a></li>
  <li><a href="#get-materials-from-github" id="toc-get-materials-from-github" class="nav-link" data-scroll-target="#get-materials-from-github">get materials from github</a></li>
  </ul></li>
  <li><a href="#lesson-1---getting-started" id="toc-lesson-1---getting-started" class="nav-link" data-scroll-target="#lesson-1---getting-started">Lesson 1 - Getting started</a>
  <ul class="collapse">
  <li><a href="#deep-learning-introduction" id="toc-deep-learning-introduction" class="nav-link" data-scroll-target="#deep-learning-introduction">Deep learning introduction</a></li>
  <li><a href="#recent-progress" id="toc-recent-progress" class="nav-link" data-scroll-target="#recent-progress">Recent progress</a></li>
  <li><a href="#self-learning-of-features" id="toc-self-learning-of-features" class="nav-link" data-scroll-target="#self-learning-of-features">Self learning of features</a></li>
  <li><a href="#vision-can-be-used-in-many-different-ways" id="toc-vision-can-be-used-in-many-different-ways" class="nav-link" data-scroll-target="#vision-can-be-used-in-many-different-ways">Vision can be used in many different ways</a></li>
  <li><a href="#tools---pytorch-jupyter-notebooks-kaggle" id="toc-tools---pytorch-jupyter-notebooks-kaggle" class="nav-link" data-scroll-target="#tools---pytorch-jupyter-notebooks-kaggle">Tools - pytorch, jupyter notebooks, kaggle</a></li>
  <li><a href="#going-through-this-is-it-a-bird-notebook" id="toc-going-through-this-is-it-a-bird-notebook" class="nav-link" data-scroll-target="#going-through-this-is-it-a-bird-notebook">Going through this “is it a bird?” notebook</a>
  <ul class="collapse">
  <li><a href="#datablock" id="toc-datablock" class="nav-link" data-scroll-target="#datablock">DataBlock</a></li>
  <li><a href="#learners" id="toc-learners" class="nav-link" data-scroll-target="#learners">learners</a></li>
  <li><a href="#predict" id="toc-predict" class="nav-link" data-scroll-target="#predict">predict</a></li>
  </ul></li>
  <li><a href="#and-beyond-image-recognition" id="toc-and-beyond-image-recognition" class="nav-link" data-scroll-target="#and-beyond-image-recognition">and beyond image recognition</a>
  <ul class="collapse">
  <li><a href="#segmentation" id="toc-segmentation" class="nav-link" data-scroll-target="#segmentation">Segmentation</a></li>
  <li><a href="#tabular-analysis" id="toc-tabular-analysis" class="nav-link" data-scroll-target="#tabular-analysis">Tabular analysis</a></li>
  <li><a href="#collaborative-filtering-recommandation-system" id="toc-collaborative-filtering-recommandation-system" class="nav-link" data-scroll-target="#collaborative-filtering-recommandation-system">Collaborative filtering (recommandation system)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#lesson-2---deployment" id="toc-lesson-2---deployment" class="nav-link" data-scroll-target="#lesson-2---deployment">Lesson 2 - Deployment</a>
  <ul class="collapse">
  <li><a href="#gradio-huggingface-spaces" id="toc-gradio-huggingface-spaces" class="nav-link" data-scroll-target="#gradio-huggingface-spaces">Gradio + HuggingFace Spaces</a>
  <ul class="collapse">
  <li><a href="#create-hf-repo" id="toc-create-hf-repo" class="nav-link" data-scroll-target="#create-hf-repo">create HF repo</a></li>
  <li><a href="#create-1st-gradio-app-and-host-it" id="toc-create-1st-gradio-app-and-host-it" class="nav-link" data-scroll-target="#create-1st-gradio-app-and-host-it">create 1st gradio app and host it</a></li>
  <li><a href="#train-and-export-a-dl-model" id="toc-train-and-export-a-dl-model" class="nav-link" data-scroll-target="#train-and-export-a-dl-model">train and export a DL model</a></li>
  <li><a href="#integrate-it-with-gradio" id="toc-integrate-it-with-gradio" class="nav-link" data-scroll-target="#integrate-it-with-gradio">integrate it with gradio</a></li>
  </ul></li>
  <li><a href="#fastsetup" id="toc-fastsetup" class="nav-link" data-scroll-target="#fastsetup">fastsetup</a></li>
  <li><a href="#api" id="toc-api" class="nav-link" data-scroll-target="#api">API</a>
  <ul class="collapse">
  <li><a href="#gradio-streamlit" id="toc-gradio-streamlit" class="nav-link" data-scroll-target="#gradio-streamlit">gradio, streamlit</a></li>
  <li><a href="#gradio-hf-api" id="toc-gradio-hf-api" class="nav-link" data-scroll-target="#gradio-hf-api">gradio, hf API</a></li>
  <li><a href="#example-from-js" id="toc-example-from-js" class="nav-link" data-scroll-target="#example-from-js">example from js</a></li>
  </ul></li>
  <li><a href="#gh-pages" id="toc-gh-pages" class="nav-link" data-scroll-target="#gh-pages">GH pages</a>
  <ul class="collapse">
  <li><a href="#by-generating-from-fastpages" id="toc-by-generating-from-fastpages" class="nav-link" data-scroll-target="#by-generating-from-fastpages">by generating from fastpages</a></li>
  <li><a href="#or-by-forking-an-existing-one-e.g.-tinypets" id="toc-or-by-forking-an-existing-one-e.g.-tinypets" class="nav-link" data-scroll-target="#or-by-forking-an-existing-one-e.g.-tinypets">or by forking an existing one (e.g.&nbsp;tinypets)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#lesson-3---neural-net-foundations" id="toc-lesson-3---neural-net-foundations" class="nav-link" data-scroll-target="#lesson-3---neural-net-foundations">Lesson 3 - Neural net foundations</a>
  <ul class="collapse">
  <li><a href="#timm" id="toc-timm" class="nav-link" data-scroll-target="#timm">timm</a></li>
  <li><a href="#using-in-an-app" id="toc-using-in-an-app" class="nav-link" data-scroll-target="#using-in-an-app">Using in an app</a></li>
  <li><a href="#applying-this-on-my-own-app-cheeses" id="toc-applying-this-on-my-own-app-cheeses" class="nav-link" data-scroll-target="#applying-this-on-my-own-app-cheeses">Applying this on my own app: cheeses</a></li>
  <li><a href="#inside-nn" id="toc-inside-nn" class="nav-link" data-scroll-target="#inside-nn">Inside NN</a></li>
  <li><a href="#using-microsoft-excel" id="toc-using-microsoft-excel" class="nav-link" data-scroll-target="#using-microsoft-excel">Using Microsoft excel</a></li>
  <li><a href="#next-lesson" id="toc-next-lesson" class="nav-link" data-scroll-target="#next-lesson">Next lesson</a></li>
  </ul></li>
  <li><a href="#lesson-4---natural-language-nlp" id="toc-lesson-4---natural-language-nlp" class="nav-link" data-scroll-target="#lesson-4---natural-language-nlp">Lesson 4 - Natural Language (NLP)</a></li>
  <li><a href="#lesson-5---from-scratch-model" id="toc-lesson-5---from-scratch-model" class="nav-link" data-scroll-target="#lesson-5---from-scratch-model">Lesson 5 - From-scratch model</a>
  <ul class="collapse">
  <li><a href="#linear-model-then-deep-learning-model" id="toc-linear-model-then-deep-learning-model" class="nav-link" data-scroll-target="#linear-model-then-deep-learning-model">linear model then deep learning model</a></li>
  <li><a href="#why-you-should-use-a-framework" id="toc-why-you-should-use-a-framework" class="nav-link" data-scroll-target="#why-you-should-use-a-framework">Why you should use a framework</a></li>
  </ul></li>
  <li><a href="#lesson-6---random-forests" id="toc-lesson-6---random-forests" class="nav-link" data-scroll-target="#lesson-6---random-forests">Lesson 6 - Random forests</a></li>
  <li><a href="#lesson-7---collaborative-filtering" id="toc-lesson-7---collaborative-filtering" class="nav-link" data-scroll-target="#lesson-7---collaborative-filtering">Lesson 7 - Collaborative filtering</a></li>
  <li><a href="#lesson-8---convolutions-cnns" id="toc-lesson-8---convolutions-cnns" class="nav-link" data-scroll-target="#lesson-8---convolutions-cnns">Lesson 8 - Convolutions (CNNs)</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<section id="source-of-inspiration" class="level1">
<h1>Source of inspiration</h1>
<p>Many sources about that, pointing all to <a href="https://course.fast.ai/" class="uri">https://course.fast.ai/</a></p>
<p>This is version 5 of this course.</p>
</section>
<section id="setup-local-conda-environment-for-fastai" class="level1">
<h1>Setup local conda environment for fastai</h1>
<section id="conda-environment" class="level2">
<h2 class="anchored" data-anchor-id="conda-environment">conda environment</h2>
<div class="cell" data-execution="{&quot;iopub.execute_input&quot;:&quot;2022-11-15T07:03:32.364344Z&quot;,&quot;iopub.status.busy&quot;:&quot;2022-11-15T07:03:32.363693Z&quot;,&quot;iopub.status.idle&quot;:&quot;2022-11-15T07:03:32.520173Z&quot;,&quot;shell.execute_reply&quot;:&quot;2022-11-15T07:03:32.519165Z&quot;,&quot;shell.execute_reply.started&quot;:&quot;2022-11-15T07:03:32.364287Z&quot;}" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>cat <span class="op">~/</span>_conda_env<span class="op">/</span>fastai.txt</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>conda create -n fastai python=3.9
conda activate fastai
conda install ipykernel
python -m ipykernel install --user --name=fastai
conda install -c fastchan fastai nbdev
pip install gradio
pip install kaggle


# update
conda activate fastai
conda update -c fastchan fastai nbdev
pip install -U gradio </code></pre>
</div>
</div>
</section>
<section id="setup-kaggle" class="level2">
<h2 class="anchored" data-anchor-id="setup-kaggle">setup kaggle</h2>
<p>And I have to setup kaggle locally:</p>
<ul>
<li>[already done] <code>pip install kaggle</code> inside my fastai env</li>
<li>create a token from my kaggle profile <a href="https://www.kaggle.com/guillaumeramelet/account">page</a></li>
<li>move this <code>kaggle.json</code> into <code>~/.kaggle/kaggle.json</code></li>
<li><code>chmod 600 /home/guillaume/.kaggle/kaggle.json</code></li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/c8926a88-d5b7-4214-ac5d-bcaf818f8c59-1-3a059c3a-b170-4943-b7bd-c44c96211fa3.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
</section>
<section id="get-materials-from-github" class="level2">
<h2 class="anchored" data-anchor-id="get-materials-from-github">get materials from github</h2>
<p><a href="https://github.com/fastai/course22/">Github fastai/course22</a> is where you’ll find the notebooks, slides, and spreadsheets for the 2022 edition of Practical Deep Learning for Coders. we can get a local version from .</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> ~/git</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> clone https://github.com/fastai/course22.git </span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="bu">cd</span> course22</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/a63057aa-0968-4c37-95fb-369f8e4d3ae5-1-31e16cdc-010d-4056-b275-a5feb523c752.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="lesson-1---getting-started" class="level1">
<h1>Lesson 1 - Getting started</h1>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/9206f93d-2255-404a-87b2-a87fbf7dc8bc-1-f65839a7-cf1c-4da2-a395-7818e5241abe.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<blockquote class="blockquote">
<p>In this lesson you’re going to hit the ground running – in the first five minutes you’ll see a complete end to end example of training and using a model that’s so advanced it was considered at the cutting edge of research capabilities in 2015.<br>
So, let’s get started!</p>
</blockquote>
<p><a href="https://course.fast.ai/Lessons/lesson1.html" class="uri">https://course.fast.ai/Lessons/lesson1.html</a></p>
<section id="deep-learning-introduction" class="level2">
<h2 class="anchored" data-anchor-id="deep-learning-introduction">Deep learning introduction</h2>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/f3d59743-04e9-4fdb-b22e-e806b84aa958-1-d9a38f06-b9ab-4b1c-8dca-8187fbb0355c.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<p>In 2015, nearly impossible to recognize a bird with CS. And Jeremy doing that in 2 minutes ;)</p>
</section>
<section id="recent-progress" class="level2">
<h2 class="anchored" data-anchor-id="recent-progress">Recent progress</h2>
<p>After this brief demonstration, Jeremy shared what he remmbers about recent progress in AI such as:</p>
<ul>
<li><p>artworks: Dall-e, midjourney to create images from text</p></li>
<li><p>explaining jokes: Google Pathways Language Model (PaLM) to explain jokes or run mathematical proof</p></li>
</ul>
</section>
<section id="self-learning-of-features" class="level2">
<h2 class="anchored" data-anchor-id="self-learning-of-features">Self learning of features</h2>
<p>Then classical but nice explanation that NN learns features (features are not given or coded) and illustrates that with Matt Zeiler and Rob Fergus works</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/a855fd4d-0ffb-4a62-bd66-2b6feaf8bdc0-1-374144e3-fa7b-4cf5-ba83-6a1d37a72288.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
</section>
<section id="vision-can-be-used-in-many-different-ways" class="level2">
<h2 class="anchored" data-anchor-id="vision-can-be-used-in-many-different-ways">Vision can be used in many different ways</h2>
<p>And it is of course used to classify images, but all these techniques can be combined out of this field for example:</p>
<ul>
<li>recognize sound by transforming sound waves into pictures (<a href="https://forums.fast.ai/t/share-your-work-here/27676/40">Ethan Sutin</a>)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/f67b71f4-57d0-4494-b202-114f06b7fed3-2-521368e2-f88d-4fd0-a52c-d3ddbef3cfc6.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<ul>
<li>turn timeseries into pictures (<a href="https://forums.fast.ai/t/time-series-sequential-data-study-group/29686">Ignacio Oguiza</a>)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/f67b71f4-57d0-4494-b202-114f06b7fed3-3-99638923-aae2-43cf-aaa2-ada718cf6cae.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<ul>
<li>pictures from mouse movements (<a href="https://forums.fast.ai/t/new-blog-post-user-classification-by-mouse-movements/2595">Gleb Esman</a>)</li>
</ul>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/f67b71f4-57d0-4494-b202-114f06b7fed3-1-3e04cfbd-19d4-49a3-922e-70da10f0bf44.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
</section>
<section id="tools---pytorch-jupyter-notebooks-kaggle" class="level2">
<h2 class="anchored" data-anchor-id="tools---pytorch-jupyter-notebooks-kaggle">Tools - pytorch, jupyter notebooks, kaggle</h2>
<p>For this course Jeremy suggests to use the kaggle cloud server.</p>
<p>If using someone else notebook, just upvote and click <code>Copy &amp; Edit</code></p>
<p><a href="https://www.kaggle.com/code/guillaumeramelet/jupyter-notebook-101/edit" class="uri">https://www.kaggle.com/code/guillaumeramelet/jupyter-notebook-101/edit</a></p>
<p>And now some hands-on starting with <code>Is it a bird?</code> <a href="https://www.kaggle.com/code/guillaumeramelet/is-it-a-bird-creating-a-model-from-your-own-data/edit">notebook</a>.</p>
<p>And aside note: Jeremy is running all the presentation through Jupyter notebook and <a href="https://rise.readthedocs.io/en/stable/">RISE</a></p>
<p>It’s a good idea to ensure you’re running the latest version of any libraries you need.</p>
<p><code>!pip install -Uqq libraries</code> upgrades to the latest version of libraries (fastai for example)</p>
</section>
<section id="going-through-this-is-it-a-bird-notebook" class="level2">
<h2 class="anchored" data-anchor-id="going-through-this-is-it-a-bird-notebook">Going through this “is it a bird?” notebook</h2>
<p>Jeremy shares best practices and steps</p>
<p>Such as viewing your data between each steps</p>
<p>Jeremy uses a lot of functional programming it is why we see things like <a href="https://www.geeksforgeeks.org/python-map-function/">map</a> used a lot.</p>
<section id="datablock" class="level3">
<h3 class="anchored" data-anchor-id="datablock">DataBlock</h3>
<p>Using Datablocks API</p>
<blockquote class="blockquote">
<p>To train a model, we’ll need DataLoaders, which is an object that contains a training set (the images used to create a model) and a validation set (the images used to check the accuracy of a model – not used during training). In fastai we can create that easily using a DataBlock, and view sample images from it:</p>
</blockquote>
<p>And Jeremy explains the logic between the 5 arguments needed to create a DataBlock:</p>
<ul>
<li><p>blocks: tupple with type of inputs and output</p></li>
<li><p>get_items: to get all data, here it points to a function to get list of image fileS</p></li>
<li><p>splitter: method to split between training set and validation set</p></li>
<li><p>get_y: to kown labels, here it is a function</p></li>
<li><p>item_tfms: which transformation to apply</p></li>
</ul>
<p>And from a DataBlock you create dataloaders (dls) provding (path for images; and bs (batch size))</p>
</section>
<section id="learners" class="level3">
<h3 class="anchored" data-anchor-id="learners">learners</h3>
<p>This is a key part.</p>
<p>Learners are taking 3 arguments: dataloaders, model, metric</p>
<p>And vision models can be from <a href="https://timm.fast.ai/">timm</a>.</p>
<p>Here we train a pre-trained model, which is called fine_tune and we do it on 3 epochs.</p>
</section>
<section id="predict" class="level3">
<h3 class="anchored" data-anchor-id="predict">predict</h3>
<p>Just providing an item to <code>lean.predict</code> will return <code>label</code>, <code>tensor value</code>, <code>probability</code></p>
<p>And it is why we have such outputs</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/245ad086-5bae-4405-aeb7-bcfd2c6eb798-1-18981c69-5b80-4d5b-a8c6-24710ba3d0fb.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
</section>
</section>
<section id="and-beyond-image-recognition" class="level2">
<h2 class="anchored" data-anchor-id="and-beyond-image-recognition">and beyond image recognition</h2>
<section id="segmentation" class="level3">
<h3 class="anchored" data-anchor-id="segmentation">Segmentation</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/1d6931ed-c358-4c9c-a75d-e22d417160ce-1-7d714c96-df7f-4758-9e69-93aa3a810658.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<p>And here we don’t have datablock but direclty dataloaders</p>
</section>
<section id="tabular-analysis" class="level3">
<h3 class="anchored" data-anchor-id="tabular-analysis">Tabular analysis</h3>
<p>Here again no need for DataBlock but a direct use of <code>TabularDataLoaders</code></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/3850c635-af2c-401c-9cf3-0e38301b8957-1-83f9e7f9-0495-4d89-82c5-15e21bddaa31.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<p>And the <code>tabular_learner</code> wich takes dls and metric.</p>
</section>
<section id="collaborative-filtering-recommandation-system" class="level3">
<h3 class="anchored" data-anchor-id="collaborative-filtering-recommandation-system">Collaborative filtering (recommandation system)</h3>
</section>
</section>
</section>
<section id="lesson-2---deployment" class="level1">
<h1>Lesson 2 - Deployment</h1>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/6deea125-0962-4449-89e7-602fa5f876f5-1-dd1b59e1-eaa3-486f-b8ac-519f4ba1e3a8.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<blockquote class="blockquote">
<p>Today you’ll be designing your own machine learning project, creating your own dataset, training a model using your data, and finally deploying an application on the web. We’ll be using a particular deployment target called <a href="https://huggingface.co/spaces">Hugging Face Space</a> with <a href="https://gradio.app/">Gradio</a>, and will also see how to use JavaScript to implement an interface in the browser. Deploying to other services will look very similar to the approach you’ll study in this lesson.</p>
</blockquote>
<p><a href="https://course.fast.ai/Lessons/lesson2.html" class="uri">https://course.fast.ai/Lessons/lesson2.html</a></p>
<p>In this lesson we will use gradio + huggingface spaces.</p>
<p>Jeremy starts by training a vision classifier and use this 1st model to clean labels using <code>ImageClassifierCleaner</code></p>
<p>This is not specific to vision.</p>
<section id="gradio-huggingface-spaces" class="level2">
<h2 class="anchored" data-anchor-id="gradio-huggingface-spaces">Gradio + HuggingFace Spaces</h2>
<section id="create-hf-repo" class="level3">
<h3 class="anchored" data-anchor-id="create-hf-repo">create HF repo</h3>
<p>Create this <a href="https://huggingface.co/spaces/Guillaume63/minima">minima</a> space from HF.</p>
<p>Aside the explanation on HF, Jeremy shares how useful <a href="https://github.com/shiftkey/desktop/releases">Github Desktop</a> is.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/15d3e6f7-032e-49ca-8ff1-6846909cd2a5-1-f95a61af-e56e-4650-b51a-c9a017744a5d.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
</section>
<section id="create-1st-gradio-app-and-host-it" class="level3">
<h3 class="anchored" data-anchor-id="create-1st-gradio-app-and-host-it">create 1st gradio app and host it</h3>
<p>Create app.py as instructed in our freshly created HF space. Commit Push (using github desktop). Back to HF interface, something is being built. and voila</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/a75f8c4f-d400-4343-8080-e5b4dcc749a6-1-46b3093a-b3cb-45dc-82e7-30e6d9e8423a.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<p>Nothing new because I played with <a href="../posts/2022-10-12-gradio_huggingface.html">gradio and HF</a> couple of weeks ago.</p>
<p>We know have a basic app hosted. We can just integrate a deep learning model.</p>
</section>
<section id="train-and-export-a-dl-model" class="level3">
<h3 class="anchored" data-anchor-id="train-and-export-a-dl-model">train and export a DL model</h3>
<p>And for that Jeremy has setup <a href="https://www.kaggle.com/code/guillaumeramelet/saving-a-basic-fastai-model/edit">something on kaggle</a></p>
<p>They key (and new) part here is</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>learn.export(<span class="st">'model.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>Finally, open the Kaggle sidebar on the right if it’s not already, and find the section marked “Output”. Open the /kaggle/working folder, and you’ll see model.pkl. Click on it, then click on the menu on the right that appears, and choose “Download”. After a few seconds, your model will be downloaded to your computer, where you can then create your app that uses the model.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/64ceac72-ba74-41b6-a8f8-492fc045312d-1-395df238-6c39-4ca7-87fa-812471437c69.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<p>And copy/past it to your local minima repo. Push it to HF.</p>
</section>
<section id="integrate-it-with-gradio" class="level3">
<h3 class="anchored" data-anchor-id="integrate-it-with-gradio">integrate it with gradio</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/1050ea4d-4e98-4c77-b7e2-c0edbaa51443-1-8dfac218-e7a8-4b71-a053-eea355eb97c5.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<p>And Jeremy illustrates how to do it with a notebook and nbdev. Exactly as I did in <a href="../posts/2022-10-12-gradio_huggingface.html">gradio and huggingface - handson</a></p>
<section id="load-model" class="level4">
<h4 class="anchored" data-anchor-id="load-model">load model</h4>
<p>Main parts are to load the model with</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> load_learner(<span class="st">'model.pkl'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="run-prediction" class="level4">
<h4 class="anchored" data-anchor-id="run-prediction">run prediction</h4>
<p>to run a prediction with</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>pred, idx, probs <span class="op">=</span> learn.predict(img)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="call-prediction-through-a-function" class="level4">
<h4 class="anchored" data-anchor-id="call-prediction-through-a-function">call prediction through a function</h4>
<p>and to create the <code>classify_image</code> function as expected by gradio</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>categories <span class="op">=</span> (<span class="st">'Dog'</span>, <span class="st">'Cat'</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify_image(img):</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    pred, idx, probs <span class="op">=</span> learn.predict(img)</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">dict</span>(<span class="bu">zip</span>(categories, <span class="bu">map</span>(<span class="bu">float</span>, probs))))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>and this return part is quite complex because gradio cannot deal with Tensors.</p>
</section>
<section id="create-gradio-ui" class="level4">
<h4 class="anchored" data-anchor-id="create-gradio-ui">create gradio UI</h4>
<p>There is now the gradio interface that takes image and returns dictionary.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>image <span class="op">=</span> gr.inputs.Image(shape<span class="op">=</span>(<span class="dv">192</span>, <span class="dv">192</span>))</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>label <span class="op">=</span> gr.outputs.Label()</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>examples <span class="op">=</span> [<span class="st">'dog.jpg'</span>, <span class="st">'cat.jpg'</span>, <span class="st">'dunno.jpg'</span>]</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>intf <span class="op">=</span> gr.Interface(fn<span class="op">=</span>classify_image, inputs<span class="op">=</span>image, outputs<span class="op">=</span>label, examples<span class="op">=</span>examples)</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>intf.launch(inline<span class="op">=</span><span class="va">False</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="export-as-app.py" class="level4">
<h4 class="anchored" data-anchor-id="export-as-app.py">export as app.py</h4>
<p>And export as app.py and for that Jeremy uses a slightly different version that I used</p>
<p>Mine;</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> nbdev<span class="op">;</span> nbdev.export.nb_export(<span class="st">'app.ipynb'</span>, lib_path<span class="op">=</span><span class="st">'.'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>His:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> nbdev.export <span class="im">import</span> notebook2script</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>notebook2script(<span class="st">'app.ipynb'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><a href="https://huggingface.co/spaces/jph00/testing" class="uri">https://huggingface.co/spaces/jph00/testing</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/eb0aa304-6cbc-438c-9ce9-d754ed437cf0-1-4d65166a-5f79-431a-9bf5-e7192e6815ae.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
</section>
</section>
</section>
<section id="fastsetup" class="level2">
<h2 class="anchored" data-anchor-id="fastsetup">fastsetup</h2>
<p><a href="https://github.com/fastai/fastsetup" class="uri">https://github.com/fastai/fastsetup</a></p>
<p>clone it with github desktop (will do cmd line I don’t have the option Jeremy has)</p>
<p><strong>install conda mamba</strong> (if needed)</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="ex">./setup-conda.sh</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>install fastai from scratch</strong></p>
<div class="sourceCode" id="cb12"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> create <span class="at">-n</span> fastai python=3.9</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate fastai</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> install <span class="at">-c</span> fastchan fastai nbdev</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install gradio</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p><strong>update to up-to-date versions</strong></p>
<div class="sourceCode" id="cb13"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> activate fastai</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="ex">conda</span> update <span class="at">-c</span> fastchan fastai nbdev</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="ex">pip</span> install <span class="at">-U</span> gradio</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="api" class="level2">
<h2 class="anchored" data-anchor-id="api">API</h2>
<section id="gradio-streamlit" class="level3">
<h3 class="anchored" data-anchor-id="gradio-streamlit">gradio, streamlit</h3>
<p>2 options within HF to build app:</p>
<ul>
<li><a href="https://gradio.app/docs/">gradio</a>. Lot of widgets, reasonably flexible to allow prototyping.</li>
<li><a href="https://streamlit.io/">streamlit</a>. More flexible. Not so easy to start with.</li>
</ul>
</section>
<section id="gradio-hf-api" class="level3">
<h3 class="anchored" data-anchor-id="gradio-hf-api">gradio, hf API</h3>
<p>and with gradio + HF you have automatically an API available <img src="2022-10-17-fastai-2022-courses_files/figure-html/8c26adf0-8899-447a-b13b-6399d5ec244d-1-1cd15510-9c6e-461f-be59-220e4554cd76.png" class="img-fluid" alt="image.png"></p>
<p>By <a href="https://hf.space/embed/jph00/testing/api">clicking it</a> you get the documentation of this API.</p>
<p>It can then be used by any JS interface you would like to develop.</p>
<p>And HF is nice enought to provide examples (live demo) in Python, curl (command line) and javascript</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/ae5534c2-d593-455e-8a8b-c7624e9b09d8-1-0e4921b6-7f1f-4ead-a7cf-e75df376aa4f.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
</section>
<section id="example-from-js" class="level3">
<h3 class="anchored" data-anchor-id="example-from-js">example from js</h3>
<p>Jeremy uses this to develop a small JS interface in <a href="https://fastai.github.io/tinypets/1single.html" class="uri">https://fastai.github.io/tinypets/1single.html</a></p>
<p>And the code is quite minimum: <a href="https://github.com/fastai/tinypets/blob/master/1single.html" class="uri">https://github.com/fastai/tinypets/blob/master/1single.html</a></p>
<div class="sourceCode" id="cb14"><pre class="sourceCode html code-with-copy"><code class="sourceCode html"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>title: 1. Single file</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>layout: page</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>---</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;input</span> <span class="er">id</span><span class="ot">=</span><span class="st">"photo"</span> <span class="er">type</span><span class="ot">=</span><span class="st">"file"</span><span class="kw">&gt;</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;div</span> <span class="er">id</span><span class="ot">=</span><span class="st">"results"</span><span class="kw">&gt;&lt;/div&gt;</span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;script&gt;</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>  <span class="kw">async</span> <span class="kw">function</span> <span class="fu">loaded</span>(reader) {</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> response <span class="op">=</span> <span class="cf">await</span> <span class="fu">fetch</span>(<span class="st">'https://hf.space/embed/jph00/pets/+/api/predict/'</span><span class="op">,</span> {</span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>      <span class="dt">method</span><span class="op">:</span> <span class="st">"POST"</span><span class="op">,</span> <span class="dt">body</span><span class="op">:</span> <span class="bu">JSON</span><span class="op">.</span><span class="fu">stringify</span>({ <span class="st">"data"</span><span class="op">:</span> [reader<span class="op">.</span><span class="at">result</span>] })<span class="op">,</span></span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>      <span class="dt">headers</span><span class="op">:</span> { <span class="st">"Content-Type"</span><span class="op">:</span> <span class="st">"application/json"</span> }</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>    })<span class="op">;</span></span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> json <span class="op">=</span> <span class="cf">await</span> response<span class="op">.</span><span class="fu">json</span>()<span class="op">;</span></span>
<span id="cb14-15"><a href="#cb14-15" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> label <span class="op">=</span> json[<span class="st">'data'</span>][<span class="dv">0</span>][<span class="st">'confidences'</span>][<span class="dv">0</span>][<span class="st">'label'</span>]<span class="op">;</span></span>
<span id="cb14-16"><a href="#cb14-16" aria-hidden="true" tabindex="-1"></a>    results<span class="op">.</span><span class="at">innerHTML</span> <span class="op">=</span> <span class="vs">`&lt;br/&gt;&lt;img src="</span><span class="sc">${</span>reader<span class="op">.</span><span class="at">result</span><span class="sc">}</span><span class="vs">" width="300"&gt; &lt;p&gt;</span><span class="sc">${</span>label<span class="sc">}</span><span class="vs">&lt;/p&gt;`</span></span>
<span id="cb14-17"><a href="#cb14-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb14-18"><a href="#cb14-18" aria-hidden="true" tabindex="-1"></a>  <span class="kw">function</span> <span class="fu">read</span>() {</span>
<span id="cb14-19"><a href="#cb14-19" aria-hidden="true" tabindex="-1"></a>    <span class="kw">const</span> reader <span class="op">=</span> <span class="kw">new</span> <span class="bu">FileReader</span>()<span class="op">;</span></span>
<span id="cb14-20"><a href="#cb14-20" aria-hidden="true" tabindex="-1"></a>    reader<span class="op">.</span><span class="fu">addEventListener</span>(<span class="st">'load'</span><span class="op">,</span> () <span class="kw">=&gt;</span> <span class="fu">loaded</span>(reader))</span>
<span id="cb14-21"><a href="#cb14-21" aria-hidden="true" tabindex="-1"></a>    reader<span class="op">.</span><span class="fu">readAsDataURL</span>(photo<span class="op">.</span><span class="at">files</span>[<span class="dv">0</span>])<span class="op">;</span></span>
<span id="cb14-22"><a href="#cb14-22" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb14-23"><a href="#cb14-23" aria-hidden="true" tabindex="-1"></a>  photo<span class="op">.</span><span class="fu">addEventListener</span>(<span class="st">'input'</span><span class="op">,</span> read)<span class="op">;</span></span>
<span id="cb14-24"><a href="#cb14-24" aria-hidden="true" tabindex="-1"></a><span class="kw">&lt;/script&gt;</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
</section>
<section id="gh-pages" class="level2">
<h2 class="anchored" data-anchor-id="gh-pages">GH pages</h2>
<p>It can run locally of course, and can be hosted with gh pages.</p>
<section id="by-generating-from-fastpages" class="level3">
<h3 class="anchored" data-anchor-id="by-generating-from-fastpages">by generating from fastpages</h3>
<p>Jeremy suggests to use <a href="https://github.com/fastai/fastpages">fastpages</a>. In the doc at the bottom there is a link to generate a website from fastapages</p>
<p><a href="https://github.com/fastai/fastpages">fastai/fastpages: An easy to use blogging platform, with enhanced support for Jupyter Notebooks.</a></p>
<blockquote class="blockquote">
<p>Setup Instructions</p>
<ol type="1">
<li>Generate a copy of this repo by clicking <a href="https://github.com/fastai/fastpages/generate">on this link</a>. Make sure to sign in to your account, or you will see a 404 error. Name your repo anything you like <strong>except</strong> {your-username}.github.io.</li>
</ol>
</blockquote>
<p>Apply a theme (to be setup in <code>_config.yml</code>)</p>
<p>Create an <code>index.md</code> file which is the landing page.</p>
</section>
<section id="or-by-forking-an-existing-one-e.g.-tinypets" class="level3">
<h3 class="anchored" data-anchor-id="or-by-forking-an-existing-one-e.g.-tinypets">or by forking an existing one (e.g.&nbsp;<a href="https://github.com/fastai/tinypets">tinypets</a>)</h3>
<p>and in that case we have to turn on gh pages</p>
<p>Settings &gt; Pages &gt; Enable gh pages (select branch and save)</p>
<p>We can now switch to different theme.</p>
<p>From <code>remote_theme: daviddarnes/alembic@main</code> to <code>remote_theme: pages-themes/hacker</code></p>
<p>it provides a complete different look</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/35e779a3-c3ad-43e9-bb90-4371217829ad-1-60c95ea4-29b6-42e6-9827-1cdafd04e705.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<p>Looks like we can browse through these jekyll themes at <a href="http://jekyllthemes.org/" class="uri">http://jekyllthemes.org/</a></p>
</section>
</section>
</section>
<section id="lesson-3---neural-net-foundations" class="level1">
<h1>Lesson 3 - Neural net foundations</h1>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/1cb73eaa-2f68-4fba-b4c0-d24170f98917-1-d4e08165-739e-4034-843b-1efe335281ad.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<blockquote class="blockquote">
<p>Today we’ll be learning about the mathematical foundations of deep learning: Stochastic gradient descent (SGD), and the flexibility of linear functions layered with non-linear activation functions. We’ll be focussing particularly on a popular combination called the Rectified linear function (ReLU).</p>
</blockquote>
<p><a href="https://course.fast.ai/Lessons/lesson3.html" class="uri">https://course.fast.ai/Lessons/lesson3.html</a></p>
<p>Jeremy mentions <a href="https://www.youtube.com/watch?v=gGxe2mN3kAg">Lesson Zero</a> which is more about the way he teaches to learn these things. and recommened process to be run by students.</p>
<p>On this lesson, Jeremy uses <a href="https://www.paperspace.com/gradient">paperspace gradient</a>. Which offers full machine with jupyter environments.</p>
<section id="timm" class="level2">
<h2 class="anchored" data-anchor-id="timm">timm</h2>
<p>To use it we have to install it: <code>pip install timm</code></p>
<p>Jeremy illsutrates how to switch model architecture. And for that uses timm fastai. He has created a notebook on kaggle to rank vision models <a href="https://www.kaggle.com/code/jhoward/which-image-models-are-best/" class="uri">https://www.kaggle.com/code/jhoward/which-image-models-are-best/</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/bb0e4629-a800-4743-a8cc-92a8763ec532-1-56e655b6-1940-4766-bf49-ff76de4ad4b7.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<p>Convnext models seem to be a good fit.</p>
<div class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> timm</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>timm.list_models(<span class="st">'convnext*'</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<pre><code>['convnext_atto',
 'convnext_atto_ols',
 'convnext_base',
 'convnext_base_384_in22ft1k',
 'convnext_base_in22ft1k',
 'convnext_base_in22k',
 'convnext_femto',
 'convnext_femto_ols',
 'convnext_large',
 'convnext_large_384_in22ft1k',
 'convnext_large_in22ft1k',
 'convnext_large_in22k',
 'convnext_nano',
 'convnext_nano_ols',
 'convnext_pico',
 'convnext_pico_ols',
 'convnext_small',
 'convnext_small_384_in22ft1k',
 'convnext_small_in22ft1k',
 'convnext_small_in22k',
 'convnext_tiny',
 'convnext_tiny_384_in22ft1k',
 'convnext_tiny_hnf',
 'convnext_tiny_in22ft1k',
 'convnext_tiny_in22k',
 'convnext_xlarge_384_in22ft1k',
 'convnext_xlarge_in22ft1k',
 'convnext_xlarge_in22k']</code></pre>
</div>
</div>
<p>And to use one it is just a matter of calling</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a>learn <span class="op">=</span> vision_learner(dls, <span class="st">'convnext_tiny_in22k'</span>, metrics<span class="op">=</span>error_rate).to_fp16()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="using-in-an-app" class="level2">
<h2 class="anchored" data-anchor-id="using-in-an-app">Using in an app</h2>
<p>When dealing with categories, fastai keep category names in the dataloader under vocab</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>categories <span class="op">=</span> learn.dls.vocab</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> classify_image(img):</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>    pred, idx, probs <span class="op">=</span> learn.predict(img)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="bu">dict</span>(<span class="bu">zip</span>(categories, <span class="bu">map</span>(<span class="bu">float</span>, probs)))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="applying-this-on-my-own-app-cheeses" class="level2">
<h2 class="anchored" data-anchor-id="applying-this-on-my-own-app-cheeses">Applying this on my own app: <a href="https://huggingface.co/spaces/Guillaume63/cheeses">cheeses</a></h2>
<p>All notebooks from these courses are at <a href="https://github.com/fastai/course22" class="uri">https://github.com/fastai/course22</a></p>
<p>And my app is at <a href="https://huggingface.co/spaces/Guillaume63/cheeses" class="uri">https://huggingface.co/spaces/Guillaume63/cheeses</a></p>
<p>I had to configure this repo to use git-lfs to store large binary files:</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode bash code-with-copy"><code class="sourceCode bash"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> lfs install</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="co">#if needed reset the last commit</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> reset <span class="at">--soft</span> HEAD^</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> status</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co">#if offeneded files ar already staged, restore them</span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> restore <span class="at">--staged</span> <span class="pp">*</span>.jpg</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> status</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co">#add them back</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> add <span class="at">-A</span></span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a><span class="co">#check they are managed by git lfs</span></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> lfs ls-files</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> commit <span class="at">-am</span><span class="st">'recommit after lfs install'</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="fu">git</span> push</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>and I pushed it to <a href="https://forums.fast.ai/t/share-your-work-here/96015/515?u=guillaumeramelet">fastai forum</a></p>
</section>
<section id="inside-nn" class="level2">
<h2 class="anchored" data-anchor-id="inside-nn">Inside NN</h2>
<p><a href="https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work" class="uri">https://www.kaggle.com/code/jhoward/how-does-a-neural-net-really-work</a></p>
<p>Illustration of a powerfull python function <code>partial</code></p>
<div class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> functools <span class="im">import</span> partial</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> mk_quad(a, b, c): <span class="cf">return</span> partial(quad, a, b, c)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>f <span class="op">=</span> mk_quad(<span class="dv">3</span>,<span class="dv">2</span>,<span class="dv">1</span>)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>f(<span class="fl">1.5</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="17">
<pre><code>10.75</code></pre>
</div>
</div>
<p>I think I will reuse that!</p>
<p>Jeremy explains NN in 3 steps:</p>
<ul>
<li>loss caculation (with nice simulator to manually approach better paameters)</li>
<li>grad calculation, adjustment (with learning rate) and loop</li>
<li>we can use combination of relu to be as close as possible to any function (whatever the dimension)</li>
</ul>
</section>
<section id="using-microsoft-excel" class="level2">
<h2 class="anchored" data-anchor-id="using-microsoft-excel">Using Microsoft excel</h2>
<p>This is fun. Not as surpising as the one from 3-4 years ago but Jeremy is very good at explaining it. Excel spreadsheet is <a href="https://github.com/fastai/course22/blob/master/xl/titanic.xlsx">here</a>.</p>
</section>
<section id="next-lesson" class="level2">
<h2 class="anchored" data-anchor-id="next-lesson">Next lesson</h2>
<p>Will practice nlp using huggingface api.</p>
</section>
</section>
<section id="lesson-4---natural-language-nlp" class="level1">
<h1>Lesson 4 - Natural Language (NLP)</h1>
<p><a href="https://course.fast.ai/Lessons/lesson4.html" class="uri">https://course.fast.ai/Lessons/lesson4.html</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/fd076952-c3a5-4a41-be6e-81395db0ee12-1-67afa14d-fd26-45ed-8d09-82a97458787d.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<blockquote class="blockquote">
<p>It’s time for us to learn how to analyse natural language documents, using Natural Language Processing (NLP). We’ll be focusing on the <a href="https://huggingface.co/">Hugging Face</a> ecosystem, especially the <a href="https://huggingface.co/docs/transformers/index">Transformers</a> library, and the vast collection of pretrained <a href="https://huggingface.co/models">NLP models</a>. Our project today will be to classify that similarity of phrases used to describe <a href="https://www.kaggle.com/competitions/us-patent-phrase-to-phrase-matching">US patents</a>. A similar approach can be applied to a wide variety of practical issues, in fields as wide-reaching as marketing, logistics, and medicine.</p>
</blockquote>
<p>Jeremy is using this notebook <a href="https://www.kaggle.com/code/jhoward/getting-started-with-nlp-for-absolute-beginners">Getting started with NLP for absolute beginners</a> on kaggle. As usually upvote &amp; copy/<a href="https://www.kaggle.com/code/guillaumeramelet/getting-started-with-nlp-for-absolute-beginners/edit">edit</a> to start using it.</p>
<p>Didn’t know that pandas author Wes McKinney has released (free) a <a href="https://wesmckinney.com/book/">book Python for Data Analysis</a> explaining how to use it brillantly.</p>
<p>At the time of the training (May/2022), HuggingFace had 44k models. Today (November/2022) it has 86k models. Huge!</p>
<p>We use dataset library from HF.</p>
<p>Jeremy explains then validation set. And points to some article from Rachel Thomas explaining <a href="https://www.fast.ai/posts/2017-11-13-validation-sets.html">how to create a good one</a>.</p>
<p>And another one from Rachel Thomas explaining how tricky can be proxy metrics: <a href="https://www.fast.ai/posts/2019-09-24-metrics.html">The problem with metrics is a big problem for AI</a></p>
</section>
<section id="lesson-5---from-scratch-model" class="level1">
<h1>Lesson 5 - From-scratch model</h1>
<p><a href="https://course.fast.ai/Lessons/lesson5.html" class="uri">https://course.fast.ai/Lessons/lesson5.html</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/85af52d2-9674-45b5-b71c-2576078497f9-1-dbe1075e-9548-4e54-9924-ca99f1e6649f.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<blockquote class="blockquote">
<p>Today we look at how to create a neural network from scratch using Python and PyTorch, and how to implement a training loop for optimising the weights of a model. We build up from a single layer regression model up to a neural net with one hidden layer, and then to a deep learning model. Along the way we’ll also look at how we can use a special function called sigmoid to make binary classification models easier to train, and we’ll also learn about metrics.</p>
</blockquote>
<p>We start from a kaggle notebook from <a href="https://www.kaggle.com/jhoward/code">jeremy’s profile</a> which is <a href="https://www.kaggle.com/code/jhoward/linear-model-and-neural-net-from-scratch">Linear model and neural net from scratch</a>. As usually upvote &amp; copy/<a href="https://www.kaggle.com/code/guillaumeramelet/linear-model-and-neural-net-from-scratch/edit">edit</a> to start using it. Or get the notebooks from <a href="https://github.com/fastai/course22/blob/master/05-linear-model-and-neural-net-from-scratch.ipynb">github</a>.</p>
<p>Today I will use the local version.</p>
<section id="linear-model-then-deep-learning-model" class="level2">
<h2 class="anchored" data-anchor-id="linear-model-then-deep-learning-model">linear model then deep learning model</h2>
<p>Just restarting from titanic dataset and exactly as what was made in excel, now we do it with PyTorch.</p>
<p>It is good to see how much fiddling it requires. This is good to develop intuititions but defintely it is not what you want to implement when exploring a question.</p>
</section>
<section id="why-you-should-use-a-framework" class="level2">
<h2 class="anchored" data-anchor-id="why-you-should-use-a-framework">Why you should use a framework</h2>
<p>It is in kaggle <a href="https://www.kaggle.com/code/jhoward/why-you-should-use-a-framework">Why you should use a framework</a>. As usually upvote &amp; copy/edit to start using it. Or get the notebooks from <a href="https://github.com/fastai/course22/blob/master/06-why-you-should-use-a-framework.ipynb">github</a>.</p>
<p>Jeremy used TabularPandas, lr_find, ensemble</p>
<div class="cell" data-tags="[]" data-execution_count="14">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>learn.lr_find(suggest_funcs<span class="op">=</span>(slide, valley))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">

</div>
<div class="cell-output cell-output-display" data-execution_count="14">
<pre><code>SuggestedLRs(slide=0.0831763744354248, valley=0.007585775572806597)</code></pre>
</div>
<div class="cell-output cell-output-display">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/cell-6-output-3.png" class="img-fluid"></p>
</div>
</div>
<p>I could try this for autoencoders: <a href="https://alanbertl.com/autoencoder-with-fast-ai/" class="uri">https://alanbertl.com/autoencoder-with-fast-ai/</a> (this is v1 but should be easy to adapt to v2)</p>
<p>And then ends with <a href="https://www.kaggle.com/code/jhoward/how-random-forests-really-work">How random forests really work</a>. Or get the notebooks from <a href="https://github.com/fastai/course22/blob/master/07-how-random-forests-really-work.ipynb">github</a>.</p>
<p>Tip: <code>pd.options.display.float_format = '{:.2f}'.format</code> will display all floats from dataframes with 2 digits</p>
<p>Tip2: <code>from fastai.imports import *</code> will import everything that we need (numpy, pandas, matplotlib, …)</p>
<p>Jeremy illustrates binary split and mentions <a href="https://link.springer.com/article/10.1023/A:1022631118932">OneR</a> classifier (paper from 1993)</p>
</section>
</section>
<section id="lesson-6---random-forests" class="level1">
<h1>Lesson 6 - Random forests</h1>
<p><a href="https://course.fast.ai/Lessons/lesson6.html" class="uri">https://course.fast.ai/Lessons/lesson6.html</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/1be83661-8a7f-45af-acfe-3045c8c77946-1-2af8bec3-ac03-4b00-97a6-d70bec83e724.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<blockquote class="blockquote">
<p>Random forests started a revolution in machine learning 20 years ago. For the first time, there was a fast and reliable algorithm which made almost no assumptions about the form of the data, and required almost no preprocessing. In today’s lesson, you’ll learn how a random forest really works, and how to build one from scratch. And, just as importantly, you’ll learn how to interpret random forests to better understand your data.</p>
</blockquote>
<p>We continue on the previous notebook <a href="https://www.kaggle.com/code/jhoward/how-random-forests-really-work">How random forests really work</a>.</p>
<p>And repeating binary split on 2 dataset already split makes it a TwoR approach… And we can continue recursively. This is what a DecisionTree is.</p>
<div class="cell" data-tags="[]" data-execution_count="35">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>draw_tree(m, trn_xs, size<span class="op">=</span><span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="35">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/cell-7-output-1.svg" class="img-fluid"></p>
</div>
</div>
<p>Then Jeremy explains different ensemble approached: - by subsetting rows (and columns) and averaging predictions - this is bagging and random forest is one implementation - by focusing on residuals on each steps and summing predictions - this is boosting and gradient boosting decision trees is one implementation. Jeremys’explanation at <a href="https://explained.ai/gradient-boosting/">explained ai</a></p>
<p>And he mentions feature importance, dependency plot, waterfall plots, oob errors, and other stuff from book <a href="https://github.com/fastai/fastbook/blob/master/09_tabular.ipynb">chapter 9</a>.</p>
<p>And then Jeremy illustrates with a kaggle competition about rice quality. This is in <a href="https://github.com/fastai/course22/blob/master/08-first-steps-road-to-the-top-part-1.ipynb">08-first-steps-road-to-the-top-part-1.ipynb in github</a></p>
<p>As always I have to accept conditions before being able to download this dataset</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/56a8e326-0b24-4b49-bc0e-f4a44ab10a65-1-ddf78814-ef73-4ad3-8cc5-3e4896f575cb.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<p>There are 6 videos (walkthrough) from Jeremy, I think 6 hours long to enter into each detail of his process to be a kaggle grandmaster.</p>
<blockquote class="blockquote">
<ul>
<li><a href="https://www.youtube.com/watch?v=-Scs4gbwWXg">Walkthru 8</a></li>
<li><a href="https://www.youtube.com/watch?v=EK5wJRzffas">Walkthru 9</a></li>
<li><a href="https://youtu.be/zhBRynq9Yvo">Walkthru 10</a></li>
<li><a href="https://youtu.be/j-zMF2VirA8">Walkthru 11</a></li>
<li><a href="https://youtu.be/GuCkpjXHdTc">Walkthru 12</a></li>
<li><a href="https://youtu.be/INrkhUGCXHg">Walkthru 13</a></li>
</ul>
</blockquote>
<p>Not so bad top80% within a couple of minutes (of running). It would have taken me days to write such a notebook.</p>
<p>And step 2 happens in <a href="https://github.com/fastai/course22/blob/master/09-small-models-road-to-the-top-part-2.ipynb">09-small-models-road-to-the-top-part-2.ipynb in github</a></p>
<p>Where Jeremy changes from resnet26d to convnext_small using <a href="https://www.kaggle.com/code/jhoward/the-best-vision-models-for-fine-tuning">The best vision models for fine-tuning</a>.(in collaboration with Thomas Capelle ;) )</p>
<p>And introduces TTA (tranformation at inference time and take avergae of it)</p>
</section>
<section id="lesson-7---collaborative-filtering" class="level1">
<h1>Lesson 7 - Collaborative filtering</h1>
<p><a href="https://course.fast.ai/Lessons/lesson7.html" class="uri">https://course.fast.ai/Lessons/lesson7.html</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/29f01da0-60c7-40bc-b4a2-ff2655209a33-1-e97eb590-fbad-4ca4-b1f1-affa840869fc.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<blockquote class="blockquote">
<p>You interact nearly every day with <em>recommendation systems</em>—algorithms which guess what products and services you might like, based on your past behavior. These systems largely rely on <em>collaborative-filtering</em>, an approach based on linear algebra that fills in the missing values in a matrix. Today we’ll see two ways to do this: one based on a classic linear algebra formulation, and one based on deep learning.</p>
</blockquote>
<p>Next is in <a href="https://github.com/fastai/course22/blob/master/10-scaling-up-road-to-the-top-part-3.ipynb">10-scaling-up-road-to-the-top-part-3.ipynb in github</a></p>
<p>This is about dealing with GPU memory management and training with less memory (and adjusting batch size in a smart way (combined with gradient accumulation))</p>
<p>In fastai, it is done with <img src="2022-10-17-fastai-2022-courses_files/figure-html/a91a8f12-70e8-4ddb-b234-3211441b9c2c-1-f2e4471d-9ab4-4510-a13f-0461d8de2ee8.png" class="img-fluid" alt="image.png"></p>
<p>you adjust bs and use callback with GradientAccumulation</p>
<p>Last part is about collaborative filtering and it is quite identical to subsequent book chapter. Notebook is at kaggle <a href="https://www.kaggle.com/code/jhoward/collaborative-filtering-deep-dive/notebook" class="uri">https://www.kaggle.com/code/jhoward/collaborative-filtering-deep-dive/notebook</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/878f5f41-fb02-4d76-8e07-e3a3a0884608-1-9f314285-1119-4290-87ef-5c0d1ab5581d.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<p>Jeremy explains latent factor, the way to implement them in pytorch. Then bias factor added to these matrices to adjust bias. ProductBias to calculate similarity. And the full learning process. Then introduces weight decay as a way to regularize (avoid overfitting).</p>
<p>There is a chapter on interpreting Embeddings and Biases but Jeremy has not gone through it.</p>
</section>
<section id="lesson-8---convolutions-cnns" class="level1">
<h1>Lesson 8 - Convolutions (CNNs)</h1>
<p><a href="https://course.fast.ai/Lessons/lesson8.html" class="uri">https://course.fast.ai/Lessons/lesson8.html</a></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="2022-10-17-fastai-2022-courses_files/figure-html/cee3aee1-77c8-4a3a-93d5-ddcc0958d0b0-1-937c5629-1a79-4873-966f-05458b912588.png" class="img-fluid figure-img"></p>
<p></p><figcaption class="figure-caption">image.png</figcaption><p></p>
</figure>
</div>
<blockquote class="blockquote">
<p>Today we finish off our study of collaborative filtering by looking closely at <em>embeddings</em>—a critical building block of many deep learning algorithms. Then we’ll dive into <em>convolutional neural networks</em> (CNNs) and see how they really work. We’ve used plenty of CNNs through this course, but we haven’t peeked inside them to see what’s really going on in there. As well as learning about their most fundamental building block, the <em>convolution</em>, we’ll also look at pooling, dropout, and more.</p>
</blockquote>
<p>First part is continuing collaborative filtering. Notebook is at kaggle <a href="https://www.kaggle.com/code/jhoward/collaborative-filtering-deep-dive/notebook" class="uri">https://www.kaggle.com/code/jhoward/collaborative-filtering-deep-dive/notebook</a></p>
<p>It starts with embeddings and bias and interpretation. Jeremy shows how to visualize bias (which movies are most liked (even by people usually not liking this kind of movies) and disliked) or from a user perspective (which users tend to like all movies or dislike alkl movies)</p>
<p>And to visualize embeddings (thanks to a PCA) to understand which kind of movies we have. (and could be which kind of users we have)</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp(/^(?:http:|https:)\/\/castorfou\.github\.io\//);
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
    var links = window.document.querySelectorAll('a:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
</div> <!-- /content -->



</body></html>