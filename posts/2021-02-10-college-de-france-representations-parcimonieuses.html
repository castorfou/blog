<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.340">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2021-02-10">
<meta name="description" content="My notes/thoughts about the lecture in French">

<title>Guillaume’s blog - Learning: College de France - Representations parcimonieuses</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../site_libs/quarto-search/fuse.min.js"></script>
<script src="../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../">
<link href="../favicon_small.png" rel="icon" type="image/png">
<script src="../site_libs/quarto-html/quarto.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../site_libs/quarto-html/anchor.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>
<script async="" src="https://www.googletagmanager.com/gtag/js?id=G-12YC1FPHWN"></script>

<script type="text/javascript">

window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-12YC1FPHWN', { 'anonymize_ip': true});
</script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<link rel="stylesheet" href="../styles.css">
<meta name="twitter:title" content="Guillaume’s blog - Learning: College de France - Representations parcimonieuses">
<meta name="twitter:description" content="My notes/thoughts about the lecture in French">
<meta name="twitter:image" content="https://castorfou.github.io/posts/images/math.jpeg">
<meta name="twitter:card" content="summary_large_image">
</head>

<body class="nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="../index.html">
    <span class="navbar-title">Guillaume’s blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../about.html" rel="" target="">
 <span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/castorfou" rel="" target=""><i class="bi bi-github" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com/GuillaumeRamel1" rel="" target=""><i class="bi bi-twitter" role="img">
</i> 
 <span class="menu-text"></span></a>
  </li>  
</ul>
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
          </div> <!-- /navcollapse -->
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Learning: College de France - Representations parcimonieuses</h1>
                  <div>
        <div class="description">
          My notes/thoughts about the lecture in French
        </div>
      </div>
                          <div class="quarto-categories">
                <div class="quarto-category">deep learning</div>
                <div class="quarto-category">math</div>
              </div>
                  </div>
  </div>
    
  
  <div class="quarto-title-meta">

      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">February 10, 2021</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#le-triangle-régularité-approximation-parcimonie-lecture-1" id="toc-le-triangle-régularité-approximation-parcimonie-lecture-1" class="nav-link active" data-scroll-target="#le-triangle-régularité-approximation-parcimonie-lecture-1">2/15/21 - Le triangle « Régularité, Approximation, Parcimonie » (lecture 1)</a></li>
  <li><a href="#approximations-linéaires-et-analyse-de-fourier-lecture-2" id="toc-approximations-linéaires-et-analyse-de-fourier-lecture-2" class="nav-link" data-scroll-target="#approximations-linéaires-et-analyse-de-fourier-lecture-2">2/10/21 - Approximations linéaires et analyse de Fourier (lecture 2)</a></li>
  <li><a href="#grande-dimension-et-composantes-principales-lecture-3" id="toc-grande-dimension-et-composantes-principales-lecture-3" class="nav-link" data-scroll-target="#grande-dimension-et-composantes-principales-lecture-3">2/23/21 - Grande dimension et composantes principales (lecture 3)</a></li>
  <li><a href="#approximations-non-linéaires-et-réseaux-de-neurones-lecture-4" id="toc-approximations-non-linéaires-et-réseaux-de-neurones-lecture-4" class="nav-link" data-scroll-target="#approximations-non-linéaires-et-réseaux-de-neurones-lecture-4">3/2/21 - Approximations non linéaires et réseaux de neurones (lecture 4)</a></li>
  <li><a href="#ondelettes-et-échantillonnage-lecture-5" id="toc-ondelettes-et-échantillonnage-lecture-5" class="nav-link" data-scroll-target="#ondelettes-et-échantillonnage-lecture-5">3/9/21 - Ondelettes et échantillonnage (lecture 5)</a></li>
  <li><a href="#multi-résolutions-lecture-6" id="toc-multi-résolutions-lecture-6" class="nav-link" data-scroll-target="#multi-résolutions-lecture-6">3/16/21 - Multi-résolutions (lecture 6)</a></li>
  <li><a href="#bases-orthonormales-dondelettes-lecture-7" id="toc-bases-orthonormales-dondelettes-lecture-7" class="nav-link" data-scroll-target="#bases-orthonormales-dondelettes-lecture-7">3/23/21 - Bases orthonormales d’ondelettes (lecture 7)</a></li>
  <li><a href="#parcimonie-et-compression-dimages-lecture-8" id="toc-parcimonie-et-compression-dimages-lecture-8" class="nav-link" data-scroll-target="#parcimonie-et-compression-dimages-lecture-8">3/30/21 - Parcimonie et compression d’images (lecture 8)</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">




<p>Un exposé en 8 cours au collège de France de Stéphane Mallat sur les <a href="https://www.college-de-france.fr/site/stephane-mallat/course-2020-2021.htm">représentations parcimonieuses - 2021</a>.</p>
<p>Cela donne envie d’aller voir ses autres cours:</p>
<ul>
<li><a href="https://www.college-de-france.fr/site/stephane-mallat/course-2017-2018.htm">2018</a>: L’apprentissage face à la malédiction de la grande dimension</li>
<li><a href="https://www.college-de-france.fr/site/stephane-mallat/course-2018-2019.htm">2019</a>: L’apprentissage par réseaux de neurones profonds</li>
<li><a href="https://www.college-de-france.fr/site/stephane-mallat/course-2019-2020.htm">2020</a>: Modèles multi-échelles et réseaux de neurones convolutifs</li>
</ul>
<p>A peu près 16 vidéos de 1h30 par cours. Et des notes de cours en pdf.</p>
<section id="le-triangle-régularité-approximation-parcimonie-lecture-1" class="level2">
<h2 class="anchored" data-anchor-id="le-triangle-régularité-approximation-parcimonie-lecture-1">2/15/21 - Le triangle « Régularité, Approximation, Parcimonie » (lecture 1)</h2>
<p>C’est l’introduction du cours. J’apprécie les références historiques et philosphiques partant du rasoir d’Ockam. C’est le principe d’économie ou de parcimonie: le beau, le vrai viendrait du simple.</p>
<p>La 1ere fois que j’entends une référence précise sur l’opposition entre biais (erreur sur modèle) et variance (erreur sur données ou mesures)</p>
<p>Et une invitation à consulter une <a href="https://www.college-de-france.fr/site/stephane-mallat/seminar-2018-02-21-11h15.htm">méthodologie d’analyse de données</a> par Pierre Courtiol en utilisant Kaggle. L’idée d’une approche simple linéaire pour bien comprendre quelles étapes successives à emprunter pour améliorer son approche. Me semble assez orthogonal à ce que peut proposer Jeremy Howard: commencer tôt, overfitting n’est pas un probleme, pas de early stopping, etc.</p>
</section>
<section id="approximations-linéaires-et-analyse-de-fourier-lecture-2" class="level2">
<h2 class="anchored" data-anchor-id="approximations-linéaires-et-analyse-de-fourier-lecture-2">2/10/21 - Approximations linéaires et analyse de Fourier (lecture 2)</h2>
<p>J’ai commencé par ce cours conseillé par Rémi mon pote enseignant chercheur en math. C’est un peu le grand écart avec des méthodes d’enseignement anglo-saxonnes mais ça fait du bien. C’est finalement plus proche de ce que j’ai connu dans ma formation initiale.</p>
<p>S.Mallat présente les équivalences (sous certaines conditions) entre</p>
<ul>
<li>Régularité</li>
<li>Approximation en basse dimension</li>
<li>et représentation parcimonieuse</li>
</ul>
<p>dans le cadre des approximations linéaires. Il parle des 2 mondes: traitement du signal et analyse de la donnée. Je suis moins intéressé par le 1er monde, mais j’apprécie la piqure de rappel. Je ne me rappelais pas du tout l’importance de l’analyse de Fourier et la construction des bases de L[0,1] par exemple.</p>
<p>Et il revient sur les singularités, beaucoup d’informations sont portées par les singularités (par exemple les frontières dans une image)</p>
<p>Je crois bien que je vais me faire toute la session, et sans doute les autres années.</p>
</section>
<section id="grande-dimension-et-composantes-principales-lecture-3" class="level2">
<h2 class="anchored" data-anchor-id="grande-dimension-et-composantes-principales-lecture-3">2/23/21 - Grande dimension et composantes principales (lecture 3)</h2>
<p>Dans ce cadre linéaire grande dimension, quelle meilleure base - approche PCA et base Karhunen-Loeve.</p>
<p>Quid quand on passe en non linéaire.</p>
<p>Réseau neurone à 1 couche cachée, théoreme de representation universel.</p>
<p>Retour sur les bases de L²[0,1] qui sont les bases de Fourier en variables complexes.</p>
<p>Pour un passage en dimension q, on remplace n par (n1, …, nq) et la multiplication n*u par le produit scalaire &lt;n, u&gt;.</p>
<p>En travaillant sur les équivalences du triangle, il montre pourquoi on est très limité en approximation lineaire quand la dimension augmente.</p>
<p>En approximation lineaire, il suffit de prendre les 1ers vecteurs (se limiter à une dimension q) (en base de fourier par exemple) pour avoir une assez bonne approximation. Dans des signaux plus perturbés (avec des singularités) on perd plus d’énergie: il faudrait échantilloner plus fin dans ces zones de singularités et si on dispose d’une base orthonormée il s’agirait non plus de prendre les q 1ers vecteurs mais de prendre ceux d’intéret.</p>
</section>
<section id="approximations-non-linéaires-et-réseaux-de-neurones-lecture-4" class="level2">
<h2 class="anchored" data-anchor-id="approximations-non-linéaires-et-réseaux-de-neurones-lecture-4">3/2/21 - Approximations non linéaires et réseaux de neurones (lecture 4)</h2>
<p>Le triangle (approximation basse dimensions, représentation parcimonieuse, régularité) d’un point de vue non linéaire.</p>
<p>Ici plutôt qu’approximer un signal en prenant les M 1ers coefficients de Fourier (basses dimensions), on va prendre M coefficients mais dépendamment de x. C’est ici qu’on introduit la non-linéarité. L’erreur est alors la queue de distribution des coefficients ordonnés. On veut que l’énergie des plus petits coefficients soit négligeable.</p>
<p>Pas facile d’obtenir cet ordre, on cherche une façon de limiter les coefficients non ordonnés nous donnant une représentation parcimonieuse. En utilisant la nome l<sub><span class="math inline">\(\alpha\)</span></sub> avec <span class="math display">\[\alpha\]</span> petit (inférieur à 2 et proche de 0), on introduit cette décroissance mais cette fois-ci sur les coefficients non ordonnés.</p>
<p>Intéressant d’avoir des normes convexes, et dans ce cas on ne peut prendre que <span class="math display">\[\alpha\]</span>=1. C’est pour ça qu’on voit apparaître partout les normes l<sub>1</sub> dans les algorithmes d’apprentissage (norme convexe garantissant une forme de sparsité).</p>
<p>On passe aux réseaux de neurones à 1 couche cachée. Et on va basculer dans les notations de x(u) à f(x)., avec x <span class="math display">\[\epsilon\]</span> [0, 1]<sup>d</sup>.</p>
<p><img src="../images/rep_par_lecture4.png" class="img-fluid"></p>
<p>Ici on projette f dans l’espace engendré par ces vecteurs { <span class="math display">\[\rho\]</span>(x.w<sub>m</sub>+b<sub>m</sub>) }<sub>n&lt;=M</sub>.</p>
<p>On peut facilement calculer l’erreur quadratique comme l’intégrale sur les x <span class="math display">\[\epsilon\]</span> [0, 1]<sup>d</sup> de la norme l² ( f(x)-f<sub>tilde</sub>(x) ) et il y a un belle démonstration qui est le <strong>théorème d’approximation universelle</strong> (démontrée entre 1988 et 1992) qui montre que l’erreur tend vers 0 quand M tend vers l’infini.</p>
<p>La démonstration avec <span class="math display">\[\rho\]</span> = e<sup>ia</sup> revient à une décomposition d’en Fourier. Et pour d’autres non régularité comme reLu ou sigmoid, il s’agit d’un changement de base.</p>
<p>Et là on arrive à la malédiction de la dimensionnalité car quand d est grand (disons 1M), les coefficients baissent à une faible vitesse. Que faut-il faire pour battre cette malédiction?</p>
<p>Baron en 1993 introduit une hypothèse de regularité qui permet de borner l’erreur par un terme qui ne dépend pas de la dimension. C’est donc gagné sauf que l’hypothèse de régularité n’est généralement pas valide dans les cas qui nous intéressent.</p>
<p>Stéphane Mallat, de façon brillante mais est-ce étonnant, explique pourquoi l’approche des mathématiciens est une impasse et pourquoi ce qu’on cherche à faire se ramène à un problème bayésien. Car les problèmes qui nous intéressent (par exemple la classification d’objets, ne va solliciter qu’un minuscule espace (même si de grande dimension) parmi toutes les images possibles). On va donc chercher à caractériser x pour chaque y (classe). (revoir vidéo entre 49’ et 1h03)</p>
<p>L’enjeu est de caractériser le support qui est beaucoup plus concentré que [0,1]<sup>d</sup>.</p>
<p>Donc on va retravailler sur les approximations non linéaires de x, le signal lui-même (et non plus f), et d’essayer de comprendre pourquoi on peut faire beaucoup mieux que la transformée de Fourier et quelle genre de bases vont nous permettre de faire bcp mieux. Une des applications va être la compression, qui va nous amener à étudier la théorie de l’information et la théorie de l’information c’est exactement la théorie probabiliste qui explique ces phénomènes de concentration et les mesure avec l’entropie.</p>
<p>Introduction des bases d’ondelettes qui vont permettre de représenter les singularités locales. Les ondelettes sont à la fois localisées (paramètre v) et dilatées (paramètre s). Il faudra à partir de ces ondelettes construire des bases orthogonales pour arriver à des approximations basses dimensions (et garder les grands coefficients)</p>
<p>On introduit la notion de régularité locale exprimée avec lipchitz <span class="math display">\[\alpha\]</span>. Avec <span class="math display">\[\alpha\]</span> &lt;1 pour exprimer les singularités.</p>
</section>
<section id="ondelettes-et-échantillonnage-lecture-5" class="level2">
<h2 class="anchored" data-anchor-id="ondelettes-et-échantillonnage-lecture-5">3/9/21 - Ondelettes et échantillonnage (lecture 5)</h2>
<p>On était resté sur une représentation de signaux qui ne présentent pas de régularité uniforme mais qui présentent des singularités que nous voulons capter, ces singularités étant porteuses d’informations importantes (par exemple les contours dans une image). Ces singularités n’étant pas très nombreuses, on peut toujours parler de <strong>régularité locale</strong>.</p>
<p>On va donc utiliser des ondelettes pour décomposer ces signaux, d’où la notion de <strong>représentation parcimonieuse</strong>, exprimée sur la base d’ondelettes orthonormales. Et enfin en en sélectionnant un petit nombre nous revenons sur nos <strong>approximations en basse dimension</strong>.</p>
<p>Le produit scalaire du signal x(u) par l’ondelette <span class="math display">\[\psi\]</span><sub>v,s</sub> revient à un produit de convolution de x par l’ondelette conjuguée. Ca veut dire que sur les points de singularités les produits scalaires vont être maximisés.</p>
<p>Stéphane Mallat passe un long moment pour nous amener à la construction de ces bases d’ondelettes orthonormales. Il part des bases de Haar puis de Shannon et arrive à une construction plus récente par Yves Meyer en 1986.</p>
</section>
<section id="multi-résolutions-lecture-6" class="level2">
<h2 class="anchored" data-anchor-id="multi-résolutions-lecture-6">3/16/21 - Multi-résolutions (lecture 6)</h2>
<p>On a vu la dernière fois qu’on pouvait construire une base d’ondelette le long des indices de dilatations en 2<sup>j</sup>.</p>
<p>On va voir maintenant qu’on peut translater les ondelettes par des facteurs 2<sup>j</sup>.n.</p>
<p>Donc quand j est grand, les échelles sont de plus en plus grande. Et j petit va amener un échantillonnage de plus en plus fin.</p>
<p><span class="math display">\[
\left\{ \Psi_{(j,n)}(u)=\frac{1}{\sqrt{2^j}}\Psi \left( \frac{u-2^jn}{2^j} \right) \right\}_{(j, n) \epsilon \Z^2}
\]</span></p>
<p>sont-elles des bases orthonormales. Ensuite on appliquerait les techniques d’approximations consistant à éliminer les petits coefficients.</p>
<p>Les multi-résolutions sont des espaces linéaires sur lesquels nous allons projeter ces signaux. On va chercher à réduire les dimensions (par ex d’une image) en projetant sur ces espaces emboîtés. Et conserver le maximum d’information.</p>
<p>Un produit scalaire avec une fonction translatée peut toujours s’écrire comme un produit de convolution (Stéphane Mallat répète souvent cette propriété)</p>
<p>Stéphane Mallat fait ensuite le lien avec les algorithmes en bancs de filtre (cascades de filtrage + échantillonnage).</p>
<p>Dans ces opérations il y a sans arrêt des passages du continu au discret. Par exemple si je prends un signal et que je le projette sur ces espaces je me retrouve avec les coordonnées, qui sont les produits scalaires avec mes <span class="math display">\[\phi\]</span><sub>j,n</sub> (car base orthogonale), ce qui revient à filtrer et sous échantillonner.</p>
</section>
<section id="bases-orthonormales-dondelettes-lecture-7" class="level2">
<h2 class="anchored" data-anchor-id="bases-orthonormales-dondelettes-lecture-7">3/23/21 - Bases orthonormales d’ondelettes (lecture 7)</h2>
<p>On repart sur notre triangle. Depuis 2 cours on est sur l’approximation basse dimension.</p>
<p>Stéphane Mallat applique le théorème sur des cas particuliers de la base de Haar, puis de la base de Shannon. Et revient sur la construction d’une base orthonormales avec des ondelettes “optimales”.</p>
<p><img src="../images/cdf_coeff_ondelette.png" class="img-fluid"></p>
<p>Quand on prend le produit scalaire de notre signal f avec les ondelettes, on obtient des résultats presque nuls lorsque le signal est régulier. Et plus on a de moments nuls avec nos ondelettes, plus la régularité est ignorée (l’approximation par projection sur un espace vectorielle des monômes à l’ordre n).</p>
<p>On va cascader les projections a<sub>j</sub> (et les détails d<sub>j</sub>), et ça va revenir à cascader les filtres (les coefficients et les ondelettes).</p>
<p>Pour cela on calcule les valeurs des a<sub>j</sub> et d<sub>j</sub> en fonction de a<sub>j-1</sub>. On montre que cela s’obtient en filtrant (respectivement avec les <span class="math display">\[\overline{h}\]</span> et <span class="math display">\[\overline{g}\]</span>) puis en sous-échantillonnant. En cascadant on obtient une série de filtrages, sous-échantillonnages, filtrages, sous-échantillonnages, , etc.</p>
<p>Les filtrages sont des convolutions. Si h a un support compact, ça va réduire le temps de calcul.(le nombre d’éléments non nuls correspond à la taille du filtre). Le nombre d’opérations pour passer de a<sub>L</sub> à a<sub>L-1</sub>, d<sub>L-1</sub> est N*2m (où N: nombre de coefficients de a<sub>L</sub> et m est le nombre de moments nuls)</p>
<p>Le nombre d’opérations est linéaire, et la constante correspond à la taille des filtres.</p>
<p>On peut inverser cet algorithmes (car base o.n.) et la structure emboîtée va nous donner algorithme de reconstruction. On va sur-échantillonner (augmenter d’un facteur 2 en intercalant des 0) et appliquer les filtres g et h, et sommer pour obtenir le résultat.</p>
<p>Donc en gardant la base fréquence a<sub>J</sub> et tous les détails {d<sub>j</sub>}, on reconstitue a<sub>L</sub>. (les signaux sur des grilles de plus en plus fines)</p>
<p>Stéphane Mallat finit sur des exemples en 2 dimensions. En 2 dimensions on aura 3 ondelettes à chaque échelle (1 avec les hautes fréquences dans une direction, 1 avec les hautes fréquences dans l’autre direction, et la dernière avec haute fréquence sur les 2 directions (les coins)).</p>
</section>
<section id="parcimonie-et-compression-dimages-lecture-8" class="level2">
<h2 class="anchored" data-anchor-id="parcimonie-et-compression-dimages-lecture-8">3/30/21 - Parcimonie et compression d’images (lecture 8)</h2>
<p>Stéphane Mallat propose un survol de tout le cours pour montrer la logique dans laquelle on a évolué.</p>
<p>En reprenant le triangle Régularité - Approximation en basse dimension (au cœur du traitement de donnée) - Représentation parcimonieuse. Les équivalences entre régularité et la construction de représentations parcimonieuses permettent de construire des approximations en basse dimension.</p>
<p>Mais on peut les interpréter différemment :</p>
<ul>
<li>d’un point de vue linéaire : on peut construire des approximations linéaires qui vont correspondre à des formes de régularité et certains types de représentations parcimonieuses (en particulier dans la base de Fourrier quand on a des invariants par translation)</li>
<li>en prenant un point de vue non linéaire : qui consiste non pas à faire des projections dans des espaces linéaires mais plutôt des projections dans des unions d’espaces linéaires obtenus en sélectionnant de façon libre dans une base orthogonale les plans les plus représentatifs.</li>
</ul>
<p>Il reprend en détail ce qu’on a vu en repartant de la théorie développée par Fourier (1822 ça ne date pas d’hier). Et reprend les réseaux de neurones à 1 couche cachée.</p>
<p><span class="math display">\[
f_M(x)=\displaystyle\sum_{m}w(m)\rho(\langle{x,w_m}\rangle+b_m)
\]</span></p>
<p>L’entrée est x en dimension d, dans la première couche on calcule des produits scalaires avec les vecteurs <span class="math inline">\(v_m\)</span> qui sont les colonnes d’un opérateur linéaire <span class="math inline">\(W_1\)</span> et ces M produits scalaires vont être regroupés avec un relu (ou toute autre non-régularité) et un biais, et dans la dernière couche on fait une combinaison linéaire pour construire l’approximation. M est le nombre d’éléments dans la couche cachée, peut-on bien approximer f(x) à partir de cette construction ?</p>
<p>Ces réseaux, en prenant comme non-régularité un cosinus, nous font retomber sur des séries de Fourier.</p>
<p><span class="math display">\[
f_M(x)=\displaystyle\sum_{\| v_m \|&lt;R}w(m) \cos (\langle{x,w_m}\rangle+b_m)
\]</span></p>
<p>Faire une décomposition avec un réseau de neurone à 1 couche cachée est très similaire à décomposer la fonction dans une base de Fourier. Prendre un relu consisterait à faire un changement de base entre le relu et le cosinus.</p>
<p>Si on veut approximer une <strong>fonction uniformément régulière</strong>, il va falloir garder les basses fréquences. Mais <span class="math inline">\(x\)</span> n’est pas en dimension 1 mais en dimension <span class="math inline">\(d\)</span>. Les fréquences qu’il va falloir prendre ici sont dans <span class="math inline">\(\Z^d\)</span>, il va falloir garder toutes les fréquences dans une boule de rayon plus petit que <span class="math inline">\(R\)</span>. Mais quand on est en dimension <span class="math inline">\(q\)</span>, le nombre d’éléments dans une boule plus petit que <span class="math inline">\(R\)</span> va croître comme <span class="math inline">\(R^q\)</span>. Donc il va falloir garder énormément d’éléments.</p>
<p>On a la possibilité d’approximer n’importe quelle fonction dans <span class="math inline">\(L^2\)</span> avec une erreur qui va décroître vers 0 quand le nombre de termes <span class="math inline">\(M\)</span> tend vers <span class="math inline">\(\infty\)</span> parce qu’on a une base orthogonale et donc n’importe quelle fonction peut être représentée à partir de la base</p>
<p><span class="math display">\[
f \in L^2 \implies \lim\limits_{M \to \infty}\| f-f_M \|=0
\]</span></p>
<p>C’est le théorème d’<strong>approximation universelle</strong>.</p>
<p>Par contre si on a une régularité on peut préciser la vitesse de décroissance de l’erreur et en particulier si ma fonction est <span class="math inline">\(\alpha\)</span> dérivée dans un espace de Sobolev de degré <span class="math inline">\(\alpha\)</span>, l’erreur va décroître d’autant plus vite que la régularité est grande, parce que les coefficients de Fourier vont décroître, et la vitesse de décroissance dépend de <span class="math inline">\(\alpha/d\)</span>.</p>
<p><span class="math display">\[
f \in H^\alpha \implies \|f-f_M\| = o(M^{-\alpha/d})
\]</span></p>
<p>C’est la <strong>malédiction de la dimensionnalité</strong>.</p>
<p>Une autre approche consiste à reprendre ce cercle d’un <strong>point de vue non-linéaire</strong>. Au lieu de toujours prendre les mêmes coefficients pour approximer les fonctions qui m’intéressent, je vais adapter les coefficients à la fonction. C’est l’esprit des approximations non-linéaires.</p>
<p>Si je considère les vecteurs de Fourier, et ses coefficients ont une norme <span class="math inline">\(L^p\)</span> qui converge, pour un <span class="math inline">\(p&lt;2\)</span>. Alors on a vu que les coefficients vont décroître à une vitesse qui dépend de <span class="math inline">\(p\)</span>. Ca veut dire qu’il y a quelques grands coefficients et beaucoup de petits. Si on choisit les grands coefficients alors on va avoir une erreur qui décroît comme <span class="math inline">\(-2/(p+1)\)</span>, l’erreur décroît lorsque <span class="math inline">\(M\)</span> augmente, indépendamment de la dimension.</p>
<p><span class="math display">\[
Sparse \quad Fourier \quad coefficients: Barron \quad p&lt;2
\\
\displaystyle\sum_{v \in \Z^d} |\langle{f(x), F_v(x)}\rangle|^p &lt; \infty \implies \|f-f_M\|=o(M^{-2/p+1})
\]</span></p>
<p><strong>no curse</strong>. Mais résultat tautologique. Pourquoi cette fonction serait approximable avec quelques coefficients de Fourier. Ça n’explique en rien pourquoi on peut améliorer fortement ce résultat en augmentant le nombre de couche. C’est simple mais ça n’explique pas les performances des réseaux de neurones profonds.</p>
<p>D’où l’<strong>approche par ondelettes</strong>.</p>
<p>Et la nécessité de construire des bases orthogonales d’ondelettes à décroissance rapide. Travaux de Yves Meyer. (en essayant de démontrer que ça n’était pas possible il a réussi à en construire ;)) Et S.Mallat a amélioré cette approche en se basant sur des approches de multi résolutions avec des espaces imbriqués.</p>
<p>On peut construire ces ondelettes en cascadant des filtres à différentes échelles (passe bas et passe bande à différentes échelles).</p>
<p>I.Daubechies a montré qu’on peut construire des ondelettes à support compact.</p>
<p>Y.Meyer a montré ce que ça donnait en dimension 2 (et c’est généralisable en dimension q) avec 3 ondelettes.</p>
<p><img src="../images/cdf_ondelettes_dim2.png" class="img-fluid"></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  let localAlternateSentinel = 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var filterRegex = new RegExp("^(?:http:|https:)\/\/castorfou\.github\.io\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
          // target, if specified
          link.setAttribute("target", "_blank");
          // default icon
          link.classList.add("external");
      }
    }
});
</script>
</div> <!-- /content -->



</body></html>